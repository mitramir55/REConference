{"4": [[{"id": 18875, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Speed up ISeq marking by introducing a bitmap and rearranging inline caches", "description": "A large percentage of major GC time is spent marking instruction sequence objects.  This PR aims to speed up major GC by speeding up marking instruction sequence objects.\r\n\r\n## Marking ISeq objects\r\n\r\nToday we have to disassemble instruction sequences in order to mark them.  The disassembly process looks for GC allocated objects and marks them.  To disassemble an iseq, we have to iterate over each instruction, convert the instruction from an address back to the original op code integer, then look up the parameters for the op code.  Once we know the parameter types, we can iterate though them and mark \"interesting\" references.  We can see this process in [the `iseq_extract_values` function](https://github.com/ruby/ruby/blob/744d17ff6c33b09334508e8110007ea2a82252f5/iseq.c#L247-L313).\r\n\r\nAccording to profile results, the biggest bottleneck in this function is converting addresses back to instruction ids.\r\n\r\n## Speeding up ISeq marking\r\n\r\nTo speed up ISeq marking, this PR introduces two changes.  The first change is adding a bitmap, and the second change is rearranging inline caches to be more \"convenient\".\r\n\r\n## Bitmaps\r\n\r\nAt compilation time, we allocate a bitmap along side of the iseq object.  The bitmap indicates offsets of VALUE objects inside the instruction sequences.  When marking an instruction, we can simply iterate over the bitmap to find VALUE objects that need to be marked.\r\n\r\n## Inline Cache Rearrangement\r\n\r\nInline cache types `IC`, `IVC`, `ICVARC`, and `ISE` are allocated from [a buffer that is stored on the iseq constant body](https://github.com/ruby/ruby/blob/744d17ff6c33b09334508e8110007ea2a82252f5/vm_core.h#L447).  These caches are a union type.  Unfortunately, these union types don't have a \"type\" field, so they can only be distinguished by looking at the parameter types of an instruction.\r\n\r\nTake the following Ruby code for example:\r\n\r\n```\r\nFoo =~ /#{foo}/o;\r\n```\r\n\r\nThe instruction sequences for this code are as follows:\r\n\r\n```\r\n== disasm: #<ISeq:<main>@-e:1 (1,0)-(1,17)> (catch: FALSE)\r\n0000 opt_getinlinecache                     9, <is:0>                 (   1)[Li]\r\n0003 putobject                              true\r\n0005 getconstant                            :Foo\r\n0007 opt_setinlinecache                     <is:0>\r\n0009 once                                   block in <main>, <is:1>\r\n0012 opt_regexpmatch2                       <calldata!mid:=~, argc:1, ARGS_SIMPLE>[CcCr]\r\n0014 leave\r\n```\r\n\r\nThe ISeq object contains two entries in the `is_entries` buffer, one for the `ISE` cache associated with the `once` instruction, and one for the `IC` cache associated with the `opt_getinlinecache` and `opt_setinlinecache` instructions.\r\n\r\nUnfortunately we cannot iterate through the caches in the `is_entries` list because the union types don't have the same layout.  [Marking an `ISE`](https://github.com/ruby/ruby/blob/744d17ff6c33b09334508e8110007ea2a82252f5/iseq.c#L296-L306) is very different than [marking an `IC`](https://github.com/ruby/ruby/blob/744d17ff6c33b09334508e8110007ea2a82252f5/iseq.c#L270-L280), and we can only differentiate them by disassembling and checking the instruction sequences themselves.\r\n\r\nTo solve this problem, this PR introduces [3 counters for the different types of inline caches](https://github.com/ruby/ruby/compare/master...tenderlove:iseq-bitmap?expand=1#diff-2989766b46aac389cc58ca9c83fac2bb85c03f3a3d37b176b4be673c9d56e0e4R463-R465).  Then, we group inline cache types within the `is_entries` buffer.\r\nSince the inline cache types are grouped, we can use the counters to iterate over the buffer and we know what type is being used.\r\n\r\nCombining bitmap marking and inline cache arrangement means that we can mark instruction sequences without disassembling the instructions.\r\n\r\n## Speed impact\r\n\r\nI benchmarked this change with a basic Rails application using the following script:\r\n\r\n```ruby\r\nputs RUBY_DESCRIPTION\r\n\r\nrequire \"benchmark/ips\"\r\n\r\nBenchmark.ips do |x|\r\n  x.report(\"major GC\") { GC.start }\r\nend\r\n```\r\n\r\nHere are the results with the master version of Ruby:\r\n\r\n```\r\n$ RAILS_ENV=production gel exec bin/rails r test.rb\r\nruby 3.2.0dev (2022-06-22T12:30:39Z master 744d17ff6c) [arm64-darwin21]\r\nWarming up --------------------------------------\r\n            major GC     4.000  i/100ms\r\nCalculating -------------------------------------\r\n            major GC     47.748  (\u00b1 2.1%) i/s -    240.000  in   5.028520s\r\n```\r\n\r\nHere it is with these patches applied:\r\n\r\n```\r\n$ RAILS_ENV=production gel exec bin/rails r test.rb\r\nruby 3.2.0dev (2022-06-22T20:52:13Z iseq-bitmap 2ba736a7f9) [arm64-darwin21]\r\nWarming up --------------------------------------\r\n            major GC     7.000  i/100ms\r\nCalculating -------------------------------------\r\n            major GC     77.208  (\u00b1 1.3%) i/s -    392.000  in   5.079023s\r\n```\r\n\r\nWith these patches applied, major GC is about 60% faster.\r\n\r\n## Memory impact\r\n\r\nThe memory increase is proportional to the number of instructions stored on an iseq.  This works about to be about 1% increase in the size of an iseq (`ceil(iseq_length / 64)` on 64 bit platforms).\r\n\r\n## Future work\r\n\r\nThis PR always mallocs a bitmap table.  We can eliminate the malloc when:\r\n\r\n1. There is nothing to mark\r\n2. iseq_length is <= 64\r\n\r\n\r\nI posted a [pull request on GitHub](https://github.com/ruby/ruby/pull/6053), and I've attached a squashed version of the patches.  The diff includes some unused code which I used to verify the bitmaps.  If we decide to merge this I'll remove the unused code.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-22T22:55:35Z", "updated_on": "2022-06-23T21:02:32Z", "closed_on": "2022-06-23T21:02:32Z", "relations": []}, {"id": 18841, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1241, "name": "fxn (Xavier Noria)"}, "subject": "Proposal: autoload_relative", "description": "In my experience, autoloads often reflect an existing hierarchical structure.\r\n\r\nIf a project does not use Zeitwerk, and the user declares autoloads for a class or module, chances are they are for child constants. As an example, see the [`ActiveRecord` module](https://github.com/rails/rails/blob/main/activerecord/lib/active_record.rb). (Those ones do not have a second argument because we define wrapper that derives it by convention, [here](https://github.com/rails/rails/blob/main/activesupport/lib/active_support/dependencies/autoload.rb)).\r\n\r\nI think it would be convenient to have an `autoload_relative` in the line of `Kernel#require_relative`. It would make existing patterns more concise, and as a practical consequence, you skip `$LOAD_PATH` lookups too.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-19T08:02:55Z", "updated_on": "2022-06-19T23:22:50Z", "closed_on": null, "relations": [{"id": 3352, "issue_id": 15330, "issue_to_id": 18841, "relation_type": "relates", "delay": null}]}, {"id": 18839, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Drop support for gcc 3", "description": "Currently we require version 3 or newer when using gcc, but no CI for gcc 3.\r\nDo we still need to support gcc 3?\r\nhttps://github.com/ruby/ruby/pull/6037\r\n\r\nBesides, I suspect we can drop old versions of gcc and clang more.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-18T08:35:26Z", "updated_on": "2022-06-20T03:12:22Z", "closed_on": "2022-06-20T03:12:22Z", "relations": []}, {"id": 18838, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 13553, "name": "andrykonchin (Andrew Konchin)"}, "subject": "Avoid swallowing regexp escapes in the lexer", "description": "According to `Regexp#source` documentation:\r\n\r\n```\r\nReturns the original string of the pattern.\r\n/ab+c/ix.source #=> \"ab+c\"\r\n\r\nNote that escape sequences are retained as is.\r\n/\\x20\\+/.source  #=> \"\\\\x20\\\\+\"\r\n```\r\n\r\nIt works well but backslash (/) is processed in different way by different regexp literal forms.\r\n\r\nExamples:\r\n\r\n```ruby\r\n/\\//.source # => \"/\"\r\n%r/\\//.source # => \"/\"\r\n%r{\\/}.source # => \"\\\\/\"\r\n```\r\n\r\nExpected result - in all the cases result is the same.\r\n\r\nMoreover as documentation states - `escape sequences are retained as is`. So I would say that only `%r{}` works properly.\r\n\r\nThe issue was reported here https://github.com/oracle/truffleruby/issues/2569.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-17T16:52:51Z", "updated_on": "2022-06-21T09:45:57Z", "closed_on": "2022-06-20T22:57:24Z", "relations": []}, {"id": 18835, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Add InstructionSequence#type method", "description": "This method returns a symbol representing the type of the instruction\r\nsequence object.\r\n\r\nI'm trying to collect some statistics about instruction sequences for an entire system, but I mostly care about methods and blocks. This feature lets me select only methods and blocks to analyze.\r\n\r\nI am using a script like this:\r\n\r\n```ruby\r\ndef walk iseq\r\n  case iseq.type\r\n  when :METHOD, :BLOCK\r\n    count = 0\r\n    sends = 0\r\n    iseq.to_a.last.each do |insn|\r\n      count += 1 if insn.is_a?(Array)\r\n\r\n      case insn\r\n      in [:opt_send_without_block, _]\r\n        sends += 1\r\n      in [:send, _]\r\n        sends += 1\r\n      in [:invokeblock]\r\n        sends += 1\r\n      else\r\n      end\r\n    end\r\n    p [count, sends]\r\n  end\r\n  iseq.each_child { |n| walk(n) }\r\nend\r\n\r\niseq = RubyVM::InstructionSequence.compile_file(ARGV[0])\r\nwalk iseq\r\n```\r\n\r\n\r\nThen in my shell I can do this:\r\n\r\n```\r\n$ find ~/git/rails/activerecord/lib -name '*.rb' -exec ./miniruby test.rb {} \\;\r\n```\r\n\r\nI'm able to calculate instructions per method as well as number of \"sends\" per iseq. (Of course this isn't 100% accurate because of metaprogramming etc, but I think it lets us get good estimates)\r\n\r\nI made a pull request [here](https://github.com/ruby/ruby/pull/5809) and I've attached a patch as well.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-16T22:30:35Z", "updated_on": "2022-06-16T22:30:35Z", "closed_on": null, "relations": []}, {"id": 18832, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1241, "name": "fxn (Xavier Noria)"}, "subject": "Do not have class/module keywords consider ancestors of Object", "description": "The following code:\r\n\r\n```ruby\r\nmodule M\r\n  class C\r\n  end\r\nend\r\n\r\ninclude M\r\n\r\np Object.const_defined?(:C, false)\r\n\r\nclass C < String # (1)\r\nend\r\n```\r\n\r\nprints `false`, as expected, but then raises `superclass mismatch for class C (TypeError)` at (1).\r\n\r\nI believe this is a bug, because `Object` itself does not have a `C` constant, so (1) should just work, and the superclasse of `M::C` should be irrelevant.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-15T20:13:13Z", "updated_on": "2022-06-21T05:50:26Z", "closed_on": null, "relations": []}, {"id": 18831, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Block argument to `yield`", "description": "Block argument to `yield` is a syntax error.\r\nThis is because there was previously no way to receive a given block in the yielded block.\r\nHowever `do |&block|` has been introduced since 1.8.7.\r\nWhy is it prohibited still now? \r\n\r\nhttps://github.com/nobu/ruby/tree/blockarg-yield", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-15T12:59:56Z", "updated_on": "2022-06-18T03:12:20Z", "closed_on": null, "relations": [{"id": 3346, "issue_id": 10436, "issue_to_id": 18831, "relation_type": "relates", "delay": null}]}, {"id": 18825, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Specialized instruction for \"array literal + `.hash`\"", "description": "Feature #18611 is merged.  That feature encourages people to write hash methods like this:\r\n\r\n```\r\ndef hash\r\n  [@a, @b, @c].hash\r\nend\r\n```\r\n\r\nI would like to add a specialized instruction for this case `opt_newarray_hash`.  It's similar to `opt_newarray_max` and `opt_newarray_min` but for the hash method.\r\n\r\nISeqs before the optimization:\r\n\r\n```\r\n== disasm: #<ISeq:hash@test.rb:1 (1,0)-(3,3)> (catch: FALSE)\r\n0000 getinstancevariable          :@a, <is:0>                         (   2)[LiCa]\r\n0003 getinstancevariable          :@b, <is:1>\r\n0006 getinstancevariable          :@c, <is:2>\r\n0009 newarray                     3\r\n0011 opt_send_without_block       <callinfo!mid:hash, argc:0, ARGS_SIMPLE>, <callcache>\r\n0014 leave  \r\n```\r\n\r\nISeqs after the optimization:\r\n\r\n```\r\n== disasm: #<ISeq:hash@test.rb:1 (1,0)-(3,3)> (catch: FALSE)\r\n0000 getinstancevariable                    :@a, <is:0>               (   2)[LiCa]\r\n0003 getinstancevariable                    :@b, <is:1>\r\n0006 getinstancevariable                    :@c, <is:2>\r\n0009 opt_newarray_hash                      3\r\n0011 leave  \r\n```\r\n\r\nThe new instruction allows us to avoid allocating a new array and also avoid pushing a stack frame.\r\n\r\nThe implementation is [here](https://github.com/ruby/ruby/pull/5980), and I've also attached a patch.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-13T16:49:05Z", "updated_on": "2022-06-14T17:24:44Z", "closed_on": null, "relations": []}, {"id": 18824, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10073, "name": "k0kubun (Takashi Kokubun)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Drop MinGW support of MJIT", "description": "## Proposal\r\nStop supporting MJIT on MinGW from Ruby 3.2\r\n\r\n## Motivation\r\nCompilers on MinGW behave weirdly and MinGW-specific C code is sometimes required as a workaround. Despite the high maintenance cost, nobody seems to be using MJIT on MinGW.\r\n\r\n## Background\r\n* I installed Ruby 3.1 with RubyInstaller2, which I believe is the most popular method to install MinGW Ruby, and MJIT didn't work in that environment.\r\n* MinGW is known to be very slow at compiling C code. It's improbable that the architecture of MJIT performs well on that platform.\r\n* In other platforms, compiling an MJIT-generated .c file to a .so file works fine, but it fails on MinGW without any error message. So we have to compile .c to .o first and then build a .so file, just for MinGW. ", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-13T07:07:46Z", "updated_on": "2022-06-13T16:41:40Z", "closed_on": "2022-06-13T16:41:40Z", "relations": []}, {"id": 18822, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Ruby lack a proper method to percent-encode strings for URIs (RFC 3986)", "description": "### Context\r\n\r\nThere are two fairly similar encoding methods that are often confused. \r\n\r\n`application/x-www-form-urlencoded` which is how form data is encoded, and \"percent-encoding\" as defined by [RFC 3986](https://www.rfc-editor.org/rfc/rfc3986).\r\n\r\nAFAIK, the only way they differ is that \"form encoding\" escape space characters as `+`, and RFC 3986 escape them as `%20`. Most of the time it doesn't matter, but sometimes it does.\r\n\r\n### Ruby form and URL escape methods\r\n\r\n  - `URI.escape(\" \") # => \"%20\"` but it was deprecated and removed (in 3.0 ?).\r\n  - `ERB::Util.url_encode(\" \") # => \"%20\"` but it's implemented with a `gsub` and isn't very performant. It's also awkward to have to reach for `ERB`\r\n  - `CGI.escape(\" \") # => \"+\"`\r\n  - `URI.encode_www_form_component(\" \") # => \"+\"`\r\n\r\n### Unescape methods\r\n\r\nFor unescaping, it's even more of a clear cut since `URI.unescape` was removed. So there's no available method that won't treat an unescaped `+` as simply `+`.\r\n\r\ne.g. in Javascript: `decodeURIComponent(\"foo+bar\") #=> \"foo+bar\"`.\r\n\r\nIf one were to use `CGI.unescape`, the string might be improperly decoded: `GI.unescape(\"foo+bar\") #=> \"foo bar\"`. \r\n\r\n### Other languages\r\n\r\n  - Javascript `encodeURI` and `encodeURIComponent` use `%20`.\r\n  - PHP has `urlencode` using `+` and `rawurlencode` using `%20`.\r\n  - Python has `urllib.parse.quote` using `%20` and `urllib.parse.quote_plus` using `+`.\r\n\r\n### Proposal\r\n\r\nSince `CGI` already have a very performant encoder for `application/x-www-form-urlencoded`, I think it would make sense that it would provide another method for RFC3986.\r\n\r\nI propose:\r\n\r\n   - `CGI.url_encode(\" \") # => \"%20\"`\r\n   - Or `CGI.encode_url`.\r\n   - Alias `CGI.escape` as `GCI.encode_www_form_component`\r\n   - Clarify the documentation of `CGI.escape`.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-09T09:12:59Z", "updated_on": "2022-06-09T14:42:24Z", "closed_on": null, "relations": []}, {"id": 18821, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7576, "name": "baweaver (Brandon Weaver)"}, "subject": "Expose Pattern Matching interfaces in core classes", "description": "## Problem Statement\r\n\r\nPattern matching is an exceptionally powerful feature in modern versions of Ruby, but it has one critical weakness that we should discuss:\r\n\r\nIt is only as powerful as the number of classes which implement its interfaces.\r\n\r\nThe more common these interfaces become, the more powerful pattern matching will become for everyday use in any scenario.\r\n\r\n## Areas of Attention\r\n\r\nThat said, what are some classes in core Ruby where it may make sense to implement pattern matching interfaces, and what do we gain from them? I will provide an abbreviated list, but can look to qualify a larger list of potentials if this is of interest.\r\n\r\n### Set\r\n\r\nCurrently `Set` does not implement `deconstruct`. Especially `Enumerable`-like and `Array` like entities make sense here:\r\n\r\n```ruby\r\n# Hypothetical implementation\r\nclass Set\r\n  alias_method :deconstruct, :to_a\r\nend\r\n\r\nSet[1, 2, 3] in [1, 2, *]\r\n# => true\r\n```\r\n\r\n### Matrix\r\n\r\nSpeaking of Array-like structures, Matrix may make sense as well:\r\n\r\n```ruby\r\nclass Matrix\r\n  alias_method :deconstruct, :to_a\r\nend\r\n# => :deconstruct\r\n\r\nMatrix[[25, 93], [-1, 66]] in [[20..30, _], [..0, _]]\r\n# => true\r\n```\r\n\r\n### CSV\r\n\r\nIn the case of headers especially this can become very powerful with `deconstruct_keys`:\r\n\r\n```ruby\r\nrequire \"csv\"\r\nrequire \"net/http\"\r\nrequire \"json\"\r\n\r\n# Hypothetical implementation\r\nclass CSV::Row\r\n  def deconstruct_keys(keys)\r\n    # Symbol/String is contentious, yes, I will address in a moment\r\n    self.to_h.transform_keys(&:to_sym)\r\n  end\r\nend\r\n\r\n# Creating some sample data for example:\r\njson_data = URI(\"https://jsonplaceholder.typicode.com/todos\")\r\n  .then { Net::HTTP.get(_1) }\r\n  .then { JSON.parse(_1, symbolize_names: true) }\r\n\r\nheaders = json_data.first.keys\r\nrows = json_data.map(&:values)\r\n\r\n# Yes yes, hacky\r\ncsv_data = CSV.generate do |csv|\r\n  csv << headers\r\n  rows.each { csv << _1 }\r\nend.then { CSV.parse(_1, headers: true) }\r\n\r\n# But can provide very interesting results:\r\ncsv_data.select { _1 in userId: \"1\", completed: \"true\" }.size\r\n# => 11\r\n```\r\n\r\nThough this one does raise the broader question of the conflation of Symbol and String keys for our convenience. Given that Ruby has a habit of coercing between the two in other cases I do not find this to be against the spirit of Ruby.\r\n\r\n### RegExp MatchData\r\n\r\nIn a similar line of thinking to the CSV I believe this would present interesting opportunities, though does raise the question of what to do with `nil` types (perhaps return `[]` and `{}` respectively? May be hacky though)\r\n\r\n```ruby\r\nclass MatchData\r\n  alias_method :deconstruct, :to_a\r\n\r\n  def deconstruct_keys(keys)\r\n    named_captures.transform_keys(&:to_sym).slice(*keys)\r\n  end\r\nend\r\n\r\nIP_REGEX = /\r\n  (?<first_octet>\\d{1,3})\\.\r\n  (?<second_octet>\\d{1,3})\\.\r\n  (?<third_octet>\\d{1,3})\\.\r\n  (?<fourth_octet>\\d{1,3})\r\n/x\r\n\r\n'192.168.1.1'.match(IP_REGEX) in {\r\n  first_octet: '198',\r\n  fourth_octet: '1'\r\n}\r\n# => true\r\n```\r\n\r\nAs with before though, we do risk setting a precedent on the conflation of Symbol and String keys when it is convenient to us, so may be worth proceeding with caution there.\r\n\r\n### OpenStruct\r\n\r\nMuch like `Struct` I believe there's a good case to make here:\r\n\r\n```ruby\r\nclass OpenStruct\r\n  def deconstruct_keys(keys) = keys ? to_h.slice(*keys) : to_h\r\nend\r\n\r\nme = OpenStruct.new(name: 'Brandon', age: 31)\r\nme in { name: /^B/ }\r\n# => true\r\n```\r\n\r\n## Other Thoughts\r\n\r\nI believe there is great potential in the core of Ruby to spread the pattern matching interface. The more common it becomes the more useful it will be to users.\r\n\r\nEspecially if this were to be adopted into places like Rack, Net::HTTP, JSON, and other areas where frequently more imperative deconstructions and querying are already commonly used.\r\n\r\nI bring this up, rather than opening PRs, as I would like to see whether or not the core Ruby team is interested in these types of PRs and work of finding where else these interfaces may make sense.\r\n\r\nIf you would like my more complete thoughts on this, and considerations for pattern matching interfaces in Ruby, I had written [Pattern Matching Interfaces in Ruby](https://docs.google.com/document/d/1spnuQTKy5i7Lx-sDCsORKN981Iam1IuNdOsYkhh9Yi0/edit#) some time ago to note concerns, potential guidelines, and other considerations.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-08T06:07:36Z", "updated_on": "2022-06-09T07:24:25Z", "closed_on": null, "relations": []}, {"id": 18819, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 31800, "name": "eightbitraptor (Matthew Valentine-House)"}, "subject": "Moving Strings between size pools", "description": "[Github PR](https://github.com/ruby/ruby/pull/5986)\r\n\r\n## Motivation\r\n\r\nUsing GC Compaction we can move objects around on a Ruby heap, this allows us to decrease memory fragmentation for more efficient memory usage and better copy on write performance. \r\n\r\nRuby currently has several heaps, each heap can hold different sizes of objects. Currently compaction can only move objects within the same heap.\r\n\r\nSome objects in Ruby can change size. For example, using `String#squeeze!` or `String#<<` will modify an existing String in place to either shrink it, or grow it respectively.\r\n\r\nThis can result in the String no longer being in the most appropriate sized heap, which can either mean wasted memory (when the string is shrunk), or negation of the benefits of Variable Width Allocation (when the String is grown).\r\n\r\nIn order to mitigate these problems we need a way of moving objects between heaps with different sized slots.\r\n\r\n### Example: Growing a String\r\n\r\nAllocating a String 16 bytes or less will result in the creation of an embedded RString object in the 40 byte size pool (assuming a 64 bit architecture). \r\n\r\nIf we now use `string << \"foobar\"` to mutate the string, increasing its size by another 6 bytes we can no longer embed the string in a 40 byte slot. \r\n\r\nIn this case the string gets its `NOEMBED` bit set, and new memory is allocated for the buffer in the system heap using `malloc`. This new memory is no longer adjacent to the RString object in the Ruby heap and so any locality benefits are gone.\r\n\r\nIn addition, if the original String exists in a slot with a size larger than `sizeof(RValue)` then the additional space at the end of the slot after the `ptr` to the heap buffer is unused.\r\n\r\n### Example: Shrinking a String\r\n\r\nAssuming a 64 but architecture, allocating a String longer than 16 bytes will result in the creation of an embedded string in one of the larger size pools (80, 160, 320 or 640 bytes).\r\n\r\nIf we were to shrink that string so that it is possible to fit into one of the smaller size pools (eg. using `string.squeeze!`), then at least half of the current slot size will be unused space at the end of the string.\r\n\r\n## PR Summary\r\n\r\nThis change builds on the work in [this feature to reverse the compaction cursor movement](https://bugs.ruby-lang.org/issues/18619) to allow movement of objects between size pools during GC Compaction.\r\n\r\nThe algorithm works as follows\r\n\r\n* During GC Compaction\r\n    * During object movement step\r\n        * If the object being moved is a string\r\n            * Calculate how much space the string would require as an embedded string\r\n            * If the embedded size fits within a size pool\r\n                * move the object to the scan cursor position within the desired pool\r\n            * If the embedded size is larger than any possible size pool\r\n                * The object must be `NOEMBED`\r\n                    * move the object to the scan cursor position within the smallest size pool\r\n    * During reference update step\r\n        * If the Object is a string and is not embedded\r\n            * Calculate its size as if it was embedded\r\n            * If the object can be embedded in its current slot\r\n                * Convert the `NOEMBED` string into an embedded string\r\n                * Copy the string buffer into the slot\r\n                * Free the original string buffer\r\n\r\n### Notes\r\n\r\n* Currently we only support movement of `T_STRING` objects. More objects will be added in further PRs as they're given VWA support.\r\n* We don't attempt to re-embed shared strings, shared roots, strings that wrap C string literals (Strings with `NOFREE` set), or \"fstrings\" (Strings with `STR_FAKESTR` set)\r\n\r\n## Testing movement\r\n\r\nThis PR adds some extra keys to the hash returned by `GC.compact`. These keys are `:moved_up` and `:moved_down`. Each contains a hash of object types and a count of those object types that have either been moved into a larger or a smaller size pool.\r\n\r\nChecking this can be done by creating some fragmentation in different heaps, and forcing strings to be resized, then running compaction.\r\n\r\n```\r\nmoveables = []\r\nlarge_slots = []\r\n\r\nn = 1500\r\n\r\n# Ensure fragmentation in the large heap\r\nbase_slot_size = GC.stat_heap[0].fetch(:slot_size)\r\nn.times {\r\n  String.new(+\"a\" * base_slot_size).downcase\r\n  large_slots << String.new(+\"a\" * base_slot_size).downcase\r\n}\r\n\r\nn.times {\r\n  # strings are created as shared strings when initialized from literals\r\n  # use downcase to force the creation of an embedded string (it calls\r\n  # rb_str_new internally)\r\n  moveables << String.new(\"a\").downcase\r\n}\r\nmoveables.map { |s| s << (\"bc\" * base_slot_size) }\r\n\r\np GC.compact.fetch(:moved_up)\r\n```\r\n\r\nThis script outputs the following on my development machine.\r\n\r\n```\r\n{:T_STRING=>319}\r\n```\r\n\r\n## Future Work\r\n\r\nThis PR implements a framework for moving objects between size pools. There are two main areas to focus on following this change\r\n\r\n* Implementing movement for existing mutatable VWA types. Currently this is just Array, as Class objects cannot be mutated and therefore cannot move between pools\r\n* Add support for VWA to more types, implementing object movement where appropriate", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-07T18:07:35Z", "updated_on": "2022-06-13T17:21:06Z", "closed_on": "2022-06-13T17:21:06Z", "relations": []}, {"id": 18817, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 38767, "name": "midnight (Sarun R)"}, "subject": "SecureRandom::choose is not being exposed", "description": "I read through [the doc of `SecureRandom`](https://ruby-doc.org/stdlib-3.1.2/libdoc/securerandom/rdoc/SecureRandom.html) and found that it has the `choose` method.  \r\nSo, I spin up `irb` for a quick test.\r\n~~~\r\n> ::SecureRandom.choose([*('0'..'9'), *('A'..'Z')], 25)\r\n(irb):47:in `<main>': private method `choose' called for SecureRandom:Module (NoMethodError)\r\n                                                                                                            \r\n::SecureRandom.choose([*('0'..'9'), *('A'..'Z')], 25)                                                       \r\n              ^^^^^^^\r\n~~~\r\nThe method is marked as private. So, I forcefully call the method with success.\r\n~~~\r\n> ::SecureRandom.send(:choose, [*('0'..'9'), *('A'..'Z')], 25)\r\n=> \"5FHY5PXLT184GIVISCVESTMGO\"\r\n~~~\r\nI did not test for uniformity of the randomness, though.\r\n\r\nI wonder why the method has been marked as private?  \r\nIs it not ready for production uses?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-05T10:17:30Z", "updated_on": "2022-06-06T03:22:31Z", "closed_on": "2022-06-06T03:22:31Z", "relations": [{"id": 3340, "issue_id": 18817, "issue_to_id": 18183, "relation_type": "duplicates", "delay": null}]}, {"id": 18815, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "instance_{eval,exec} vs Proc#>>", "description": "```ruby\r\nmeasure = proc { p \"self=#{self}\"; size }\r\nmultiply = proc { '*' * _1 }\r\n\r\n'test'.instance_eval(&measure)\r\n# \"self=test\"\r\n#  => 4\r\n\r\n'test'.instance_eval(&measure >> multiply)\r\n# \"self=main\"\r\n# NameError (undefined local variable or method `size' for main:Object)\r\n```\r\n\r\nSo, `Proc#>>` produces a proc which is not suitable for `instance_eval`/`instance_exec`. The same as the \"naive\" implementation:\r\n```ruby\r\n# Naive sequence\r\nsequence = proc { measure.call.then(&multiply) }\r\n```\r\n\r\n...but is it possible to make the combination to behave like the first proc is not wrapped into an additional layer of indirection?.. Intuitively, it shouldn't be completely impossible.\r\n```ruby\r\n# What I meant actually:\r\nintended = proc { size.then(&multilpy) }\r\n\"test\".instance_eval(&intended)\r\n# => \"****\"\r\n```\r\n\r\nThe example is invented, the question is \"whether this should work\", not \"how to solve this task with another approach\".", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-02T12:58:03Z", "updated_on": "2022-06-02T17:17:05Z", "closed_on": null, "relations": [{"id": 3336, "issue_id": 18815, "issue_to_id": 18067, "relation_type": "duplicates", "delay": null}]}, {"id": 18814, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52350, "name": "phigrofi (Philipp Gro\u00dfelfinger)"}, "subject": "Ractor: add method to query incoming message queue size ", "description": "## Abstract\r\n  A simple method to query the current size of a Ractor's incoming queue from outside. Can be used to decide on the sender's side if a message is sent or postponed. \r\n\r\n## Background\r\n  Ractors have an infinite incoming message queue. When messages are sent to a Ractor it is not possible to check the current count of elements in the queue. A workaround would be: The receiving Ractor could immediately accept each message and put them into a separate queue and keep track of their count. Then the sending Ractor could query the count from the receiving Ractor as a message. \r\nWhile this message exchange would be short and simple, it still requires the receiving Ractor to process the \"queue-count\" message and respond to it. \r\n\r\n## Proposal\r\n  The Ractor implementation already keeps track of the current incoming message fill level in the field `sync.incoming_queue.cnt`. A simple method in the ruby code of Ractor could expose this number so that it is simple to query the queue size from outside. This works without any interaction of the queried Ractor. \r\n\r\nThe code would work as follows:\r\n``` ruby\r\nractor = Ractor.new do\r\n  loop { sleep(1) }\r\nend\r\nractor.queue_size #=> 0\r\nractor << \"message\"\r\nractor.queue_size #=> 1\r\nractor << \"message\"\r\nractor.queue_size #=> 2\r\n```\r\n\r\n\r\n## Use cases\r\n  1. Avoid queue overflow by checking queue size from outside before sending further messages. \r\n  2. Incoming queue sizes can be monitored. \r\n\r\n## Discussion\r\n  The proposal makes it much easier to prevent overflow of a message queue than managing a separate queue inside of a Ractor and keeping track of its element count. I think also having a separate queue where the count needs to communicated, ignores the concept of a Ractor's incoming message queue and makes it quite complicated. \r\n\r\n## See also\r\n  In this [issue](https://bugs.ruby-lang.org/issues/17679) a middleman solution was proposed which keeps track of a separate queue count. ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-02T10:57:23Z", "updated_on": "2022-06-02T11:59:18Z", "closed_on": null, "relations": []}, {"id": 18812, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9236, "name": "eileencodes (Eileen Uchitelle)"}, "subject": "Add ability to trace exit locations for YJIT", "description": "Currently, when running yjit with `--yjit-stats` you are able to see method call exit reasons and the top 20 most frequent exits. This is useful to know where to spend time investigating whether an exit should be fixed, but in a larger codebase like Rails, it's next to impossible to know what the Ruby code that is exiting looks like.\r\n\r\nAaron Patterson and I aim to fix that with the addition of `--yjit-trace-exits` option and feature.\r\n\r\nWhen running with `--yjit-stats` turned on Ruby code can inform the user\r\nwhat the most common exits are. While this is useful information it\r\ndoesn't tell you the source location of the code that exited or what the\r\ncode that exited looks like. This change intends to fix that.\r\n\r\nTo use the feature, run yjit with `--yjit-stats` and `--yjit-trace-exits`,\r\nwhich will record the backtrace for every exit that occurs. Users must save\r\nthe output of `RubyVM::YJIT.exit_locations` to a dump file. That file\r\ncan then be read by StackProf to see the code that exited and the\r\nreason.\r\n\r\n*Example usage:*\r\n\r\nGiven the following script, we write to a file called\r\n`concat_array.dump` the results of `RubyVM::YJIT.exit_locations`.\r\n\r\n```ruby\r\ndef concat_array\r\n  [\"t\", \"r\", *x = \"u\", \"e\"].join\r\nend\r\n\r\n1000.times do\r\n  concat_array\r\nend\r\n\r\nFile.write(\"concat_array.dump\", Marshal.dump(RubyVM::YJIT.exit_locations))\r\n```\r\n\r\nWhen we run the file with this branch and the appropriate flags the\r\nstacktrace will be recorded. Note Stackprof needs to be installed or you\r\nneed to point to the library directly.\r\n\r\n```\r\n./ruby --yjit --yjit-call-threshold=1 --yjit-stats --yjit-trace-exits -I/Users/eileencodes/open_source/stackprof/lib test.rb\r\n```\r\n\r\nWe can then read the dump file with Stackprof:\r\n\r\n```\r\n./ruby -I/Users/eileencodes/open_source/stackprof/lib/ /Users/eileencodes/open_source/stackprof/bin/stackprof --text concat_array.dump\r\n```\r\n\r\nResults will look similar to the following:\r\n\r\n```\r\n==================================\r\n  Mode: ()\r\n  Samples: 1817 (0.00% miss rate)\r\n  GC: 0 (0.00%)\r\n==================================\r\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\r\n      1001  (55.1%)        1001  (55.1%)     concatarray\r\n       335  (18.4%)         335  (18.4%)     invokeblock\r\n       178   (9.8%)         178   (9.8%)     send\r\n       140   (7.7%)         140   (7.7%)     opt_getinlinecache\r\n       ...etc...\r\n```\r\n\r\nSimply inspecting the `concatarray` method will give `SOURCE\r\nUNAVAILABLE` because the source is insns.def.\r\n\r\n```\r\n./ruby -I/Users/eileencodes/open_source/stackprof/lib/ /Users/eileencodes/open_source/stackprof/bin/stackprof --text concat_array.dump --method concatarray\r\n```\r\n\r\nResult:\r\n\r\n```\r\nconcatarray (nonexistent.def:1)\r\n  samples:  1001 self (55.1%)  /   1001 total (55.1%)\r\n  callers:\r\n    1000  (   99.9%)  Object#concat_array\r\n       1  (    0.1%)  Gem.suffixes\r\n  callees (0 total):\r\n  code:\r\n        SOURCE UNAVAILABLE\r\n```\r\n\r\nHowever if we go deeper to the callee we can see the exact\r\nsource of the `concatarray` exit.\r\n\r\n```\r\n./ruby -I/Users/eileencodes/open_source/stackprof/lib/ /Users/eileencodes/open_source/stackprof/bin/stackprof --text concat_array.dump --method Object#concat_array\r\n```\r\n\r\n```\r\nObject#concat_array (/Users/eileencodes/open_source/rust_ruby/test.rb:1)\r\n  samples:     0 self (0.0%)  /   1000 total (55.0%)\r\n  callers:\r\n    1000  (  100.0%)  block in <main>\r\n  callees (1000 total):\r\n    1000  (  100.0%)  concatarray\r\n  code:\r\n                                  |     1  | def concat_array\r\n 1000   (55.0%)                   |     2  |   [\"t\", \"r\", *x = \"u\", \"e\"].join\r\n                                  |     3  | end\r\n```\r\n\r\nThe `--walk` option is recommended for this feature as it make it\r\neasier to traverse the tree of exits.\r\n\r\n*Goals of this feature:*\r\n\r\nThis feature is meant to give more information when working on YJIT.\r\nThe idea is that if we know what code is exiting we can decide what\r\nareas to prioritize when fixing exits. In some cases this means adding\r\nprioritizing avoiding certain exits in yjit. In more complex cases it\r\nmight mean changing the Ruby code to be more performant when run with\r\nyjit. Ultimately the more information we have about what code is exiting\r\nAND why, the better we can make yjit.\r\n\r\n*Known limitations:*\r\n\r\n* Due to tracing exits, running this on large codebases like Rails\r\ncan be quite slow.\r\n* On complex methods it can still be difficult to pinpoint the exact cause of\r\nan exit.\r\n* Stackprof is a requirement to to view the backtrace information from\r\nthe dump file\r\n\r\nPR https://github.com/ruby/ruby/pull/5970", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-06-01T14:42:45Z", "updated_on": "2022-06-01T14:42:45Z", "closed_on": null, "relations": []}, {"id": 18809, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 963, "name": "kyanagi (Kouhei Yanagita)"}, "subject": "Add Numeric#ceildiv", "description": "pull request: https://github.com/ruby/ruby/pull/5965\r\n\r\nI have needed to implement \"rounding up division\" several times.\r\n\r\n(\"rounding up division\" means getting a quotient of division which is rounded up to the nearest integer.)\r\n\r\nTypically, this is implemented as follows:\r\n\r\n``` ruby\r\n# notice that b > 0 is assumed\r\ndef rounding_up_division(a, b)\r\n  (a + b - 1) / b\r\nend\r\n```\r\n\r\nBut for me, this is difficult to write without careful consideration.\r\nEvery time I implement this, I need to think for a few minutes on paper.\r\n\r\nSo I propose to add a new method `Numeric#ceildiv`.\r\n\r\nTypical examples where this is necessary are counting groups and pagination.\r\n\r\ne.g. There are 123 items. If you display 10 items on each page, how many pages are there?\r\n\r\n``` ruby\r\n123.ceildiv(10) # => 13\r\n```\r\n\r\nWe can find several examples of this division also in the Ruby's source code. (Try `grep -r -E -e '([^ ]+) *- *1\\) */ *\\1' .`)\r\n\r\n\r\n```\r\n./internal.h:#define roomof(x, y) (((x) + (y) - 1) / (y))\r\n./array.c:    len = (len + ustep - 1) / ustep;\r\n./include/ruby/internal/memory.h:    const size_t cnt = (total_size + sizeof(VALUE) - 1) / sizeof(VALUE);\r\n./ext/bigdecimal/missing/dtoa.c:#define PRIVATE_mem ((PRIVATE_MEM+sizeof(double)-1)/sizeof(double))\r\n./ext/bigdecimal/bigdecimal.c:  nc += (nc + mc - 1) / mc + 1;\r\n./ext/bigdecimal/bigdecimal.c:    mx = (mx + BASE_FIG - 1) / BASE_FIG;    /* Determine allocation unit. */\r\n./ext/bigdecimal/bigdecimal.c:                mf = (mf + BASE_FIG - 1) / BASE_FIG + 2; /* Needs 1 more for div */\r\n./ext/bigdecimal/bigdecimal.c:    nalloc = (ni + nf + BASE_FIG - 1) / BASE_FIG + 1;    /* set effective allocation  */\r\n./ext/bigdecimal/bigdecimal.c:    size_t const round_limit = (VpGetPrecLimit() + BASE_FIG - 1) / BASE_FIG;\r\n./ext/bigdecimal/bigdecimal.c:    if ((ix + BASE_FIG - 1) / BASE_FIG > ixDigit + 1) return 0;\r\n./ext/bigdecimal/bits.h:#define roomof(x, y) (((x) + (y) - 1) / (y))\r\n./internal/numeric.h:    VALUE values[(SIZEOF_DOUBLE + SIZEOF_VALUE - 1) / SIZEOF_VALUE];\r\n./regcomp.c:  OnigDistance str_len = (byte_len + mb_len - 1) / mb_len;\r\n./bignum.c:    size_t num_bdigits = (num_bits + BITSPERDIG - 1) / BITSPERDIG;\r\n./missing/dtoa.c:#define PRIVATE_mem ((PRIVATE_MEM+sizeof(double)-1)/sizeof(double))\r\n./numeric.c:    char buf[float_dig + (decimal_mant + CHAR_BIT - 1) / CHAR_BIT + 10];\r\n./gc.c:#define CEILDIV(i, mod) (((i) + (mod) - 1)/(mod))\r\n```\r\n\r\nNaming:\r\n\r\nI was not sure whether to name it `ceildiv` or `divceil` because there are both `divmod` and `fdiv`.\r\nSince `divmod` is a method that returns two elements, the quotient and the remainder,\r\nwhile `fdiv` is a method that performs Float division, I decided to follow `fdiv`.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-27T22:23:57Z", "updated_on": "2022-06-21T18:21:04Z", "closed_on": null, "relations": []}, {"id": 18798, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "`UnboundMethod#==` with inherited classes", "description": "Now `UnboundMethod` for a same method from a superclass and an inherited class are not `==`.\r\n\r\n```ruby\r\nclass C\r\n  def foo = :C\r\n  $mc = instance_method(:foo)\r\nend\r\n\r\nclass D < C\r\n  $md = instance_method(:foo)\r\nend\r\n\r\np $mc == $md #=> false\r\np $mc.owner #=> C\r\np $mc.owner == $md.owner #=> true\r\np $mc.source_location == $md.source_location #=> true\r\np $mc.inspect #=> \"#<UnboundMethod: C#foo() t.rb:3>\"\r\np $md.inspect #=> \"#<UnboundMethod: D(C)#foo() t.rb:3>\"\r\n```\r\n\r\nHow about to make it `UnboundMethod#==` return true for this case?\r\nRule: \"return true if the UnboundMethod objects point to a same method definition\" seems simple.\r\n\r\nFYI: On aliased unbound methods point to a same method are `==`.\r\n\r\n\r\n```ruby\r\nclass C\r\n  def foo = :C\r\n  alias bar foo\r\n  $mfoo = instance_method(:foo)\r\n  $mbar = instance_method(:bar)\r\nend\r\n\r\np $mfoo, $mbar\r\n#=> #<UnboundMethod: C#foo() t.rb:2>\r\n#=> #<UnboundMethod: C#bar(foo)() t.rb:2>\r\n\r\np $mfoo == $mbar #=> true\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-24T01:55:49Z", "updated_on": "2022-05-25T00:32:15Z", "closed_on": null, "relations": []}, {"id": 18788, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12619, "name": "janosch-x (Janosch M\u00fcller)"}, "subject": "Support passing Regexp options as String to Regexp.new", "description": "## Current situation\r\n\r\n`Regexp.new` takes an integer as second argument which needs to be ORed together from multiple constants:\r\n\r\n```ruby\r\nRegexp.new('foo', Regexp::IGNORECASE | Regexp::MULTILINE | Regexp::EXTENDED) # => /foo/imx\r\n```\r\n\r\nAny other non-nil value is treated as `i` flag:\r\n\r\n```ruby\r\nRegexp.new('foo', Object.new) # => /foo/i\r\n```\r\n\r\n## Suggestion\r\n\r\n`Regexp.new` should support passing the regexp flags not only as an Integer, but also as a String, like so:\r\n\r\n```ruby\r\nRegexp.new('foo', 'i')   # => /foo/i\r\nRegexp.new('foo', 'imx') # => /foo/imx\r\n\r\n# edge cases\r\nRegexp.new('foo', 'iii') # => /foo/i\r\nRegexp.new('foo', '')    # => /foo/\r\n\r\n# unsupported flags should probably emit a warning\r\nRegexp.new('foo', 'jmq') # => /foo/m\r\nRegexp.new('foo', '-m')  # => /foo/m\r\n```\r\n\r\n## Reasons\r\n\r\n1. The constants are a bit cumbersome to use, particularly when building the regexp from variable data:\r\n\r\n```ruby\r\ndef make_regexp(regexp_body, opt_string)\r\n  opt_int = 0\r\n  opt_int |= Regexp::IGNORECASE if opt_string.include?('i')\r\n  opt_int |= Regexp::MULTILINE  if opt_string.include?('m')\r\n  opt_int |= Regexp::EXTENDED   if opt_string.include?('x')\r\n\r\n  Regexp.new(regexp_body, opt_int)\r\nend\r\n```\r\n\r\n2. Passing a String is already silently accepted, and people might get the wrong impression that it works:\r\n\r\n```ruby\r\nRegexp.new('foo', 'i') # => /foo/i\r\n```\r\n\r\n... but it doesn't really work:\r\n\r\n```ruby\r\nRegexp.new('foo', 'x') # => /foo/i\r\n```\r\n\r\n## Backwards compatibility\r\n\r\nThis change would not be fully backwards compatible.\r\n\r\nCode that relies on the second argument being a String which does not contain \"i\" in order to make the Regexp case insensitive would break.\r\n\r\n*Note: originally I suggested supporting Symbols in the same way as Strings, but removed that in light of the discussion.*\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-17T12:11:56Z", "updated_on": "2022-06-20T10:35:30Z", "closed_on": "2022-06-20T10:35:30Z", "relations": []}, {"id": 18776, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 45106, "name": "jemmai (Jemma Issroff)"}, "subject": "Object Shapes", "description": "# Object Shapes implementation\r\n\r\nAaron Patterson, Eileen Uchitelle and I have been working on an implementation of Object Shapes for Ruby.  We are filing a ticket to share what we've been doing, as well as get feedback on the project in its current state.\r\n\r\nWe hope to eventually submit the finalized project upstream after verifying efficacy.\r\n\r\n## What are Object Shapes?\r\n\r\nObject shapes are a technique for representing properties of an object. Other language implementations, including [TruffleRuby](https://github.com/oracle/truffleruby) and [V8](https://v8.dev/), use this technique. Chris Seaton, the creator of TruffleRuby, discussed object shapes in his [RubyKaigi 2021 Keynote](https://rubykaigi.org/2021-takeout/presentations/chrisgseaton.html) and Maxime Chevalier-Boisvert discussed the implications for YJIT in the latter part of [her talk at RubyKaigi 2021](https://www.youtube.com/watch?v=PBVLf3yfMs8&t=1100s). The original idea of object shapes [originates from the Self language](https://bibliography.selflanguage.org/_static/implementation.pdf), which is considered a direct descendant of Smalltalk.\r\n\r\nEach shape represents a specific set of attributes (instance variables and other properties) and their values. In our implementation, all objects have a shape. The shapes are nodes in a tree data structure. Every edge in the tree represents an attribute transition.\r\n\r\nMore specifically, setting an instance variable on an instance of an object creates an outgoing edge from the instance's current shape. This is a transition from one shape to another. The edge represents the instance variable that is set.\r\n\r\nFor example:\r\n\r\n```ruby\r\nclass Foo\r\n  def initialize\r\n    # Currently this instance is the root shape (ID 0)\r\n    @a = 1 # Transitions to a new shape via edge @a (ID 1)\r\n    @b = 2 # Transitions to a new shape via edge @b (ID 2)\r\n  end\r\nend\r\n\r\nfoo = Foo.new\r\n```\r\n\r\nWhen `Foo` is intialized, its shape is the root shape with ID 0.  The root shape represents an empty object with no instance variables. Each time an instance variable is set on `foo`, the shape of the instance changes. It first transitions with `@a` to a shape with ID 1, and then transitions with `@b` to a shape with ID 2. If `@a` is then set to a different value, its shape will remain the shape with ID 2, since this shape already includes the instance variable `@a`.  \r\n\r\n![](https://user-images.githubusercontent.com/1988560/167918360-0a6c91aa-2587-48cb-8ff2-7f3a9583288e.svg)\r\n\r\nThere is one global shape tree and objects which undergo the same shape transitions in the same order will end up with the same final shape.\r\n\r\nFor instance, if we have a class `Bar` defined as follows, the first transition on `Bar.new` through the instance variable `@a` will be the same as `Foo.new`'s first transition:\r\n\r\n```ruby\r\nclass Foo\r\n  def initialize\r\n    # Currently this instance is the root shape (ID 0)\r\n    @a = 1 # Transitions to a new shape via edge @a (ID 1)\r\n    @b = 2 # Transitions to a new shape via edge @b (ID 2)\r\n  end\r\nend\r\n\r\nclass Bar\r\n  def initialize\r\n    # Currently this instance is the root shape (ID 0)\r\n    @a = 1 # Transitions to shape defined earlier via edge @a (ID 1)\r\n    @c = 1 # Transitions to a new shape via edge @c (ID 3)\r\n    @b = 1 # Transitions to a new shape via edge @b (ID 4)\r\n  end\r\nend\r\n\r\nfoo = Foo.new # blue in the diagram\r\nbar = Bar.new # red in the diagram\r\n```\r\n\r\nIn the diagram below, purple represents shared transitions, blue represents transitions for only `foo`, and red represents transitions for only `bar`.\r\n\r\n![](https://user-images.githubusercontent.com/1988560/167918899-f1a6f344-ae5e-4dc0-b17a-fb156d1d550f.svg)\r\n\r\n### Cache structure\r\n\r\nFor instance variable writers, the current shape ID, the shape ID that ivar write would transition to and instance variable index are all stored in the inline cache. The shape ID is the key to the cache.\r\n\r\nFor instance variable readers, the shape ID and instance variable index are stored in the inline cache.  Again, the shape ID is the cache key.\r\n\r\n```ruby\r\nclass Foo\r\n  def initialize\r\n    @a = 1 # IC shape_id: 0, next shape: 1, iv index 0\r\n    @b = 1 # IC shape_id: 1, next shape: 2, iv index 1\r\n  end\r\n    \r\n  def a\r\n    @a # IC shape_id: 2, iv index 0\r\n  end\r\nend\r\n```\r\n\r\n## Rationale\r\n\r\nWe think that an object shape implementation will simplify cache checks, increase inline cache hits, decrease runtime checks, and enable other potential future optimizations. These are all explained below. \r\n\r\n### Simplify caching\r\n\r\nThe current cache implementation depends on the class of the receiver. Since the address of the class can be reused, the current cache implementation also depends on an incrementing serial number set on the class (the class serial).  The shape implementation has no such dependency. It only requires checking the shape ID to determine if the cache is valid.\r\n\r\n### Cache hits\r\n\r\nObjects that set properties in the same order can share shapes.  For example:\r\n\r\n```ruby\r\nclass Hoge\r\n  def initialize\r\n    # Currently this instance is the root shape (ID 0)\r\n    @a = 1 # Transitions to the next shape via edge named @a\r\n    @b = 2 # Transitions to next shape via edge named @b\r\n  end\r\nend\r\n\r\nclass Fuga < Hoge; end\r\n\r\nhoge = Hoge.new\r\nfuga = Fuga.new\r\n```\r\n\r\nIn the above example, the instances `hoge` and `fuga` will share the same shape ID.  This means inline caches in `initialize` will hit in both cases.  This contrasts with the current implementation that uses the class as the cache key.  In other words, with object shapes the above code will hit inline caches where the current implementation will miss.\r\n\r\nIf performance testing reveals that cache hits are *not* substantially improved, then we can use shapes to reclaim memory from `RBasic`. We can accomplish this by encoding the class within the shape tree. This will have an equivalent cache hit rate to the current implementation. Once the class is encoded within the shape tree, we can remove the class pointer from `RBasic` and either reclaim that memory or free it for another use.\r\n\r\n### Decreases runtime checking\r\n\r\nWe can encode attributes that aren't instance variables into an object's shape. Currently, we also include frozen within the shape. This means we can limit frozen checks to only cache misses.\r\n\r\nFor example, the following code:\r\n\r\n```ruby\r\nclass Toto\r\n  def set_a\r\n    @a = 1 # cache: shape: 0, next shape: 1, IV idx: 0\r\n  end\r\nend\r\n\r\ntoto = Toto.new # shape 0\r\ntoto.set_a     # shape 1\r\n\r\ntoto = Toto.new # shape 0\r\ntoto.freeze    # shape 2\r\ntoto.set_a     # Cache miss, Exception!\r\n```\r\n\r\n![](https://user-images.githubusercontent.com/1988560/167920001-c4e6326b-3a3c-483b-a797-9e02317647d7.svg)\r\n\r\nWithout shapes, all instance variable sets require checking the frozen status of the object. With shapes, we only need to check the frozen status on cache misses.\r\n\r\nWe can also eliminate embedded and extended checks with the introduction of object shapes. Any particular shape represents an object that is _either_ extended or embedded. JITs can possibly take advantage of this fact by generating specialized machine code based on the shapes. \r\n    \r\n### Class instance variables can be stored in an array\r\n\r\nCurrently, `T_CLASS` and `T_MODULE` instances cannot use the same IV index table optimization that `T_OBJECT` instances use.  We think that the object shapes technique can be leveraged by class instances to use arrays for class instance variable storage and may possibly lead to a reduction in memory usage (though we have yet to test this).\r\n\r\n## Implementation Details\r\n\r\n[Here](https://github.com/jemmaissroff/ruby/commit/4e95d01654f24ceff6c8330cf4e5c7dac504739e) is a link to our code so far.\r\n\r\nAs mentioned earlier, shape objects form a tree data structure.  In order to look up the shape quickly, we also store the shapes in a weak array that is stored on the VM.  The ID of the shape is the index in to the array, and the ID is stored on the object.\r\n\r\nFor `T_OBJECT` objects, we store the shape ID in the object's header. On 64 bit systems, the upper 32 bits are used by Ractors.  We want object shapes to be enabled on 32 bit systems and 64 bit systems so that limits us to the bottom 32 bits of the Object header.  The top 20 bits for `T_OBJECT` objects was unused, so we used the top 16 bits for the shape id.  We chose the top 16 bits because this allows us to use `uint16_t` and masking the header bits is easier.\r\n\r\nThis implementation detail limits us to ~65k shapes. We measured the number of shapes used on a simple [Discourse](https://github.com/discourse/discourse) application (~3.5k), [RailsBench](https://github.com/k0kubun/railsbench) (~4k), and Shopify's monolith's test suite (~40k). Accordingly, we decided to implement garbage collection on object shapes so we can recycle shape IDs which are no longer in use.  We are currently working on shape GC.\r\n\r\nEven though it's unlikely, it's still possible for an application to run out of shapes. Once all shape IDs are in use, any objects that need new shape IDs will never hit on inline caches.\r\n\r\n## Evaluation\r\n\r\nWe have so far tested this branch with [Discourse](https://github.com/discourse/discourse), [RailsBench](https://github.com/k0kubun/railsbench) and Shopify's monolith. We plan to test this branch more broadly against several open source Ruby and Rails applications. \r\n\r\nBefore we consider this branch to be ready for formal review, we want the runtime performance and memory usage of these benchmarks to be equivalent or better than it is currently. In our opinion, even with equivalent runtime performance and memory usage, the future benefits of this approach make the change seem worthwhile.\r\n\r\n## Feedback\r\n\r\nIf you have any feedback, comments, or questions, please let us know and we'll do our best to address it. Thank you!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-11T21:02:13Z", "updated_on": "2022-05-13T01:11:02Z", "closed_on": null, "relations": []}, {"id": 18774, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Add Queue#pop(timeout:)", "description": "This has been mentioned many times but somehow was never added.\r\nIt is useful for many different use cases:\r\n* Implementing Timeout#timeout without needing to create a Thread per call which is very inefficient (especially when the timeout is not hit): https://github.com/ruby/timeout/pull/14#issuecomment-1123380880\r\n* @jeremyevans0 I would love a Queue#pop :timeout argument. It would simplify the mutex/condition variable approach currently used for Sequel's connection pool.\r\n* @byroot Same. I wanted it so many times\r\n* https://bugs.ruby-lang.org/issues/17363\r\n* https://spin.atomicobject.com/2014/07/07/ruby-queue-pop-timeout/ + https://spin.atomicobject.com/2017/06/28/queue-pop-with-timeout-fixed/\r\n* More in my email searches but this seems already plenty\r\n\r\nI think it should be a keyword argument for clarity, and so there is no confusion with the existing optional argument `non_block=false`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-11T19:38:42Z", "updated_on": "2022-05-20T00:27:17Z", "closed_on": null, "relations": [{"id": 3329, "issue_id": 17363, "issue_to_id": 18774, "relation_type": "relates", "delay": null}]}, {"id": 18773, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "deconstruct to receive a range", "description": "Currently when you're pattern matching against a hash pattern, `deconstruct_keys` receives the keys that are being matched. This is really useful for computing expensive hashes.\r\n\r\nHowever, when you're pattern matching against an array pattern, you don't receive any information. So if the array is expensive to compute (for instance loading an array of database records), you have no way to bail out. It would be useful to receive a range signifying how many records the pattern is specifying. It would be used like the following:\r\n\r\n```ruby\r\nclass ActiveRecord::Relation\r\n  def deconstruct(range)\r\n    (loaded? || range.cover?(count)) ? records : nil\r\n  end\r\nend\r\n```\r\n\r\nIt needs to be a range and not just a number to handle cases where `*` is used. You would use it like:\r\n\r\n```ruby\r\ncase Person.all\r\nin []\r\n  \"No records\"\r\nin [person]\r\n  \"Only #{person.name}\"\r\nelse\r\n  \"Multiple people\"\r\nend\r\n```\r\n\r\nIn this way, you wouldn't have to load the whole thing into memory to check if it pattern matched. The patch is here: https://github.com/ruby/ruby/pull/5905.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-11T17:13:54Z", "updated_on": "2022-06-24T07:21:56Z", "closed_on": null, "relations": []}, {"id": 18762, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6603, "name": "shan (Shannon Skipper)"}, "subject": "Add an Array#undigits that compliments Integer#digits", "description": "I've found Integer#digits convenient and useful but several times have needed to go from the place-value notation back to an Integer after manipulation and wished there was a complimentary Array#undigits.\r\n\r\n``` ruby\r\nclass Array\r\n  def undigits(base = 10)\r\n    each_with_index.sum do |digit, exponent|\r\n      digit * base**exponent\r\n    end\r\n  end\r\nend\r\n\r\n42.digits.undigits\r\n#=> 42\r\n\r\n42.digits(16).undigits(16)\r\n#=> 42\r\n```\r\n\r\nBelow is my stab at a Ruby implementation with behavior mirroring Integer#digits.\r\n``` ruby\r\nclass Array\r\n  def undigits(base = 10)\r\n    base_int = base.to_int\r\n    raise TypeError, \"wrong argument type #{base_int.class} (expected Integer)\" unless base_int.is_a?(Integer)\r\n    raise ArgumentError, 'negative radix' if base_int.negative?\r\n    raise ArgumentError, \"invalid radix #{base_int}\" if base_int < 2\r\n\r\n    each_with_index.sum do |digit, exponent|\r\n      raise MathDomainError, 'out of domain' if digit.negative?\r\n\r\n      digit * base_int**exponent\r\n    end\r\n  end\r\nend\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-05-02T22:47:02Z", "updated_on": "2022-05-03T20:08:14Z", "closed_on": null, "relations": []}, {"id": 18757, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52300, "name": "zeke (Zeke Gabrielse)"}, "subject": "Introduce %R percent literal for anchored regular expression patterns", "description": "When defining regular expression patterns, it's often the case that you want to anchor with `\\A` and `\\z` to match the full text input, rather than `^` and `$`, respectively, which may (unintentionally) match text including newlines. This is especially true in the context of a web application such as a Rails app. Unfortunately, `\\A` and `\\z` reduce the legibility of a regular expression.\r\n\r\nFor example, take this `ActionMailbox` usage:\r\n\r\n```ruby\r\nclass ApplicationMailbox < ActionMailbox::Base\r\n  routing %r{\\Areplies\\+.*?@ruby-lang\\.org\\z}i => :replies\r\n  routing %r{\\Asales@.*?\\z}i                   => :leads\r\nend\r\n```\r\n\r\nAt first glance, it may look as if the second route matches `Asales`, but that's not the case upon further inspection. To improve legibility, a developer may choose to use `^` instead of `\\A`. Because when defining a pattern using `\\A` and `\\z`, readability suffers, but especially for `\\A`. In other cases, developers forget to use `\\A` and `\\z` over `^` or `$` when validating or matching against user input.\r\n\r\nI propose Ruby introduces a new percent-notation, `%R{}`, for defining interpolated regular expression patterns that automatically anchor a pattern with `\\A` and `\\z`.\r\n\r\nFor example, the above will look like below:\r\n\r\n```ruby\r\nclass ApplicationMailbox < ActionMailbox::Base\r\n  routing %R{replies\\+.*?@ruby-lang\\.org}i => :replies\r\n  routing %R{sales@.*?}i                   => :leads\r\nend\r\n```\r\n\r\nThis is much more readable, and it's safer \u2014 developers using `%R{}` are not going to accidentally use `^` or `$` instead of `\\A` and `\\z`, respectively (the former being vulnerable to matching input data containing newlines).\r\n\r\nThis is especially useful in pattern matching data where some values may be a symbol or a string, depending on where the data originated (internally vs externally):\r\n\r\n```ruby\r\ndata = { type: :foo, id: 1 } # Could also be: { type: 'foo', id: 1 }\r\n\r\ncase data\r\nin type: %R(foo), id:\r\n  # ...\r\nelse\r\nend\r\n```\r\n\r\nFormally, the new anchored regex percent notation would work as follows:\r\n\r\n```ruby\r\nre = %R(test)\r\n# => /\\Atest\\z/\r\n\r\nre.match?('test')    # => true\r\nre.match?('testing') # => false\r\nre.match?('a test')  # => false\r\nre.match?(:test)     # => true\r\nre.match?(:testing)  # => false\r\nre.match?(:a_test)   # => false\r\n```\r\n\r\nThis would also be useful for data validation purposes, where a developer could clean up patterns that previously used regular expressions with `\\A...\\z` and `^...$`, such as with Rails model validations, e.g. `validates_format(with: %R{[-a-z0-9]+})`\r\n\r\nI do understand that having an uppercase `%R` behaves differently than other percent notations (i.e. lowercase is typically non-interpolated, uppercase interpolated), but since `%r` already allows interpolation, I figured it was okay to be a bit different. Regardless \u2014 I'm open to other syntax suggestions.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-27T14:58:50Z", "updated_on": "2022-04-27T17:30:27Z", "closed_on": null, "relations": []}, {"id": 18749, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Strangeness of endless inclusive ranges", "description": "I came to think about this while looking at the pull request linked in #18748.\r\n\r\nCurrently, an endless inclusive range covers the corresponding endless exclusive range, but not vice versa:\r\n\r\n```ruby\r\n(\"a\"..nil).cover?(\"a\"...nil) #=> true\r\n(\"a\"...nil).cover?(\"a\"..nil) #=> false\r\n\r\n(nil..nil).cover?(nil...nil) #=> true\r\n(nil...nil).cover?(nil..nil) #=> false\r\n```\r\n\r\nThis looks strange to me. There is not a single element covered by an endless inclusive range that is not covered by the corresponding endless exclusive range. This should mean that there is no difference in coverage between an endless inclusive range and the corresponding endless exclusive range.\r\n\r\nHowever, actually, an interval in mathematics (which I think is the counterpart to Ruby's range) ending in \u221e (which I think is the counterpart to an endless range) is always an open interval (which I think is the counterpart to an exclusive range), and never a closed interval (which I think is the counterpart to an inclusive range).\r\n\r\n[a, \u221e) is correct.\r\n[a, \u221e] is wrong.\r\n\r\nFrom analogy, ideally, endless inclusive ranges should be prohibited in the first place. But that would cause new issues: There is no inclusive-exclusive distinction on the begin side of a range, and that is actually always assumed to be inclusive. Since we have beginless (inclusive) ranges, prohibiting endless inclusive ranges would cause asymmetry.\r\n\r\nSo what I can think of are the following possibilities (ordered from conservative to radical):\r\n\r\nA. Endless inclusive ranges are allowed as is. An endless inclusive range and the corresponding endless exclusive range cover each other.\r\nB. Endless inclusive ranges are disallowed. Beginless (inclusive) ranges are allowed as is.\r\nC. New syntax is introduced in order to describe ranges that are exclusive on the begin side. Inclusive-exclusive distinction can be described on both begin and end sides independently. Endless inclusive ranges and beginless inclusive ranges are disallowed.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-22T05:55:59Z", "updated_on": "2022-06-17T09:25:37Z", "closed_on": "2022-06-14T07:07:53Z", "relations": []}, {"id": 18742, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11019, "name": "Dan0042 (Daniel DeLorme)"}, "subject": "Introduce a way to tell if a method invokes the `super` keyword", "description": "In order to implement a \"no clobber\" checker as in #18618, I would like to have a way to check if a method calls `super` or not.\r\n\r\nSo I'm thinking that something along the line of `Method#calls_super?` could return true/false if the method simply contains the `super` keyword. I'm not really interested in handling weird/artificial edge cases with eval and binding and whatnot.\r\n\r\n```ruby\r\nclass X\r\n  def a\r\n  end; p instance_method(:a).calls_super? #=> false\r\n\r\n  def b\r\n    super\r\n  end; p instance_method(:b).calls_super? #=> true\r\n\r\n  def c\r\n    super if false\r\n  end; p instance_method(:c).calls_super? #=> true\r\n\r\n  def d\r\n    eval 'super'\r\n  end; p instance_method(:d).calls_super? #=> false (I doubt there's a reasonable way for this to return true)\r\nend\r\n```\r\n\r\nWith the above it would be possible to warn against a method that has a `super_method` but doesn't use the `super` keyword.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-19T01:19:40Z", "updated_on": "2022-05-19T08:09:16Z", "closed_on": "2022-05-19T08:09:16Z", "relations": []}, {"id": 18736, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52287, "name": "aDAVISk (Akito D. Kawamura)"}, "subject": "self-p for method chain", "description": "You may want to check object with `p` method at the middle of a method chain.\r\nHere is my recomendation.\r\n \r\n```ruby\r\nclass Object\r\n  def sp(method=nil, *args, &block)\r\n    if method\r\n        Kernel.p self.public_send(method, *args, &block)\r\n    elsif block_given?\r\n        Kernel.p block.call(self)\r\n    else\r\n      Kernel.p self\r\n    end\r\n    return self\r\n  end\r\nend\r\n```\r\n\r\nExample of usage:\r\n1) check itself in the middle of a method-call\r\n```ruby\r\np [1,2,3].map{|x| x**2}.sp.map{|x| x**2}\r\n```\r\n- output\r\n```\r\n[1,4,9]\r\n[1,16,81]\r\n```\r\n2) check its value in some string format\r\n```ruby\r\n[1,2,3].sp{|x| \"my List = #{x}\"}\r\n```\r\n- output\r\n```\r\n\"my List = [1,2,3]\"\r\n```\r\n3) check its sum with an initial value\r\n```ruby\r\n[1,2,3].sp(:sum,-10)\r\n```\r\n- output\r\n```\r\n-4\r\n```\r\n4) check its value with a `map` operation\r\n```ruby\r\n[1,2,3].sp(:map){|x| x**2}\r\n```\r\n- output\r\n```\r\n[1,4,9]\r\n```\r\n5) check its value connected in string\r\n```ruby\r\n[1,2,3].sp(:sum,\"\"){|x| x.to_s}\r\n```\r\n- output\r\n```\r\n\"123\"\r\n```\r\n\r\n---\r\nYour brush-up comments are welcomed. thx.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-15T09:03:03Z", "updated_on": "2022-04-15T11:09:56Z", "closed_on": null, "relations": [{"id": 3320, "issue_id": 14609, "issue_to_id": 18736, "relation_type": "relates", "delay": null}]}, {"id": 18690, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Allow `Kernel#then` to take arguments", "description": "`Kernel#then` passes the receiver to the block as its first positional block parameter.\r\n\r\n```ruby\r\n1.5.then{|x| Math.atan(x)}\r\n```\r\n\r\nI would like to propose to let `then` take arguments, which would be passed to the block as the other block parameters.\r\n\r\n```ruby\r\n3.then(4){|x, y| Math.hypot(x, y)}\r\n```\r\n\r\nThere are two uses. First, to separate bulky or repeated parameters from the routine. Instead of writing:\r\n\r\n```ruby\r\nhonyarara.then{|x|\r\n  foo(x)\r\n  bar(fugafugafuga)\r\n  baz(hogehogehoge)\r\n  qux(x, fugafugafuga, hogehogehoge)\r\n}\r\n```\r\n\r\nwe can then write:\r\n\r\n```ruby\r\nhonyarara.then(fugafugafuga, hogehogehoge){|x, y, z|\r\n  foo(x)\r\n  bar(y)\r\n  baz(x)\r\n  qux(x, y, z)\r\n}\r\n```\r\n\r\nSecond, to use a proc with multiple parameters when, for some reason, you do not want to define a method to do it:\r\n\r\n\r\n```ruby\r\np = ->(x, y, z){\r\n  foo(x)\r\n  bar(y)\r\n  baz(x)\r\n  qux(x, y, z)\r\n}\r\n\r\nhonyarara.then(fugafugafuga, hogehogehoge, &p)\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-12T09:20:21Z", "updated_on": "2022-05-10T18:16:24Z", "closed_on": null, "relations": []}, {"id": 18685, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8, "name": "knu (Akinori MUSHA)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Enumerator.product: Cartesian product of enumerables", "description": "I'd like to add a new Enumerator class method for generating the Cartesian product of given enumerators.\r\nA product here does not mean an accumulated array of arrays, but an enumerator to enumerate all combinations.\r\n\r\n```ruby\r\nproduct = Enumerator.product(1..3, [\"A\", \"B\"])\r\np product.class #=> Enumerator\r\n\r\nproduct.each do |i, c|\r\n  puts \"#{i}-#{c}\"\r\nend\r\n\r\n=begin output\r\n1-A\r\n1-B\r\n2-A\r\n2-B\r\n3-A\r\n3-B\r\n=end\r\n```\r\n\r\nThis can be used to reduce nested blocks and allows for iterating over an indefinite number of enumerable objects.\r\n\r\n## Implementation notes\r\n\r\n- It should internally use `each_entry` instead of `each` on enumerable objects to make sure to capture all yielded arguments.\r\n- If no enumerable object is given, the block is called once with no argument.\r\n- It should reject a keyword-style hash argument so we can add keyword arguments in the future without breaking existing code.\r\n- Here's an example implementation:\r\n\r\n  ```ruby\r\n  # call-seq:\r\n  #   Enumerator.product(*enums)                   -> enum\r\n  #   Enumerator.product(*enums) { |*args| block } -> return value of args[0].each_entry {}\r\n  def Enumerator.product(*enums, **nil, &block)\r\n   # TODO: size should be calculated if possible\r\n    return to_enum(__method__, *enums) if block.nil?\r\n\r\n    enums.reverse.reduce(block) { |inner, enum|\r\n      ->(*values) {\r\n        enum.each_entry { |value|\r\n          inner.call(*values, value)\r\n        }\r\n      }\r\n    }.call()\r\n  end\r\n  ```\r\n\r\n- Not to be confused with `Enumerator.produce`. \ud83d\ude1d\r\n\r\n## Prior case\r\n- Python: https://docs.python.org/3/library/itertools.html#itertools.product\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-08T07:20:29Z", "updated_on": "2022-04-26T07:02:36Z", "closed_on": null, "relations": []}, {"id": 18683, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Allow to create hashes with a specific capacity.", "description": "Various protocol parsers such as Redis `RESP3` or `msgpack`, have to create hashes, and they know the size in advance.\r\nFor efficiency, it would be preferable if they could directly allocate a Hash of the necessary size, so that large hashes wouldn't cause many re-alloccations.\r\n\r\nExample of code that would benefit:\r\n\r\n - [`hiredis` bindings](https://github.com/redis-rb/redis-client/blob/830d586b665bc9569335d70e82c41377f18e0c16/ext/redis_client/hiredis/hiredis_connection.c#L157-L162)\r\n - [Ruby `redis RESP3` parser](https://github.com/redis-rb/redis-client/blob/830d586b665bc9569335d70e82c41377f18e0c16/lib/redis_client/resp3.rb#L173-L175)\r\n - [magpack-ruby](https://github.com/msgpack/msgpack-ruby/blob/c46bb60f79312cab902356e89f3f6035d7cad03f/ext/msgpack/unpacker.c#L641-L644)\r\n\r\n`String` and `Array` both already offer similar APIs:\r\n\r\n```ruby\r\nString.new(capacity: XXX)\r\nArray.new(XX) / rb_ary_new_capa(long)\r\n```\r\n\r\nHowever there's no such public API for Hashes, neither in Ruby land not in the C extension API.\r\n\r\n### Proposal\r\n\r\nI think `Hash.new` should accept a `capacity:` named parameter:\r\n\r\n```ruby\r\nhash = Hash.new(capacity: 1000)\r\n```\r\n\r\nAdditionally I think the internal `rb_hash_new_with_size` function should be exposed to C extensions as `rb_hash_new_capa(long)`, for consistency with `rb_ary_new_capa(long)`.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-06T10:55:11Z", "updated_on": "2022-04-22T14:34:56Z", "closed_on": null, "relations": []}, {"id": 18675, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52242, "name": "geffatpier64 (Geff Hanoain)"}, "subject": "Add new exception class for resolv timeouts", "description": "I have 2.7.4 but I also checked 3.0, same code in resolv.rb.\r\n\r\nto reproduce:\r\n```\r\nirb(main):001:0> require 'resolv'\r\n=> true\r\nirb(main):002:0> Resolv::DNS.new(nameserver: ['127.0.0.5']).getaddress(\"google.com\")\r\nTraceback (most recent call last):\r\n        5: from /usr/bin/irb:23:in `<main>'\r\n        4: from /usr/bin/irb:23:in `load'\r\n        3: from /usr/share/gems/gems/irb-1.2.6/exe/irb:11:in `<top (required)>'\r\n        2: from (irb):2\r\n        1: from /usr/share/ruby/resolv.rb:379:in `getaddress'\r\nResolv::ResolvError (DNS result has no information for google.com)\r\nirb(main):003:0>\r\n```\r\nIdeal Expectation:\r\n```\r\n#<Resolv::ResolvTimeout: Resolv::ResolvTimeout>\r\n```\r\n\r\nsuggested fix:\r\n\r\n```\r\nclass Resolv\r\n  class DNS\r\n    class Config\r\n      def resolv(name)\r\n        candidates = generate_candidates(name)\r\n        timeouts = @timeouts || generate_timeouts\r\n        begin\r\n          candidates.each {|candidate|\r\n            begin\r\n              timeouts.each {|tout|\r\n                @nameserver_port.each {|nameserver, port|\r\n                  begin\r\n                    yield candidate, tout, nameserver, port\r\n                  rescue ResolvTimeout\r\n                  end\r\n                }\r\n              }\r\n              #raise ResolvError.new(\"DNS resolv timeout: #{name}\")\r\n              raise ResolvTimeout\r\n            rescue NXDomain\r\n            end\r\n          }\r\n          #rescue ResolvError\r\n        end\r\n      end\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nI have commented out the code that seemed to arbitrarily swallow any raised exception.\r\n\r\nhttps://github.com/ruby/ruby/blob/ruby_2_7/lib/resolv.rb - line 1125\r\n```\r\n        rescue ResolvError\r\n```\r\n\r\nI would prefer raising ResolvTimeout to ResolvError.new(\"DNS resolv timeout: #{name}\")\r\n\r\nBut as long is it does something that isn't:\r\n```\r\nDNS result has no information for google.com\r\n```\r\nI'd be okay with it.  I'm happy to help with this via a pull request in github, a diff patch or what ever is needed.  I just didn't want to spend too much time \"fixing\" it the \"wrong\" way.  I'm not intimately familiar with the code in resolv.rb so I'm not 100% sure my \"fix\" wouldn't break other stuff.  I did some minor testing of my minor change.\r\n\r\nSeparately - This also highlights that a timeout condition isn't in or doesn't work in unit tests.\r\n\r\nThanks so much,", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-04-01T18:33:24Z", "updated_on": "2022-04-01T23:22:57Z", "closed_on": null, "relations": []}, {"id": 18668, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Merge `io-nonblock` gems into core", "description": "The new io-nonblock gem defines just 3 methods on IO: (https://github.com/ruby/io-nonblock/blob/e20578b24405d225e6383d6c5ebfb7ffefac646b/ext/io/nonblock/nonblock.c#L137-L139)\r\n* IO#nonblock?\r\n* IO#nonblock=(nonblock)\r\n* IO#nonblock(nonblock = true, &block)\r\n\r\nI think these 3 methods should move to core, and the gem become a noop if these methods are already defined in core.\r\nThese methods are small and yet they access IO internals and their behavior is extremely unlikely to change.\r\nTheir behavior and names are well known and established.\r\n\r\nThe benefit of a gem seems nonexistent here (no point to version those 3 methods), while the cost is significant (have to support each Ruby implementation, while this code just makes more sense in each Ruby implementation's repo).\r\n\r\nio/nonblock is useful to tell if an IO is in non-blocking mode and to set it upfront.\r\nThis is needed when using a Fiber scheduler but also other cases such as https://bugs.ruby-lang.org/issues/18630#note-9.\r\n\r\nIn fact `io/nonblock` is so small it's already core in TruffleRuby.\r\nMany core IO methods even need to check/set whether an IO is nonblocking, so it's natural to just use the existing methods for that when such IO methods are written in Ruby.\r\n\r\nNo gem seems to depend on io-nonblock anyway, so it seems of no use to be a gem, and it should either be core or stdlib-not-a-gem:\r\nhttps://github.com/ruby/io-nonblock/network/dependents\r\nhttps://rubygems.org/gems/io-wait/reverse_dependencies\r\n\r\nProposal:\r\n\r\n* Merge io-nonblock into io.c for Ruby 3.2\r\n* Publish a new io-nonblock version that simply noops if the methods are already defined, or an empty gem (so the stdlib io/nonblock gets used).\r\n* Add a lib/io/nonblock.rb stub for compatibility, with eventually a deprecation warning.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-30T12:11:19Z", "updated_on": "2022-04-21T10:02:28Z", "closed_on": null, "relations": [{"id": 3283, "issue_id": 18566, "issue_to_id": 18668, "relation_type": "relates", "delay": null}]}, {"id": 18660, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 44574, "name": "hurricup (Alexandr Evstigneev)"}, "subject": "Line event flags on instruction in method/block signature", "description": "Ruby in question is 3.0.3. Not sure what behavior is on different versions, but presume the same.\r\n\r\nIt's unclear why operations in signatures are not marked with `Li`, despite they may be a valid and meaningful code. Consider example:\r\n\r\n```\r\nclass A\r\n  def foo(some = BasicObject.new)\r\n    yield\r\n  end\r\nend\r\n\r\nA.new.foo {|a = BasicObject.new| 1 + a}\r\n```\r\n\r\nAnd here is the disasm of method iseq:\r\n```\r\nlocal table (size: 1, argc: 0 [opts: 1, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])\r\n[ 1] some@0<Opt=0>\r\n0000 opt_getinlinecache                     9, <is:0>                 (   2)\r\n0003 putobject                              true\r\n0005 getconstant                            :BasicObject\r\n0007 opt_setinlinecache                     <is:0>\r\n0009 opt_send_without_block                 <calldata!mid:new, argc:0, ARGS_SIMPLE>\r\n0011 setlocal_WC_0                          some@0\r\n0013 invokeblock                            <calldata!argc:0, ARGS_SIMPLE>(   3)[LiCa]\r\n0015 leave                                                            (   4)[Re]\r\n\r\n```\r\n\r\nHere is the block iseq:\r\n```\r\nlocal table (size: 1, argc: 0 [opts: 1, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])\r\n[ 1] a@0<Opt=0>\r\n0000 opt_getinlinecache                     9, <is:0>                 (   7)\r\n0003 putobject                              true\r\n0005 getconstant                            :BasicObject\r\n0007 opt_setinlinecache                     <is:0>\r\n0009 opt_send_without_block                 <calldata!mid:new, argc:0, ARGS_SIMPLE>\r\n0011 setlocal_WC_0                          a@0\r\n0013 nop                                    [Bc]\r\n0014 putobject_INT2FIX_1_                   [Li]\r\n0015 getlocal_WC_0                          a@0\r\n0017 opt_plus                               <calldata!mid:+, argc:1, ARGS_SIMPLE>\r\n0019 nop\r\n0020 leave                                                            (   7)[Br]\r\n```\r\n\r\nAnd this is a bit confusing. \r\n1. I would expect `Ca`/`Bc` events to be fired on the first instruction, not in the middle of `iseq`\r\n2. I would expect `Li` to exist on pc=0 for the both method and block", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-25T12:43:02Z", "updated_on": "2022-03-30T12:27:08Z", "closed_on": "2022-03-28T01:47:23Z", "relations": []}, {"id": 18659, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 471, "name": "pedz (Perry Smith)"}, "subject": "Create a Binding at the time of an exception and make it available to Rescue", "description": " When an exception occurs, create a binding or I assume make a reference to the current binding and then add that to the Exception class via (e.g.) a #binding method.  This would allow users to have a more global rescue code but would still have access to the variables that were in scope at the time of the exception.\r\n\r\nMy particular use case is when parsing files -- especially a list of files.  The outer loop is for each file.  The next inner loop is for each line in the file.  At the time of an exception, it would be nice to have access while in the a rescue clause to the file name, line number, current line, and other interesting variables.  Adding rescue closes in the inner blocks creates a lot of redundant code.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-25T02:02:50Z", "updated_on": "2022-03-25T10:55:24Z", "closed_on": null, "relations": []}, {"id": 18655, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Copy `IO#wait_readable`, `IO#wait_writable`, `IO#wait_priority` and `IO#wait` into core.", "description": "Extracted from [Feature #18566].\r\n\r\nThe decision was made to consider the methods from `io-wait` and `io-nonblock` one by one.\r\n\r\nI think `wait_readable` and `wait_writeable` should be fairly non-controversial. They're quite essential to use `IO#read_nonblock` and `IO#write_nonblock` effectively.\r\n\r\nProposed patch: https://github.com/ruby/ruby/pull/5694\r\n\r\nNB: if we only merge some methods, then `io/wait` must test which methods it needs to define or not. For now I use a `if RUBY_VERSION >= \"3.2\"` check in `extconf.rb`, but there might be a better approach.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-23T13:45:48Z", "updated_on": "2022-06-25T09:20:28Z", "closed_on": "2022-06-25T09:20:28Z", "relations": [{"id": 3279, "issue_id": 18566, "issue_to_id": 18655, "relation_type": "relates", "delay": null}]}, {"id": 18654, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Enhancements to prettyprint", "description": "This issue mirrors the pull request open at https://github.com/ruby/prettyprint/pull/3.\r\n\r\nThis pull request adds a bunch of new functionality to the PrettyPrint class. The goal is to enhance the PrettyPrint class enough to support all of the necessary print functionality that a formatter requires in order to print out Ruby source correctly.\r\n\r\nFirst, how PrettyPrint works today. PrettyPrint has 3 primitives:\r\n\r\n* `Group` - an object that represents a set of content and its associated breakpoints. These objects are usually nested. When one of them no longer fits on a single line, it is broken at all of its associated breakpoints. For example, if you have something like [text(\"abc\"), breakable, text(\"def\")] and that group no longer fits on one line, then you will have two lines of output.\r\n* `Breakable` - an object that represents a location where a line of content can be split. When it is created, if the current group is broken already, then it inserts a newline and carries on. If it is not, then it adds itself to the output buffer.\r\n* `Text` - this is a set of objects that are appended to a buffer. If the buffer overflows the maximum print width for the line, then the surrounding group is broken and the buffer is flushed to the output.\r\n\r\nWith those primitives in place, the printer maintains a buffer of content that is being added. If the buffer overflows the line, the content is flushed until another group is hit or there are no more breakpoints. There are a couple of limitations with the current approach:\r\n\r\n* `PrettyPrint` assumes that content in `Text` will not change its representation if it is contained within a broken group versus contained within a flat group. This isn't a problem for the existing uses of `PrettyPrint`, but for my purposes of building a formatter, it definitely is. Consider something like trailing commas (where you want a comma if it is broken but nothing if it's not) or block operators (where you would use a do and end for multi-line (broken group) or braces for single line (flat group)).\r\n* The `Breakable` class assumes that you always want to indent the subsequent line up to the current indentation level. This is true in most cases, and certainly for all the existing use cases. But there are times when you don't want that behavior (for example if you're in the middle of a nested indentation structure but have to force content to start at the beginning of the next line as in a comment with `=begin`..`=end` bounds).\r\n* There's no way to force a group to break. You can access the current group in the printer with `current_group`, but that won't force the parent groups to break. Without hacking around a lot of stuff, it's difficult to get this behavior. This is necessary if you want to ensure a newline is added and respected, like after a keyword where it would be necessary.\r\n\r\nThis commit adds a couple new nodes to the printing tree, as well as enhancing the Breakable class. First, the new nodes:\r\n\r\n* `Align` - this node effectively wraps the old @indent variable but allows you to align content within any of the other containers. You can also align to a string now instead of just an integer, which will print that string before each line.\r\n* `BreakParent` - enforces that the surrounding group and all ancestral groups are broken.\r\n* `IfBreak` - contains two sets of nodes, one for if the surrounding group is broken and one for if the surrounding group is flat.\r\n* `Indent` - similar to the align node, but you don't have to specify anything and it just indents by one level.\r\n* `LineSuffix` - this is a big enhancement to the printing algorithm that maintains a separate buffer for content that should be flushed before the next newline. This is convenient for implementing things like heredocs and trailing comments.\r\n* `Trim` - a rarely used but important node that trims off whitespace that has already been added to the buffer in the case that you need to force something to begin at the start of the next line.\r\n\r\nAs for the enhancements to `Breakable`:\r\n\r\n* It now accepts a force parameter (default to false), which will insert a BreakParent and slightly change semantics so that a newline is always added.\r\n* It now accepts an indent parameter (default to true), which allows you to specify if you want the subsequent line to indent automatically.\r\n\r\nFor the most part, the code is completely compatible with the previous version. There are a couple of things that were removed that appeared to be all internally-facing functions. When they were removed all of the tests still passed, so I'm assuming they were only called internally. I can certainly add them back if it's deemed too risky but I very much doubt this is a problem.\r\n\r\n* indent attr_reader which is now encapsulated in the printing algorithm\r\n* group_queue attr_reader which had a reference to a queue that is no longer necessary\r\n* break_outmost_groups method, which is now encapsulated in the printing algorithm\r\n* group_sub method, which was only called by the group method anyway and is no longer necessary\r\n\r\nThere were a bunch of things that were added, including:\r\n\r\n* force and indent parameters to the breakable method (they both have defaults so this shouldn't be an issue)\r\n* Align, BreakParent, IfBreak, Indent, LineSuffix, and Trim nodes\r\n* Buffer::DefaultBuffer, Buffer::StringBuffer, and Buffer::ArrayBuffer, which is just there to provide the ability to trim trailing whitespace\r\n* PrettyPrint.visit(doc, visitor), which is useful for debugging and also necessary for propagating break parent nodes up the tree\r\n\r\nAll in all, none of the tests had to change, which is a good sign. From the user of this class's perspective, nothing is different. Internally however, there's a bunch of additional functionality and a lot more control over the printing algorithm! Also the ability to debug has been greatly enhanced with pretty_print methods on each of the nodes and the ability to walk the print tree nodes before they're printed.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-22T20:26:06Z", "updated_on": "2022-05-12T13:44:22Z", "closed_on": null, "relations": [{"id": 3319, "issue_id": 18450, "issue_to_id": 18654, "relation_type": "relates", "delay": null}]}, {"id": 18653, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Use RE2 for Regexp", "description": "I have tried to use [RE2](https://github.com/google/re2) as Ruby's regular expression engine. As it turns out, it seems difficult to merge it to Ruby right now. But I'd like to share some of my findings for those who may consider doing the same in the future.\r\n\r\n## What I did\r\n\r\nHere is my prototype.\r\n\r\nhttps://github.com/mame/ruby/tree/re2-prototype\r\n\r\nMy prototype first attempts to use RE2 for any Regexp matching. If it is impossible for any reason, it degenerates into onigmo, which is the regular expression engine that Ruby is currently using. This hybrid approach is the same as TruffleRuby's. Actually I was inspired by [@eregon's talk at RubyKaigi takeout 2021](https://rubykaigi.org/2021-takeout/presentations/eregontp.html).\r\n\r\nMy prototype degenerates into onigmo in the following cases.\r\n\r\n* A Regexp uses any feature that RE2 does not support\r\n  * For example, lookahead, back references (`\\1`), and many advanced features are not supported by RE2.\r\n  * Notably, RE2 does not support a large repeat like `/a{0,9999}/`, which is often used in some actual projects.\r\n* The encoding of a match target string is not in UTF-8, US-ASCII, or ASCII-8BIT\r\n  * This is because RE2 supports only UTF-8 and Latin1 encoding.\r\n  * This means, the backend engine is not determined when the Regexp object is created. It can switch to each other depending on the encoding of a match target string.\r\n* A Regexp uses any option but `//m`.\r\n  * Even `//i` degenerates to onigmo because they are incompatible. In RE2, `/ss/i =~ \"\u00df\"` does not match.\r\n  * We may support `//x` by preprocessing a pattern string to remove spaces.\r\n* A Regexp includes `^`.\r\n  * In onigmo, `^` matches \"the beginning of the string\" or \"after \\n and before any character\".\r\n  * In RE2, `^` matches \"the beginning of the string\" or \"after \\n\".\r\n  * For example, `\"abc\\n\" =~ /^$/` does not match in onigmo, but does in RE2. Some actual projects (like rdoc) seem to depend on this behavior of onigmo.\r\n* A Regexp includes `\\b`.\r\n  * In onigmo, `\\b` matches the boundary of space and non-space.\r\n  * In RE2, `\\b` matches ASCII word boundary.\r\n  * For example, `\"\u03b1 \" =~ /.\\b./` does match in onigmo, but does not in RE2.\r\n\r\nAlso, my prototype applies some preprocessing to a pattern string. For example, it replaces `\\s` with `/[\\t\\n\\v\\f\\r\\x20]/` because `/\\s/` does not match with `\"\\v\"` in RE2.\r\n\r\n## Evaluation\r\n\r\nMy prototype passes almost all tests in `make test-all` (except some tests that are checking warning messages emitted from onigmo).\r\n\r\nBy running `rails new foo && cd foo && rails s`, half of Regexps are processed by RE2: 865 unique Regexps are processed by RE2, and 811 unique Regexps are by onigmo.\r\n\r\nI think that it is possible to increase the percentage of RE2 by increasing custom preprocessing, but I am not sure that it would pay for the complexity of adding new code.\r\n\r\nIn terms of performance, `make rdoc` takes 20.2s before the patch, and 22.6s after the patch ;-( I guess that degeneration to onigmo is the main overhead.\r\n\r\n## Notes / Problems\r\n\r\n* According to `make test-spec`, there are still some minor incompatibilities: for example, `/(a|())*/.match(\"aaa\"); $1 #=> RE2: \"a\", onigmo: \"\"`.\r\n* One of the main motivations to use RE2 is security measure against ReDoS. However, RE2 supports only UTF-8 and Latin1, so it seems difficult for us to satisfy this motivation (unless we decide to ignore non-ASCII / non-UTF-8 encodings).\r\n* My prototype requires C++ compiler because RE2 only provides C++ API.\r\n* RE2 seems not to provide interruption API. So, we cannot stop RE2 matching by Ctrl+C. (In general, RE2 matching is faster enough, but it can take longer when a target string is long enough.)\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-22T08:51:30Z", "updated_on": "2022-03-23T06:42:42Z", "closed_on": "2022-03-22T08:51:30Z", "relations": []}, {"id": 18648, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7179, "name": "aaronjensen (Aaron Jensen)"}, "subject": "ruby2_keywords and ... name arguments with impossible names", "description": "While investigating a break in a library using reflection, I realized that when ... is used or ruby2_keywords is used that Ruby will name arguments with their symbol, rather than leaving them unnamed. This test demonstrates the issue:\r\n\r\nhttps://github.com/ruby/ruby/blob/97426e15d721119738a548ecfa7232b1d027cd34/test/ruby/test_method.rb#L35\r\nhttps://github.com/ruby/ruby/blob/97426e15d721119738a548ecfa7232b1d027cd34/test/ruby/test_method.rb#L586\r\n\r\nI do not understand how `:*`, `:**`, and `:&` are meant to be considered valid parameter names. I assume the reason is so that they do not conflict with something a person could write but that they can still be referenced in Ruby to facilitate delegation but I just wanted to report that it caused a problem downstream.\r\n\r\nIt's also curious that:\r\n\r\n```\r\ndef foo(*, **, &)\r\nend\r\n```\r\n\r\nGives these parameter: `[[:rest], [:keyrest], [:block, :&]]`\r\n\r\nWhy does only `block` get the faux name? Is it because that's how yield works so there needs to be a way to reference it in Ruby?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-18T15:20:36Z", "updated_on": "2022-03-18T18:25:42Z", "closed_on": "2022-03-18T15:59:31Z", "relations": []}, {"id": 18647, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 44574, "name": "hurricup (Alexandr Evstigneev)"}, "subject": "Non-recursive option for iseq-targeted Tracepoints in ruby 2.6+", "description": "I can see that iseq-targeted TracePoints introduced in ruby 2.6 working recursively and there is no API to avoid that, even on C level, because related method is not exported by rubylib. \r\nThis may be handy in some cases, but I'd like to be able to put precise tracepoint to the method line (without any child iseqs, like blocks on the same line)\r\n\r\nWould be really nice to have some `recursive = true` argument in the `enable` method.\r\n\r\nOtherwise, to implement some precise breakpoint I need manually to check if topmost user iseq is the expected one. This may be really bad for performance in some cases.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-18T09:41:37Z", "updated_on": "2022-03-18T09:41:37Z", "closed_on": null, "relations": []}, {"id": 18644, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52215, "name": "waiting_for_dev (Marc Busqu\u00e9)"}, "subject": "Coerce anything callable to a Proc", "description": "Functional objects are increasingly popular in Ruby. Having objects that respond to `#call` makes them interchangeable with a `Proc`.\r\n\r\nHowever, when you need to perform some Proc-specific operation, like currying, you have to break the abstraction and ask for the type of object. Example:\r\n\r\n```ruby\r\n(callable.is_a?(Proc) ? callable : callable.method(:call)).curry[value]\r\n```\r\n\r\nBecause of https://bugs.ruby-lang.org/issues/18620, it's not possible to make them polymorphic by taking the `:call` method:\r\n\r\n```ruby\r\ncallable.method(:call).curry[value] # won't work!\r\n```\r\n\r\nConsequently, I propose adding a built-in Ruby way to coerce anything callable to a proc (examples in Ruby):\r\n\r\n### Option 1: `Object#to_proc`\r\n\r\n```ruby\r\nclass Object\r\n  def to_proc\r\n    return method(:call).to_proc if respond_to?(:call)\r\n  \r\n    raise \"Needs to respond to :call\"\r\n  end\r\nend\r\n\r\nclass Proc\r\n  def to_proc\r\n    self\r\n  end\r\nend\r\n\r\ncallable.to_proc.curry[value]\r\n```\r\n\r\n### Option 2. `Kernel#Proc`\r\n\r\n```ruby\r\nclass Kernel\r\n  def Proc(value)\r\n    if value.is_a?(::Proc)\r\n      value\r\n    elsif value.respond_to?(:call)\r\n      value.method(:call).to_proc\r\n    else\r\n      raise \"Needs to implement :call\"\r\n    end\r\n  end\r\nend\r\n\r\nProc(callable).curry[value]\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-18T05:48:52Z", "updated_on": "2022-06-18T17:28:13Z", "closed_on": null, "relations": []}, {"id": 18642, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "subject": "Named ripper fields", "description": "One of the biggest pain-points working with the existing ripper subclasses is that you have to know what each array index represents in any given node. I'm proposing adding a subclass of ripper where every field is named so that it makes it easier to work with different versions of ruby. The PR is here: https://github.com/ruby/ruby/pull/5679. Below is copied the description from the PR.\r\n\r\nThis is a new subclass of the Ripper parser. It is based on/extracted from the work done in https://github.com/ruby-syntax-tree/syntax_tree. This subclass is similar to SexpBuilderPP in that it provides individual shapes per production rule from ripper. However, there are a couple of differences:\r\n\r\n* Tree uses class instances instead of arrays to represent nodes.\r\n* Comments are automatically attached to the various nodes when parsing is finished.\r\n* A couple of additional nodes are added for clarity (i.e., ArgStar, Not, PinnedBegin, etc.).\r\n* Every node has location information attached to it (as opposed to just the scanner event nodes).\r\n* There's a standard interface for descending the tree (child_nodes).\r\n* Additionally, each node has pattern matching (both array and hash patterns) as well as pretty_print defined to make it easier to work with.\r\n\r\nI think we should ship this with Ruby to make it easier to build tools (like formatters and linters) on top of this structure. It also will make it easier to change the parser in the future (if we ever do) because any tools built on top of these objects will not have to worry about the specific order of the nodes (unlike the SexpBuilderPP version) since everything has a named field. Additionally, since everything is written in pure Ruby, it makes it easy for other implementations of Ruby to benefit.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-17T21:36:18Z", "updated_on": "2022-05-12T13:37:41Z", "closed_on": null, "relations": []}, {"id": 18640, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48480, "name": "dorianmariefr (Dorian Mari\u00e9)"}, "subject": "default empty string argument for `String#sub` and `String#sub!`, e.g. `\"hello\".sub(\"l\")`", "description": "Most of the time I replace a string with an empty string. And I think that's the main use case.\r\n\r\nAlso, `String#delete` deletes every character provided when passed a string.\r\n\r\n```ruby\r\nclass String\r\n  alias original_sub sub\r\n  alias original_sub! sub!\r\n\r\n  def sub(pattern, replacement = \"\", &block)\r\n    original_sub(pattern, replacement, &block)\r\n  end\r\n\r\n  def sub!(pattern, replacement = \"\", &block)\r\n    original_sub!(pattern, replacement, &block)\r\n  end\r\nend\r\n\r\nputs \"hello\".sub(\"l\")\r\nputs \"hello\".sub!(\"l\")\r\n```\r\n\r\nWhat do you think?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-17T14:46:34Z", "updated_on": "2022-03-19T02:33:30Z", "closed_on": null, "relations": []}, {"id": 18639, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Update Unicode data to Unicode Version 15.0.0", "description": "Unicode Version 15.0.0 is currently in alpha.\r\n\r\nSee the announcement at http://blog.unicode.org/2022/02/unicode-150-alpha-review.html. At this time, we cannot test this, because not all necessary data files are available yet. The beta period is scheduled to start in late May, 2022.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-16T23:21:05Z", "updated_on": "2022-03-22T19:38:15Z", "closed_on": null, "relations": [{"id": 3275, "issue_id": 18037, "issue_to_id": 18639, "relation_type": "relates", "delay": null}]}, {"id": 18634, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "subject": "Variable Width Allocation: Arrays", "description": "# GitHub PR: https://github.com/ruby/ruby/pull/5660\r\n\r\n# Feature description\r\n\r\nThis patch changes arrays to allocate through Variable Width Allocation.\r\n\r\nSimilar to strings (implemented in ticket [#18239](https://bugs.ruby-lang.org/issues/18239)), arrays allocated through Variable Width Allocation are embedded, meaning the contents of the array directly follow the array object headers.\r\n\r\nWhen an array is resized, we fallback to allocating memory through the malloc heap. If the array was initially allocated in a larger slot, it would result in wastage of memory. However, in the benchmarks below, we can see that this wastage does not cause memory usage to increase significantly.\r\n\r\n# What's next\r\n\r\nWe're working on implementing cross size pool compaction for Variable Width Allocation. This will allow us to both downsize objects (to save memory) and upsize objects (to improve cache performance).\r\n\r\nWe're going to continue on implementing more types on Variable Width Allocation, such as Objects, Hashes, and ISeqs.\r\n\r\n# Benchmark setup\r\n\r\nBenchmarking was done on a bare-metal Ubuntu machine on AWS. All benchmark results are using glibc by default, except when jemalloc is explicitly specified.\r\n\r\n```\r\n$ uname -a\r\nLinux 5.13.0-1014-aws #15~20.04.1-Ubuntu SMP Thu Feb 10 17:55:03 UTC 2022 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nglibc version:\r\n\r\n```\r\n$ ldd --version\r\nldd (Ubuntu GLIBC 2.31-0ubuntu9.2) 2.31\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\nWritten by Roland McGrath and Ulrich Drepper.\r\n```\r\n\r\njemalloc version:\r\n\r\n```\r\n$ apt list --installed | grep jemalloc\r\n\r\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\nlibjemalloc-dev/focal,now 5.2.1-1ubuntu1 amd64 [installed]\r\nlibjemalloc2/focal,now 5.2.1-1ubuntu1 amd64 [installed,automatic]\r\n```\r\n\r\nTo measure memory usage over time, the [mstat tool](https://github.com/bpowers/mstat) was used.\r\n\r\nmaster was benchmarked on commit [bec492c77e](https://github.com/ruby/ruby/commit/bec492c77ed7659cafd2447cd042acde489c8d28). The branch was rebased on top of the same commit.\r\n\r\n## railsbench\r\n\r\nFor railsbench, we ran the [railsbench benchmark](https://github.com/k0kubun/railsbench/blob/master/bin/bench). For both the performance and memory benchmarks, 25 runs were conducted for each combination (branch + glibc, master + glibc, branch + jemalloc, master + jemalloc).\r\n\r\nFor both glibc and jemalloc allocators, there is not a significant change in RPS, response times, or max memory usage. We can see in the RSS over time graph that the memory behavior of the branch and master is very similar.\r\n\r\n### glibc\r\n\r\n```\r\n+-----------------------+--------+--------+-------------+\r\n|                       | Branch | master | Improvement |\r\n+-----------------------+--------+--------+-------------+\r\n| RPS                   | 810.38 | 809.50 | 1.00x       |\r\n| p50 (ms)              | 1.20   | 1.20   | 1.00x       |\r\n| p90 (ms)              | 1.32   | 1.32   | 1.00x       |\r\n| p99 (ms)              | 1.75   | 1.72   | 0.98x       |\r\n| p100 (ms)             | 5.53   | 6.02   | 1.09x       |\r\n| Max memory usage (MB) | 90.19  | 90.45  | 1.00x       |\r\n+-----------------------+--------+--------+-------------+\r\n```\r\n\r\n![](https://user-images.githubusercontent.com/15860699/157101671-98568350-8960-4a33-8e55-856ab32a4bc1.png)\r\n\r\n\r\n### jemalloc\r\n\r\n```\r\n+-----------------------+--------+--------+-------------+\r\n|                       | Branch | master | Improvement |\r\n+-----------------------+--------+--------+-------------+\r\n| RPS                   | 834.04 | 840.81 | 0.99x       |\r\n| p50 (ms)              | 1.18   | 1.17   | 0.99x       |\r\n| p90 (ms)              | 1.27   | 1.26   | 0.99x       |\r\n| p99 (ms)              | 1.69   | 1.65   | 0.98x       |\r\n| p100 (ms)             | 5.54   | 7.03   | 1.27x       |\r\n| Max memory usage (MB) | 88.50  | 87.48  | 0.99x       |\r\n+-----------------------+--------+--------+-------------+\r\n```\r\n\r\n![](https://user-images.githubusercontent.com/15860699/157101712-27d3e02f-4611-45b6-9c8b-c5983c301817.png)\r\n\r\n## discourse\r\n\r\nDiscourse was benchmarked through the [`script/bench.rb`](https://github.com/discourse/discourse/blob/main/script/bench.rb) benchmarking script. The response times for the `home` endpoint and RSS memory usage is shown below.\r\n\r\nWe see a slight increase in memory usage (5%) with glibc and an insignificant memory usage increase with jemalloc. We don't see big differences in response times.\r\n\r\n### glibc\r\n\r\n```\r\n+-----------+--------+--------+-------------+\r\n|           | Branch | master | Improvement |\r\n+-----------+--------+--------+-------------+\r\n| p50 (ms)  | 75     | 76     | 1.01x       |\r\n| p90 (ms)  | 88     | 90     | 1.02x       |\r\n| p99 (ms)  | 248    | 261    | 1.05x       |\r\n| RSS (MB)  | 364.48 | 383.80 | 1.05x       |\r\n+-----------+--------+--------+-------------+\r\n```\r\n\r\n### jemalloc\r\n\r\n```\r\n+-----------+--------+--------+-------------+\r\n|           | Branch | master | Improvement |\r\n+-----------+--------+--------+-------------+\r\n| p50 (ms)  | 73     | 73     | 1.00x       |\r\n| p90 (ms)  | 84     | 86     | 1.02x       |\r\n| p99 (ms)  | 241    | 242    | 1.00x       |\r\n| RSS (MB)  | 347.56 | 349.86 | 1.01x       |\r\n+-----------+--------+--------+-------------+\r\n```\r\n\r\n## rdoc generation\r\n\r\nIn rdoc generation, we see a small improvement in performance in glibc and no change in performance for jemalloc. We see a small max memory usage increase for both glibc and jemalloc. Howevver, the RSS over time graph shows that except for the very end, the branch actually has lower memory usage than master.\r\n\r\n### glibc\r\n\r\n```\r\n+-----------------------+--------+--------+-------------+\r\n|                       | Branch | master | Improvement |\r\n+-----------------------+--------+--------+-------------+\r\n| Time (s)              | 17.81  | 18.11  | 1.02x       |\r\n| Max memory usage (MB) | 287.74 | 283.24 | 0.98x       |\r\n+-----------------------+--------+--------+-------------+\r\n```\r\n\r\n![](https://user-images.githubusercontent.com/15860699/157101976-805bde67-897e-473e-a2b7-16cdba7d21e4.png)\r\n\r\n### jemalloc\r\n\r\n```\r\n+-----------------------+--------+--------+-------------+\r\n|                       | Branch | master | Improvement |\r\n+-----------------------+--------+--------+-------------+\r\n| Time (s)              | 17.59  | 17.46  | 0.99x       |\r\n| Max memory usage (MB) | 289.92 | 277.30 | 0.96x       |\r\n+-----------------------+--------+--------+-------------+\r\n```\r\n\r\n![](https://user-images.githubusercontent.com/15860699/157102010-ad5cd8b9-91ab-4058-8e1b-35bdf2af47a4.png)\r\n\r\n## optcarrot\r\n\r\nWe don't see a change in performance in optcarrot.\r\n\r\n```\r\n+------+--------+--------+-------------+\r\n|      | Branch | master | Improvement |\r\n+------+--------+--------+-------------+\r\n| FPS  | 43.10  | 43.25  | 1.00x       |\r\n+------+--------+--------+-------------+\r\n```\r\n\r\n## Liquid benchmarks\r\n\r\nWe don't see a big change in performance in liquid benchmarks.\r\n\r\n```\r\n+----------------------+--------+--------+-------------+\r\n|                      | Branch | master | Improvement |\r\n+----------------------+--------+--------+-------------+\r\n| Parse (i/s)          | 39.57  | 40.43  | 0.98x       |\r\n| Render (i/s)         | 129.78 | 130.22 | 1.00x       |\r\n| Parse & Render (i/s) | 28.43  | 28.89  | 0.98x       |\r\n+----------------------+--------+--------+-------------+\r\n```\r\n\r\n## Microbenchmarks\r\n\r\nThese microbenchmarks are very favourable for VWA since the arrays created have a length of 10, so they are embedded in VWA and allocated on the malloc heap for master.\r\n\r\n```\r\n+-------------+--------+--------+-------------+\r\n|             | Branch | master | Improvement |\r\n+-------------+--------+--------+-------------+\r\n| Array#first | 2.282k | 2.014k | 1.13x       |\r\n| Array#last  | 2.095k | 2.092k | 1.00x       |\r\n| Array#[0]=  | 2.232k | 2.079k | 1.07x       |\r\n| Array#[-1]= | 2.181k | 2.064k | 1.06x       |\r\n| Array#each  | 319.92 | 314.22 | 1.02x       |\r\n+-------------+--------+--------+-------------+\r\n```\r\n\r\n{{collapse(Benchmark source code)\r\n\r\n\r\n```ruby\r\nrequire \"bundler/inline\"\r\ngemfile do\r\n  source \"https://rubygems.org\"\r\n  gem \"benchmark-ips\"\r\nend\r\n\r\nCOUNT = 10_000\r\n\r\narrays = []\r\n\r\nCOUNT.times do\r\n  arrays << Array.new(10)\r\nend\r\n\r\nBenchmark.ips do |x|\r\n  x.report(\"Array#first\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| arrays[i].first }\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"Array#last\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| arrays[i].last }\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"Array#[0]=\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| arrays[i][0] = 0 }\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"Array#[-1]=\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| arrays[i][-1] = 9 }\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"Array#each\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| arrays[i].each { |x| } }\r\n      i += 1\r\n    end\r\n  end\r\nend\r\n```\r\n}}\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-15T13:39:44Z", "updated_on": "2022-03-22T13:43:29Z", "closed_on": "2022-03-22T13:43:29Z", "relations": []}, {"id": 18630, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce general `IO#timeout` and `IO#timeout=`for all (non-)blocking operations.", "description": "I would like us to consider introducing a general IO timeout for all (non-)blocking operations, specified per-IO instance. It's useful for ensuring programs don't stop responding or spend an unreasonable amount of time waiting for IO operations.\r\n\r\nThere are effectively two kinds of interfaces that we need to address:\r\n\r\n- Those that already have a timeout argument (e.g. `wait_readable`) and we follow the existing semantics.\r\n- Those that don't have a timeout argument or timeout semantics (e.g. `puts`, `gets`), and thus probably need to raise an exception on timeout.\r\n\r\nWe have three possible kinds of exceptions we could raise:\r\n\r\n- `Errno::ETIMEDOUT`\r\n- `Timeout::Error` (from `timeout.rb`)\r\n- Introduce `IO::Timeout` or something similar.\r\n\r\nTimeout isn't necessarily an error condition. There are different arguments for whether we should define:\r\n\r\n```ruby\r\nclass IO::Timeout < Exception\r\nend\r\n\r\n# or\r\n\r\nclass IO::Timeout < StandardError\r\nend\r\n```\r\n\r\nI believe the latter (`StandardError`) is more practical but I'm open to either option. I might have more specific arguments later why one is better than the other after testing in a practical system.\r\n\r\nThere is already a PR to try it out: https://github.com/ruby/ruby/pull/5653", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-14T02:43:43Z", "updated_on": "2022-04-21T09:36:40Z", "closed_on": null, "relations": []}, {"id": 18626, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3418, "name": "takiuchi (Genki Takiuchi)"}, "subject": "\u6ce8\u91c8\u4ed8\u304d\u4ee3\u5165\u6f14\u7b97\u5b50 ()= \u306e\u63d0\u6848", "description": "\u578b\u5236\u7d04\u3092\u5b9f\u73fe\u3059\u308b\u305f\u3081\u306b\u4ee5\u4e0b\u306e\u3088\u3046\u306a\u6ce8\u91c8\u4ed8\u304d\u4ee3\u5165\u6f14\u7b97\u5b50\u3092\u63d0\u6848\u3057\u307e\u3059\u3002\r\n\r\n```\r\nclass Object\r\n  def self.()= (what)\r\n    what.is_a? self or raise TypeRestrictionError\r\n  end\r\nend\r\n\r\nage (Fixnum) = 30\r\n\r\ndef add(a(Numeric), b(Numeric))\r\n  a + b\r\nend\r\nadd 1, \"2\" # raises TypeRestrictionError\r\n```\r\n\r\n\u5de6\u8fba\u5024\u306e\u5f8c\u306b`(...)` \u304c\u7d9a\u3044\u305f\u5834\u5408\u306b`()`\u5185\u306e\u5024\u306b\u5bfe\u3057\u3066`()=`\u6f14\u7b97\u5b50\u3092\u547c\u3073\u51fa\u3057\u307e\u3059\u3002\r\nRuby\u306f\u30e1\u30bd\u30c3\u30c9\u306e\u8fd4\u308a\u5024\u304c\u5de6\u8fba\u5024\u306b\u306a\u308b\u3053\u3068\u306f\u7121\u3044\u306e\u3067\u65e2\u5b58\u306e\u6587\u6cd5\u3068\u306f\u885d\u7a81\u3057\u306a\u3044\u304b\u306a\u3068\u3002\r\n\r\n\u4ee5\u4e0b\u306e\u3088\u3046\u306aenum\u7684\u306a\u5236\u7d04\u3082\u4fbf\u5229\u3060\u3068\u601d\u3044\u307e\u3059\u3002\r\n\r\n```\r\nclass Array\r\n  def ()= (what)\r\n    self.include? what or raise ValueRestrictionError\r\n  end\r\nend\r\n\r\nflag([1,2,3]) = 3\r\n```\r\n\r\n\u3044\u304b\u304c\u3067\u3057\u3087\u3046\u304b\u3002", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-12T01:47:08Z", "updated_on": "2022-03-20T14:24:49Z", "closed_on": "2022-03-20T14:24:49Z", "relations": []}, {"id": 18621, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Fiber.yield loses the fact it was kwargs from Fiber#resume", "description": "```ruby\r\nf = Fiber.new do\r\n  args = Fiber.yield\r\n  args\r\nend\r\nf.resume\r\nargs = f.resume(a: 1)\r\nHash.ruby2_keywords_hash?(args) # => false, but should be true, isn't it?\r\n```\r\n\r\nThis also means if there is `foo(*args)` later and `foo` would require kwargs it would fail:\r\n\r\n```ruby\r\ndef foo(a: 1) = a\r\n\r\nf = Fiber.new do\r\n  args = Fiber.yield\r\n  args\r\nend\r\nf.resume\r\nargs = f.resume(a: 1)\r\nfoo(*args)\r\n# =>\r\n# -:1:in `foo': wrong number of arguments (given 1, expected 0) (ArgumentError)\r\n# \tfrom -:9:in `<main>'\r\n```\r\n\r\ncc @jeremyevans0 @mame", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-10T15:12:45Z", "updated_on": "2022-03-10T17:47:34Z", "closed_on": "2022-03-10T17:46:05Z", "relations": []}, {"id": 18619, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 31800, "name": "eightbitraptor (Matthew Valentine-House)"}, "subject": "Reverse the order of GC Compaction cursor movement", "description": "# Reverse the order of GC Compaction cursor movement\r\n\r\n\r\n**Github PR: [https://github.com/ruby/ruby/pull/5637](https://github.com/ruby/ruby/pull/5637)**\r\n\r\n\r\n## Summary\r\n\r\nThe current compaction algorithm works by walking up the heap until it finds a slot to fill and then asking \"what object can I use to fill this slot\"\r\n\r\nThis PR reverses the cursor movement to walk down the heap until it gets to a moveable live object and then asking \"where is the best place to put this object\"\r\n\r\nThis animation shows a very simplified view of what we mean by \"reversing the cursor movement\"\r\n\r\n![](https://i.imgur.com/LT2L6Ep.gif)\r\n\r\n## Rationale\r\n\r\nThe current approach works well for a single heap containing fixed width slots because both empty and filled slots within that heap are a known and consistent size, and there is only a single set of scan/compact cursors to manage.\r\n\r\nNow that the memory space contains multiple size pools, each containing their own heap and scan/compact cursors the current approach has some problems:\r\n\r\n- **Moving objects between pools is hard**\r\n    \r\n  Objects that are mutable, such as strings, can be made larger(eg. using `String#<<`). Currently, when this modification happens we have no way of moving the object to a larger size pool, so we fall back to using `malloc` to allocate the buffer. By doing this we lose the cache locality benefits that VWA provides.\r\n\r\n  The current compaction algorithm makes moving these objects hard. by starting with an empty slot of a known size, determining what to fill it with (an object from the same heap, or from a different heap that wants to move) would involve either more heap scans, or a data structure to keep track of resized objects that can move between pools.\r\n\r\n- **Only the first size pool (40 byte slot_size) is being swept**\r\n    \r\n  The current compaction algorithm uses a global flag attached to `rb_objspace`.  When compaction is triggered, the flag is set true, and compaction starts scanning the size pools (starting with the smallest) until the scan/compact cursors have met.\r\n\r\n  As soon as the first size pool has finished compacting and the cursors have met, the current implementation assumes that compaction has finished, updates the references and disables the global compaction flag, resulting in no compaction of any size pools other than the smallest.\r\n\r\n## Implementation\r\n\r\nThis PR implements an algorithm that flips the order in which we consider the scan and compact cursors. That is: Rather than discovering an empty slot and attempting to fill it, we discover an object that can move, and then find an appropriate place for it.\r\n\r\nThe outline of the new algorithm (in pseudo-Ruby) looks like this:\r\n\r\n```\r\ndef find_destination_heap(slot)\r\n  # Future versions of this work will determine the most space \r\n  # efficient heap in which to move this object to. This version \r\n  # always keeps it within the same heap\r\n  \r\n  slot.heap\r\nend\r\n\r\ndef gc_compact\r\n  until all_cursors_met do\r\n    size_pools.each do |pool|\r\n      pool.heap.compact_cursor.each_slot do |slot|\r\n        if is_moveable?(slot)\r\n          destination_heap = find_destination_heap(slot)\r\n\r\n          until move(src: slot, dest: destination_heap.scan_cursor)\r\n            sweep(destination_page)\r\n\r\n            unless has_free_slots(destination_page)\r\n              increment_scan_cursor(destination_heap)\r\n            end\r\n          end\r\n        end\r\n      end\r\n\r\n      decrement_compact_cursor(pool.heap)\r\n    end\r\n  end\r\nend\r\n\r\nupdate_references\r\n```\r\n\r\nSome considerations of the new approach are:\r\n\r\n- In this initial implementation the destination heap is always the same as the source heap. No movement between size pools is taking place. This is for backward compatibility with the existing compaction algorithm. _Movement between size pools will be added as a seperate feature_.\r\n  \r\n- We compact a single page from each pool in the loop rather than compacting one pool to completion and then moving to the next. This is to give objects that wish to move between pools chance to do so. If we compacted an entire heap before moving to the next, we risk filling the heap and not providing opportunity for objects in different heaps the chance to move into it.\r\n\r\n## Measuring compaction\r\n\r\n### Railsbench heap visualisation\r\n\r\nWe [wrote a tool to help visualise the heap](https://github.com/eightbitraptor/heapviz) before and after compaction.\r\n\r\nWe ran a [patched version of railsbench](https://github.com/eightbitraptor/railsbench/commit/482bdcf738464d3be4d14428a3739dbcf395e359) to dump the heap before and after compaction on master and this branch. \r\n\r\nColours in the visualisation correspond to different size pools. Pools are ordered from left to right - 40 bytes, 80 bytes, 160 bytes, 320 bytes. Empty slots are white, and pinned slots are coloured black.\r\n\r\nResults are:\r\n#### Before compaction (master)\r\n![](https://i.imgur.com/JN1FpZz.png)\r\n\r\n#### After compaction (master)\r\n![](https://i.imgur.com/DODHNQb.png)\r\n\r\n#### Before compaction (this PR)\r\n![](https://i.imgur.com/Nm198Qw.png)\r\n\r\n#### After compaction (this PR)\r\n![](https://user-images.githubusercontent.com/31869/159297572-9b4ce551-7604-464d-b92e-3c10a6c93032.png)\r\n\r\n### Discourse benchmarks\r\n\r\nWe ran Discourse benchmarks for both master and this PR, with `GC.auto_compact=true` configured in `config/boot.rb`. \r\n\r\nBenchmarks were run using\r\n\r\n```\r\nruby script/bench.rb -i 100 -s\r\n```\r\n\r\nWe can see a slight slowdown when using auto_compact on this branch when compared with master. This can be attributed to the extra work the compactor is now doing as it's compacting all 4 size pools rather than just the first one.\r\n\r\nRaw results are as follows:\r\n\r\n```\r\n|                         | Master (auto-compact enabled)     | mvh-vwa-compaction (auto-compact enabled) |\r\n|-------------------------|-----------------------------------|-------------------------------------------|\r\n| categories              |                                   |                                           |\r\n| 50                      | 32                                | 53                                        |\r\n| 75                      | 33                                | 55                                        |\r\n| 90                      | 36                                | 55                                        |\r\n| 99                      | 186                               | 174                                       |\r\n| home                    |                                   |                                           |\r\n| 50                      | 58                                | 83                                        |\r\n| 75                      | 60                                | 86                                        |\r\n| 90                      | 65                                | 90                                        |\r\n| 99                      | 198                               | 289                                       |\r\n| topic                   |                                   |                                           |\r\n| 50                      | 35                                | 36                                        |\r\n| 75                      | 35                                | 39                                        |\r\n| 90                      | 36                                | 55                                        |\r\n| 99                      | 185                               | 175                                       |\r\n| categories_admin        |                                   |                                           |\r\n| 50                      | 35                                | 40                                        |\r\n| 75                      | 55                                | 55                                        |\r\n| 90                      | 57                                | 57                                        |\r\n| 99                      | 168                               | 65                                        |\r\n| home_admin              |                                   |                                           |\r\n| 50                      | 83                                | 58                                        |\r\n| 75                      | 87                                | 63                                        |\r\n| 90                      | 92                                | 83                                        |\r\n| 99                      | 243                               | 263                                       |\r\n| topic_admin             |                                   |                                           |\r\n| 50                      | 35                                | 35                                        |\r\n| 75                      | 35                                | 36                                        |\r\n| 90                      | 36                                | 36                                        |\r\n| 99                      | 160                               | 162                                       |\r\n| timings                 | load_rails: 2205                  | load_rails: 2116                          |\r\n| rss_kb                  | 303556                            | 350344                                    |\r\n| pss_kb                  | 293186                            | 340314                                    |\r\n| ruby-version            | 3.2.0-p-1                         | 3.2.0-p-1                                 |\r\n| processor0              | AMD Ryzen 5 3600 6-Core Processor | AMD Ryzen 5 3600 6-Core Processor         |\r\n| physicalprocessorcount: | 1                                 | 1                                         |\r\n| memorysize:             | 15.61 GiB                         | 15.61 GiB                                 |\r\n| kernelversion           | 5.16.11                           | 5.16.11                                   |\r\n| virtual                 | physical                          | physical                                  |\r\n| architecture            | x86_64                            | x86_64                                    |\r\n| operatingsystem         | Archlinux                         | Archlinux                                 |\r\n```\r\n\r\n## What's next\r\n\r\n* Discourse is showing slightly higher memory usage on this branch when compaction is enabled. This could be related to the slightly less efficient compaction results on the smallest size pool (see the differences in the Railsbench heap maps). We will be improving this algorithm to improve performance\r\n* Implement cross size pool movement, as this version of the algorithm still only moves objects within their existing size pool", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-10T09:57:29Z", "updated_on": "2022-04-01T12:46:14Z", "closed_on": "2022-04-01T12:46:14Z", "relations": []}, {"id": 18618, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52212, "name": "ed_ (Ed Mangimelli)"}, "subject": "no clobber def", "description": "Sometimes I want to be certain I'm not clobbering/masking a method:\r\n\r\n```\r\nclass Dog\r\n  def bark\r\n    'bark!'\r\n  end\r\nend\r\n\r\nclass Poodle < Dog\r\n  raise if method_defined? :bark\r\n  def bark\r\n    'bow-wow'\r\n  end\r\nend\r\n```\r\n\r\nI propose creating a shorthand. Maybe something like:\r\n\r\n```\r\nclass Dog\r\n  def bark\r\n    'bark!'\r\n  end\r\nend\r\n\r\nclass Poodle < Dog\r\n  ncdef bark        # \"no clobber\" def\r\n    'bow-wow'\r\n  end\r\nend\r\n\r\n=> #<MethodAlreadyDefined: Method `bark' already defined.>\r\n```\r\n\r\nThis would be useful in scenarios where subclassing a class (or including a mixin) ***you don't own*** is common practice --for instance, subclassing `ApplicationRecord` for your model in Rails.\r\n\r\nI agree that `ncdef` is pretty ugly. Maybe `def!` \r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-09T15:31:27Z", "updated_on": "2022-05-19T08:13:22Z", "closed_on": "2022-05-19T08:13:22Z", "relations": []}, {"id": 18617, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52210, "name": "ddfznt (Ederson Fuzinato)"}, "subject": "Allow multiples keys in Hash#[] acting like Hash#dig", "description": "# Abstract\r\n\r\nSince is very common the hash nested hashes, expecialy in the API world, I whold love to use Hash#[] syntax as alias for Hash#dig.\r\n\r\n# Background\r\n\r\nSince a start to learn ruby, Hashes are the most powerful structure I can use to build API. It's intuitive and concise way to represent data.\r\nBut something always make me unconfortable, the excess of square brackets([]) to access nested data.\r\nEverytime is a \"nasty\", to access things like \r\n``` ruby\r\npurchase[:customer][:addresses][:delivery][:street]\r\n```\r\neven worse when data is missing anypoint.\r\nSo, I meet the Hash#dig. Wonderful, easy, and powerful as well.\r\n\r\nBut .dig is not so intuitive, and I think, why not use the most common way to access data with multiple keys. \r\nWhy not use the most powerful method, with all powerfulness.\r\nWhy limitate Hash#[] to one single param. :( \r\n\r\n# Proposal\r\n\r\nSo, my proposal is to allow Hash#[] to take undefinily params, and act like .dig, more concise to access nested data, more powerful, more happy :D.\r\n\r\n**Stop:**\r\n``` ruby\r\nhash[:a][:b][:c][:d][:e][:f][:u]\r\n``` \r\n\r\n**Just:**\r\n\r\n``` ruby\r\nhash[:a, :b, :c, :d, :e, :lov, :u]\r\n``` \r\n\r\n# Implementation\r\n\r\nSince Hash#[] and Hash.dig, both calling Hash::new when key is not found, just check the arity for performance.\r\nCurrently, I use something like:\r\n\r\n``` ruby\r\nmodule AwesoneAccess\r\n  def [] *keys\r\n    if keys.many?\r\n      dig *keys\r\n    else\r\n      super\r\n    end\r\n  end\r\nend\r\n\r\nclass Hash\r\n  prepend AwesoneAccess\r\nend\r\n\r\na = {foo: {bar: :baz}} # => { foo: { bar: :baz }\r\n\r\na[:foo][:bar] == a[:foo, :bar] # => true\r\n```\r\n \r\n\r\n# Evaluation\r\n\r\nIt'll be awesome. (\uff89\u25d5\u30ee\u25d5)\uff89*:\uff65\uff9f\u2727 \u2727\uff9f\uff65: *\u30fd(\u25d5\u30ee\u25d5\u30fd)\r\n\r\n# Discussion\r\n\r\nI would love listen you guys.\r\nSincerely...\u0ca5_\u0ca5\r\n\r\n# Summary\r\n\r\nFaces by [[textfac.es]] ?!\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-08T21:52:59Z", "updated_on": "2022-03-10T13:36:25Z", "closed_on": null, "relations": []}, {"id": 18615, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Use -Werror=implicit-function-declaration by default for building C extensions", "description": "Currently, if a C extension refers a non-existing function it will continue to compile and only emit a warning.\r\nAnd compilation warnings are hidden by default for both `gem install` and `bundle install` (`gem install -V somegem` shows them).\r\n\r\nA concrete example is the sqlite3 gem, if we use version 1.3.13 it fails only at runtime:\r\n```\r\n$ gem install sqlite3:1.3.13\r\nFetching sqlite3-1.3.13.gem\r\nBuilding native extensions. This could take a while...\r\nSuccessfully installed sqlite3-1.3.13\r\n1 gem installed\r\n\r\n$ ruby -rsqlite3 -e 'db = SQLite3::Database.new \"test.db\"; p db'\r\nruby: symbol lookup error: /home/eregon/.rubies/ruby-3.0.2/lib/ruby/gems/3.0.0/gems/sqlite3-1.3.13/lib/sqlite3/sqlite3_native.so: undefined symbol: rb_check_safe_obj\r\n```\r\nThis is not nice, it should have failed clearly at compile time, saying the function does not exist.\r\n\r\nThere is a compiler warning, which can only be seen with (and so most users would miss it):\r\n```\r\n$ gem install -V sqlite3:1.3.13\r\n...\r\ndatabase.c: In function \u2018initialize\u2019:\r\ndatabase.c:60:3: warning: implicit declaration of function \u2018rb_check_safe_obj\u2019; did you mean \u2018rb_check_safe_str\u2019? [-Wimplicit-function-declaration]\r\n   60 |   rb_check_safe_obj(file);\r\n      |   ^~~~~~~~~~~~~~~~~\r\n      |   rb_check_safe_str\r\n...\r\n```\r\n\r\nAlso multiple CRuby releases are broken on macOS which seems to enable `-Werror=implicit-function-declaration` by default (e.g., #17777).\r\nEDIT: `-Werror=implicit-function-declaration` is now default for building CRuby, but not for C extensions.\r\n\r\nHow about we just always enable `-Werror=implicit-function-declaration` for all C extensions? (builtin or not). \r\n\r\nIt:\r\n* shows clear errors early on and shows where the missing function is called (explained just above), instead of delaying them to runtime\r\n* never compiles a call in C with the wrong type due to a missing include\r\n\r\nFrom https://github.com/oracle/truffleruby/issues/2618", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-08T13:01:56Z", "updated_on": "2022-03-17T05:42:13Z", "closed_on": "2022-03-17T05:42:13Z", "relations": []}, {"id": 18611, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8671, "name": "chrisseaton (Chris Seaton)"}, "subject": "Promote best practice for combining multiple values into a hash code", "description": "User-defined hash methods often work by combining the hash code of several values into one. This requires some logic to combine the values. In our experience, users are making a variety of choices for the algorithm for this, and in many cases are picking an option which may not be the best for security and performance in multiple ways. It's also a shame that users are having to think about how to do this basic operation themselves.\r\n\r\nFor example, this hash method creates a single hash code by combining the hash value of three values that make up the object. The user has combined the values using the xor operator and multiplication by prime numbers to distribute bits. This is an ok way to combine multiple values into a hash code.\r\n\r\n```ruby\r\ndef hash\r\n  x.hash ^ (y.hash * 3) ^ (z.hash * 5)\r\nend\r\n```\r\n\r\nBut users have to know to do this, and they sometimes get it wrong, writing things like this.\r\n\r\n```ruby\r\ndef hash\r\n  x.hash ^ y.hash ^ z.hash\r\nend\r\n```\r\n\r\nThis isn't distributing the bits very well. A bad hash code may harm performance if it cause more collisions in a hash table. Collisions may also cause excess cache eviction, which would further harm performance. If performance is reduced in this way there's a potential security risk due to denial-of-service. (We don't think this is an immediate practical security problem, which is why we're discussing in the open issue tracker, not the security mailing list.)\r\n\r\nThe `x.hash ^ (y.hash * 3) ^ (z.hash * 5)` pattern is still not ideal, as users have to manually write it, and it's a lot of logic to execute in the Ruby interpreter, when it could be possibly be done in native code instead. A better pattern we think is this:\r\n\r\n```ruby\r\ndef hash\r\n  [x, y, z].hash\r\nend\r\n```\r\n\r\nThis leaves the logic of creating a suitable and safe hash value to `[...].hash`, which does it correctly.\r\n\r\nWhy doesn't everyone already use this pattern? Because it's not documented as the right thing to do. We want to present a couple of options for what could be done to encourage people to use this pattern or an equivalent, to help people write more concise and clear code that is also more performant and secure.\r\n\r\n# Document `[...].hash` as best practice and optimise it\r\n\r\nIf we want people to use `[...].hash`, we should say that in the documentation for `Kernel#hash` as the best practice. Wording along the lines of\r\n\r\n> If you're implementing a hash code for a compound set of values, best practice is to combine them with `[...].hash`. For example....\r\n\r\nThis way people reading the documentation on `Kernel#hash` get pointed in the clear, concise, performant, secure direction.\r\n\r\nWe can combine this recommendation with an optimisation to `[...].hash` to remove the array allocation in implementation of Ruby without escape analysis and scalar replacement, similar to what is done for `Array#min` and `#max`. This way the best practice is even faster.\r\n\r\n# Introduce a new similar method, but specifically for the purpose so it is discoverable\r\n\r\nA second option is to introduce a new method, specifically for this task, `hash_objects(...)`. This is inspired By Java's `Objects.hash(...)`. The reason for the new method is that it should make it more discoverable - if you go looking for a tool to combine hash values you'd find one. We'd still link to it from `Kernel#hash`. This method would not require the array allocation removal optimisation, as it's just a simple call.\r\n\r\n# Examples of hash methods\r\n\r\nEven the MRI codebase has some suboptimal hash methods we don't need to look very far for examples. For example lib `lib/resolv.rb`, these two hash methods don't distribute the bits they combine\r\n\r\n* https://github.com/ruby/ruby/blob/c445963575a8572f6b0baf7135093c128adab3b9/lib/resolv.rb#L1734\r\n* https://github.com/ruby/ruby/blob/c445963575a8572f6b0baf7135093c128adab3b9/lib/resolv.rb#L1307\r\n\r\nBoth these examples could be replaced with either of our proposals.\r\n\r\nA good example of someone already using best practice is this.\r\n\r\n* https://github.com/ruby/ruby/blob/128972189284f4338722e8a910d0b4f6e7a02b31/lib/bundler/source/git.rb#L50\r\n\r\nBut this would still be faster with the optimisation we proposed, or using `hash_objects(...)`, as that'd remove the array allocation and the `hash` call.\r\n\r\n# Other things we've already done\r\n\r\nWe've proposed a RuboCop cop to try to catch the pattern we think is suboptimal https://github.com/rubocop/rubocop/pull/10441.\r\n\r\nCo-authored with @sambostock.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-03-07T17:57:17Z", "updated_on": "2022-05-10T06:24:17Z", "closed_on": "2022-04-30T10:58:27Z", "relations": []}, {"id": 18603, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52035, "name": "hmdne (hmdne -)"}, "subject": "Allow syntax like obj.method(arg)=value", "description": "I propose here to allow a syntax like:\r\n\r\n```ruby\r\nobj.method(arg) = value\r\n```\r\n\r\nIt would be translated to the following:\r\n\r\n```ruby\r\nobj.__send__(:method=, arg, value)\r\n```\r\n\r\nThe lack of this syntax kind of limits the ability to design DSLs in Ruby in my opinion. I don't think this would bring any conflicts with existing parser rules.\r\n\r\nMy proposal would be to put the value at the last argument, akin to how `[]=` works. So, for example this code would work:\r\n\r\n```ruby\r\nmodule Indexable\r\n  def dig=(*path, last, value)\r\n    if path.empty?\r\n      self[last] = value\r\n    else\r\n      first = path.shift\r\n      self[first]&.dig(*path, last) = value\r\n    end\r\n  end\r\nend\r\n\r\nHash.include Indexable\r\nArray.include Indexable\r\n```\r\n\r\nThe kwargs may be supported similarly to how they work on `[]=`, ie. becoming a penultimate Hash argument. While maybe not perfect, it is consistent with how `[]=` works and I imagine most usecases won't require kwargs.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-27T03:14:11Z", "updated_on": "2022-02-27T17:04:12Z", "closed_on": null, "relations": []}, {"id": 18598, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12, "name": "shugo (Shugo Maeda)"}, "subject": "Add String#bytesplice", "description": "I withdrew the proposal of String#bytesplice in #13110 because it may cause problems if the specified offset does not land on character boundary.\r\nBut how about to raise IndexError in such cases?\r\n\r\n```\r\n# encoding: utf-8\r\n\r\ns = \"\u3042\u3044\u3046\u3048\u304a\u304b\u304d\u304f\u3051\u3053\"\r\ns.bytesplice(9, 6, \"xx\")\r\np s #=> \"\u3042\u3044\u3046xx\u304b\u304d\u304f\u3051\u3053\"\r\ns.bytesplice(2, 3, \"x\") #=> offset 2 does not land on character boundary (IndexError)\r\ns.bytesplice(3, 4, \"x\") #=> offset 7 does not land on character boundary (IndexError)\r\n```\r\n\r\n## Pull request\r\n\r\nhttps://github.com/ruby/ruby/pull/5584\r\n\r\n## Spec\r\n\r\n```\r\nbytesplice(index, length, str) -> string\r\nbytesplice(range, str)         -> string\r\n```\r\n\r\nReplaces some or all of the content of +self+ with +str+, and returns +str+.\r\nThe portion of the string affected is determined using the same criteria as String#byteslice, except that +length+ cannot be omitted.\r\nIf the replacement string is not the same length as the text it is replacing, the string will be adjusted accordingly.\r\nThe form that take an Integer will raise an IndexError if the value is out of range; the Range form will raise a RangeError.\r\nIf the beginning or ending offset does not land on character (codepoint) boundary, an IndexError will be raised.\r\n\r\n## Motivation\r\n\r\nOn a text editor [Textbringer](https://github.com/shugo/textbringer/pull/31/files), the content of a buffer is represented by a String whose encoding is ASCII-8BIT, and `force_encoding(Encoding::UTF_8)` is called when necessary.\r\nIt's because point (cursor position) and marks are represented by byte offsets for performance, and currently there is no way to modify UTF-8 strings with byte offsets.\r\nIf String#bytesplice is introduced, the content of a text buffer can be represented by a UTF-8 string, and force_encoding can be removed: https://github.com/shugo/textbringer/pull/31/files\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-22T09:21:14Z", "updated_on": "2022-03-18T03:01:00Z", "closed_on": "2022-03-18T02:55:09Z", "relations": []}, {"id": 18597, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51329, "name": "danh337 (Dan H)"}, "subject": "Strings need a named method like `dup` that doesn't duplicate if receiver is mutable", "description": "This is related to #16295, but focuses only on the `.+@` part.\r\n\r\nCurrently we can use `.dup` in a method chain when we need to mutate a String.\r\n\r\nHowever there are cases where the code's context *expects* the String to be mutated. In cases like this, `.dup` always works, but we don't want to duplicate a String that is already mutable.\r\n\r\nSince `.+@` looks more like an operator, it can be unintuitive in a method chain, so this is asking for a new named method that can be used in its place, instead of always `.dup`.\r\n\r\nFor example:\r\n```\r\ndef add_result_text(buffer, new_result)\r\n  text = \"#{new_result.count} #{new_result.input} #{do_fancy_calc(new_result)}\\n\"\r\n  buffer.dup_if_immutable << text\r\n  #      ^^^^^^^^^^^^^^^^ new method?\r\nend\r\n\r\nbuffer = \"\" # ...maybe immutable\r\n\r\nget_lots_of_results.each do |result|\r\n  buffer = add_result_text(buffer, result) # In case it was dup'ed\r\nend\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-21T20:35:31Z", "updated_on": "2022-02-26T23:56:22Z", "closed_on": null, "relations": [{"id": 3263, "issue_id": 16295, "issue_to_id": 18597, "relation_type": "relates", "delay": null}]}, {"id": 18596, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 37693, "name": "jackmaple (maple jack)"}, "subject": "Enhance the syntax for getting values in existing arrays.", "description": "Hello everyone.\r\nIs it possible to enhance the value syntax in arrays, currently we can pass one or two parameters in the array to take values.\r\n``` ruby\r\n[1,2,3,4,5,6,7,8,9][2]    #result=3\r\n[1,2,3,4,5,6,7,8,9][2,8]  #result=[3, 4, 5, 6, 7, 8, 9]\r\n[1,2,3,4,5,6,7,8,9][-1]   #result=9\r\n```\r\nAlthough negative values are supported (from back to front), they are not supported as the second parameter.\r\nThe following example is wrong and will not get the desired result.\r\n**Is it possible to make the second parameter also support negative values?**\r\n``` ruby\r\n[1,2,3,4,5,6,7,8,9][2,-1] #result=nil,the expected result is from index 2 to the end\r\n```\r\nSometimes we want to get interval values with step size.\r\n``` ruby\r\n[1,2,3,4,5,6,7,8,9][(2..8).step(2)] #result=[3, 5, 7, 9]\r\n```\r\n**Is it possible to add a third parameter to the array value syntax in order to simplify the syntax?**\r\nfor example:\r\n``` ruby\r\n[1,2,3,4,5,6,7,8,9][2,8,2] #result=[3, 5, 7, 9]\r\n```\r\nthanks.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-21T16:16:04Z", "updated_on": "2022-02-22T10:58:02Z", "closed_on": "2022-02-21T17:56:17Z", "relations": []}, {"id": 18595, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Alias `String#-@` as `String#dedup`", "description": "This is a rescoped feature request for https://bugs.ruby-lang.org/issues/16295\r\n\r\n### Rationale\r\n\r\n[Unary operator have some precedence oddities](https://bugs.ruby-lang.org/issues/16150#note-39) (@headius)\r\n\r\nThis often force to use parentheses, which is awkward and breaks the chaining flow.\r\n\r\nIt's really not obvious what it does. I submitted many pull requests to various open source projects to reduce their memory footprint, and I am constantly asked what it does and I have to point to the `String#-@` documentation. [The last example was 3 days ago](https://github.com/dry-rb/dry-schema/pull/399#issuecomment-1043963073).\r\n\r\nI believe that `String#dedup` would help users discover this feature, and in projects where 3.2 is the oldest supported version, it would allow for much clearer code.\r\n\r\n### Proposal\r\n\r\nIt's all in the title: Alias `String#-@` as `String#dedup`.\r\n\r\nOr maybe even rename `String#-@` as `String#dedup`, and make `String#-@` the alias?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-21T10:56:56Z", "updated_on": "2022-05-20T18:32:58Z", "closed_on": "2022-05-20T18:32:58Z", "relations": [{"id": 3262, "issue_id": 16295, "issue_to_id": 18595, "relation_type": "relates", "delay": null}, {"id": 3337, "issue_id": 16150, "issue_to_id": 18595, "relation_type": "relates", "delay": null}]}, {"id": 18594, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52183, "name": "jimcavoli (Jim Cavoli)"}, "subject": "Add a #to_h method on URI::Generic", "description": "It's just surprisingly challenging to get a hash representation of a parsed URI where the keys are the component names and the values are the component values.\r\n\r\nThe shortest form I could come up with using only public methods on `URI::Generic` is rather clumsy-feeling:\r\n\r\n```ruby\r\nuri = ::URI.parse(url)\r\nhsh = [uri.component, uri.select(*uri.component)].transpose.to_h\r\n```\r\n\r\nHence this suggested patch: \r\n\r\n```\r\ndiff --git a/lib/uri/generic.rb b/lib/uri/generic.rb\r\nindex cfa0de6b74..f27a07a53c 100644\r\n--- a/lib/uri/generic.rb\r\n+++ b/lib/uri/generic.rb\r\n@@ -1367,6 +1367,13 @@ def to_s\r\n       str\r\n     end\r\n\r\n+    #\r\n+    # Returns a Hash representing the URI components\r\n+    #\r\n+    def to_h\r\n+      [component, component_ary].transpose.to_h\r\n+    end\r\n+\r\n     #\r\n     # Compares two URIs.\r\n     #\r\n```\r\n\r\nWhich would allow the much more ergonomic, idiomatic and terse usage:\r\n\r\n```ruby\r\nuri = ::URI.parse(url)\r\nhsh = uri.to_h\r\n```\r\n\r\nAlso happy to put together tests/specs for that as required.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-21T07:30:49Z", "updated_on": "2022-03-31T13:18:34Z", "closed_on": null, "relations": []}, {"id": 18593, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1098, "name": "kallisti5 (Alexander von Gluck)"}, "subject": "Add back URI.escape", "description": "It seems like there should have been a compatibility call left in place for the removal of URI escape between stdlib 2.x and 3.x\r\n\r\nAs seen here:\r\nhttps://github.com/qoobaa/s3/issues/132\r\n\r\nVarious projects are breaking due to the move of escape to DEFAULT_PARSER\r\n\r\n```\r\n--- /home/kallisti5/.gem/ruby/3.0.0/gems/s3-0.3.29/lib/s3/bucket.rb.original\t2022-02-18 13:26:37.247078560 -0600\r\n+++ /home/kallisti5/.gem/ruby/3.0.0/gems/s3-0.3.29/lib/s3/bucket.rb\t2022-02-18 13:26:47.707146732 -0600\r\n@@ -151,7 +151,7 @@\r\n       # If there are more than 1000 objects S3 truncates listing and\r\n       # we need to request another listing for the remaining objects.\r\n       while parse_is_truncated(response.body)\r\n-        next_request_options = {:marker => URI.escape(objects_attributes.last[:key])}\r\n+        next_request_options = {:marker => URI::DEFAULT_PARSER.escape(objects_attributes.last[:key])}\r\n \r\n         if max_keys\r\n           break if objects_attributes.length >= max_keys\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-18T19:33:31Z", "updated_on": "2022-02-18T19:45:29Z", "closed_on": null, "relations": [{"id": 3261, "issue_id": 17309, "issue_to_id": 18593, "relation_type": "relates", "delay": null}]}, {"id": 18589, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "subject": "Finer-grained constant invalidation", "description": "This is related to https://github.com/ruby/ruby/pull/5433.\r\n\r\n## Current behavior\r\n\r\nCaches depend on a global counter. All constant mutations cause all caches to be invalidated.\r\n\r\n```ruby\r\nclass A\r\n  B = 1\r\nend\r\n\r\ndef foo\r\n  A::B # inline cache depends on global counter\r\nend\r\n\r\nfoo # populate inline cache\r\nfoo # hit inline cache\r\n\r\nC = 1 # global counter increments, all caches are invalidated\r\n\r\nfoo # misses inline cache due to `C = 1`\r\n```\r\n\r\n## Proposed behavior\r\n\r\nCaches depend on name components. Only constant mutations with corresponding names will invalidate the cache.\r\n\r\n```ruby\r\nclass A\r\n  B = 1\r\nend\r\n\r\ndef foo\r\n  A::B # inline cache depends constants named \"A\" and \"B\"\r\nend\r\n\r\nfoo # populate inline cache\r\nfoo # hit inline cache\r\n\r\nC = 1 # caches that depend on the name \"C\" are invalidated\r\n\r\nfoo # hits inline cache because IC only depends on \"A\" and \"B\"\r\n```\r\n\r\nExamples of breaking the new cache:\r\n\r\n```ruby\r\nmodule C\r\n  # Breaks `foo` cache because \"A\" constant is set and the cache in foo depends\r\n  # on \"A\" and \"B\"\r\n  class A; end\r\nend\r\n\r\nB = 1\r\n```\r\n\r\nWe expect the new cache scheme to be invalidated less often because names aren't frequently reused. With the cache being invalidated less, we can rely on its stability more to keep our constant references fast and reduce the need to throw away generated code in YJIT.\r\n\r\n## Performance benchmarks\r\n\r\nThe following benchmark (included in this pull request) performs about 2x faster than master.\r\n\r\n```ruby\r\nCONSTANT1 = 1\r\nCONSTANT2 = 1\r\nCONSTANT3 = 1\r\nCONSTANT4 = 1\r\nCONSTANT5 = 1\r\n\r\ndef constants\r\n  [CONSTANT1, CONSTANT2, CONSTANT3, CONSTANT4, CONSTANT5]\r\nend\r\n\r\n500_000.times do\r\n  constants\r\n  INVALIDATE = true\r\nend\r\n```\r\n\r\nIn terms of macro benchmarks, I ran with this code on railsbench and there was not a statistically significant different in startup time or overall runtime performance.\r\n\r\n@byroot also ran performance benchmarks on our production application. He noticed that there were several cache busts related to Object#extend (from core libraries), ActiveRecord::Relation#extending (from Rails), and autoload (from various gems, both internal and external). After a lot of work, the cache busts went down:\r\n\r\n![Cache bust changes](https://user-images.githubusercontent.com/19192189/156726006-75aab77a-7fdf-47cf-88cb-1175f193c18a.png)\r\n\r\nbut they're still frequent enough that it's a problem. These changes had a measurable performance difference in request speed:\r\n\r\n![Request speed changes](https://user-images.githubusercontent.com/19192189/156727814-adb0f8b5-9012-4d2c-ab9c-b29d80748a5c.png)\r\n\r\n## Memory benchmarks\r\n\r\nIn terms of memory, this includes an increase in VM size by about 500KiB when running on railsbench. This is because we're now tracking cache associations ({ ID => IC[] }) on the VM to know how to invalidate specific caches when constants change.\r\n\r\nI booted Shopify's core monolith with this branch as well. It increased proportional to the number of constant caches found in the application. For each constant cache 1 level deep (e.g., `Foo`) the increase is about 33 bytes. For a constant cache 2 levels deep (e.g., `Foo::Bar`) the increase is about 67 bytes. The overall increase was around 16Mb or about 1% of the total retained memory.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-16T17:32:42Z", "updated_on": "2022-03-25T11:30:05Z", "closed_on": "2022-03-25T11:30:05Z", "relations": []}, {"id": 18585, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "Promote find pattern to official feature", "description": "\"Find pattern\" has introduced in 3.0 and it is still marked as an experimental.\r\nI don't see any problems, so it is time to promote it to official feature.\r\n\r\n(BTW, it was useful when writing code like the following for a practical example.)\r\n\r\n```ruby\r\nif ary in [*, {a: 0, b: 1 | 2} => i, *]\r\n  ...\r\nend\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-14T14:05:37Z", "updated_on": "2022-02-21T02:43:38Z", "closed_on": "2022-02-19T10:06:25Z", "relations": []}, {"id": 18583, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "Pattern-matching: API for custom unpacking strategies?", "description": "I started to think about it when discussing https://github.com/ruby/strscan/pull/30. \r\nThe thing is, usage of StringScanner for many complicated parsers invokes some kind of branching.\r\n\r\nIn pseudocode, the \"ideal API\" would allow to write something like this:\r\n```ruby\r\ncase <what next matches>\r\nin /regexp1/ => value_that_matched\r\n  # use value_that_matched\r\nin /regexp2/ => value_that_matched\r\n  # use value_that_matched\r\n# ...\r\n```\r\nThis seems \"intuitively\" that there *should* be some way of implementing it, but we fall short. We can do some StringScanner-specific matcher object which defines its own `#===` and use it with pinning:\r\n```ruby\r\ncase scanner\r\nin ^(Matcher.new(/regexp1/)) => value_that_matched\r\n# ...\r\n```\r\nBut there is no API to tell how the match result will be unpacked, just the whole `StringScanner` will be put into `value_that_matched`.\r\n\r\nSo, I thought that maybe it would be possible to define some kind of API for pattern-like objects, the method with signature like `try_match_pattern(value)`, which by default is implemented like `return value if self === value`, but can be redefined to return something different, like part of the object, or object transformed somehow.\r\n\r\nThis will open some interesting (if maybe uncanny) possibilities: not just slicing out the necessary part, but something like\r\n```ruby\r\nvalue => ^(type_caster(Integer)) => int_value\r\n```\r\n\r\nSo... Just a discussion topic!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-12T20:22:53Z", "updated_on": "2022-03-17T13:10:51Z", "closed_on": null, "relations": []}, {"id": 18579, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Concatenation of ASCII-8BIT strings shouldn't behave differently depending on string contents", "description": "Currently strings tagged with ASCII-8BIT will behave differently when concatenating depending on the string contents.\r\n\r\nWhen concatenating strings the resulting string has the encoding of the LHS.  For example:\r\n\r\n```\r\nz = a + b\r\n```\r\n\r\n`z` will have the encoding of `a` (if the encodings are compatible).\r\n\r\n\r\nHowever `ASCII-8BIT` behaves differently.  If `b` has \"ASCII-8BIT\" encoding, then the encoding of `z` will sometimes be the encoding of `a`, sometimes it will be the encoding of `b`, and sometimes it will be an exception.\r\n\r\nHere is an example program:\r\n\r\n```ruby\r\ndef concat a, b\r\n  str = a + b\r\n  str\r\nend\r\n\r\nconcat \"bar\",                     \"foo\".encode(\"US-ASCII\")    # Return value encoding is LHS, UTF-8\r\nconcat \"bar\".encode(\"US-ASCII\"),  \"foo\".b                     # Return value encoding is LHS, US-ASCII\r\nconcat \"\u307b\u3052\",                    \"foo\".b                     # Return value encoding is LHS, UTF-8\r\nconcat \"bar\",                     \"bad\\376\\377str\".b          # Return value encoding is RHS, ASCII-8BIT.  Why?\r\nconcat \"\u307b\u3052\",                    \"bad\\376\\377str\".b          # Exception\r\n```\r\n\r\nThis behavior is too hard to understand.  Usually we think LHS encoding will win, or there will be an exception. Even worse is that string concatenation can \"infect\" strings.  For example:\r\n\r\n\r\n```ruby\r\ndef concat a, b\r\n  str = a + b\r\n  str\r\nend\r\n\r\nstr = concat \"bar\", \"bad\\376\\377str\".b # this worked\r\np str\r\nstr = concat \"\u307b\u3052\", str               # exception\r\np str\r\n```\r\n\r\nThe first concatenation succeeded, but the second one failed.  As a developer it is difficult to find where the \"bad string\" was introduced.  In the above example, the string may have been read from the network, but by the time an exception is raised it is far from where the \"bad string\" originated.  In the above example, the bad data came from like 6, but the exception was raised on line 8.\r\n\r\nI propose that ASCII-8BIT strings raise an exception if they cannot be converted in to the LHS encoding.  So the above program would become like this:\r\n\r\n```ruby\r\ndef concat a, b\r\n  str = a + b\r\n  str\r\nend\r\n\r\nconcat \"bar\",                     \"foo\".encode(\"US-ASCII\")    # Return value encoding is LHS, UTF-8\r\nconcat \"bar\".encode(\"US-ASCII\"),  \"foo\".b                     # Return value encoding is LHS, US-ASCII\r\nconcat \"\u307b\u3052\",                    \"foo\".b                     # Return value encoding is LHS, UTF-8\r\nconcat \"bar\",                     \"bad\\376\\377str\".b          # Exception <--- NEW!!\r\nconcat \"\u307b\u3052\",                    \"bad\\376\\377str\".b          # Exception\r\n```\r\n\r\n\r\nI'm open to other solutions, but the underlying issue is that concatenating an ASCII-8BIT string with a non-ASCII-8BIT string is usually a bug and by the time an exception is raised, it is very far from the origin of the string.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-09T23:32:36Z", "updated_on": "2022-02-10T16:34:56Z", "closed_on": "2022-02-10T00:20:32Z", "relations": []}, {"id": 18576, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Rename `ASCII-8BIT` encoding to `BINARY`", "description": "### Context\r\n\r\nI'm now used to it, but something that confused me for years was errors such as:\r\n\r\n```ruby\r\n>> \"f\u00e9e\" + \"\\xFF\".b\r\n(irb):3:in `+': incompatible character encodings: UTF-8 and ASCII-8BIT (Encoding::CompatibilityError)\r\n```\r\n\r\nWhen you aren't that familiar with Ruby, it's really not evident that `ASCII-8BIT` basically means \"no encoding\" or \"binary\".\r\n\r\nAnd even when you know it, if you don't read carefully it's very easily confused with `US-ASCII`.\r\n\r\nThe `Encoding::BINARY` alias is much more telling IMHO.\r\n\r\n### Proposal\r\n\r\nSince `Encoding::ASCII_8BIT` has been aliased as `Encoding::BINARY` for years, I think renaming it to `BINARY` and then making asking `ASCII_8BIT` the alias would significantly improve usability without backward compatibility concerns.\r\n\r\nThe only concern I could see would be the consistency with a handful of C API functions:\r\n\r\n  - `rb_encoding *rb_ascii8bit_encoding(void)`\r\n  - `int rb_ascii8bit_encindex(void)`\r\n  - `VALUE rb_io_ascii8bit_binmode(VALUE io)`\r\n\r\nBut that's for much more advanced users, so I don't think it's much of a concern.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-08T09:08:05Z", "updated_on": "2022-03-17T15:06:32Z", "closed_on": "2022-02-17T09:14:53Z", "relations": []}, {"id": 18573, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 33140, "name": "os (Shigeki OHARA)"}, "subject": "Object#pack1", "description": "# \u6982\u8981\r\n\r\nString#unpack1 \u306e\u9006\u306e Object#pack1 \u304c\u6b32\u3057\u3044\u3002\r\n\r\n# \u80cc\u666f\r\n\r\nArray#pack \u3068\u3044\u3046\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308a\u307e\u3059\u304c\u3001\u30ec\u30b7\u30fc\u30d0\u30fc\u306e Array \u306e\u8981\u7d20\u6570\u304c 1 \u3064\u3057\u304b\u306a\u3044\u3053\u3068\u304c\u826f\u304f\u3042\u308a\u307e\u3059\u3002\r\n\r\n``` ruby\r\n[codepoint].pack('U')\r\n[digest].pack('m0')\r\n[mail_body].pack('M')\r\n[ip_address].pack('N')\r\n```\r\n\r\n\u6a19\u6e96\u6dfb\u4ed8\u30e9\u30a4\u30d6\u30e9\u30ea\u30fc\u306a\u3069\u3092\u773a\u3081\u3066\u307f\u3066\u3082\u30c1\u30e9\u30db\u30e9\u3042\u308b\u3088\u3046\u3067\u3059\u3002\r\n\r\n\u3067\u3059\u304c\u3001\u3053\u306e\u3088\u3046\u306a\u30b1\u30fc\u30b9\u3067\u5909\u63db\u5bfe\u8c61\u306e\u30aa\u30d6\u30b8\u30a7\u30af\u30c8\u3092\u308f\u3056\u308f\u3056 Array \u3067\u304f\u308b\u307e\u306a\u304f\u3066\u306f\u3044\u3051\u306a\u3044\u3068\u3044\u3046\u306e\u306f\u9762\u5012\u306a\u6c17\u3082\u3057\u307e\u3059\u3002\r\n\r\n# \u63d0\u6848\r\n\r\nString#unpack \u306b\u5bfe\u3057\u3066 String#unpack1 \u3068\u3044\u3046\u30e1\u30bd\u30c3\u30c9\u304c\u3042\u308a\u307e\u3059\u304c\u3001\r\nArray#pack \u306b\u5bfe\u3059\u308b Object#pack1 \u3068\u3044\u3046\u30e1\u30bd\u30c3\u30c9\u3092\u63d0\u6848\u3057\u307e\u3059\u3002\r\n\r\n\u30a4\u30e1\u30fc\u30b8\u3068\u3057\u3066\u306f\u4ee5\u4e0b\u306e\u30b3\u30fc\u30c9\u306e\u3088\u3046\u306a\u611f\u3058\u3067\u3059\u3002\r\n\r\n``` ruby\r\nclass Object\r\n  def pack1(template, option = {})\r\n    [self].pack(template, **option)\r\n  end\r\nend\r\n```\r\n\r\n# \u8b70\u8ad6\u30fb\u8ab2\u984c\r\n\r\n* Object \u3067\u826f\u3044\u304b\u3069\u3046\u304b\u306f\u8b70\u8ad6\u306e\u4f59\u5730\u304c\u3042\u308d\u3046\u304b\u3068\u601d\u3044\u307e\u3059\r\n* \u30e1\u30bd\u30c3\u30c9\u540d\u304c pack1 \u3067\u826f\u3044\u304b\u306f\u308f\u304b\u308a\u307e\u305b\u3093\u304c\u3001\u4ed6\u3068\u304b\u3076\u308b\u53ef\u80fd\u6027\u306f\u4f4e\u3044\u304b\u3068\u601d\u3044\u307e\u3059\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-06T16:33:01Z", "updated_on": "2022-02-08T08:51:36Z", "closed_on": null, "relations": []}, {"id": 18571, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "subject": "Removed the bundled sources from release package after Ruby 3.2", "description": "We shipped release package with the 3rd party source for mswin environment especially. \r\n\r\nThe current status is here:\r\n\r\n * libyaml: psych gem, ruby repo and package always bundled it.\r\n * libffi: only ruby package bundled it. fiddle gem and repo are not bundled.\r\n * zlib: gem, ruby repo and package don't bundled.\r\n\r\nI propose we stop bundling the third-party source for security and maintenance reasons. Because we have [vcpkg](https://github.com/microsoft/vcpkg) for mswin environment today. So, vcpkg provides the runtime for psych, fiddle and zlib.\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-04T11:45:12Z", "updated_on": "2022-03-28T06:23:49Z", "closed_on": "2022-03-28T06:05:58Z", "relations": [{"id": 3282, "issue_id": 18571, "issue_to_id": 18666, "relation_type": "relates", "delay": null}]}, {"id": 18568, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 286, "name": "headius (Charles Nutter)"}, "subject": "Explore lazy RubyGems boot to reduce need for --disable-gems", "description": "In https://bugs.ruby-lang.org/issues/17684 there was debate about whether the `--disable-gems` flag should be removed. Several folks were in favor, since Ruby without RubyGems is fairly limited, but others wanted to keep the flag for small, fast command line scripts that do not depend on RubyGems.\r\n\r\nLazily loading RubyGems might be a middle ground, and it has been explored in some depth by TruffleRuby:\r\n\r\nhttps://github.com/oracle/truffleruby/blob/master/src/main/ruby/truffleruby/core/lazy_rubygems.rb\r\n\r\n@eregon shows how this improves their startup time in this article from a couple years ago:\r\n\r\nhttps://eregon.me/blog/2019/04/24/how-truffleruby-startup-became-faster-than-mri.html\r\n\r\nI believe this approach has merit and could be beneficial to both CRuby and JRuby if we can collaborate on how the lazy loading should happen and figuring out where the edges are. @eregon may know some of those edges if they have run into them in TruffleRuby.\r\n\r\nA simple test of `--disable-gems` on CRuby 3.1 shows what an impact it has, which we might be able to duplicate in a lazy boot WITHOUT losing RubyGems functionality and default gem upgrading:\r\n\r\n```\r\n$ time ruby -e 1\r\n\r\nreal    0m0.107s\r\nuser    0m0.068s\r\nsys     0m0.030s\r\n\r\n$ time ruby --disable-gems -e 1\r\n\r\nreal    0m0.019s\r\nuser    0m0.007s\r\nsys     0m0.008s\r\n```\r\n\r\nOver 80% of CRuby's base startup is due to eagerly booting RubyGems. We can do better!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-02T19:13:52Z", "updated_on": "2022-02-17T07:15:43Z", "closed_on": null, "relations": [{"id": 3258, "issue_id": 17684, "issue_to_id": 18568, "relation_type": "relates", "delay": null}]}, {"id": 18566, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Merge `io-wait` and `io-nonblock` gems into core IO", "description": "I think we should reconsider status of `io-wait`, and consider simply merging it into core's `IO`.\r\n\r\nAccording to @nobu it's only a gem for \"historical\" reasons.\r\n\r\nAny non trivial IO code will likely make use of it, and it's just 400 lines of code.\r\n\r\nRecently with the extraction of `net-protocol`, it was added add a dependency and that caused Ruby 3.1 compatibility issues with some gems (e.g. with [`mail`](https://github.com/mikel/mail/pull/1439)).\r\n\r\n### Proposal\r\n\r\n  - Merge `io-wait` into `io.c` for Ruby 3.2\r\n  - Remove `io-wait` as a dependency of all gems maintained by `ruby-core` (e.g. `net-protocol`).\r\n  - Publish a new `io-wait` version that is simply an empty gem.\r\n  - Add a `lib/io/wait.rb` stub, with eventually a deprecation warning.\r\n\r\ncc @eregon @headius @mame @ioquatix", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-02T08:17:27Z", "updated_on": "2022-06-25T09:21:22Z", "closed_on": "2022-03-23T13:47:50Z", "relations": [{"id": 3257, "issue_id": 18566, "issue_to_id": 18567, "relation_type": "relates", "delay": null}, {"id": 3279, "issue_id": 18566, "issue_to_id": 18655, "relation_type": "relates", "delay": null}, {"id": 3283, "issue_id": 18566, "issue_to_id": 18668, "relation_type": "relates", "delay": null}]}, {"id": 18564, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Add Exception#detailed_message", "description": "(This ticket is for recording the final spec of #18438)\r\n\r\n## Proposal\r\n\r\nI would introduce a method `Exception#detailed_message`, and let the default error printer use it instead of `Exception#message` to create a error output.\r\n\r\n```\r\nclass MyClass < StandardError\r\n  def message = \"my error!\"\r\n  def detailed_message(highlight: false, **opt)\r\n    super + \"\\nThis is\\nan additional\\nmessage\"\r\n  end\r\nend\r\n\r\nraise MyClass\r\n```\r\n\r\n```\r\n$ ./miniruby test.rb\r\ntest.rb:8:in `<main>': my error! (MyClass)\r\nThis is\r\nan additional\r\nmessage\r\n```\r\n\r\nHere is the implementation: https://github.com/ruby/ruby/pull/5516\r\n\r\n## Spec\r\n\r\n`Exception#detailed_message(highlight: false)` calls `#message` and decorates the returned string. It may add the class name of exception and, when `highlight` keyword is true, some escape sequences for highlights.\r\n\r\n```\r\ne = RuntimeError.new(\"my error!\")\r\np e.detailed_message                  #=> \"my error! (RuntimeError)\"\r\np e.detailed_message(highlight: true) #=> \"\\e[1mmy error! (\\e[1;4mRuntimeError\\e[m\\e[1m)\\e[m\"\r\n```\r\n\r\nPreviously, the default error printer and `Exception#full_message` called `#message` to get the error message, applied some processing (adding the error class name and adding escape sequences) to the string, and added backtrace. Now, they now use `#detailed_message(highlight: Exception.to_tty?)` instead of `#message`.\r\n\r\nAll keyword arguments passed to `Exception#full_message` are delegated to `detailed_message`.\r\n\r\n## Motivation\r\n\r\nThe primary motivation is a clean integration of did_you_mean and error_highlight gems.\r\n\r\nAt the present time, they overrides `Exception#to_s` to add their suggestions. However, there are some known problems in this approach:\r\n\r\n* It may break some tests to check the result of `Exception#to_s` depending on whether the gems add suggestions or not.\r\n* Some Ruby scripts re-raise an exception by `raise e.class, e.message, e.backtrace`, which makes the gems add their suggestion multiple times (currently, [the gems ad-hocly check and avoid multiple addition](https://github.com/ruby/did_you_mean/blob/531760f323df8d43a7017af5a3052f20e8a03fda/lib/did_you_mean/core_ext/name_error.rb#L18)).\r\n* Sometimes a user needs to get the original message without their addition. For the sake, did_you_mean provides `Exception#original_message`, but [the workaround is not very well known](https://github.com/ruby/error_highlight/pull/10).\r\n\r\nThis proposal allows the gems to override `Exception#detailed_message`. `Exception#to_s` is kept as-is, so the above problems will no longer occur.\r\n\r\nAlso, the proposal allows a user to get a full_message without the suggestions by `err.full_message(did_you_mean: false, error_highlight: false)`.\r\n\r\nHere is a proof-of-concept patch for did_you_mean and error_highlight: https://gist.github.com/mame/2c34230f11237dc4af64510cb98acdd8 I'll create PRs for the gems after `Exception#detailed_message` is merged.\r\n\r\n# Cooperation needed\r\n\r\nThis change requires application monitoring services such as Sentry, DataDog, ScoutAPM, etc. They need to use `Exception#detailed_message(highlight: false)` instead of `Exception#message` to log the error messages after Ruby 3.2. Thankfully, @st0012 (the maintainer of Sentry's Ruby SDK) and @ivoanjo and @marcotc (the maintainers of Datadog's application monitoring gem) have agreed with this change.\r\n\r\nhttps://bugs.ruby-lang.org/issues/18438#note-1\r\nhttps://bugs.ruby-lang.org/issues/18438#note-9\r\n\r\n@matz has already approved this proposal in #18438 . I'll merge my PR in a few days after some reviews.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-01T19:49:25Z", "updated_on": "2022-02-01T20:06:34Z", "closed_on": null, "relations": []}, {"id": 18563, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6603, "name": "shan (Shannon Skipper)"}, "subject": "Add \"graphemes\" and \"each_grapheme\" aliases", "description": "https://bugs.ruby-lang.org/issues/13780#note-10\r\n\r\n> grapheme sounds like an element in the grapheme cluster. How about each_grapheme_cluster?\r\n> If everyone gets used to the grapheme as an alias of grapheme cluster, we'd love to add an alias each_grapheme.\r\n\r\n> Matz.\r\n\r\nLanguages that have added grapheme cluster support seem to be almost exclusively opting for the shorter \"graphemes\" alias as a part that stands for the whole.\r\n* JavaScript/TypeScript grapheme-splitter library: `splitGraphemes`\r\n* PHP: `grapheme_extract`\r\n* Zig ziglyph library: `GraphemeIterator`\r\n* Golang uniseg library: `NewGraphemes`\r\n* Matlab: `splitGraphemes`\r\n* Python grapheme library: `graphemes`\r\n* Elixir: `graphemes`\r\n* Crystal uni_text_seg library: `graphemes`\r\n* Nim nim-graphemes library: `graphemes`\r\n* Rust unicode-segmentation library: `graphemes`\r\n\r\nNow that some time has passed and the \"graphemes\" alias for \"grapheme clusters\" has been fairly widely adopted by languages and libraries, I'd like to go ahead and propose a `graphemes` alias for `grapheme_clusters` and an `each_grapheme` alias for `each_grapheme_cluster`.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-02-01T19:44:41Z", "updated_on": "2022-03-17T18:18:21Z", "closed_on": "2022-03-17T08:56:48Z", "relations": [{"id": 3256, "issue_id": 13780, "issue_to_id": 18563, "relation_type": "relates", "delay": null}]}, {"id": 18559, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Allocation tracing: Objects created by the parser are attributed to Kernel.require", "description": "Marking this as a feature, because I think it should be improved but can hardly be considered a bug.\r\n\r\n### Repro\r\n\r\nConsider the following script:\r\n\r\n```ruby\r\n# /tmp/allocation-source.rb\r\nrequire 'objspace'\r\nrequire 'tmpdir'\r\n\r\nsource = File.join(Dir.tmpdir, \"foo.rb\")\r\nFile.write(source, <<~RUBY)\r\n  # frozen_string_literal: true\r\n  class Foo\r\n    def plop\r\n      \"fizz\"\r\n    end\r\n  end\r\nRUBY\r\n\r\nObjectSpace.trace_object_allocations_start\r\n\r\nGC.start\r\ngen = GC.count\r\nrequire(source)\r\nObjectSpace.dump_all(output: $stdout, since: gen)\r\n```\r\n\r\n### Expected behavior\r\n\r\nI'd expect the `ObjectSpace.dump_all` output to attribute all new objects, including `T_IMEMO` etc, to `foo.rb`\r\n\r\n### Actual behavior\r\n\r\nThey are attributed to the source file that called `Kernel.require` (so with `--disable-gems`):\r\n\r\n```\r\n{\"address\":\"0x11acaec78\", \"type\":\"CLASS\", \"class\":\"0x11acaebb0\", \"superclass\":\"0x10fa4a848\", \"name\":\"Foo\", \"references\":[\"0x10fa4a848\", \"0x11acaea98\", \"0x11acaf790\"], \"file\":\"/var/folders/vy/srfpq1vn6hv5r6bzkvcw13y80000gn/T/foo.rb\", \"line\":2, \"generation\":1, \"memsize\":544, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaeca0\", \"type\":\"IMEMO\", \"class\":\"0x8\", \"imemo_type\":\"cref\", \"references\":[\"0x10fa4a848\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaecc8\", \"type\":\"STRING\", \"class\":\"0x10fa42418\", \"frozen\":true, \"embedded\":true, \"fstring\":true, \"bytesize\":4, \"value\":\"fizz\", \"encoding\":\"UTF-8\", \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaecf0\", \"type\":\"ARRAY\", \"class\":\"0x10fa28f68\", \"frozen\":true, \"length\":2, \"embedded\":true, \"references\":[\"0x11acaff88\", \"0x11acaf240\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaed18\", \"type\":\"IMEMO\", \"imemo_type\":\"iseq\", \"references\":[\"0x11acaecc8\", \"0x11acaf600\", \"0x11acaf600\", \"0x11acaecf0\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":416, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaf1a0\", \"type\":\"ARRAY\", \"class\":\"0x10fa28f68\", \"frozen\":true, \"length\":2, \"embedded\":true, \"references\":[\"0x11acaff88\", \"0x11acaf240\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaf1c8\", \"type\":\"IMEMO\", \"imemo_type\":\"iseq\", \"references\":[\"0x11acaed18\", \"0x11acaf1f0\", \"0x11acaf1f0\", \"0x11acaf1a0\", \"0x11acaf290\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":456, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaf1f0\", \"type\":\"STRING\", \"class\":\"0x10fa42418\", \"frozen\":true, \"embedded\":true, \"fstring\":true, \"bytesize\":11, \"value\":\"<class:Foo>\", \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaf218\", \"type\":\"ARRAY\", \"class\":\"0x10fa28f68\", \"frozen\":true, \"length\":2, \"embedded\":true, \"references\":[\"0x11acaff88\", \"0x11acaf240\"], \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x11acaf240\", \"type\":\"STRING\", \"class\":\"0x10fa42418\", \"frozen\":true, \"fstring\":true, \"bytesize\":63, \"value\":\"/private/var/folders/vy/srfpq1vn6hv5r6bzkvcw13y80000gn/T/foo.rb\", \"encoding\":\"UTF-8\", \"file\":\"/tmp/allocation-source.rb\", \"line\":19, \"method\":\"require\", \"generation\":1, \"memsize\":104, \"flags\":{\"wb_protected\":true}}\r\n....\r\n\r\n```\r\n\r\n### Why is it a problem?\r\n\r\nThis behavior makes it impossible to properly analyze which part of an application use the most memory. For instance when using `heap-profiler` on an app using `Bootsnap`, all objects created as a result of loading source file are attributed to bootsnap:\r\n\r\n```\r\nretained memory by gem\r\n-----------------------------------\r\n 351.64 MB  bootsnap-1.10.2\r\n```\r\n\r\nIf this behaved as I expect, `heap-profiler` would be able to report how much each gem contribute to the app RAM usage.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-31T12:14:42Z", "updated_on": "2022-06-27T14:48:26Z", "closed_on": null, "relations": []}, {"id": 18554, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 286, "name": "headius (Charles Nutter)"}, "subject": "Move unicode_normalize to a default gem", "description": "Could we move the rest of unicode_normalize to a default gem?\r\n\r\nThe recent updates were mostly updating the Unicode tables, which a user might want to be able to update in an existing Ruby installation. Additionally, this is one of the few stdlib we have to copy into JRuby from the CRuby repository; it would be easier for both if we just pulled in a default gem.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-27T16:49:48Z", "updated_on": "2022-01-31T17:51:12Z", "closed_on": null, "relations": []}, {"id": 18552, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Expose `VALUE rb_singleton_class_get(VALUE)` to extensions", "description": "Right now the only way to check wether an object has a singleton class is to do something akin to:\r\n\r\n```c\r\n!SPECIAL_CONST(obj) && FL_TEST(RBASIC(obj)->klass, FL_SINGLETON);\r\n```\r\n\r\nWhich doesn't seem very clean.\r\n\r\n### Use case\r\n\r\nThis came up in `msgpack`. The library have a registry of serializers on a per class basis, and wish to support singleton classes too.\r\nSo it is calling `rb_singleton_class()` which cause lots of useless singleton classes to be created: https://github.com/msgpack/msgpack-ruby/pull/245\r\n\r\n\r\n### Proposed patch\r\n\r\nhttps://github.com/ruby/ruby/pull/5499", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-27T11:57:21Z", "updated_on": "2022-01-28T09:43:43Z", "closed_on": "2022-01-28T09:43:43Z", "relations": []}, {"id": 18551, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 963, "name": "kyanagi (Kouhei Yanagita)"}, "subject": "Make Range#reverse_each to raise an exception if endless", "description": "https://github.com/ruby/ruby/pull/5498\r\n\r\nCurrently, `Range#reverse_each` for an endless range never returns.\r\n\r\n```\r\n% ruby -e '(1..).reverse_each { }'\r\n# never return ...\r\n```\r\n\r\n(This is because `Enumerable#reverse_each` tries `#to_a` and `#to_a` for an endless range comes into an infinite loop.)\r\n\r\nI think `Range#reverse_each` for an endless range should raise an exception, similar to `Range#each` for a beginless range.\r\n\r\n```\r\n% ruby -e '(..1).each { }' \r\n-e:1:in `each': can't iterate from NilClass (TypeError)\r\n\tfrom -e:1:in `<main>'\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-27T05:58:09Z", "updated_on": "2022-01-28T23:13:45Z", "closed_on": null, "relations": []}, {"id": 18515, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 963, "name": "kyanagi (Kouhei Yanagita)"}, "subject": "Add Range#reverse_each implementation for performance", "description": "PR is https://github.com/ruby/ruby/pull/5489\r\n\r\nCurrent `Range#reverse_each` uses `Enumerable#reverse_each` which is implemented with `#to_a`.\r\nSo we are virtually not able to use `reverse_each` for a very large or beginless range, even if few elements are iterated on actually.\r\n\r\n```\r\n(1..2**100).reverse_each { |x| p x; break if x.odd? }\r\n(..5).reverse_each { |x| p x; break if x == 0 }\r\n(1..2**32).reverse_each.lazy.select { |x| Prime.prime?(x) }.take(3).to_a\r\n```\r\n\r\nThis patch, implements `Range#reverse_each` for Integer elements,  enables these examples.\r\n\r\nI think `#reverse_each` for an endless range should raise an exception.\r\nThis is a different issue, so I'll create another ticket later.\r\n-> posted: https://bugs.ruby-lang.org/issues/18551", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-26T05:57:47Z", "updated_on": "2022-01-31T02:23:09Z", "closed_on": null, "relations": []}, {"id": 18513, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Hide patchlevel from `ruby -v`", "description": "We still show patch-level like `3.1.0p0` with `ruby -v`. But it has no benefit for users. \r\n\r\nIn fact, I heard \"What does \"p0\" mean?\" from Ruby programmer in this week.\r\n\r\nI think we should show only `3.2.0` after Ruby 3.2.0 for especially new users. ", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-25T12:39:29Z", "updated_on": "2022-02-17T06:03:11Z", "closed_on": "2022-02-17T06:03:11Z", "relations": []}, {"id": 18508, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 37693, "name": "jackmaple (maple jack)"}, "subject": "Is it possible to turn off irb autocomplete, it doesn't work very well in my visual studio code terminal.", "description": "Is it possible to turn off irb autocomplete, it doesn't work very well in my visual studio code terminal.\r\nWhen the content you enter is close to the bottom and there is not enough space for the content displayed in the autocomplete, it will cause the terminal to display incorrectly, the cursor will jump directly to the top, but the content below will not be cleared.\r\nSo I'm wondering if it's possible to turn off autocomplete until it works better.\r\nthanks.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-21T17:27:58Z", "updated_on": "2022-01-21T17:35:15Z", "closed_on": "2022-01-21T17:35:15Z", "relations": []}, {"id": 18498, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Introduce a public WeakKeysMap that compares by equality", "description": "This is a clean take on #16038 \r\n\r\n### Spec\r\n\r\n#### Weak keys only\r\n\r\nAfter a chat with @eregon we believe that what would make the most sense and would be most useful would be\r\na \"WeakKeysMap\". Meaning **the keys would be weak references, but the values would be strong references**.\r\nThis behavior is also consistent with the terminology in other popular languages such as Javascript and Java were `WeakMap` only have weak keys.\r\n\r\nBy default **it would use equality semantic, just like a regular `Hash`**. Having an option to compare by indentity instead\r\ncould be useful, but not strictly required.\r\n\r\n#### Immediate objects support\r\n\r\nMany WeakMap implementation in other languages don't accept \"immediate\" objects (or their equivalent) in the weak slots.\r\nThis is because since they are never collected, the weak reference will never possibly expire.\r\n\r\n`ObjectSpace::WeakMap` currently accept them, but since both keys and values are weak references, there is legitimate use.\r\n\r\nHowever in a `WeakKeysMap`, using an immediate object as key should likely raise a `TypeError`.\r\n\r\nWhat is less clear is wether `BIGNUM` (allocated `Integer`) and dynamic symbols (allocated `Symbol`) should be accepted.\r\n\r\nI believe they shouldn't for consistency, so:\r\n\r\n  - No immediate objects\r\n  - No `Integer`\r\n  - No `Symbol`\r\n\r\n#### `member` method to lookup an existing key\r\n\r\nFor some use case, notably deduplication sets, a `member` method that maps `st_get_key` would be useful.\r\n\r\n```ruby\r\ndef member(key) -> existing key or nil\r\n```\r\n\r\nNot sure if `member` is the best possible name, but `#key` is already used for looking up a key by value.\r\n\r\nThat same method could be useful on `Hash` and `Set` as well, but that would be a distinct feature request.\r\n\r\n#### Naming\r\n\r\nPossible names:\r\n\r\n  - `::WeakMap`\r\n  - `::WeakKeysMap`\r\n  - `::WeakRef::Map`\r\n  - `::WeakRef::WeakMap`\r\n  - `::WeakRef::WeakKeysMap`\r\n  - `::WeakRef::WeakHash`\r\n  - `::WeakRef::WeakKeysHash`\r\n\r\nMy personal, ligthly held, preference goes toward `::WeakRef::WeakKeysMap`.\r\n\r\n### Use cases\r\n\r\n\r\n#### WeakSet\r\n\r\nA `WeakKeysMap` would be a good enough primitive to implement a `WeakSet` in pure Ruby code, just like `Set` is\r\nimplemented with a `Hash`.\r\n\r\n`WeakSet` are useful for use cases such as avoiding cycles in an object graph without holding strong references.\r\n\r\n#### Deduplication sets\r\n\r\nAssuming `WeakMap` have the `#member` method.\r\n\r\nA small variation on the \"deduplicating constructors\" use case, better suited for smaller but numerous objects.\r\nThe difference here is that we first build the object and then lookup for a pre-existing one. This is the\r\nstrategy used to [deduplicate Active Record schema metadata](https://github.com/rails/rails/blob/3be590edbedab8ddcacdf72790d50c3cf9354434/activerecord/lib/active_record/connection_adapters/deduplicable.rb#L5).\r\n\r\n\r\n```ruby\r\nclass DeduplicationSet\r\n  def initialize\r\n    @set = WeakKeysMap.new\r\n  end\r\n\r\n  def dedup(object)\r\n    if existing_object = @set.member(object)\r\n      existing_object\r\n    else\r\n      @set[object] = true\r\n      object\r\n    end\r\n  end\r\nend\r\n```\r\n\r\n#### Third party object extension\r\n\r\nWhen you need to record some associated data on third party objects for which you don't control the lifetime.\r\nA WeakMap can be used:\r\n\r\n```ruby\r\nMETADATA = WeakKeysMap.new\r\ndef do_something(third_party_object)\r\n  metadata = (METADATA[third_party_object] ||= Metadata.new)\r\n  metadata.foo = \"bar\"\r\nend\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-19T11:14:20Z", "updated_on": "2022-02-20T16:06:14Z", "closed_on": null, "relations": [{"id": 3218, "issue_id": 16038, "issue_to_id": 18498, "relation_type": "relates", "delay": null}]}, {"id": 18494, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 724, "name": "normalperson (Eric Wong)"}, "subject": "[RFC] ENV[\"RUBY_GC_...\"]= changes GC parameters dynamically", "description": " This is intended to give Ruby application developers a way to to\r\n improve the out-of-the-box experience for end users running\r\n tools written in Ruby.  In most cases, end users are not and\r\n cannot be expected to know how to tune the GC better than the\r\n developers who wrote the Ruby code.\r\n \r\n This has no extra API footprint, and will silently be a no-op\r\n for other Ruby implementations.\r\n \r\n One potential incompatibility is users doing something like:\r\n \r\n ENV[\"RUBY_GC_...\"] = \"1m\"\r\n system(...)\r\n \r\n However, the different behavior would be largely innocuous aside from\r\n different performance characteristics in the parent process.  Using:\r\n \r\n system({ \"RUBY_GC_...\" => \"1m\" }, ...)\r\n \r\n ...would restore the previous behavior (and is generally the\r\n preferred usage, anyways, to avoid thread-safety issues).\r\n \r\n RFC since I've only tested this with RUBY_GC_MALLOC_LIMIT and\r\n RUBY_GC_MALLOC_LIMIT_MAX, so far.  I've yet to check Ractor\r\n interactions since haven't followed Ruby in several years.\r\n \r\n I made this change to reduce memory use in a single-threaded\r\n pipeline+process manager designed for audio playback; but it\r\n probably makes sense for many long-running daemons that want\r\n to clamp memory use after all code is loaded.\r\n ---\r\n Note: I can't create Redmine tickets due to MFA: [ruby-core:105878].\r\n I completely disagree with MFA for Open Source contributions as it's a\r\n needless barrier to participation.  Open Source worked fine for decades\r\n without MFA.  I show you my code and even explain my changes; but nobody\r\n here knows me and nobody ever will.  I don't want nor need anyone to\r\n trust me when they can read my code and even ask me to clarify things\r\n if needed.\r\n \r\n```diff\r\n hash.c               | 5 +++++\r\n test/ruby/test_gc.rb | 4 ++++\r\n 2 files changed, 9 insertions(+)\r\n \r\n diff --git a/hash.c b/hash.c\r\n index f032ef642a..d7cc797ef5 100644\r\n --- a/hash.c\r\n +++ b/hash.c\r\n @@ -4911,6 +4911,7 @@ static VALUE env_aset(VALUE nm, VALUE val);\r\n static void\r\n reset_by_modified_env(const char *nam)\r\n {\r\n +    static char gc_var_pfx[] = \"RUBY_GC_\";\r\n /*\r\n  * ENV['TZ'] = nil has a special meaning.\r\n  * TZ is no longer considered up-to-date and ruby call tzset() as needed.\r\n @@ -4919,6 +4920,10 @@ reset_by_modified_env(const char *nam)\r\n  */\r\n if (ENVMATCH(nam, TZ_ENV)) {\r\n ruby_reset_timezone();\r\n +    } else if (ENVNMATCH(nam, gc_var_pfx, sizeof(gc_var_pfx) - 1)) {\r\n +        ENV_LOCK();\r\n +        ruby_gc_set_params();\r\n +        ENV_UNLOCK();\r\n }\r\n }\r\n \r\n diff --git a/test/ruby/test_gc.rb b/test/ruby/test_gc.rb\r\n index 788f2974b5..5fd5924fb3 100644\r\n --- a/test/ruby/test_gc.rb\r\n +++ b/test/ruby/test_gc.rb\r\n @@ -334,6 +334,10 @@ def test_gc_parameter\r\n assert_in_out_err([env, \"-w\", \"-e\", \"exit\"], \"\", [], /RUBY_GC_OLDMALLOC_LIMIT_MAX=16000000/, \"\")\r\n assert_in_out_err([env, \"-w\", \"-e\", \"exit\"], \"\", [], /RUBY_GC_OLDMALLOC_LIMIT_GROWTH_FACTOR=2.0/, \"\")\r\n end\r\n +\r\n +    assert_in_out_err([\"-w\", \"-e\", <<-'end'], \"\", [], /RUBY_GC_MALLOC_LIMIT=1024/, \"\")\r\n +      ENV['RUBY_GC_MALLOC_LIMIT'] = '1k'\r\n +    end\r\n end\r\n \r\n def test_profiler_enabled\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-17T01:08:40Z", "updated_on": "2022-01-17T23:15:17Z", "closed_on": null, "relations": []}, {"id": 18491, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "subject": "Drop support for IBM AIX and HP UX", "description": "There's code in Ruby for IBM AIX and HP UX (macros `_AIX` and `__hpux`), but we don't test on these systems nor do we have testing machines. IBM AIX's maintainer is listed as @kanemoto and HP UX does not have a maintainer. Are these systems still actively maintained? Are there users of Ruby on these systems? Can we drop support for them?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-14T15:01:00Z", "updated_on": "2022-01-18T14:52:38Z", "closed_on": "2022-01-18T14:52:38Z", "relations": [{"id": 3217, "issue_id": 15894, "issue_to_id": 18491, "relation_type": "relates", "delay": null}]}, {"id": 18490, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 443, "name": "mdalessio (Mike Dalessio)"}, "assigned_to": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "MakeMakefile.pkg_config should accept multiple options", "description": "## Summary\r\n\r\nWhen building static libraries it is sometimes necessary to pass multiple flags to `pkg-config`. Currently, `MakeMakefile.pkg_config` does not allow this.\r\n\r\nA PR has been submitted at https://github.com/ruby/ruby/pull/5436\r\n\r\n\r\n## Real-world example\r\n\r\nOne example of this is the `libmagic` library which is wrapped by the `ruby-magic` gem. The `ruby-magic` gem's `extconf.rb` needs to pass two options to pkg-config, so that the command executed should be:\r\n\r\n```\r\npkg-config --libs --static libmagic\r\n```\r\n\r\n(Note that passing only `--libs` then only `--static` and merging the results is not sufficient; both must be passed on the same invocation.)\r\n\r\n`MakeMakefile.pkg_config` only supports passing **one** option to `pkg-config` today.\r\n\r\n\r\n## Historical context\r\n\r\nPrior to Ruby 3.1.0, it was possible to work around this limitation by crafting an options string like so:\r\n\r\n```\r\npkg_config('libmagic', 'libs --static')\r\n```\r\n\r\nThe `option` parameter would be interpolated into the command template as variable `opt`:\r\n\r\n```\r\n\"#{$PKGCONFIG} --#{opt} #{pkg}\r\n```\r\n\r\nresulting in the desired command string of `pkg-config --libs --static libmagic`.\r\n\r\nHowever, with commit https://github.com/ruby/ruby/commit/dff8d12 this hack stopped working because the underlying ruby code is now:\r\n\r\n```\r\nxpopen([*envs, $PKGCONFIG, \"--#{opt}\", pkg], err:[:child, :out], &:read)\r\n```\r\n\r\nwhich results in `pkg-config` returning an error:\r\n\r\n```\r\n\"Unknown option --libs --static\\n\"\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-14T14:52:20Z", "updated_on": "2022-02-15T07:30:12Z", "closed_on": "2022-02-15T07:30:12Z", "relations": []}, {"id": 18483, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "`RUBY_ON_BUG` feature for ruby release version", "description": "Now development version of MRI (`RUBY_DEVEL` macro enabled binary) supports `RUBY_ON_BUG` environment variable.\r\nIt kicks the specified process with PID of the Ruby process when `rb_bug()` function is called, like:\r\n\r\n```\r\n$ RUBY_ON_BUG='gdb -p' ./miniruby -e 'Process.kill(:SEGV, $$)'\r\n-e:1: [BUG] Segmentation fault at 0x000003e800000512\r\nruby 3.2.0dev (2022-01-12T02:02:24Z master dcb02cb28a) [x86_64-linux]\r\n\r\nGNU gdb (Ubuntu 9.2-0ubuntu1~20.04) 9.2\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nLicense GPLv3+: GNU GPL version 3 or later <http://gnu.org/licenses/gpl.html>\r\nThis is free software: you are free to change and redistribute it.\r\nThere is NO WARRANTY, to the extent permitted by law.\r\nType \"show copying\" and \"show warranty\" for details.\r\nThis GDB was configured as \"x86_64-linux-gnu\".\r\nType \"show configuration\" for configuration details.\r\nFor bug reporting instructions, please see:\r\n<http://www.gnu.org/software/gdb/bugs/>.\r\nFind the GDB manual and other documentation resources online at:\r\n    <http://www.gnu.org/software/gdb/documentation/>.\r\n\r\nFor help, type \"help\".\r\nType \"apropos word\" to search for commands related to \"word\".\r\nAttaching to process 1298\r\nReading symbols from /home/ko1/ruby/build/trunk/miniruby...\r\nReading symbols from /lib/x86_64-linux-gnu/libz.so.1...\r\n(No debugging symbols found in /lib/x86_64-linux-gnu/libz.so.1)\r\nReading symbols from /lib/x86_64-linux-gnu/libpthread.so.0...\r\nReading symbols from /usr/lib/debug/.build-id/e5/4761f7b554d0fcc1562959665d93dffbebdaf0.debug...\r\n[Thread debugging using libthread_db enabled]\r\nUsing host libthread_db library \"/lib/x86_64-linux-gnu/libthread_db.so.1\".\r\nReading symbols from /lib/x86_64-linux-gnu/librt.so.1...\r\nReading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/librt-2.31.so...\r\nReading symbols from /lib/x86_64-linux-gnu/libgmp.so.10...\r\n(No debugging symbols found in /lib/x86_64-linux-gnu/libgmp.so.10)\r\nReading symbols from /lib/x86_64-linux-gnu/libcapstone.so.3...\r\n(No debugging symbols found in /lib/x86_64-linux-gnu/libcapstone.so.3)\r\nReading symbols from /lib/x86_64-linux-gnu/libdl.so.2...\r\nReading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libdl-2.31.so...\r\nReading symbols from /lib/x86_64-linux-gnu/libcrypt.so.1...\r\n(No debugging symbols found in /lib/x86_64-linux-gnu/libcrypt.so.1)\r\nReading symbols from /lib/x86_64-linux-gnu/libm.so.6...\r\nReading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libm-2.31.so...\r\nReading symbols from /lib/x86_64-linux-gnu/libc.so.6...\r\nReading symbols from /usr/lib/debug//lib/x86_64-linux-gnu/libc-2.31.so...\r\nReading symbols from /lib64/ld-linux-x86-64.so.2...\r\n(No debugging symbols found in /lib64/ld-linux-x86-64.so.2)\r\n0x00007fc0a0099dba in __GI___wait4 (pid=1299, stat_loc=stat_loc@entry=0x558e2382b5d8, options=options@entry=0, usage=usage@entry=0x0)\r\n    at ../sysdeps/unix/sysv/linux/wait4.c:27\r\n27      ../sysdeps/unix/sysv/linux/wait4.c: No such file or directory.\r\n(gdb)\r\n```\r\n\r\nThis feature is convenient for CI and so on.\r\nAgain, this feature is only enabled on `RUBY_DEVEL`. This is because I'm not sure it can be a security issue.\r\nHowever, we discussed about this feature and we concluded it is not a problem to contain this kind of feature (if `RUBYOPT` is modified, it is already issue).\r\n\r\nSo I want to enable this feature.\r\n\r\nTwo points we need to discuss.\r\n\r\n* anyone have security concern about this feature on release version?\r\n* `RUBY_ON_BUG` is named without any discussion because it is only MRI development. However if it is enabled on release version, the name should be discussed. Any good name?\r\n\r\nThanks,\r\nKoichi", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-13T05:26:01Z", "updated_on": "2022-01-25T07:44:21Z", "closed_on": "2022-01-25T07:44:21Z", "relations": []}, {"id": 18481, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51917, "name": "maximecb (Maxime Chevalier-Boisvert)"}, "assigned_to": {"id": 51917, "name": "maximecb (Maxime Chevalier-Boisvert)"}, "subject": "Porting YJIT to Rust (request for feedback)", "description": "TL;DR: The YJIT team wants to explore using Rust to help develop YJIT. The rest of CRuby will continue to build without Rust tools and building YJIT will remain optional.\r\n\r\nWe\u2019re currently exploring the possibility of porting YJIT to Rust and working on a small proof of concept that should be ready next month. The motivation behind this is that we are facing challenges in terms of code maintainability. As you know, JIT compilers can get very complex, and C99 doesn't offer many tools to manage this complexity. There are no classes and methods, limited type checking, and it's hard to fully separate code into modules, for instance.\r\n\r\nWe believe that having access to object oriented programming and a more expressive type system would help us manage growing complexity better and also improve the safety/robustness of YJIT. For instance we would like to add Windows support and a new backend to YJIT. That means we\u2019ll have two separate backends (x86, arm64) and we\u2019ll need to support two different calling conventions (Microsoft, SystemV), but currently, we have limited tools to build the abstractions needed, such as preprocessor macros and if-statements.\r\n\r\nWe\u2019ve discussed the idea of porting YJIT to Rust with some of the Ruby core developers (@ko1, @k0kubun, @mame), and it seems they would be open to merging something like this if it works well. I\u2019m opening this ticket so that everyone can have a chance to provide feedback and participate in the discussion. We realize that adding Rust code to the CRuby codebase could be challenging and that there are open questions.\r\n\r\nWe are planning to make it so that YJIT will only need the Rust compiler and `cargo` to build. Building YJIT would then require the Rust compiler to be installed, but CRuby could build without YJIT and without the Rust compiler. There would be no new dependencies for the compiled binary. Rust is supported on Mac, Windows, BSDs, and Linux, which covers all the platforms on which we plan to support YJIT. Since Rust is based on LLVM, it has good support for cross-compilation.\r\n\r\nWe would like to solicit input from Ruby distributors who create `.deb` and `.rpm` packages. We will likely remain conservative when updating Rust versions to make OS packaging easier. We believe that in the general, the resulting code should be easier to maintain because it will be better organized, but the YJIT team will help out with YJIT-related backports and will be available to help if needed.\r\n\r\nValue proposition:\r\n- Rust type systems will catch more bugs early, help prevent new bugs\r\n- Easier to manage growing complexity of YJIT\r\n- Easier to maintain codebase, fewer \u201cfootguns\u201d\r\n- Easier for newcomers because the compiler catches more bugs\r\n- Better performance because we can implement more sophisticated optimizations\r\n- Easier to add support for new platforms (which adds complexity)\r\n- Rust has mature and easy-to-install tools such as source code formatter and editor plugins\r\n- Rust as a programming language community has a great deal of enthusiasm behind it. This could translate to more enthusiasm for YJIT and for Ruby as well.\r\n\r\nIntegration:\r\n- YJIT will only depend on the Rust language and the standard library, no other dependencies\r\n- YJIT will be able to build without an internet connection\r\n- Rust has good support for cross-compilation\r\n- Rust is supported on all platforms on which we plan to support with YJIT (Mac, Linux, Windows)\r\n- The compiled CRuby binary won\u2019t have any new dependencies on shared libraries\r\n- CRuby will still be able to build without `rustc`, with YJIT disabled\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-12T15:53:32Z", "updated_on": "2022-05-06T17:43:18Z", "closed_on": "2022-05-06T17:43:18Z", "relations": []}, {"id": 18478, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52079, "name": "johansenjaa (Joseph Johansen)"}, "subject": "Module#constant_pairs", "description": "Let's say I have a module like this:\r\n```ruby\r\nmodule A\r\n  B = 1\r\n\r\n  class C\r\n  end\r\nend\r\n```\r\n\r\nI can find out its constants with `constants`:\r\n```ruby\r\nA.constants # => [:B, :C]\r\n```\r\n\r\nBut if I also want to get the values of the constants, the best way at the moment seems to be with `Object#const_get` (and perhaps not so performant too? By the looks of things it has a fair bit of logic in it)\r\n\r\n```ruby\r\nA.constants.to_h { |c| [ c, A.const_get(c)] }\r\n```\r\n\r\nIt would be great if there was an easier/more optimal way of doing this:\r\n\r\n```ruby\r\nA.constant_pairs # => { B: 1, C: A::C }\r\n```\r\n\r\nIt seems like others have been interested in similar functionality before too:\r\n\r\nhttps://stackoverflow.com/questions/48386101/get-value-of-all-constants-defined-in-a-module\r\nhttps://stackoverflow.com/questions/9848153/how-do-you-find-all-modules-and-classes-within-a-module-recursively\r\nhttps://github.com/rails/rails/blob/f95c0b7e96eb36bc3efc0c5beffbb9e84ea664e4/activesupport/test/core_ext/object/json_gem_encoding_test.rb#L23\r\nhttps://github.com/rails/rails/blob/f95c0b7e96eb36bc3efc0c5beffbb9e84ea664e4/activerecord/test/cases/arel/nodes/node_test.rb#L12\r\nhttps://github.com/rails/rails/blob/f95c0b7e96eb36bc3efc0c5beffbb9e84ea664e4/activesupport/test/broadcast_logger_test.rb#L18\r\nhttps://github.com/rails/rails/blob/f95c0b7e96eb36bc3efc0c5beffbb9e84ea664e4/activesupport/test/json/encoding_test.rb#L30", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-11T19:55:38Z", "updated_on": "2022-01-11T19:55:38Z", "closed_on": null, "relations": []}, {"id": 18477, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48480, "name": "dorianmariefr (Dorian Mari\u00e9)"}, "subject": "Float#sqrt and Integer#sqrt", "description": "Would be nice to do:\r\n\r\n```ruby\r\n10.sqrt # => 3.1622776601683795\r\n3.5.sqrt # => 1.8708286933869707\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-11T19:26:35Z", "updated_on": "2022-01-11T19:34:20Z", "closed_on": null, "relations": [{"id": 3211, "issue_id": 18477, "issue_to_id": 18179, "relation_type": "duplicates", "delay": null}]}, {"id": 18463, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52084, "name": "bbrklm (Benson Muite)"}, "subject": "Random number generation with xoshiro", "description": "Xoshiro https://prng.di.unimi.it/  random number generation is typically faster than Mersenne Twister currently used in Ruby in https://github.com/ruby/ruby/blob/master/random.c  It would be good to allow use of xoshiro either as an option or as default. Xoshiro is the default for Fortran https://gcc.gnu.org/onlinedocs/gfortran/RANDOM_005fNUMBER.html and Julia https://github.com/JuliaLang/julia/tree/master/stdlib/Random/src Happy to implement this.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-07T06:34:23Z", "updated_on": "2022-02-13T09:12:44Z", "closed_on": null, "relations": [{"id": 3207, "issue_id": 16827, "issue_to_id": 18463, "relation_type": "relates", "delay": null}]}, {"id": 18462, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51839, "name": "katei (Yuta Saito)"}, "subject": "Proposal to merge WASI based WebAssembly support", "description": "# Proposal to merge WASI based WebAssembly support\r\n\r\nThis is an initial port of WASI based WebAssembly support.\r\nThis enables a CRuby binary to be available on Web browser, Serverless Edge environment, and other WebAssembly/WASI embedders. \r\nCurrently this port passes basic and bootstrap test suites not using Thread API.\r\n\r\nThe upstreaming PR on ruby/ruby is here: https://github.com/ruby/ruby/pull/5407\r\n\r\n## Background\r\n\r\nFor example, CRuby already supports WebAssembly target by Emscripten, but Emscripten heavily depends on JavaScript to emulate some missing features in WebAssembly itself.\r\n\r\nIn short the WASI is an effort to define a standard set of syscalls for WebAssembly modules, allowing WebAssembly modules to not only be portable across architectures but also be portable across environments implementing this standard set of system calls. The environments includes non JS environments, Edge Computing platforms, IoT devices, and so on.\r\n\r\nThis is a proposal ticket to support WASI based WebAssembly target.\r\n\r\nThis is a part of Ruby Association Grant project\r\n\r\n## Lexicon\r\n\r\n- [WASI](https://wasi.dev): A system call interface for WebAssembly\r\n- [wasi-libc](https://github.com/WebAssembly/wasi-libc): A libc implementation for WebAssembly programs built on top of WASI system calls.\r\n\r\n## Current Limitation of WebAssembly and WASI\r\n\r\n### Threads\r\n\r\nCurrently WebAssembly has no threads, and WASI doesn't provide any API to create a thread, but they are [on the roadmap](https://github.com/WebAssembly/threads/blob/main/proposals/threads/Overview.md). This means `Thread.new` doesn't work on this target, and it raises `ENOSUP` for now.\r\n\r\n### Register operations\r\n\r\nCurrent WebAssembly doesn't allow to touch the program counter, but they are also [on the roadmap](https://github.com/WebAssembly/stack-switching).\r\nThis limitation makes it hard to implement setjmp/longjmp and context-switching on this target, and wasi-libc doesn't provide such implementations.\r\n\r\nAnd also WebAssembly has function local infinite registers, but there is no way to scan the values in a call stack for now.\r\nThis limitation makes it unable to mark living objects by Conservative GC in a simple way.\r\n\r\n## Patch Overview\r\n\r\nThis patch is a set of minor changes:\r\n\r\n### Adapt to wasi-libc API\r\n\r\nwasi-libc is almost compatible with other libc implementations, but it doesn't have some functions.\r\nSo this patch adds stub implementations for them.\r\n\r\n### Add no thread variant\r\n\r\nAs mentioned above, WebAssembly has no thread, so this patch adds a thread_none.c, which is a sibling of thread_win32.c and thread_pthread.c. This implementation does nothing around preemptive context switching because there is no native thread.\r\n\r\n### Emulate setjmp/longjmp, coroutine, and register scan by Asyncify\r\n\r\nAs mentioned above, WebAssembly has no context switching feature, but there is an userland technique to pause and resume a WebAssembly process by binary transformation.\r\nThis technique is called [Asyncify](https://kripken.github.io/blog/wasm/2019/07/16/asyncify.html).\r\nThis patch utilizes it to emulate setjmp/longjmp, coroutine, and register scan for GC.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-07T06:10:07Z", "updated_on": "2022-03-24T03:05:28Z", "closed_on": null, "relations": []}, {"id": 18461, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8741, "name": "bughit (bug hit)"}, "subject": "closures are capturing unused variables", "description": "```rb\r\ndef foo\r\n  a = 1\r\n  ->{}\r\nend\r\np foo.binding.local_variables # [:a]\r\n\r\n```\r\n\r\nShouldn't `a` be optimized away? Like v8 does (https://bugs.chromium.org/p/v8/issues/detail?id=3491)", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-05T23:45:09Z", "updated_on": "2022-06-16T06:44:32Z", "closed_on": "2022-06-16T06:44:32Z", "relations": []}, {"id": 18460, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9554, "name": "cvss (Kirill Vechera)"}, "subject": "implicit self for .() syntax without rvalue", "description": "We have a nice `.()` shorthand for calling Proc\r\n\r\n```ruby\r\nm = 1.method(:+)\r\nm.(2) # 3\r\n```\r\n\r\nBut while we can use this shorthand in a Proc's context with the explicit self, we cannot use it with the implicit self:\r\n```ruby\r\nm.instance_exec { self.(2) } # 3\r\nm.instance_exec { .(2) } # syntax error, unexpected '.' (SyntaxError)\r\n```\r\n\r\nSo I propose to make this syntax valid too.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-05T14:51:16Z", "updated_on": "2022-01-06T11:13:18Z", "closed_on": "2022-01-06T11:13:18Z", "relations": []}, {"id": 18459, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52079, "name": "johansenjaa (Joseph Johansen)"}, "assigned_to": {"id": 11389, "name": "aycabta (aycabta .)"}, "subject": "IRB autocomplete dropdown colour options", "description": "It would be great to be able to specify bg/fg colours for the new autocomplete dropdown in irb in ruby 3.1. This could help for accessibility purposes, or for anyone who just wants to make it look more personalised for their terminal \ud83d\ude0e\r\n\r\nPerhaps irbrc could do the trick?\r\n\r\n```ruby\r\nIRB.conf[:AUTOCOMPLETE] = {\r\n  BG_COLOR: 0,\r\n  FG_COLOR: 15,\r\n}\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2022-01-04T19:28:54Z", "updated_on": "2022-01-05T02:15:28Z", "closed_on": null, "relations": []}, {"id": 18450, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52074, "name": "firasalkhalil (Firas al-Khalil)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Force break in prettyprint", "description": "# Abstract\r\n\r\nSupport force-breaking a group in the std's [prettyprint](https://github.com/ruby/prettyprint)\r\n\r\n# Background\r\n\r\nThere is a need to forcibly break a group and transform breakables into\r\nnewlines. The library doesn't provide this possibility, directly, through\r\nits public API.\r\n\r\n# Proposal\r\n\r\nAdd a single convenience function to the library's public class `PrettyPrint`\r\n\r\n# Implementation\r\n\r\nAn implementation was submitted to the project's github repository as a \r\n[pull request](https://github.com/ruby/prettyprint/pull/2).\r\n\r\nHere's the patch:\r\n\r\n```\r\ndiff --git a/lib/prettyprint.rb b/lib/prettyprint.rb\r\nindex 188c2e6..1d675a7 100644\r\n--- a/lib/prettyprint.rb\r\n+++ b/lib/prettyprint.rb\r\n@@ -236,6 +236,14 @@ class PrettyPrint\r\n     end\r\n   end\r\n\r\n+  # This says \"force a line break here\".\r\n+  #\r\n+  # It will force the current group's \"breakables\" to break.\r\n+  def break\r\n+    breakable\r\n+    current_group.break\r\n+  end\r\n+\r\n   # Groups line break hints added in the block. The line break hints are all\r\n   # to be used or not.\r\n   #\r\ndiff --git a/test/test_prettyprint.rb b/test/test_prettyprint.rb\r\nindex 27e7198..cf889d1 100644\r\n--- a/test/test_prettyprint.rb\r\n+++ b/test/test_prettyprint.rb\r\n@@ -518,4 +518,31 @@ End\r\n\r\n end\r\n\r\n+\r\n+class Break < Test::Unit::TestCase # :nodoc:\r\n+  def format()\r\n+    PrettyPrint.format(''.dup) {|q|\r\n+      q.group {\r\n+        q.text 'abc'\r\n+        q.breakable\r\n+        q.text 'def'\r\n+        q.group {\r\n+          q.break\r\n+          q.text 'ghi'\r\n+        }\r\n+        q.breakable\r\n+        q.text 'jkl'\r\n+      }\r\n+    }\r\n+  end\r\n+\r\n+  def test_00_04\r\n+    expected = <<'End'.chomp\r\n+abc def\r\n+ghi jkl\r\n+End\r\n+    assert_equal(expected, format())\r\n+  end\r\n+end\r\n+\r\n```\r\n\r\n# Evaluation\r\n\r\nIt's a simple implementation with no caveats.\r\n\r\n# Discussion\r\n\r\nEven though it's a simple functionality, and the implementation is straightforward,\r\ngetting to this point is not that obvious. This is why it might be helpful for other\r\nusers who face such a need.\r\n\r\nIndeed, an issue was [opened](https://github.com/ruby/prettyprint/issues/1) not so long ago,\r\nand the proposed solution worked but not quite as expected. The provided implementation\r\nworks as expected without tampering with the API's internals, and it's proven in production\r\nenvironment.\r\n\r\n# Summary\r\n\r\nThis is a feature request for the `prettyprint` library: adding support for _force breaking_\r\na group. An implementation is provided as both a patch and a PR on github.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-29T13:16:58Z", "updated_on": "2021-12-29T14:02:55Z", "closed_on": null, "relations": [{"id": 3319, "issue_id": 18450, "issue_to_id": 18654, "relation_type": "relates", "delay": null}]}, {"id": 18440, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 27474, "name": "georgeclaghorn (George Claghorn)"}, "subject": "YJIT is enabled if any YJIT tuning options are set", "description": "I was testing YJIT in a Rails app with `RUBYOPT=\"--yjit --yjit-exec-mem-size=32\"`. I saw some weird issues around Rails view caching, so I attempted to temporarily disable YJIT by removing `--yjit` and leaving the tuning options in place (`RUBYOPT=\"--yjit-exec-mem-size=32\"`). However, YJIT remained enabled until I also removed `--yjit-exec-mem-size=32`.\r\n\r\n```\r\n$ ruby -e 'puts RubyVM::YJIT.runtime_stats.inspect'\r\nnil\r\n\r\n$ ruby --yjit-exec-mem-size -e 'puts RubyVM::YJIT.runtime_stats.inspect'\r\n{:inline_code_size=>378495, :outlined_code_size=>311079}\r\n```\r\n\r\nI expected removing `--yjit` to disable YJIT and was surprised by this.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-27T15:41:22Z", "updated_on": "2021-12-30T20:17:30Z", "closed_on": null, "relations": []}, {"id": 18439, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9, "name": "usa (Usaku NAKAMURA)"}, "assigned_to": {"id": 51917, "name": "maximecb (Maxime Chevalier-Boisvert)"}, "subject": "Support YJIT for VC++", "description": "I heard that supporting YJIT for VC++ needs mmap from k0kubun-san, so I implemented tiny mmap emulation on Windows and committed it to master.\r\nAnd, I found we need more changes to actually enabled YJIT for VC++, at least:\r\n\r\n- YJIT requires `OPT_DIRECT_THREADED_CODE` or `OPT_CALL_THREADED_CODE` in `rb_yjit_compile_iseq()`.  Really?\r\n- Maybe ABI deffers between VC++ and YJIT's expectation.\r\n\r\nCan I get support to fix above?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-27T08:47:04Z", "updated_on": "2022-01-10T23:29:12Z", "closed_on": null, "relations": []}, {"id": 18438, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Add `Exception#additional_message` to show additional error information", "description": "## Proposal\r\n\r\nI'd like to introduce a method `Exception#additional_message`, and let the Ruby error printer show it after `Exception#message`.\r\n\r\n```ruby\r\nclass MyError < StandardError\r\n  def message = \"my error!\"\r\n  def additional_message = \"This is\\nan additional\\nmessage\"\r\nend\r\n\r\nraise MyError\r\n```\r\n\r\n```\r\n$ ./miniruby test.rb\r\ntest.rb:6:in `<main>': my error! (MyError)\r\n| This is\r\n| an additional\r\n| message\r\n```\r\n\r\nPoC implementation: https://github.com/ruby/ruby/pull/5351\r\n\r\n## Motivation\r\n\r\nAt the present time, did_you_mean and error_highlight overrides `Exception#message` to add their suggestions.\r\n\r\n```ruby\r\nbegin; 1.time; rescue NoMethodError; pp $!.message; end\r\n#=> \"undefined method `time' for 1:Integer\\n\" +\r\n#   \"\\n\" +\r\n#   \"  1.time\\n\" +\r\n#   \"   ^^^^^\\n\" +\r\n#   \"Did you mean?  times\"\r\n```\r\n\r\nThis implementation approach has a practical problem. Because it changes the return value of `Exception#message`, it breaks a test that checks the return value of `Exception#message`.\r\nThough such a test is never recommended, I encountered some actual cases when creating error_highlight. See the change of tests of minitest as a typical example: https://github.com/seattlerb/minitest/pull/880/files\r\n\r\nCurrently, error_highlight shows hint information only for NoMethodError because it is relatively rare to check the message of `NameError`. Still, it broke some tests unfortunately, though. If possible, I'd like to add suggestions to other kinds of errors, but it will break much more tests.\r\n\r\nIf `Exception#additional_message` is introduced, and if did_you_mean and error_highlight overrides the method to add their suggestions, this problem will not occur because they no longer changes the result value of `#message` method.\r\n\r\n## Cooperation needed\r\n\r\nCurrently, many Ruby/Rails users montiors their production services by using application monitoring services such as Sentry, DataDog, ScoutAPM, etc. The original motivation of error_highlight is for production (see #17930), so it will lose the significance if such services do not support `Exception#additional_message`. So, I'd like to hear opinions from developers of such services. If they are against this proposal or if we can't get their cooperation, I don't think my proposal should be accepted.\r\n\r\nIf you are a developer of these services, I would be very grateful if you could comment on this ticket. @ivoanjo\r\n\r\n## Bikesheds\r\n\r\n* I'm unsure if `Exception#additional_message` is a good name. Please propose alternatives if it is not good.\r\n* Currently, the result of `addtional_message` is printed with no escape. This may be a more compatible solution against https://bugs.ruby-lang.org/issues/18367.\r\n* It may be good to let `Exception#additional_message` accept `highlight` keyword as boolean information whether the output target is a terminal or not. Currently `Exception#full_message` accepts it. I have no plan to use the information in `error_highlight`, though. Not only `highlight` but also any keywords may be forwarded from `full_message(**opt)` to `additional_message(**opt)` for future use case.\r\n* My current PoC adds prefixs \"`| `\" before each line of `addtional_message`. I'm unsure if this is good or bad. I'm happy to change or remove the prefixes.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-27T06:46:29Z", "updated_on": "2022-02-07T02:55:59Z", "closed_on": null, "relations": [{"id": 3206, "issue_id": 18296, "issue_to_id": 18438, "relation_type": "relates", "delay": null}]}, {"id": 18427, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52064, "name": "dklein (Dmitri Klein)"}, "subject": "fileutils.rb: - No such file or directory", "description": "gem install msgpack-1.3.3.gem --debug\r\n\r\n...\r\nException `NoMethodError' at /opt/csw/lib/ruby/2.0.0/rubygems/package.rb:420 - undefined method `readpartial' for #<Gem::Package::TarReader::Entry:0x877f634>\r\n\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1439 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/spec_helper.rb\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1319 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/timestamp_spec.rb\r\n...\r\nException `NoMethodError' at /opt/csw/lib/ruby/2.0.0/rubygems/package/tar_reader.rb:71 - undefined method `seek' for #<Zlib::GzipReader:0x859f79c>\r\n...\r\n\r\nERROR:  Error installing msgpack-1.3.3.gem:\r\n        ERROR: Failed to build gem native extension.\r\n...\r\n\r\nmake \"DESTDIR=\"\r\ncompiling buffer.c\r\ncc: -W option with unknown program all\r\n*** Error code 1\r\nThe following command caused the error:\r\n/opt/SUNWspro/bin/cc -I. -I/opt/csw/include/ruby-2.0.0/i386-solaris2.10 -I/opt/csw/include/ruby-2.0.0/ruby/backward -I/opt/csw/include/ruby-2.0.0 -I. -DHAVE_RUBY_ST_H -DHAVE_ST_H -DHAVE_RB_STR_REPLACE -DHAVE_RB_INTERN_STR -DHAVE_RB_STR_INTERN -DHAVE_RB_BLOCK_LAMBDA -DHAVE_RB_HASH_DUP -DHAVE_RB_HASH_CLEAR -I/opt/csw/include -D_FILE_OFFSET_BITS=64  -KPIC -xO3 -xarch=pentium_pro -xchip=pentium_pro  -KPIC -I.. -Wall -O3 -g -std=gnu99 -m32 -o buffer.o -c buffer.c\r\nmake: Fatal error: Command failed for target `buffer.o'\r\n\r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-23T15:35:43Z", "updated_on": "2021-12-23T22:41:02Z", "closed_on": "2021-12-23T16:01:07Z", "relations": [{"id": 3197, "issue_id": 18426, "issue_to_id": 18427, "relation_type": "duplicates", "delay": null}, {"id": 3198, "issue_id": 18425, "issue_to_id": 18427, "relation_type": "duplicates", "delay": null}]}, {"id": 18426, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52064, "name": "dklein (Dmitri Klein)"}, "subject": "fileutils.rb: - No such file or directory", "description": "gem install msgpack-1.3.3.gem --debug\r\n\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1439 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/spec_helper.rb\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1319 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/timestamp_spec.rb\r\n...\r\nException `NoMethodError' at /opt/csw/lib/ruby/2.0.0/rubygems/package/tar_reader.rb:71 - undefined method `seek' for #<Zlib::GzipReader:0x859f79c>\r\n...\r\n\r\nERROR:  Error installing msgpack-1.3.3.gem:\r\n        ERROR: Failed to build gem native extension.\r\n...\r\n\r\nmake \"DESTDIR=\"\r\ncompiling buffer.c\r\ncc: -W option with unknown program all\r\n*** Error code 1\r\nThe following command caused the error:\r\n/opt/SUNWspro/bin/cc -I. -I/opt/csw/include/ruby-2.0.0/i386-solaris2.10 -I/opt/csw/include/ruby-2.0.0/ruby/backward -I/opt/csw/include/ruby-2.0.0 -I. -DHAVE_RUBY_ST_H -DHAVE_ST_H -DHAVE_RB_STR_REPLACE -DHAVE_RB_INTERN_STR -DHAVE_RB_STR_INTERN -DHAVE_RB_BLOCK_LAMBDA -DHAVE_RB_HASH_DUP -DHAVE_RB_HASH_CLEAR -I/opt/csw/include -D_FILE_OFFSET_BITS=64  -KPIC -xO3 -xarch=pentium_pro -xchip=pentium_pro  -KPIC -I.. -Wall -O3 -g -std=gnu99 -m32 -o buffer.o -c buffer.c\r\nmake: Fatal error: Command failed for target `buffer.o'\r\n\r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-23T15:28:45Z", "updated_on": "2021-12-23T22:41:02Z", "closed_on": "2021-12-23T16:01:29Z", "relations": [{"id": 3197, "issue_id": 18426, "issue_to_id": 18427, "relation_type": "duplicates", "delay": null}]}, {"id": 18425, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52064, "name": "dklein (Dmitri Klein)"}, "subject": "fileutils.rb: - No such file or directory", "description": "gem install msgpack-1.3.3.gem --debug\r\n\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1439 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/spec_helper.rb\r\n...\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1319 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/spec/timestamp_spec.rb\r\n...\r\nException `NoMethodError' at /opt/csw/lib/ruby/2.0.0/rubygems/package/tar_reader.rb:71 - undefined method `seek' for #<Zlib::GzipReader:0x859f79c>\r\n...\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-23T15:27:26Z", "updated_on": "2021-12-23T22:41:02Z", "closed_on": "2021-12-23T16:01:54Z", "relations": [{"id": 3198, "issue_id": 18425, "issue_to_id": 18427, "relation_type": "duplicates", "delay": null}]}, {"id": 18423, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52064, "name": "dklein (Dmitri Klein)"}, "subject": "Installing stable versions like 3.0.3 from source generates fatal error by make", "description": "# make\r\n        BASERUBY = echo executable host ruby is required.  use --with-baseruby option.; false\r\n        CC = /opt/SUNWspro/bin/CC\r\n        LD = /usr/ccs/bin/ld\r\n        LDSHARED = /opt/SUNWspro/bin/CC -G\r\n        CFLAGS =  -g  \r\n        XCFLAGS = -DRUBY_EXPORT -I. -I.ext/include/i386-solaris2.10 -I./include -I. -I./enc/unicode/12.1.0\r\n        CPPFLAGS = -D_XOPEN_SOURCE=500   \r\n        DLDFLAGS =  \r\n        SOLIBS = -lz -lpthread -lrt -lrt -lrt -lsocket -ldl -lcrypt -lm\r\n        LANG = \r\n        LC_ALL = \r\n        LC_CTYPE = \r\n        MFLAGS = \r\nCC: Sun C++ 5.12 SunOS_i386 2011/11/16\r\ncompiling vm.c\r\n\"./include/ruby/backward/cxxanyargs.hpp\", line 207: Warning (Anachronism): Formal argument 1 of type extern \"C\" unsigned long(*)(unsigned long) in call to rb_iterate(extern \"C\" unsigned long(*)(unsigned long), unsigned long, extern \"C\" unsigned long(*)(unsigned long,unsigned long,int,const unsigned long*,unsigned long), unsigned long) is being passed unsigned long(*)(unsigned long).\r\n...\r\n\"./include/ruby/backward/cxxanyargs.hpp\", line 648: Error: Template parameter ruby::backward::cxxanyargs::define_method::F requires an expression of type void(*)(const char*,unsigned long(*)(...),int).\r\n\"./include/ruby/internal/fl_type.h\", line 205: Warning: Identifier expected instead of \"}\".\r\n\"internal.h\", line 16: Error: #error not for C++.\r\n*** Error code 2\r\nThe following command caused the error:\r\n/opt/SUNWspro/bin/CC  -g   -DRUBY_EXPORT -I. -I.ext/include/i386-solaris2.10 -I./include -I. -I./enc/unicode/12.1.0 -D_XOPEN_SOURCE=500    -o vm.o -c vm.c\r\nmake: Fatal error: Command failed for target `vm.o'\r\n# \r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-22T22:43:56Z", "updated_on": "2021-12-23T23:44:00Z", "closed_on": null, "relations": []}, {"id": 18422, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52064, "name": "dklein (Dmitri Klein)"}, "subject": "Installing fluentd on Solaris 10 by Ruby gems with error message: \"ERROR: Failed to build gem native extension\"", "description": "Installing fluentd on Solaris 10 by Ruby gems with error message: \"ERROR: Failed to build gem native extension\": \r\n\r\ngem install fluentd -v '0.12.43'\r\n\r\nBuilding native extensions. This could take a while...\r\nERROR: Error installing fluentd:\r\nERROR: Failed to build gem native extension.\r\n\r\n/opt/csw/bin/ruby2.0 extconf.rb\r\nchecking for ruby/st.h... yes\r\nchecking for st.h... yes\r\nchecking for rb_str_replace() in ruby.h... yes\r\nchecking for rb_intern_str() in ruby.h... yes\r\nchecking for rb_sym2str() in ruby.h... no\r\nchecking for rb_str_intern() in ruby.h... yes\r\nchecking for rb_block_lambda() in ruby.h... yes\r\nchecking for rb_hash_dup() in ruby.h... yes\r\nchecking for rb_hash_clear() in ruby.h... yes\r\ncreating Makefile\r\n\r\nmake \"DESTDIR=\"\r\ncompiling buffer.c\r\ncc: -W option with unknown program all\r\n*** Error code 1\r\nThe following command caused the error:\r\n/opt/SUNWspro/bin/cc -I. -I/opt/csw/include/ruby-2.0.0/i386-solaris2.10 -I/opt/csw/include/ruby-2.0.0/ruby/backward -I/opt/csw/include/ruby-2.0.0 -I. -DHAVE_RUBY_ST_H -DHAVE_ST_H -DHAVE_RB_STR_REPLACE -DHAVE_RB_INTERN_STR -DHAVE_RB_STR_INTERN -DHAVE_RB_BLOCK_LAMBDA -DHAVE_RB_HASH_DUP -DHAVE_RB_HASH_CLEAR -I/opt/csw/include -D_FILE_OFFSET_BITS=64 -KPIC -xO3 -xarch=pentium_pro -xchip=pentium_pro -KPIC -I.. -Wall -O3 -g -std=gnu99 -m32 -o buffer.o -c buffer.c\r\nmake: Fatal error: Command failed for target `buffer.o'\r\n\r\nGem files will remain installed in /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3 for inspection.\r\nResults logged to /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/ext/msgpack/gem_make.out\r\n\r\ngem install fluentd -v '0.12.43' --debug\r\n....\r\nException NoMethodError' at /opt/csw/lib/ruby/2.0.0/rubygems/package.rb:551 - undefined method readpartial' for #Gem::Package::TarReader::Entry:0x8547948\r\n....\r\nException `Errno::ENOENT' at /opt/csw/lib/ruby/2.0.0/fileutils.rb:1319 - No such file or directory - /opt/csw/lib/ruby/gems/2.0.0/gems/msgpack-1.3.3/lib/msgpack.rb\r\n...", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-22T18:54:16Z", "updated_on": "2021-12-23T23:41:10Z", "closed_on": "2021-12-22T21:45:12Z", "relations": []}, {"id": 18418, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 30835, "name": "hoshinotsuyoshi (tsuyoshi hoshino)"}, "subject": "Add Net::HTTP#security_level=", "description": "### Use Case:\r\n\r\nI want to connect to an HTTP(S) server (using `Net::HTTP`) that cannot connect with security level[^1] 2 and needs to specify security level 1.\r\nMy server is a newer debian (docker image `ruby:3.0.3`, based on debian bullseye) and I need to change the configuration in `/etc/ssl/openssl.cnf` to do the above.\r\nAnd I really don't want to do that, because it affects other SSL communication between my server and other servers.\r\n\r\n---\r\n\r\nSo it would be nice if there is a `Net::HTTP#security_level=` that can change the `OpenSSL::SSL::SSLContext` instance, just like we already have `Net::HTTP#max_version=`.\r\n\r\nNote that similar information has been posted[^2] to the mailing list in the past.\r\n\r\n[^1]: https://www.openssl.org/docs/man1.1.1/man3/SSL_CTX_set_security_level.html\r\n[^2]: http://blade.nagaokaut.ac.jp/cgi-bin/scat.rb/ruby/ruby-list/50825\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-19T11:58:52Z", "updated_on": "2021-12-19T11:58:52Z", "closed_on": null, "relations": []}], [{"id": 18411, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce `Fiber.blocking` for disabling scheduler.", "description": "When implementing pure-ruby IO scheduler, we may need to invoke some Ruby IO operations without entering the scheduler.\r\n\r\n```ruby\r\ndef io_write(fiber, io, buffer, length)\r\n  offset = 0\r\n  \r\n  while length > 0\r\n    # From offset until the end:\r\n    chunk = buffer.to_str(offset, length)\r\n    case result = io.write_nonblock(chunk, exception: false)\r\n    when :wait_readable\r\n      self.io_wait(fiber, io, IO::READABLE)\r\n    when :wait_writable\r\n      self.io_wait(fiber, io, IO::WRITABLE)\r\n    else\r\n      offset += result\r\n      length -= result\r\n    end\r\n  end\r\n  \r\n  return offset\r\nend\r\n```\r\n\r\nThere are some cases where even in this code `read_nonblock` can invoke fiber scheduler creating infinite recursion.\r\n\r\nTherefore, I propose to introduce `Fiber.blocking{...}` which has almost identical implementation to `Fiber.new(blocking: true) {}.resume`.\r\n\r\nIn the above code, we change the line:\r\n\r\n```\r\n    case result = io.write_nonblock(chunk, exception: false)\r\n```\r\n\r\nto\r\n\r\n```\r\n    case result = Fiber.blocking{io.write_nonblock(chunk, exception: false)}\r\n```\r\n\r\nThis ensures that `write_nonblock` can never enter the scheduler again.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-16T07:58:58Z", "updated_on": "2021-12-23T17:10:01Z", "closed_on": null, "relations": []}, {"id": 18410, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9224, "name": "brightbits (Michael Baldry)"}, "subject": "Proposal to make inspect include underscores on numerics", "description": "The documentation for inspect reads \"Returns a string containing a human-readable representation of obj.\" but for large numerical values, while 964218442 is human-readable, 964_218_442 is a lot more readable. The language allows the use of underscores to make numbers more readable, so why should inspect not also honour this?\r\n\r\nHappy to provide a patch if this would be an acceptable change.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-15T21:30:35Z", "updated_on": "2021-12-16T09:07:34Z", "closed_on": null, "relations": [{"id": 3193, "issue_id": 16011, "issue_to_id": 18410, "relation_type": "relates", "delay": null}, {"id": 3194, "issue_id": 17339, "issue_to_id": 18410, "relation_type": "relates", "delay": null}]}, {"id": 18408, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11019, "name": "Dan0042 (Daniel DeLorme)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "Allow pattern match to set instance variables", "description": "I expected this to work:\r\n\r\n```ruby\r\n42 => @v\r\n```\r\n\r\nBut instead it raises \"syntax error, unexpected instance variable\"\r\n\r\nIs this intentional?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-13T20:57:04Z", "updated_on": "2022-01-26T19:07:45Z", "closed_on": null, "relations": [{"id": 3215, "issue_id": 16372, "issue_to_id": 18408, "relation_type": "relates", "delay": null}]}, {"id": 18406, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Remove `NODE_DASGN_CURR`", "description": "This `NODE` type was used in pre-YARV implementation, to improve the performance of assignment to dynamic local variable defined at the innermost scope.\r\nIt has no longer any actual difference with `NODE_DASGN`, except for the node dump.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-13T01:55:41Z", "updated_on": "2021-12-13T03:53:26Z", "closed_on": "2021-12-13T03:53:26Z", "relations": []}, {"id": 18402, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 52048, "name": "Lomig (Lomig Enfroy)"}, "subject": "Argument Labels", "description": "As a developer, I mainly program in two languages: Swift and Ruby.\r\n\r\nI love Ruby with all my heart, but I came to like a particular feature of Swift: **Argument labels** ; I would love to see them appear in Ruby.\r\nMatz on Twitter suggested I post a feature request, so here we are!\r\n\r\n\r\n# Context\r\nNaming is hard.\r\nKeyword arguments helps defining methods that are readable and allow for flexibility ordering arguments, but the result may be a little too verbose as I use to create methods like:\r\n\r\n``` ruby\r\ndef change_color_for_user_until_date(new_color:, user:, end_date:)\r\n  do_something_with(new_color)\r\n  do_something_else_with(user, end_date)\r\nend\r\n\r\nchange_color_for_user_until_date(new_color: :blue, user: user, end_date: DateTime.tomorrow)\r\n```\r\n\r\nAlso, that's not as readable in a \"natural way\" as plenty of code we can produce with Ruby.\r\n\r\nCopying Swift, I would love to have argument labels, aka the option to define a different name for the argument and its related parameter.\r\n\r\n\r\n\r\n# Right now\r\n\r\nThis code is a no-go, as it would be a nightmare to maintain:\r\n(the code below is using reserved keywords so would not work in reality, but it's for the sake of clarity and the sake of the example)\r\n\r\n\r\n```ruby\r\ndef change_color(to:, for:, until:)\r\n  new_color, user, end_date = to, for, until\r\n\r\n  do_something_with(to)\r\n  do_something_else_with(for, until)  # What does this do with which data again?\r\nend\r\n\r\nchange_color(to: :blue, for: user, until: DateTime.tomorrow)\r\n```\r\n\r\nThis being said, I can simulate such a behaviour this way:\r\n(the code below is using reserved keywords so would not work in reality, but it's for the sake of clarity and the sake of the example)\r\n\r\n```ruby\r\ndef change_color(to:, for:, until:)\r\n  new_color, user, end_date = to, for, until # well, those are reserved keywords, I would never be able to use them like that\r\n\r\n  do_something_with(new_color)\r\n  do_something_else_with(user, end_date)\r\nend\r\n\r\nchange_color(to: :blue, for: user, until: DateTime.tomorrow)\r\n```\r\n\r\nThat's not perfect though:\r\n* Not standardized enough\r\n* Conflict with reserved keywords (in reality, I would try to find synonyms? `change_color(with: :blue, regarding: user, up_until: DateTime.tomorrow)` ?)\r\n* An extra line, and not so elegant\r\n\r\n# The feature request mirroring Swift\r\nIt does not have to be implemented exactly this way, of course!\r\n\r\n```ruby\r\ndef change_color(to new_color:, for user:, until end_date:)\r\n\r\n  do_something_with(new_color)\r\n  do_something_else_with(user, end_date) # No use of reserved keywords anymore, and readable variable name!\r\nend\r\n\r\nchange_color(to: :blue, for: user, until: DateTime.tomorrow)\r\n\r\n```\r\n\r\nThanks in advance for your insight on this matter,\r\nCheers!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-11T01:08:43Z", "updated_on": "2022-01-31T18:14:05Z", "closed_on": null, "relations": [{"id": 3192, "issue_id": 17785, "issue_to_id": 18402, "relation_type": "relates", "delay": null}]}, {"id": 18401, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 703, "name": "vo.x (Vit Ondruch)"}, "subject": "Rework `require_relative` to add the \"current path\" on `$LOAD_PATH`", "description": "I think that since inception of `require_relative`, the implementation is wrong and is going against the spirit of `require` functionality. Let me explain.\r\n\r\nIf there is `require \"foo\"`, it does something like:\r\n\r\n~~~\r\nr = $LOAD_PATH.select {|lp| File.exist? File.join(lp, \"foo\")}.first\r\nload(r)\r\n~~~\r\n\r\nBut `require_relative \"foo\"` does something different:\r\n\r\n~~~\r\nr = File.join(File.realpath(__dir__), \"foo\")\r\nload(r)\r\n~~~\r\n\r\nPlease note that this is problematic if mixture of `require` and `require_relative` (not mentioning `__FILE__` and `__dir__` are used. The major difference is actually the `File.realpath` here, because it expands symlinks and that is difference to `require` and may allow double loading.\r\n\r\nMy proposal is to change the `require_relative` in following way:\r\n\r\n~~~\r\n$LOAD_PATH.unshift __dir__\r\nrequire \"foo\"\r\n~~~\r\n\r\nIn essence, non of the `require_relative`, `require`, `__FILE__` or `__dir__` would need to use real path. The scenario bellow would provide expected output:\r\n\r\n~~~\r\n$ mkdir a\r\n$ mkdir b\r\n$ echo 'puts __dir__' > a/test.rb\r\n$ cd b\r\n$ ln -s ../a/test.rb test.rb\r\n$ ruby test.rb\r\n/home/vondruch/ruby/a\r\n~~~\r\n\r\nThis would also resolve issues such as #16978, #10222 or #17885", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-09T17:41:24Z", "updated_on": "2021-12-09T17:41:24Z", "closed_on": null, "relations": []}, {"id": 18397, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 45106, "name": "jemmai (Jemma Issroff)"}, "subject": "Remove documentation that Qfalse == 0 in `extension.rdoc`, instead encourage use of RTEST", "description": "Currently, [the extension documentation](https://github.com/ruby/ruby/blob/master/doc/extension.rdoc#label-Convert+VALUE+into+C+Data) states that \u201cQfalse is false in C (i.e. 0).\u201d Instead, we should encourage the use of RTEST in documentation so that we can change the value of Qfalse in the future. \r\n\r\n**Why would we want to change Qfalse away from 0?**\r\n\r\nMethod calls on objects are one of the most common operations in Ruby. Each time this happens, Ruby needs to resolve the class of the object for method lookup. If the object is a Heap object, this means that Ruby must first check that the handle is a heap object pointer, so it can resolve the class by dereferencing the pointer.\r\n\r\nUnder CRuby\u2019s current value tagging scheme, there are at least 2 comparisons necessary across 4 machine instructions to do this check. In YJIT, for example, this looks like the following:\r\n\r\n```\r\n; assume VALUE is in rax\r\nheap_object_p:\r\ntest rax, immediate_flags\r\njnz not_heap_object          \r\ncmp rax, Qnil \r\njbe not_heap_object\r\n```\r\n\r\nThis is because Qfalse is all 0 bits, whereas other types, like Qnil, Qtrue, flonums, etc, all have toggled bits. This means that [`RB_SPECIAL_CONST_P`](https://github.com/ruby/ruby/blob/715a51a0d6963f9d727191d4e1ad0690fd28c4dd/include/ruby/internal/special_consts.h#L252-L263) (which we negate to check if a handle is a heap pointer), has two distinct operations:  `RB_IMMEDIATE_P(obj) || ! RB_TEST(obj)`. \r\n\r\nIf, however, `Qfalse` was not 0, we could instead rework the value tagging scheme so that all of this could be done with one operation, similar to the existing [`RB_IMMEDIATE_P`](https://github.com/ruby/ruby/blob/715a51a0d6963f9d727191d4e1ad0690fd28c4dd/include/ruby/internal/special_consts.h#L233-L247) check. In an ideal world, the check could look something like this, where `Qfalse` is included in `immediate_flags`:\r\n\r\n```\r\n; assume VALUE is in rax\r\nheap_object_p:\r\ntest rax, immediate_flags\r\njnz not_heap_object          \r\n```\r\n\r\nThis could yield performance benefits in the Ruby Interpreter, YJIT and MJIT because it would speed up any method calls on an object.\r\n\r\n**Why does the current documentation make it difficult to do this?**\r\n\r\nOne current barrier to changing Qfalse away from 0 is that the extension documentation guarantees that in CRuby `Qfalse == 0`. This means that native extensions can (and do!) rely on this fact, and use Qfalse and 0 interchangeably. \r\n\r\nIn fact, even in CRuby itself, there are several examples of when we make implicit assumptions about Qfalse. For instance, using a VALUE as the sole condition in an if statement to check for Qfalse, using MEMZERO to fill a buffer with Qfalse, using calloc to get a buffer filled with Qfalse, and many more.\r\n\r\n**How could changing the documentation help?**\r\n\r\nIf we remove the documentation stating that Qfalse is 0, and instead add documentation insisting on the use of [`RTEST`](https://github.com/ruby/ruby/blob/715a51a0d6963f9d727191d4e1ad0690fd28c4dd/include/ruby/internal/special_consts.h#L123-L149), we will position ourselves to be able to more easily change the value of Qfalse away from 0 in the future.\r\n\r\n**Proposed new documentation**\r\n\r\nSee [this PR](https://github.com/ruby/ruby/pull/5230) or the attached patch for the specific proposed new documentation.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-08T18:34:18Z", "updated_on": "2021-12-09T16:24:21Z", "closed_on": "2021-12-09T16:24:21Z", "relations": []}, {"id": 18395, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "subject": "Introduce Array#subtract! for performance ", "description": "PR: https://github.com/ruby/ruby/pull/5110#issuecomment-984345309\r\n\r\nIt is common to use `-=` to modify an array to remove elements. Also, there is `Array#difference` which accepts multiple arguments. Both of these methods allocate an intermediate array when the original array could be re-used.\r\n\r\nI am proposing we add an API onto Array that allows the programmer to perform a subtraction/difference operation and mutate the original array.\r\n\r\nI am proposing `Array#subtract!`. Reasons why I did not choose `Array#difference!` are discussed in the comments of the PR. I'm also happy to discuss alternative names.\r\n\r\n```\r\nary = [0, 1, 1, 2, 1, 1, 3, 1, 1]\r\nary.subtract!([1]) #=> [0, 2, 3]\r\nary                #=> [0, 2, 3]\r\n\r\nary = [0, 1, 2, 3]\r\nary.subtract!([3, 0], [1, 3]) #=> [2]\r\nary                           #=> [2]\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-07T21:21:05Z", "updated_on": "2021-12-08T16:42:25Z", "closed_on": null, "relations": []}, {"id": 18384, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7576, "name": "baweaver (Brandon Weaver)"}, "subject": "Pattern Match Object", "description": "Related to discussion in #18369 it might be nice to have a literal syntax for constructing a single pattern match case outside of a one-liner.\r\n\r\nYears ago in Qo I had done this via `===` to enable syntax like this:\r\n\r\n```ruby\r\nlist_of_people.select(&Qo[first_name: /^F/, last_name: /r$/, age: 20..40])\r\n```\r\n\r\nThis is valid Ruby, but the pattern match syntax itself cannot be used outside of a literal match, making this impossible without syntax changes.\r\n\r\n### Proposal\r\n\r\nMy proposal would be a case which would be very useful in predicate methods (`any?`, `all?`, etc) and triple-equals responding methods (`select`, `reject`, `grep`, etc):\r\n\r\n```ruby\r\nlist_of_people.select(&pattern(\r\n  first_name: /^F/,\r\n  last_name: /r$/,\r\n  age: 20..40 \r\n))\r\n```\r\n\r\n...in which `pattern` would be substituted with a more appropriate name which I cannot think of at the moment.\r\n\r\n### Portability\r\n\r\nNow the reason I think this could be very interesting is the portability of patterns. Consider the potential of making a `PatternMatch` object much like a Regular Expression:\r\n\r\n```ruby\r\nTARGET_PERSON = PatternMatch.new(first_name: 'something')\r\nlist_of_people.select(&TARGET_PERSON)\r\n```\r\n\r\nAs they can serve similar purposes of giving an expressive language to query against known structures I can see this making sense. The challenge is that the initialization of such an object would need to be special to accommodate the pattern matching syntax, adding more complicated parsing rules.\r\n\r\nThis behavior might be consistent with `Proc`, `RegExp`, and `Range`-like behavior.\r\n\r\n### ActiveRecord-like\r\n\r\nThis gets very close to the classic ActiveRecord `where` pattern:\r\n\r\n```ruby\r\nPeople.where(age: 20..30)\r\n```\r\n\r\n### Potential Issues\r\n\r\nNow this is not without potential issue, as must be highlighted. The first, as just mentioned, is the ActiveRecord syntax and potentially overloading that and keyword arguments:\r\n\r\n```ruby\r\nPeople.where(age: 20..30)\r\n```\r\n\r\nWithout a clear signifier this could make parsing much more difficult.\r\n\r\n### Current Viable Workarounds\r\n\r\nIt also must be mentioned that this is currently possible:\r\n\r\n```ruby\r\nlist_of_people.select { _1 in { first_name: 'something' } }\r\n```\r\n\r\n...though the requirement of explicit braces feels a tinge verbose, I understand why they're present.\r\n\r\nI think this is an acceptable compromise at the moment, but feel we're very close to an interesting syntactic breakthrough.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-03T07:05:32Z", "updated_on": "2022-05-07T18:01:13Z", "closed_on": null, "relations": []}, {"id": 18376, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 703, "name": "vo.x (Vit Ondruch)"}, "subject": "Version comparison API", "description": "Is there a chance to have version comparison API? For example if `Gem::Version` was extracted into `::Version`. This idea was triggered by this PR [1] and [2], where the `Gem::Version` API is used for comparing Ruby versions. While RubyGems might be available everywhere, it does not look correct to introduce dependencies on RubyGems into libraries which could run without them just fine.\r\n\r\n\r\n\r\n[1]: https://github.com/mperham/connection_pool/pull/157\r\n[2]: https://github.com/mperham/connection_pool/issues/158", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-12-01T16:56:05Z", "updated_on": "2021-12-30T10:33:01Z", "closed_on": null, "relations": [{"id": 3185, "issue_id": 17684, "issue_to_id": 18376, "relation_type": "relates", "delay": null}, {"id": 3186, "issue_id": 18376, "issue_to_id": 5861, "relation_type": "duplicates", "delay": null}]}, {"id": 18370, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Call Exception#full_message to print exceptions reaching the top-level", "description": "Extracted from https://bugs.ruby-lang.org/issues/18296#note-6.\r\n\r\nI think this a clear gain to improve consistency in how exceptions are shown, and it also makes it easier to evolve exception formatting in the future.\r\n\r\nIt would also solve https://bugs.ruby-lang.org/issues/18367.\r\n\r\nhttps://bugs.ruby-lang.org/issues/18296#note-7 has more specifics, I'll copy here for convenience:\r\n\r\nmame (Yusuke Endoh) wrote in #note-6:\r\n> Does this proposal include that the ruby interpreter should use `#full_message` to show the error information? This is an incompatibility, is it acceptable?\r\n\r\nYes, let's fix that.\r\nI don't think there is much if any compatibility issue here.\r\nThe output of the uncaught exception handler is already the same as the default Exception#full_message AFAIK, let's actually call it.\r\nTruffleRuby already calls `exc.full_message` for the uncaught exception handler.\r\n\r\nIf the custom `exc.full_message` raises an exception, then it's best to report that exception *and* the original exception using the default `Exception#full_message` (written in C).\r\nThis is the current TruffleRuby output for that case and I think it's clear:\r\n```\r\n$ ruby -e 'class Foo < Exception; def full_message(**); raise \"bar\"; end; end; raise Foo, \"message\"'\r\nError while formatting Ruby exception:\r\n-e:1:in `full_message': bar (RuntimeError)\r\n\tfrom <internal:core> core/truffle/exception_operations.rb:183:in `get_formatted_backtrace'\r\nOriginal Ruby exception:\r\n-e:1:in `<main>': message (Foo)\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-30T14:36:03Z", "updated_on": "2022-02-22T02:56:05Z", "closed_on": "2022-02-22T02:56:05Z", "relations": [{"id": 3183, "issue_id": 18296, "issue_to_id": 18370, "relation_type": "relates", "delay": null}, {"id": 3184, "issue_id": 18367, "issue_to_id": 18370, "relation_type": "relates", "delay": null}]}, {"id": 18369, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48480, "name": "dorianmariefr (Dorian Mari\u00e9)"}, "subject": "users.detect(:name, \"Dorian\") as shorthand for users.detect { |user| user.name == \"Dorian\" }", "description": "Hi,\r\n\r\nI was thinking I often do things like `collection.detect { |item| item.attribute == value }` and a shorthand like `collection.detect(:attribute, value)` would be quite useful\r\n\r\nWhat do you think?\r\n\r\nAnd I know there is `collection.detect { _1.attribute == value }` but I try not to use `_1` and this syntax would be shorter and simpler\r\n\r\nCould also apply to other methods like `all?` (`collection.all?(:attribute, value)`), and basically any Enumerable method https://rubydoc.info/stdlib/core/Enumerable", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-30T12:40:09Z", "updated_on": "2021-12-03T14:23:50Z", "closed_on": null, "relations": []}, {"id": 18368, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "Range#step semantics for non-Numeric ranges", "description": "I am sorry if the question had already been discussed, can't find the relevant topic.\r\n\r\n\"Intuitively\", this looks (for me) like a meaningful statement:\r\n\r\n```ruby\r\n(Time.parse('2021-12-01')..Time.parse('2021-12-24')).step(1.day).to_a\r\n#                                                         ^^^^^ or just 24*60*60\r\n```\r\nUnfortunately, it doesn't work with \"TypeError (can't iterate from Time)\".\r\nInitially it looked like a bug for me, but after digging a bit into code/docs, I understood that `Range#step` has an odd semantics of \"advance the begin N times with `#succ`, and yield the result\", with N being always integer:\r\n```ruby\r\n('a'..'z').step(3).first(5)\r\n# => [\"a\", \"d\", \"g\", \"j\", \"m\"]\r\n```\r\n\r\nThe fact that semantic is \"odd\" is confirmed by the fact that for Float it is redefined to do what I \"intuitively\" expected:\r\n```ruby\r\n(1.0..7.0).step(0.3).first(5)\r\n# => [1.0, 1.3, 1.6, 1.9, 2.2] \r\n```\r\n(Like with [`Range#===` some time ago](https://bugs.ruby-lang.org/issues/14575), I believe that to be a strong proof of the wrong generic semantics, if for numbers the semantics needed to be redefined completely.)\r\n\r\nAnother thing to note is that \"skip N elements\" seem to be rather \"generically Enumerable-related\" yet it isn't defined on `Enumerable` (because nobody needs this semantics, typically!)\r\n\r\nHence, two questions:\r\n* Can we redefine generic `Range#step` to new semantics (of using `begin + step` iteratively)? It is hard to imagine the amount of actual usage of the old behavior (with String?.. to what end?) in the wild\r\n* If the answer is \"no\", can we define a new method with new semantics, like, IDK, `Range#over(span)`?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-29T15:30:40Z", "updated_on": "2022-02-02T15:42:36Z", "closed_on": null, "relations": []}, {"id": 18367, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Stop the interpreter from escaping error messages", "description": "## Proposal\r\n\r\nAt the present time, the Ruby interpreter escapes some characters (*1) in error messages when an uncaught error is printed. I'd like to propose stopping this escaping behavior.\r\n\r\n```\r\nclass MyError < StandardError\r\n  def message\r\n    \"foo\\\\bar\"\r\n  end\r\nend\r\n\r\nraise MyError\r\n#=> current:  test.rb:7: in `<main>': foo\\\\bar (MyError)\r\n#=> excepted: test.rb:7: in `<main>': foo\\bar (MyError)\r\n```\r\n\r\n*1: Escaped characters are any control characters except `\\t` and `\\n`, and a backslash `\\\\`.\r\n\r\n\r\n## Motivation\r\n\r\nThis behavior prevents us from adding an attribution (color, underline, etc.) to the error message because it escapes escape sequences. Nowadays, such a rich presentation of terminal output is more and more important.\r\n\r\n```\r\n$ ruby -e 'raise \"\\e[31mRed\\x1b[0m error\"'\r\n-e:1:in `<main>': \\e[31mRed\\x1b[0m error (RuntimeError)\r\n```\r\n\r\nAlso, the behavior in question leads to rather confusing error printing. See the error output of `\"\\\\\".no_method`:\r\n\r\n```\r\n$ ruby -e '\"\\\\\".no_method'\r\n-e:1:in `<main>': undefined method `no_method' for \"\\\\\\\\\":String (NoMethodError)\r\n\r\n\"\\\\\\\\\".no_method\r\n    ^^^^^^^^^^\r\n```\r\n\r\nThe two occurrences of `\"\\\\\\\\\"` must be `\"\\\\\"`. Worse, the output of error_highlight `^^^^` points wrong position.\r\n\r\nNote that this issue is never specific to error_highlight. The receiver of NoMethodError, `\"\\\\\\\\\":String`, is also wrongly escaped. It must be `\"\\\\\":String`.\r\n\r\n\r\n## Why the escaping behavior was introduced\r\n\r\nAFAIK, the behavior was introduced because of a security concern. It is considered harmful for an attacker to be able to print arbitrary escape sequences to victim's terminal. (See [this article](https://marc.info/?l=bugtraq&m=104612710031920&w=2) in detail.)\r\n\r\nHowever, I believe it is rare to see the error logs of an application that may be exposed to attacks (i.e. in production mode) in a terminal, as the error output of the Ruby interpreter.\r\n\r\nEven if that is the case, I think such escaping should be done as a responsibility of the application, and not implicitly by the interpreter. I briefly surveyed other major languages than Ruby, and I could find no language that escapes error messages. This is the transcript of Python and Node.js.\r\n\r\n```\r\n$ python3 -c 'raise Exception(\"\\x1b[31mRed\\x1b[0m error\")'\r\nTraceback (most recent call last):\r\n  File \"<string>\", line 1, in <module>\r\nException: Red error\r\n\r\n$ node -e 'throw(\"\\x1b[31mRed\\x1b[0m error\")'\r\n\r\n[eval]:1\r\nthrow(\"\\x1b[31mRed\\x1b[0m error\")\r\n^\r\nRed error\r\n(Use `node --trace-uncaught ...` to show where the exception was thrown)\r\n```\r\n\r\nJust in case, I reported these behaviors to the security contacts of Python and Node.js, and both responded to me that this is not a securty issue. I think their decisions are quite reasonable.\r\n\r\n## Migration\r\n\r\nIt would be a good idea to first make the following behavior as a migration path.\r\n\r\n* When an error message does not include a control character, no escaping is applied.\r\n* When an error message does include a control character, \"Warning: this error message is currently escaped because it includes a control character(s), but this will not be escaped in Ruby 3.X\" is printed, and the escaping is applied.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-29T06:29:48Z", "updated_on": "2022-02-22T02:56:05Z", "closed_on": "2022-02-22T02:56:05Z", "relations": [{"id": 3184, "issue_id": 18367, "issue_to_id": 18370, "relation_type": "relates", "delay": null}]}, {"id": 18366, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Enumerator#return_eval", "description": "Some `Enumerable` methods return one or more of the receiver's elements according to the return value of a block it takes. Often, we want such evaluated value rather than the original element.\r\n\r\nFor example, suppose we want to know the character width sufficient to fit all the strings in an array:\r\n\r\n```ruby\r\na = [\"Hello\", \"my\", \"name\", \"is\", \"Ruby\"]\r\n```\r\n\r\nWe either have to repeat the evaluation of the block:\r\n\r\n```ruby\r\na.max_by(&:length).length # => 5\r\n```\r\n\r\nor create a temporal array:\r\n\r\n```ruby\r\na.map(&:length).max # => 5\r\n```\r\n\r\nboth of which seem not to be optimal.\r\n\r\nI propose to have a method `Enumerator#return_eval` that returns the evaluated value(s) of the block:\r\n\r\n```ruby\r\na.max_by.return_eval(&:length) # => 5\r\na.min_by.return_eval(&:length) # => 2\r\na.minmax_by.return_eval(&:length) # => [2, 5]\r\n[\"Ava Davidson\", \"Benjamin Anderson\", \"Charlie Baker\"]\r\n.sort_by.return_eval{_1.split.reverse.join(\", \")}  # => [\"Anderson, Benjamin\", \"Baker, Charlie\", \"Davidson, Ava\"]\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-29T04:04:05Z", "updated_on": "2021-11-30T06:05:46Z", "closed_on": "2021-11-30T02:53:04Z", "relations": []}, {"id": 18364, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Add GC.stat_pool for Variable Width Allocation", "description": "# GitHub PR: https://github.com/ruby/ruby/pull/5177\r\n\r\nWe're proposing an API to get statistics for size pools for Variable Width Allocation similar to `GC.stat`. This will make it easier for us (and other developers) to tune VWA.\r\n\r\nBefore 3.1 release, we plan to keep this method hidden from the documentation using `:nodoc:` since it is not useful when not using VWA.\r\n\r\nFor example:\r\n\r\n```ruby\r\n# Get stats for size pool 2\r\nputs GC.stat_pool(2)\r\n#=> {:slot_size=>160, :heap_allocatable_pages=>80, :heap_eden_pages=>14, :heap_eden_slots=>1424, :heap_tomb_pages=>0, :heap_tomb_slots=>0}\r\nputs GC.stat_pool(2, :heap_eden_pages)\r\n#=> 14\r\n```\r\n\r\nWe aim to keep the keys in the outputted hash the same as the keys used in `GC.stat`.\r\n\r\nWe chose to implement a new method instead of re-using an existing API (`GC.stat`) because the keys returned by `GC.stat_pool` will not be the same as `GC.stat`. We believe that having `GC.stat` return different shapes of hashes based on its arguments is confusing.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-25T15:58:53Z", "updated_on": "2022-01-04T14:48:28Z", "closed_on": "2022-01-04T14:48:28Z", "relations": []}, {"id": 18360, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "subject": "PrettyPrint enhancements", "description": "The message below is a duplicate of the commit message and the PR that I just opened on GitHub (https://github.com/ruby/ruby/pull/5163). I figured I'd open this issue here as there would probably be more discussion than just a GitHub PR warranted.\r\n\r\n## Overall\r\n\r\nThis commit adds a bunch of new functionality to the PrettyPrint class. It is part of my continued work on the Ruby formatter sponsored by the Ruby association (https://www.ruby.or.jp/en/news/20211025). The goal is to enhance the PrettyPrint class enough to support all of the necessary print functionality that the formatter will require in order to print out Ruby source correctly.\r\n\r\n## Current algorithm\r\n\r\nFirst, let's take a look at how PrettyPrint works today. PrettyPrint has 3 primitives:\r\n\r\n* Group - an object that represents a set of content and its associated breakpoints. These objects are usually nested. When one of them no longer fits on a single line, it is broken at all of its associated breakpoints. For example, if you have something like `[text(\"abc\"), breakable, text(\"def\")]` and that group no longer fits on one line, then you will have two lines of output.\r\n* Breakable - an object that represents a location where a line of content can be split. When it is created, if the current group is broken already, then it inserts a newline and carries on. If it is not, then it adds itself to the output buffer.\r\n* Text - this is a set of objects that are appended to a buffer. If the buffer overflows the maximum print width for the line, then the surrounding group is broken and the buffer is flushed to the output.\r\n\r\nWith those primitives in place, the printer maintains a buffer of content that is being added. If the buffer overflows the line, the content is flushed until another group is hit or there are no more breakpoints.\r\n\r\n## Limitations\r\n\r\nThere are a couple of limitations with the current approach.\r\n\r\n* PrettyPrint assumes that content in Text will not change its representation if it is contained within a broken group versus contained within a flat group. This isn't a problem for the existing uses of PrettyPrint, but for my purposes of building a formatter, it definitely is. Consider something like trailing commas (where you want a comma if it is broken but nothing if it's not) or block operators (where you would use a `do` and `end` for multi-line (broken group) or braces for single line (flat group)).\r\n\r\n* The Breakable class assumes that you always want to indent the subsequent line up to the current indentation level. This is true in most cases, and certainly for all the existing use cases. But there are times when you don't want that behavior (for example if you're in the middle of a nested indentation structure but have to force content to start at the beginning of the next line as in a comment with `=begin`..`=end` bounds).\r\n\r\n* There's no way to force a group to break. You can access the current group in the printer with `current_group`, but that won't force the parent groups to break. Without hacking around a lot of stuff, it's difficult to get this behavior. This is necessary if you want to ensure a newline is added and respected, like after a keyword where it would be necessary.\r\n\r\n## Enhancements\r\n\r\nThis commit adds a couple new nodes to the printing tree, as well as enhancing the Breakable class. First, the new nodes:\r\n\r\n* Align - this node effectively wraps the old @indent variable but allows you to align content within any of the other containers. You can also align to a string now instead of just an integer, which will print that string before each line.\r\n* BreakParent - enforces that the surrounding group and all ancestral groups are broken.\r\n* IfBreak - contains two sets of nodes, one for if the surrounding group is broken and one for if the surrounding group is flat.\r\n* Indent - similar to the align node, but you don't have to specify anything and it just indents by one level.\r\n* LineSuffix - this is a big enhancement to the printing algorithm that maintains a separate buffer for content that should be flushed before the next newline. This is convenient for implementing things like heredocs and trailing comments.\r\n* Trim - a rarely used but important node that trims off whitespace that has already been added to the buffer in the case that you need to force something to begin at the start of the next line.\r\n\r\nAs for the enhancements to Breakable:\r\n\r\n* It now accepts a `force` parameter (default to false), which will insert a BreakParent and slightly change semantics so that a newline is _always_ added.\r\n* It now accepts an `indent` parameter (default to true), which allows you to specify if you want the subsequent line to indent automatically.\r\n\r\n## Compatibility\r\n\r\nFor the most part, the code is completely compatible with the previous version.\r\n\r\nThere are a couple of things that were removed that appeared to be all internally-facing functions. When they were removed all of the tests still passed, so I'm assuming they were only called internally. I can certainly add them back if it's deemed too risky but I very much doubt this is a problem.\r\n\r\n* `indent` attr_reader which is now encapsulated in the printing algorithm\r\n* `group_queue` attr_reader which had a reference to a queue that is no longer necessary\r\n* `break_outmost_groups` method, which is now encapsulated in the printing algorithm\r\n* `group_sub` method, which was only called by the `group` method anyway and is no longer necessary\r\n\r\nThere were a bunch of things that were added, including:\r\n\r\n* `force` and `indent` parameters to the `breakable` method (they both have defaults so this shouldn't be an issue)\r\n* `Align`, `BreakParent`, `IfBreak`, `Indent`, `LineSuffix`, and `Trim` nodes\r\n* `Buffer::DefaultBuffer`, `Buffer::StringBuffer`, and `Buffer::ArrayBuffer`, which is just there to provide the ability to trim trailing whitespace\r\n* `PrettyPrint.visit(doc, visitor)`, which is useful for debugging and also necessary for propagating break parent nodes up the tree\r\n\r\nAll in all, none of the tests had to change, which is a good sign.\r\n\r\n## Summary\r\n\r\nFrom the user of this class's perspective, nothing is different. Internally however, there's a bunch of additional functionality and a lot more control over the printing algorithm! Also the ability to debug has been greatly enhanced with pretty_print methods on each of the nodes and the ability to walk the print tree nodes before they're printed.\r\n\r\nI'd still like to add some more tests and work on the documentation a bit more before it's merged. Also, the RBS tests are failing because some of the things have changed type signatures. I'm not sure if I should open a PR over there first or what the policy is for that. Please let me know what I should do with regard to that gem.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-24T00:15:34Z", "updated_on": "2021-11-24T00:15:34Z", "closed_on": null, "relations": []}, {"id": 18357, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 27474, "name": "georgeclaghorn (George Claghorn)"}, "subject": "Proposal: stop raising when block passed to IO#each_* closes the IO", "description": "As of #17661, all of the enumeration methods on `IO`\u2014e.g. `each_line`, `each_byte`, `each_codepoint`\u2014raise `IOError` when the given block closes the `IO`. For example, the following code raises an `IOError` if the peer sends a line containing only `quit`:\r\n\r\n``` ruby\r\nsocket.each_line do |line|\r\n  if line.casecmp?(\"quit\\n\")\r\n    socket.puts \"Goodbye\"\r\n    socket.close\r\n  end\r\nend\r\n```\r\n\r\nIn this example, it\u2019s trivial to `break` after closing the client socket. However, in real code, it\u2019s likely that the command-handling code will be further away from the loop and unable to `break` out of the loop. Either the command-handling method and all intervening methods need to pass an indication of whether to keep reading back down the stack, or the block needs to include an explicit `break if io.closed?`.\r\n\r\nIn my experience, when I close an `IO`within a read loop, I intend to immediately stop reading as well. It would be more agreeable if `each_line` et al. simply stopped reading when the `IO` is closed in the block instead of raising `IOError`.\r\n\r\nI recognize this may be considered a breaking change. The patch for #17661 was backported to 3.0, and `each_line` has behaved this way for longer. This may be workable as an option to the enumeration methods, but I\u2019m not sure an option is worth its weight compared to explicit `break if io.closed?`. I\u2019m mostly asking for a decision on whether the implicit behavior is worth changing for convenience and developer happiness (and aware the answer may be no).\r\n\r\nI\u2019ve attached a patch containing a sample implementation for `IO#each_line` and updated specs. I believe this change can be implemented similarly for all other enumeration methods.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-22T21:03:39Z", "updated_on": "2021-11-22T21:03:39Z", "closed_on": null, "relations": []}, {"id": 18351, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1604, "name": "jeremyevans0 (Jeremy Evans)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Support anonymous rest and keyword rest argument forwarding", "description": "I would like to add support for the following syntax:\r\n\r\n```ruby\r\ndef foo(*)\r\n  bar(*)\r\nend\r\ndef baz(**)\r\n  quux(**)\r\nend\r\n```\r\n\r\nThis is a natural addition after the introduction of anonymous block forwarding.  Anonymous rest and keyword rest arguments were already supported in method parameters, this just allows them to be used as arguments to other methods.  The same advantages of anonymous block forwarding apply to rest and keyword rest argument forwarding.\r\n\r\nI've submitted a pull request implementing this syntax: https://github.com/ruby/ruby/pull/5148", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-19T18:58:30Z", "updated_on": "2021-12-30T22:39:12Z", "closed_on": "2021-12-30T22:39:12Z", "relations": [{"id": 3345, "issue_id": 18351, "issue_to_id": 18828, "relation_type": "relates", "delay": null}]}, {"id": 18349, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10073, "name": "k0kubun (Takashi Kokubun)"}, "subject": "Let --jit enable YJIT on supported platforms", "description": "## Proposal\r\n* Rename the current `--jit` to `--mjit`, as well as reverting [Feature #17490]\r\n* Let `--jit` mean `--yjit` on YJIT-supported platforms, and `--mjit` on other platforms.\r\n\r\n## Use case\r\nYJIT currently achieves better performance than MJIT in many benchmarks, which means users should choose YJIT over MJIT with Ruby 3.1 in many cases. Even in benchmarks where MJIT could perform well, you need to spend a lot of time to finish warmup and [tune MJIT carefully](https://speakerdeck.com/k0kubun/rubyconf-2021?slide=11) to see the peak performance.\r\n\r\nHowever, it's hard for many people, not including heavy users like you reading this, to understand which JIT variant they should try and/or use MJIT properly. Assuming x86 is prevalent enough, I want to make YJIT the default JIT so that non-heavy users will be able to see the benefit of JIT earlier.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-19T18:05:22Z", "updated_on": "2021-12-14T00:08:50Z", "closed_on": "2021-12-14T00:08:50Z", "relations": [{"id": 3216, "issue_id": 17490, "issue_to_id": 18349, "relation_type": "relates", "delay": null}]}, {"id": 18344, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance Kernel#Float with using Primitive.mandatory_only? method", "description": "Recently, introduce `Primitive.mandatory_only?` method(to improve performance Time.at methods).\r\nAnd, I tried to if can improve `Kernel#Float` method perfomance  with using `Primitive.mandatory_only?` method.\r\n\r\nbenchmark:\r\n```yml\r\nbenchmark:\r\n  float: \"Float(42)\"\r\n  float_true: \"Float(42, exception: true)\"\r\n  float_false: \"Float(42, exception: false)\"\r\nloop_count: 10000\r\n\r\n```\r\n\r\nresult:\r\n```\r\nsh@DESKTOP-L0NI312:~/rubydev/build$ make benchmark/kernel_float.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby -e BENCH_OPTS=--repeat-count=4\r\ngenerating vm_call_iseq_optimized.inc\r\nvm_call_iseq_optimized.inc unchanged\r\nCalculating -------------------------------------\r\n                     compare-ruby  built-ruby\r\n               float      41.000M     47.416M i/s -     10.000k times in 0.000244s 0.000211s\r\n          float_true      10.875M     21.317M i/s -     10.000k times in 0.000920s 0.000469s\r\n         float_false      13.910M     22.847M i/s -     10.000k times in 0.000719s 0.000438s\r\n\r\nComparison:\r\n                            float\r\n          built-ruby:  47415837.0 i/s\r\n        compare-ruby:  41000410.0 i/s - 1.16x  slower\r\n\r\n                       float_true\r\n          built-ruby:  21317416.4 i/s\r\n        compare-ruby:  10875475.8 i/s - 1.96x  slower\r\n\r\n                      float_false\r\n          built-ruby:  22846698.6 i/s\r\n        compare-ruby:  13910140.5 i/s - 1.64x  slower\r\n```\r\n\r\n`COMPARE_RUBY` is `ruby 3.1.0dev (2021-11-17T13:21:42Z master b95d7d2099) [x86_64-linux]`. BENCH_RUBY is ahead of `ruby 3.1.0dev (2021-11-17T13:21:42Z master b95d7d2099) [x86_64-linux]`.\r\n\r\npull request: https://github.com/ruby/ruby/pull/5133", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-17T14:47:40Z", "updated_on": "2021-11-18T04:27:26Z", "closed_on": "2021-11-18T04:27:26Z", "relations": []}, {"id": 18339, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "GVL instrumentation API", "description": "# GVL instrumentation API\r\n\r\n### Context\r\n\r\nOne of the most common if not the most common way to deploy Ruby application these days is through threaded runners (typically `puma`, `sidekiq`, etc).\r\n\r\nWhile threaded runners can offer more throughput per RAM than forking runners, they do require to carefully set the concurrency level (number of threads).\r\nIf you increase concurrency too much, you'll experience GVL contention and the latency will suffer.\r\n\r\nThe common way today is to start with a relatively low number of threads, and then increase it until CPU usage reach an acceptably high level (generally `~75%`).\r\nBut this method really isn't precise, require to saturate one process with fake workload, and doesn't tell how much threads are waiting on the GVLs, just how much the CPU is used.\r\n\r\nBecause of this, lots of threaded applications are not that well tuned, even more so because the ideal configuration is very dependant on the workload and can vary over time. So a decent setting might not be so good six months later.\r\n\r\nIdeally, application owners should be able to continuously see the impact of the GVL contention on their latency metric, so they can more accurately decide what throughput vs latency tradeoff is best for them and regularly adjust it.\r\n\r\n### Existing instrumentation methods\r\n\r\nCurrently, if you want to measure how much GVL contention is happening, you have to use some lower level tracing tools\r\nsuch as `bpftrace`, or `dtrace`. These are quite advanced tools and require either `root` access or to compile Ruby with different configuration flags etc.\r\n\r\nThey're also external, so common Application Performance Monitoring (APM) tools can't really report it.\r\n\r\n### Proposal\r\n\r\nI'd like to have a C-level hook API around the GVL, with 3 events:\r\n\r\n  - `RUBY_INTERNAL_EVENT_THREAD_READY`\r\n  - `RUBY_INTERNAL_EVENT_THREAD_RESUME`\r\n  - `RUBY_INTERNAL_EVENT_THREAD_PAUSE`\r\n\r\nSuch API would allow to implement C extensions that collect various metrics about the GVL impact, such as median / p90 / p99 wait time, or even per thread total wait time.\r\n\r\nAditionaly it would be very useful if the hook would pass some metadata, most importantly, the number of threads currently waiting.\r\nPeople interested in a lower overhead monitoring method not calling `clock_gettime` could instrument that number of waiting thread instead. It would be less accurate, but enough to tell wether there might be problem.\r\n\r\nWith such metrics, application owners would be able to much more precisely tune their concurrency setting, and deliberately chose their own tradeoff between throughput and latency.\r\n\r\n\r\n### Implementation\r\n\r\nI submitted a PR for it https://github.com/ruby/ruby/pull/5500 (lacking windows support for now)\r\n\r\nThe API is as follow:\r\n\r\n  - `rb_thread_hook_t * rb_thread_event_new(rb_thread_callback callback, rb_event_flag_t event)`\r\n  - `bool rb_thread_event_delete(rb_thread_hook_t * hook)`\r\n\r\nThe overhead when no hook is registered is just a single unprotected boolean check, so close to zero.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-15T09:29:24Z", "updated_on": "2022-06-03T13:14:48Z", "closed_on": "2022-06-03T13:14:48Z", "relations": []}, {"id": 18336, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "subject": "How to deal with Trojan Source vulnerability", "description": "The \"Torjan Source\" vulnerability recently has caught some attention.\r\n\r\nThe vulnerability involves using certain combinations of Unicode characters to let source code look like it is correct (and therefore pass code review,...) but actually do something else than intended.\r\n\r\nFor background, please see discussion on KrebsonSecurity (https://krebsonsecurity.com/2021/11/trojan-source-bug-threatens-the-security-of-all-code/) and the Web site (https://www.trojansource.codes/) and original paper (https://www.trojansource.codes/trojan-source.pdf).\r\n\r\nI contacted the Ruby security list, which was already aware of the issue, and we agreed to discuss this here because the vulnerability is already public.\r\n\r\nThe paper focuses on the use of [A] Directional Formatting Characters (*1) in string constants, comments, and similar constructs to change the visual appearance of code outside these constructs. There are related vulnerabilities, namely the use of [B] non-spacing (and therefore mostly invisible) characters e.g. in variable names, and the use of [C] mixed-script identifiers, which also lets some variable names look identical even if they are not.\r\n\r\nSome languages, such as Rust, have addressed [A] (see https://blog.rust-lang.org/2021/11/01/cve-2021-42574.html) by requiring escapes to be used for the relevant characters in source. On the other hand, people such as Russ Cox think compilers are the wrong place to address the issue; it should be addressed in editors and similar tools (see https://research.swtch.com/trojan). Github now warns about \r\n\r\nThe question is what Ruby should do, if anything.\r\nAddressing [A] similar to how Rust does it can be done relatively easily. If that's done, I'd prefer to only reject incomplete Bidi control sequences, which is a bit more complicated. In particular, string interpolation needs a very careful analysis.\r\nFor [B], I'll open a separate issue.\r\nFor [C], we have all data about scripts, but the way it's currently structured makes finding out which character a script belongs to quite inefficient.\r\n\r\n\r\n(*1) \"Directional Formatting Character\" is the official Unicode term (see https://www.unicode.org/reports/tr9/#Directional_Formatting_Characters). The terms \"Bidi/Bidirectional control\" or \"Bidi/Bidirectional control character\" are also used. Overall, there are 9 such characters. Unfortunately, both the paper and KrebsonSecurity use the term \"Bidi Override\", which is highly misleading. The term \u201cBidi Override\u201d is reserved for two characters only:\r\nLRO, U+202D, Left-to-Right Override, and RLO, U+202E, Right-to-Left Override (see Table 1 in the paper). It is also used for the phenomenon associated with these two characters, a \u201chard\u201d override (i.e. affecting all characters including e.g. the Latin alphabet), and mechanisms in other technology that achieve the same (e.g. the HTML bdo element (https://html.spec.whatwg.org/#the-bdo-element) or the \u2018bidi-override\u2019 value of the unicode-bidi property in CSS (https://www.w3.org/TR/CSS2/visuren.html#propdef-unicode-bidi)).\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-15T00:08:46Z", "updated_on": "2021-11-23T20:39:34Z", "closed_on": "2021-11-22T02:55:36Z", "relations": [{"id": 3170, "issue_id": 18336, "issue_to_id": 18337, "relation_type": "relates", "delay": null}]}, {"id": 18334, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 288, "name": "postmodern (Hal Brodigan)"}, "subject": "ENV#to_h returns a new Hash object but Hash#to_h does not, which can cause inconsistencies", "description": "I noticed that in ruby-3.1.0-preview1 ENV#dup was removed in favor of ENV#to_h. However, methods that accept either ENV or a Hash object will not behave the same, since ENV#to_h returns a new Hash object but Hash#to_h returns the same Hash instance.\r\n\r\n    ENV.to_h.object_id\r\n    # => 14700\r\n    ENV.to_h.object_id\r\n    # => 14760\r\n    hash = {\"FOO\" => \"bar\"}\r\n    hash.to_h.object_id\r\n    # => 14820\r\n    hash.to_h.object_id\r\n    # => 14820\r\n\r\nI propose that the ENV#dup method be re-added as `self.to_h.dup`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-14T05:08:50Z", "updated_on": "2021-11-17T17:46:33Z", "closed_on": null, "relations": []}, {"id": 18332, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48480, "name": "dorianmariefr (Dorian Mari\u00e9)"}, "subject": "a ? b", "description": "It would be a shortcut for `a ? b : nil`:\r\n\r\ne.g.\r\n\r\n```\r\n\"#{current_path == \"/\" ? \"font-bold\"}\"\r\n\"#{user.admin? ? \"text-red-600\"}\"\r\n```\r\n\r\nDoing `a && b` returns `false` which converted to a string gives `\"false\"`.\r\n\r\nWhen `nil` converts to a string it gives `\"\"`.\r\n\r\nI would use it mostly in string interpolations.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-13T18:41:51Z", "updated_on": "2021-12-29T04:38:43Z", "closed_on": null, "relations": []}, {"id": 18331, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Kernel.#Time", "description": "I remember that, once, Matz suggested a new literal notation for date/time, but he later withdrew it. It seems like introducing new syntax at this point is less realistic. But I believe that many people have wanted a simple way to create a date/time object.\r\n\r\nI propose `Kernel.Time` or `Kernel#Time`, in much of the same way as `Kernel.#Integer`, `Kernel.#Float`, `Kernel.#Complex` and others. It should take a string as the first required argument and some optional keyword arguments.\r\n\r\n```rb\r\nTime(\"2021-11-13T21:21:18.027294 +0900\") # => 2021-11-13 21:21:18.027294 +0900\r\nTime(\"2021-11-13 21:21:18.027294 +0900\") # => 2021-11-13 21:21:18.027294 +0900\r\nTime(\"foo\", exception: false) # => nil\r\n```\r\n\r\nI leave out the specifics. There should be room for debate.\r\n\r\nI wish the features nobu implemented in https://bugs.ruby-lang.org/issues/18033 for `Time.new` can be carried over to `Kernel.#Time`.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-13T12:27:30Z", "updated_on": "2021-11-13T12:41:33Z", "closed_on": null, "relations": [{"id": 3187, "issue_id": 18033, "issue_to_id": 18331, "relation_type": "relates", "delay": null}]}, {"id": 18296, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Custom exception formatting should override `Exception#full_message`.", "description": "After discussing with @eregon, we came to the conclusion that the current implementation of `did_you_mean` and `error_highlight` could avoid many issues by using `Exception#full_message`.\r\n\r\nWe propose to introduce a more nuanced interface:\r\n\r\n```ruby\r\nclass Exception\r\n  def full_message(highlight: bool, order: [:top or :bottom], **options)\r\n    # ...\r\n  end\r\nend\r\n\r\nmodule DidYouMean\r\n  module Formatter\r\n    def full_message(highlight:, did_you_mean: true, **options)\r\n      buffer = super(highlight: highlight, **options).dup\r\n      buffer << \"extra stuff\"\r\n    end\r\n  end\r\nend\r\nException.prepend DidYouMean::Formatter\r\n\r\nmodule ErrorHighlight\r\n  module Formatter\r\n    def full_message(highlight:, error_highlight: true, **options)\r\n      # same as above\r\n    end\r\n  end\r\nend\r\nException.prepend ErrorHighlight::Formatter\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-10T11:49:32Z", "updated_on": "2021-12-15T20:49:55Z", "closed_on": null, "relations": [{"id": 3137, "issue_id": 18170, "issue_to_id": 18296, "relation_type": "relates", "delay": null}, {"id": 3138, "issue_id": 18194, "issue_to_id": 18296, "relation_type": "relates", "delay": null}, {"id": 3183, "issue_id": 18296, "issue_to_id": 18370, "relation_type": "relates", "delay": null}, {"id": 3206, "issue_id": 18296, "issue_to_id": 18438, "relation_type": "relates", "delay": null}]}, {"id": 18291, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2083, "name": "zw963 (Wei Zheng)"}, "subject": "When use =~ with named group, if regex is on the right side, variable not defined.", "description": "Following code not work.\r\n\r\n\r\n```rb\r\nif \"Billy Zheng\" =~ /(?<first_name>\\w+)\\s+(?<last_name>\\w+)/\r\n  p first_name\r\n  p last_name\r\nend\r\n# NameError: undefined local variable or method `first_name' for main:Object\r\n```\r\n\r\nBut, if we switch left and right between =~\r\n\r\n```rb\r\nif /(?<first_name>\\w+)\\s+(?<last_name>\\w+)/ =~ \"Billy Zheng\"\r\n  p first_name\r\n  p last_name\r\nend\r\n# => \"Billy\"\r\n# =>\"Zheng\"\r\n```\r\n\r\nI know ruby keep this same behavior since 1.9, but i am curious if we can improve this?\r\n\r\nI consider this as a bug, because that not good, when i want to use this way, i have to\r\ntake care must write regexp before =~\r\n\r\nThank you.\r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-05T15:12:55Z", "updated_on": "2021-11-06T12:36:26Z", "closed_on": null, "relations": []}, {"id": 18290, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "subject": "Deprecate rb_gc_force_recycle", "description": "# GitHub PR: https://github.com/ruby/ruby/pull/4363\r\n\r\nI'm proposing to deprecate `rb_gc_force_recycle` and make it a no-op function because it is a burden to maintain and makes changes to the GC difficult. It is also easy to incorrectly use this function and cause memory leaks such as #18065.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-05T14:01:37Z", "updated_on": "2021-11-08T19:06:13Z", "closed_on": "2021-11-08T19:06:13Z", "relations": []}, {"id": 18287, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10409, "name": "Strech (Sergey Fedorov)"}, "assigned_to": {"id": 10409, "name": "Strech (Sergey Fedorov)"}, "subject": "Support nil value for sort in Dir.glob", "description": "Good day, everyone.\r\n\r\nI would like to suggest (or question) the support of a `nil` value for `sort` argument in `Dir.glob`.\r\nI find this behaviour a bit surprising, here is an example:\r\n\r\n```\r\nirb(main):001:0> Dir.glob(\"brace/a{.js,*}\", sort: true)\r\n=> [\"brace/a.js\", \"brace/a\", \"brace/a.erb\", \"brace/a.html.erb\", \"brace/a.js\", \"brace/a.js.rjs\"]\r\n\r\nirb(main):001:0> Dir.glob(\"brace/a{.js,*}\", sort: false)\r\n=> [\"brace/a.js\", \"brace/a.js\", \"brace/a.html.erb\", \"brace/a.erb\", \"brace/a.js.rjs\", \"brace/a\"]\r\n\r\nirb(main):001:0> Dir.glob(\"brace/a{.js,*}\", sort: nil)\r\n=> [\"brace/a.js\", \"brace/a\", \"brace/a.erb\", \"brace/a.html.erb\", \"brace/a.js\", \"brace/a.js.rjs\"]\r\n```\r\n\r\nAs you can see \u2013 `sort: nil` produces the same results as `sort: true` which is confusing\r\n\r\nGithub link: https://github.com/ruby/ruby/pull/5079\r\nRuby spec link: https://github.com/ruby/spec/pull/894", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-04T08:47:31Z", "updated_on": "2021-11-18T14:34:32Z", "closed_on": "2021-11-18T12:47:33Z", "relations": []}, {"id": 18285, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 16600, "name": "ivoanjo (Ivo Anjo)"}, "subject": "NoMethodError#message uses a lot of CPU/is really expensive to call", "description": "Hello there! I'm working at Datadog on the ddtrace gem -- https://github.com/DataDog/dd-trace-rb and we ran into this issue on one of our internal testing applications. I also blogged about this issue in <https://ivoanjo.me/blog/2021/11/01/nomethoderror-ruby-cost/>.\r\n\r\n### Background\r\n\r\nWhile testing an application that threw a lot of `NoMethodError`s in a Rails controller (this was used for validation), we discovered that service performance was very much impacted when we were logging these exceptions. While investigating with a profiler, the performance impact was caused by calls to `NoMethodError#message`, because this Rails controller had a quite complex `#inspect` method, that was getting called every time we tried to get the `#message` from the exception.\r\n\r\n### How to reproduce\r\n\r\n```ruby\r\nrequire 'bundler/inline'\r\n\r\ngemfile do\r\n  source 'https://rubygems.org'\r\n\r\n  gem 'benchmark-ips'\r\nend\r\n\r\nputs RUBY_DESCRIPTION\r\n\r\nclass GemInformation\r\n  # ...\r\n\r\n  def get_no_method_error\r\n    method_does_not_exist\r\n  rescue => e\r\n    e\r\n  end\r\n\r\n  def get_runtime_error\r\n    raise 'Another Error'\r\n  rescue => e\r\n    e\r\n  end\r\n\r\n  def inspect # <-- expensive method gets called when calling NoMethodError#message\r\n    Gem::Specification._all.inspect\r\n  end\r\nend\r\n\r\nNO_METHOD_ERROR_INSTANCE = GemInformation.new.get_no_method_error\r\nRUNTIME_ERROR_INSTANCE = GemInformation.new.get_runtime_error\r\n\r\nBenchmark.ips do |x|\r\n  x.config(:time => 5, :warmup => 2)\r\n\r\n  x.report(\"no method error message cost\") { NO_METHOD_ERROR_INSTANCE.message }\r\n  x.report(\"runtime error message cost\") { RUNTIME_ERROR_INSTANCE.message }\r\n\r\n  x.compare!\r\nend\r\n```\r\n\r\n### Expectation and result\r\n\r\nGetting the `#message` from a `NoMethodError` should be no costly than getting it from any other exception.\r\n\r\nIn reality:\r\n\r\n```\r\nruby 3.0.2p107 (2021-07-07 revision 0db68f0233) [x86_64-linux]\r\n\r\nno method error message cost\r\n                        115.390  (\u00b1 1.7%) i/s -    580.000  in   5.027822s\r\nruntime error message cost\r\n                          6.938M (\u00b1 0.5%) i/s -     35.334M in   5.092617s\r\n\r\nComparison:\r\nruntime error message cost:  6938381.6 i/s\r\nno method error message cost:      115.4 i/s - 60130.02x  (\u00b1 0.00) slower\r\n```\r\n\r\n### Suggested solutions\r\n\r\n1. Do not call `#inspect` on the object on which the method was not found (see <https://github.com/ruby/ruby/blob/e0915ba67964d843832148aeca29a1f8244ca7b1/error.c#L1962>)\r\n2. Cache result of calling `#message` after the first call. Ideally this should be done together with suggestion 1.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-02T12:08:10Z", "updated_on": "2022-01-30T12:45:29Z", "closed_on": null, "relations": [{"id": 3173, "issue_id": 6733, "issue_to_id": 18285, "relation_type": "relates", "delay": null}, {"id": 3176, "issue_id": 6291, "issue_to_id": 18285, "relation_type": "relates", "delay": null}, {"id": 3177, "issue_id": 6783, "issue_to_id": 18285, "relation_type": "relates", "delay": null}]}, {"id": 18280, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 13640, "name": "ukolovda (Dmitry Ukolov)"}, "subject": "Allow rb_utf8_str_new_cstr(NULL)", "description": "Ruby process crushed.\r\n\r\n`\r\nAddressable::URI when parsed from 'http://example.com/%E8'\r\n/home/ukolovda/RubymineProjects/external/addressable/lib/addressable/idna/native.rb:34: [BUG] Segmentation fault at 0x0000000000000000\r\nruby 3.1.0dev (2021-10-31T09:27:55Z master 13a9597c7c) [x86_64-linux]\r\n\r\n-- Control frame information -----------------------------------------------\r\nc:0043 p:---- s:0231 e:000230 CFUNC  :nfkc_normalize\r\nc:0042 p:0019 s:0226 e:000225 METHOD /home/ukolovda/RubymineProjects/external/addressable/lib/addressable/idna/native.rb:34\r\nc:0041 p:0323 s:0221 e:000219 METHOD /home/ukolovda/RubymineProjects/external/addressable/lib/addressable/uri.rb:583\r\nc:0040 p:0038 s:0210 e:000209 BLOCK  /home/ukolovda/RubymineProjects/external/addressable/lib/addressable/uri.rb:1559 [FINISH]\r\n...\r\n\r\n-- Machine register context ------------------------------------------------\r\n RIP: 0x00007feea7aa9f35 RBP: 0x0000000000000000 RSP: 0x00007ffc0e4ffdf8\r\n RAX: 0x0000000000000000 RBX: 0x0000000055550083 RCX: 0x0000000000000000\r\n RDX: 0x0000000000000000 RDI: 0x0000000000000000 RSI: 0x0000000004f72d81\r\n  R8: 0x0000000004f72d83  R9: 0x00007fee95642a68 R10: 0x0000000000000001\r\n R11: 0x0000000000000000 R12: 0x00007fee96663dc0 R13: 0x0000000000000001\r\n R14: 0x00007fee9a414590 R15: 0x0000000002ce4b20 EFL: 0x0000000000010283\r\n\r\n-- C level backtrace information -------------------------------------------\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(rb_print_backtrace+0x11) [0x7feea80838d5] vm_dump.c:759\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(rb_vm_bugreport) vm_dump.c:1045\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(rb_bug_for_fatal_signal+0xf0) [0x7feea7e88cb0] error.c:820\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(sigsegv+0x49) [0x7feea7fd99b9] signal.c:964\r\n/lib64/libpthread.so.0(__restore_rt+0x0) [0x7feea7d601b0]\r\n/lib64/libc.so.6(__strlen_avx2+0x15) [0x7feea7aa9f35]\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(rb_str_new_cstr+0x9) [0x7feea7ff4999] string.c:958\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(rb_utf8_str_new_cstr+0x7) [0x7feea7ff49f7] string.c:972\r\n/home/ukolovda/.rvm/gems/ruby-head/gems/idn-ruby-0.1.2/lib/idn.so(nfkc_normalize+0x4d) [0x7fee96668a5d] stringprep.c:159\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(vm_cfp_consistent_p+0x0) [0x7feea80636a4] vm_insnhelper.c:3025\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(vm_call_cfunc_with_frame) vm_insnhelper.c:3027\r\n/home/ukolovda/.rvm/rubies/ruby-head/lib/libruby.so.3.1(vm_sendish+0x4e) [0x7feea80688e9] vm_insnhelper.c:4651\r\n...\r\n\r\n`\r\n\r\nLalest ruby version (`rvm install ruby-head`)\r\n\r\n\r\nIn previous version it give exception:\r\n`ArgumentError: NULL pointer given`\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-11-01T07:06:00Z", "updated_on": "2021-11-11T10:28:16Z", "closed_on": "2021-11-01T13:39:18Z", "relations": []}, {"id": 18279, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2083, "name": "zw963 (Wei Zheng)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "ENV.merge! support multiple arguments as Hash.merge!", "description": "I give a useful example for this.\r\n\r\n```rb\r\nrequire 'yaml'\r\nenv_files = ['config.yml', 'config.local']\r\nenvs = env_files.filter_map {|file| YAML.load_file(file)['env'] if File.file?(file) }\r\nENV.merge!(*envs) # Raise wrong number of arguments (given 2, expected 1)\r\n\r\n\r\n```\r\n\r\nFor now, above code have do like this in ruby 3.0.2\r\n\r\n```rb\r\nENV.merge!({}.merge!(*envs))\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-30T17:00:16Z", "updated_on": "2022-06-16T16:22:44Z", "closed_on": "2022-06-16T16:22:44Z", "relations": []}, {"id": 18276, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "`Proc#bind_call(obj)` same as `obj.instance_exec(..., &proc_obj)`", "description": "`Proc#bind_call(obj)` same as `obj.instance_exec(..., &proc_obj)`\r\n\r\n```ruby\r\nproc_obj = proc{|params...| ...}\r\nobj.instance_exec(params..., &proc_obj)\r\n```\r\n\r\nis frequent pattern.\r\n\r\n```\r\n$ gem-codesearch 'instance_exec.+\\&' | wc -l\r\n9558\r\n```\r\n\r\nHow about to introduce new method `Proc#bind_call`?\r\n\r\n```ruby\r\nclass Proc\r\n  def bind_call obj, *args\r\n    obj.instance_exec(*args, &self)\r\n  end\r\nend\r\n\r\npr = ->{ p self }\r\npr.bind_call(\"hello\") #=> \"hello\"\r\npr.bind_call(nil)     #=> nil\r\n```\r\n\r\nIt is similar to `UnboundMethod#bind_call`.\r\n\r\n----\r\n\r\nMy motivation;\r\n\r\nI want to solve shareable Proc's issue https://bugs.ruby-lang.org/issues/18243 and one idea is to prohibit `Proc#call` for shareable Proc's, but allow `obj.instance_exec(&pr)`. To make shortcut, I want to introduce `Proc#bind_call`.\r\n\r\n`UnboundProc` is another idea, but I'm not sure it is good idea...\r\n\r\nAnyway, we found that there are many usage of `instance_exec(&proc_obj)`, so `Proc#bind_call` is useful not for Ractors.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-28T12:37:12Z", "updated_on": "2021-12-03T04:04:33Z", "closed_on": "2021-12-03T04:04:33Z", "relations": [{"id": 3129, "issue_id": 18243, "issue_to_id": 18276, "relation_type": "relates", "delay": null}]}, {"id": 18275, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 27992, "name": "vinistock (Vinicius Stock)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Add an option to define_method to not capture the surrounding environment", "description": "Invoking `define_method` will capture the surrounding environment, making sure we have access to anything defined in that surrounding scope. However, that\u2019s not always necessary. There are uses for `define_method` where the surrounding environment is not needed.\r\n\r\nAlways capturing the surrounding environment slows down even the methods that don\u2019t need access to it. Additionally, it prevents methods created using `define_method` to exist in all Ractors in a program.\r\n\r\nIf we could add an option to disable capturing the surrounding environment for `define_method`, we could make it so that it creates the dynamic method in all Ractors.\r\n\r\nThere could also be some performance benefits for the usages that do not need the surrounding environment. By not having to keep references to the surrounding scope, the GC could let go of locals from that environment, which might benefit GC as well.\r\n\r\nAnother option could be to accept the list of locals that the `define_method` invocation will need, as a way of letting go of references that are no longer needed.\r\n\r\nExamples:\r\n\r\n```ruby\r\n# Current behavior\r\n#\r\n# All of the surrounding environment is captured and references are kept for the locals\r\n# The method created only exists in the current Ractor, due to possible references to the captured variables\r\n\r\nsome_random_thing = \"a\" * 10000\r\nsome_captured_block = -> { ... }\r\n\r\ndefine_method(:my_method, &some_captured_block)\r\n```\r\n\r\n```ruby\r\n# Enable/disable all option\r\n#\r\n# Add an option that allows disabling capturing the surrounding environment completely\r\n# The method created exists in all Ractors and none of the references are kept\r\n\r\nsome_random_thing = \"a\" * 10000\r\nsome_captured_block = -> { ... }\r\n\r\ndefine_method(:my_method, capture_environment: false, &some_captured_block)\r\n```\r\n\r\n```ruby\r\n# Choose variables option\r\n#\r\n# Add an option that allows indicating which locals are needed for a define_method invocation\r\n# The method created exists in all Ractors if no locals are needed\r\n# The method is created only in the current Ractor if at least one local is needed\r\n# All \u201cunneeded\u201d locals are let go\r\n\r\nsome_random_thing = \"a\" * 10000 # kept because `my_method` needs it\r\nanother_random_thing = \"b\" * 10000 # not kept\r\nsome_captured_block = -> { ... }\r\n\r\ndefine_method(:my_method, needs: [:some_random_thing], &some_captured_block)\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-27T19:27:45Z", "updated_on": "2021-12-03T14:34:29Z", "closed_on": "2021-10-29T20:07:50Z", "relations": []}, {"id": 18273, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Class#subclasses", "description": "Ref: https://github.com/rails/rails/pull/43481\r\n\r\nSomething we forgot to mention in [Feature #14394], is either a parameter or another method to only get direct descendants.\r\n\r\nActive Support has been offering `Class.subclasses` as:\r\n\r\n```ruby\r\n  def subclasses\r\n    descendants.select { |descendant| descendant.superclass == self }\r\n  end\r\n```\r\n\r\nIt seems a bit silly to grab all descendants and then restrict the list when `Class#descendants` had to do some recursion to get them all in the first place.\r\n\r\n### Proposal\r\n\r\nWe could either implement `Class#subclasses` directly, or accept a parameter in `Class#descendants`, e.g. `descendants(immediate = false)`.\r\n\r\ncc @eregon", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-27T13:27:27Z", "updated_on": "2022-01-24T22:40:04Z", "closed_on": "2021-11-23T12:04:18Z", "relations": [{"id": 3125, "issue_id": 14394, "issue_to_id": 18273, "relation_type": "relates", "delay": null}]}, {"id": 18272, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10968, "name": "pvalena (Pavel Valena)"}, "subject": "Please replace unsafe SHA1 with another digest algorithm", "description": "## Context\r\nWhen working on a new version of RHEL (with Ruby 3.0), the requirement is to have a better security (remove unsafe digests or limit the use for non-security purposes). This would be achieved with using OpenSSL 3.0 as well, which will have a raised security level by default, forbidding the use of unsafe digests.\r\n\r\n## Issue\r\nSHA-1 does not conform to the security requirements, and its replacement would be preferred.\r\nA quote from the discussion (the Bug is marked as internal):\r\n```\r\nSHA-1 is still possible to use for non-security use cases, but it we should try to prevent their use for signatures if possible. The Python took a way to prevent this using non-mandatory argument usedforsecurity=True to the constructor, which lets the programmers to indicate their intention explicitly and policy-makers to verify no SHA1 is used in security context. [1]\r\n\r\n[1] https://docs.python.org/3/library/hashlib.html#hashlib.new\r\n```\r\n\r\n## Question\r\nAFAICT in Ruby it is used for non-security purposes only. Could you confirm that?\r\n\r\n## Possible solution\r\nThe use for non-security purposes might be indicated with setting an internal variable, which would allow the use of SHA-1 (although forbidden via OpenSSL setting). Do you think this would be possible?\r\n\r\n## Additional information\r\nThe failing tests upon SHA-1 removal in Ruby 3.0.2: https://gist.github.com/pvalena/9a053c5585329b595e2bff504198eba5", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-27T12:00:28Z", "updated_on": "2021-11-24T09:09:36Z", "closed_on": "2021-10-31T03:53:26Z", "relations": [{"id": 3178, "issue_id": 18272, "issue_to_id": 18356, "relation_type": "relates", "delay": null}]}, {"id": 18270, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12, "name": "shugo (Shugo Maeda)"}, "assigned_to": {"id": 12, "name": "shugo (Shugo Maeda)"}, "subject": "Refinement#{extend_object,append_features,prepend_features} should be removed", "description": "Refinement#{extend_object,append_features,prepend_features} are not useful and should be removed.\r\n\r\nHow about to deprecate them in Ruby 3.1 and remove in Ruby 3.1?\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-26T10:20:14Z", "updated_on": "2022-01-05T18:59:19Z", "closed_on": "2022-01-05T18:59:19Z", "relations": [{"id": 3123, "issue_id": 17429, "issue_to_id": 18270, "relation_type": "relates", "delay": null}]}, {"id": 18265, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2083, "name": "zw963 (Wei Zheng)"}, "subject": "Self-contained one-binary feature which discuss on ruby kaigi 2021 day 2, \u300a Ruby Committers vs the World / CRuby Committers\u300b", "description": "![](clipboard-202110232053-mgbon.png)\r\n\r\nhttps://www.youtube.com/watch?v=zQnN1pqK4FQ\r\n\r\nYes, what i said is this.\r\n\r\n1. Go-language supports to make self-contained one-binary.\r\n2. Is it useful for ruby?\r\n\r\n\r\nI personal propose add this feature into ruby 3.X in the future, i consider this is a killer\r\nadvantage compare to others dynamic language.\r\n\r\nAnd, this feature is very important for distribute code to the third party.(e.g. client) for two reason:\r\n\r\n1. distribute is easy.\r\n2. for protect code change unexpectly by client\r\n\r\nin fact, my friend switch from ruby to go recent days, the only reason is, it could not find out\r\na usable solution to distribute code to our client safely.\r\n\r\nBecause i could not find out a mature similar issue, so, just create this for discuss.\r\n\r\nBTW: maybe not so useful, Emacs editor since version 28 can native compilation of Elisp files which has greatly improved performance and start-up time, i don't know if this tech can be borrow from there for ruby.\r\n\r\nanyway, i consider both are similarities, i hope that can help.\r\n\r\nFollowing is some links come from Andrea Corallo, the emacs native compilation maintainer.\r\n\r\n\r\nhttps://akrl.sdf.org/gccemacs.html\r\nhttps://akrl.sdf.org/Kludging_LPC_2020.pdf\r\n\r\nHope there have useful info for AoT ruby .rb source code into `.rbn`(rb native, as .el compile to .eln) use libgccjit.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-23T13:02:25Z", "updated_on": "2021-10-24T16:11:25Z", "closed_on": null, "relations": []}, {"id": 18262, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "Enumerator::Lazy#partition", "description": "(Part of my set of proposals about making `.lazy` more useful/popular.)\r\n\r\nCurrently:\r\n```ruby\r\nfile = File.open('very-large-file.txt')\r\nlines_with_errors, lines_without_errors = file.lazy.partition { _1.start_with?('E:') }\r\nlines_with_errors.class\r\n# => Array, all file is read by this moment\r\n```\r\nThis might be not very practical performance-wise and memory-wise.\r\n\r\nI am thinking that maybe returning a pair of lazy enumerators might be a good addition to `Enumerator::Lazy`\r\n\r\nNaive prototype:\r\n\r\n```ruby\r\nclass Enumerator::Lazy\r\n  def partition(&block)\r\n    buffer1 = []\r\n    buffer2 = []\r\n    source = self\r\n\r\n    [\r\n      Enumerator.new { |y|\r\n        loop do\r\n          if buffer1.empty?\r\n            begin\r\n              item = source.next\r\n              if block.call(item)\r\n                y.yield(item)\r\n              else\r\n                buffer2.push(item)\r\n              end\r\n            rescue StopIteration\r\n              break\r\n            end\r\n          else\r\n            y.yield buffer1.shift\r\n          end\r\n        end\r\n      }.lazy,\r\n      Enumerator.new { |y|\r\n        loop do\r\n          if buffer2.empty?\r\n            begin\r\n              item = source.next\r\n              if !block.call(item)\r\n                y.yield(item)\r\n              else\r\n                buffer1.push(item)\r\n              end\r\n            rescue StopIteration\r\n              break\r\n            end\r\n          else\r\n            y.yield buffer2.shift\r\n          end\r\n        end\r\n      }.lazy\r\n    ]\r\n  end\r\nend\r\n```\r\nTesting it:\r\n```ruby\r\nEnumerator.produce(1) { |i| puts \"processing #{i}\"; i + 1 }.lazy\r\n  .take(30)\r\n  .partition(&:odd?)\r\n  .then { |odd, even|\r\n    p odd.first(3), even.first(3)\r\n  }\r\n# Prints:\r\n# processing 1\r\n# processing 2\r\n# processing 3\r\n# processing 4\r\n# processing 5\r\n# [1, 3, 5]\r\n# [2, 4, 6]\r\n```\r\nAs you might notice by the \"processing\" log, it only fetched the amount of entries that was required by produced enumerators.\r\n\r\nThe **drawback** would be\u2014as my prototype implementation shows\u2014the need of internal \"buffering\" (I don't think it is possible to implement lazy partition without it), but it still might be worth a shot?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-22T12:08:59Z", "updated_on": "2021-11-20T10:17:24Z", "closed_on": null, "relations": []}, {"id": 18259, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51944, "name": "amcalvo (Adri\u00e1n Medra\u00f1o Calvo)"}, "subject": "Support quarter spec %q in Time#strftime", "description": "This syntax is used by coreutil's `date` program (since 8.26):\r\n\r\n> \u2018%q\u2019\r\n> \r\n>     quarter of year (\u20181\u2019\u2026\u20184\u2019) ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-21T09:39:47Z", "updated_on": "2021-10-21T12:15:40Z", "closed_on": null, "relations": []}, {"id": 18256, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Change the canonical name of Thread::Mutex, Thread::Queue, Thread::SizedQueue and Thread::ConditionVariable to just Mutex, Queue, SizedQueue and ConditionVariable", "description": "Currently these 4 classes are defined as both constants of `Object` and of `Thread`.\r\n\r\nOn CRuby 3.0.2, their `#inspect` shows they were first defined under `Thread` and then aliased in Object:\r\n```\r\n$ ruby -ve 'p [Mutex, Queue, SizedQueue, ConditionVariable]'\r\nruby 3.0.2p107 (2021-07-07 revision 0db68f0233) [x86_64-linux]\r\n[Thread::Mutex, Thread::Queue, Thread::SizedQueue, Thread::ConditionVariable]\r\n```\r\n\r\nFWIW this contrasts to TruffleRuby which has:\r\n```\r\n$ ruby -ve 'p [Mutex, Queue, SizedQueue, ConditionVariable]'\r\ntruffleruby 22.0.0-dev-589c944e, like ruby 2.7.4, GraalVM CE Native [x86_64-linux]\r\n[Mutex, Queue, SizedQueue, ConditionVariable]\r\n```\r\n(because these classes are all core now and I thought the Thread:: prefix was the alias since they moved to core)\r\n\r\nHowever I believe most usages out there do *not* use the `Thread::` prefix, or in other words almost nobody uses the `Thread::` prefix for those classes.\r\nAnd it seems very clearly confirmed by `gem-codesearch`:\r\n\r\n```\r\n$ gem-codesearch 'Thread::Mutex' | wc -l\r\n254\r\n$ gem-codesearch '\\bMutex\\b' | wc -l\r\n19378\r\n```\r\nAbout 75x more common to use `Mutex` than `Thread::Mutex` it seems.\r\n\r\n```\r\n$ gem-codesearch 'Thread::Queue' | wc -l\r\n138\r\n$ gem-codesearch '\\bQueue\\b' | wc -l\r\n38174\r\n```\r\nAbout 276x more common to use `Queue` than `Thread::Queue` it seems.\r\n\r\n```\r\n$ gem-codesearch 'Thread::ConditionVariable' | wc -l\r\n110\r\n$ gem-codesearch '\\bConditionVariable\\b' | wc -l\r\n2145\r\n```\r\nAbout 19.5x more common to use `ConditionVariable` than `Thread::ConditionVariable` it seems.\r\n\r\n```\r\n$ gem-codesearch 'Thread::SizedQueue' | wc -l\r\n27\r\n$ gem-codesearch '\\bSizedQueue\\b' | wc -l\r\n633\r\n```\r\nAbout 23x more common to use `SizedQueue` than `Thread::SizedQueue` it seems.\r\n\r\nSo I propose to update the canonical names of these classes to be without the `Thread::` prefix, to represent the vast majority of usages, and also the fact these classes are core now and not stdlib.\r\nIn other words, for 3.1.0 I propose:\r\n```\r\n$ ruby -ve 'p [Mutex, Queue, SizedQueue, ConditionVariable]'\r\nruby 3.1.0 ...\r\n[Mutex, Queue, SizedQueue, ConditionVariable]\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-19T09:23:38Z", "updated_on": "2021-10-20T22:59:46Z", "closed_on": null, "relations": []}, {"id": 18254, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Add an `offset` parameter to String#unpack and String#unpack1", "description": "When working with binary protocols it's common to have to first unpack some kind of header or type prefix, and then based on that unpack another part of the string.\r\n\r\nFor instance here's [a code snippet from Dalli, the most common Memcached client](https://github.com/petergoldstein/dalli/blob/76b79d78cda13562da17bc99f92edcedf1873994/lib/dalli/protocol/binary.rb#L156-L184):\r\n\r\n```ruby\r\nwhile buf.bytesize - pos >= 24\r\n  header = buf.slice(pos, 24)\r\n  (key_length, _, body_length, cas) = header.unpack(KV_HEADER)\r\n\r\n  if key_length == 0\r\n    # all done!\r\n    @multi_buffer = nil\r\n    @position = nil\r\n    @inprogress = false\r\n    break\r\n\r\n  elsif buf.bytesize - pos >= 24 + body_length\r\n    flags = buf.slice(pos + 24, 4).unpack1(\"N\")\r\n    key = buf.slice(pos + 24 + 4, key_length)\r\n    value = buf.slice(pos + 24 + 4 + key_length, body_length - key_length - 4) if body_length - key_length - 4 > 0\r\n\r\n    pos = pos + 24 + body_length\r\n\r\n    begin\r\n      values[key] = [deserialize(value, flags), cas]\r\n    rescue DalliError\r\n    end\r\n\r\n  else\r\n    # not enough data yet, wait for more\r\n    break\r\n  end\r\nend\r\n@position = pos\r\n```\r\n\r\n### Proposal\r\n\r\nIf `unpack` and `unpack1` had an `offset:` parameter, it would allow this kind of code to extract the fields it needs without allocating and copying as much strings, e.g.:\r\n\r\n```ruby\r\nflags = buf.slice(pos + 24, 4).unpack1(\"N\")\r\n```\r\n\r\ncould be:\r\n\r\n```ruby\r\nbuf.unpack1(\"N\", offset: pos + 24)\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-18T08:04:03Z", "updated_on": "2021-10-26T20:27:50Z", "closed_on": "2021-10-26T20:27:50Z", "relations": []}, {"id": 18253, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "assigned_to": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "`ID` in `rb_id_table_foreach_with_replace`", "description": "`rb_id_table_foreach_with_replace` doesn't pass the `ID` to `func` and `replace`.\r\n\r\nIf this is intensional, `func` should be `rb_id_table_foreach_values_func_t` and `rb_id_table_update_callback_func_t` doesn't need the `id` argument?\r\n\r\nOr should the function pass the `ID`?\r\n```diff\r\ndiff --git a/id_table.c b/id_table.c\r\nindex b2ba6fae89e..281a0fb50a7 100644\r\n--- a/id_table.c\r\n+++ b/id_table.c\r\n@@ -274,12 +274,14 @@ rb_id_table_foreach_with_replace(struct rb_id_table *tbl, rb_id_table_foreach_fu\r\n \r\n     for (i=0; i<capa; i++) {\r\n         if (ITEM_KEY_ISSET(tbl, i)) {\r\n-            enum rb_id_table_iterator_result ret = (*func)((ID)0, tbl->items[i].val, data);\r\n-            assert(ITEM_GET_KEY(tbl, i));\r\n+            const id_key_t key = ITEM_GET_KEY(tbl, i);\r\n+            ID id = key2id(key);\r\n+            enum rb_id_table_iterator_result ret = (*func)(id, tbl->items[i].val, data);\r\n+            assert(key != 0);\r\n \r\n             if (ret == ID_TABLE_REPLACE) {\r\n                 VALUE val = tbl->items[i].val;\r\n-                ret = (*replace)(NULL, &val, data, TRUE);\r\n+                ret = (*replace)(&id, &val, data, TRUE);\r\n                 tbl->items[i].val = val;\r\n             }\r\n             else if (ret == ID_TABLE_STOP)\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-18T06:22:01Z", "updated_on": "2022-01-24T23:41:02Z", "closed_on": "2022-01-24T23:41:02Z", "relations": []}, {"id": 18242, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51329, "name": "danh337 (Dan H)"}, "subject": "Parser makes multiple assignment sad in confusing way", "description": "Example:\r\n``` ruby\r\na, b = 2, 1     if 1 < 2     # Works\r\na, b = [2, 1]   if 1 < 2     # Works\r\n(a, b) = 2, 1   if 1 < 2     # Works\r\n(a, b) = [2, 1] if 1 < 2     # Works\r\n(a, b = [2, 1]) if 1 < 2     # Works\r\na, b = 2, 1     unless 2 < 1 # Works\r\na, b = [2, 1]   unless 2 < 1 # Works\r\n(a, b) = 2, 1   unless 2 < 1 # Works\r\n(a, b) = [2, 1] unless 2 < 1 # Works\r\n(a, b = [2, 1]) unless 2 < 1 # Works\r\n1 < 2   and a, b = 2, 1      # SyntaxError\r\n1 < 2   and a, b = [2, 1]    # SyntaxError\r\n1 < 2   and (a, b) = 2, 1    # SyntaxError\r\n1 < 2   and (a, b) = [2, 1]  # SyntaxError\r\n(1 < 2) and a, b = 2, 1      # SyntaxError\r\n(1 < 2) and a, b = [2, 1]    # SyntaxError\r\n(1 < 2) and (a, b) = 2, 1    # SyntaxError\r\n(1 < 2) and (a, b) = [2, 1]  # SyntaxError\r\n1 < 2   and (a, b = 2, 1)    # Works\r\n1 < 2   and (a, b = [2, 1])  # Works\r\n2 < 1   or a, b = 2, 1       # SyntaxError\r\n2 < 1   or a, b = [2, 1]     # SyntaxError\r\n2 < 1   or (a, b) = 2, 1     # SyntaxError\r\n2 < 1   or (a, b) = [2, 1]   # SyntaxError\r\n(2 < 1) or a, b = 2, 1       # SyntaxError\r\n(2 < 1) or a, b = [2, 1]     # SyntaxError\r\n(2 < 1) or (a, b) = 2, 1     # SyntaxError\r\n(2 < 1) or (a, b) = [2, 1]   # SyntaxError\r\n2 < 1   or (a, b = 2, 1)     # Works\r\n2 < 1   or (a, b = [2, 1])   # Works\r\n```\r\nBased on the precedence rules I've been able to find, all of these should work.\r\n\r\nBelieve it or not, there are cases where using `and` or `or` in a stanza of lines is much more readable.\r\n\r\nShould the parser allow all of these? See attached driver script to reproduce this output.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-06T04:39:59Z", "updated_on": "2021-10-09T07:58:47Z", "closed_on": null, "relations": []}, {"id": 18239, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "subject": "Variable Width Allocation: Strings", "description": "# GitHub PR: https://github.com/ruby/ruby/issues/4933\r\n\r\n# Feature description\r\n\r\nSince merging #18045 which introduced size pools inside the GC to allocate various sized slots, we've been working on expanding the usage of VWA into more types (before this patch, only classes are allocated through VWA). This patch changes strings to use VWA.\r\n\r\n## Summary\r\n\r\n- This patch allocates strings using VWA.\r\n- String allocated through VWA are embedded. The patch changes strings to support dynamic capacity embedded strings.\r\n- We do not handle resizing in VWA in this patch (embedded strings resized up are moved back to malloc), which may result in wasted space. However, in benchmarks, this does not appear to be an issue.\r\n- We propose enabling VWA by default. We are confident about the stability and performance of this feature.\r\n\r\n## String allocation\r\n\r\nStrings with known sizes at allocation time that are small enough is allocated as an embedded string. Embedded string headers are now 18 bytes, so the maximum embedded string length is now 302 bytes (currently VWA is configured to allocate up to 320 byte slots, but can be easily configured for even larger slots). Embedded strings have their contents directly follow the object headers. This aims to improve cache performance since the contents are on the same cache line as the object headers. For strings with unknown sizes, or with contents that are too large, it falls back to allocate 40 byte slots and store the contents in the malloc heap.\r\n\r\n## String reallocation\r\n\r\nIf an embedded string is expanded and can no longer fill the slot, it is moved into the malloc heap. This may mean that some space in the slot is wasted. For example, if the string was originally allocated in a 160 byte slot and moved to the malloc heap, 120 bytes of the slot is wasted (since we only need 40 bytes for a string with contents on the malloc heap). This patch does not aim to tackle this issue. Memory usage also does not appear to be an issue in any of the benchmarks.\r\n\r\n## Incompatibility of VWA and non-VWA built gems\r\n\r\nGems with native extensions built with VWA are not compatible with non-VWA built gems (and vice versa). When switching between VWA and non-VWA rubies, gems must be rebuilt. This is because the header file `rstring.h` changes depending on whether `USE_RVARGC` is set or not (the internal string implementation changes with VWA).\r\n\r\n## Enabling VWA by default\r\n\r\nIn this patch, we propose enabling VWA by default. We believe that the performance data supports this (see the [benchmark results](#Benchmark-results) section). We're also confident about its stability. It passess all tests on CI for the Shopify monolith and we've ran this version of Ruby on a small portion of production traffic in a Shopify service for about a week (where it served over 500 million requests).\r\n\r\nAlthough VWA is enabled by default, we plan on supporting the `USE_RVARGC` flag as an escape hatch to disable VWA until at least Ruby 3.1 is released (i.e. we may remove it starting 2022).\r\n\r\n# Benchmark setup\r\n\r\nBenchmarking was done on a bare-metal Ubuntu machine on AWS. All benchmark results are using glibc by default, except when jemalloc is explicitly specified.\r\n\r\n```\r\n$ uname -a\r\nLinux 5.8.0-1038-aws #40~20.04.1-Ubuntu SMP Thu Jun 17 13:25:28 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nglibc version:\r\n\r\n```\r\n$ ldd --version\r\nldd (Ubuntu GLIBC 2.31-0ubuntu9.2) 2.31\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\nWritten by Roland McGrath and Ulrich Drepper.\r\n```\r\n\r\njemalloc version:\r\n\r\n```\r\n$ apt list --installed | grep jemalloc\r\n\r\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\nlibjemalloc-dev/focal,now 5.2.1-1ubuntu1 amd64 [installed]\r\nlibjemalloc2/focal,now 5.2.1-1ubuntu1 amd64 [installed,automatic]\r\n```\r\n\r\nTo measure memory usage over time, the [mstat tool](https://github.com/bpowers/mstat) was used.\r\n\r\nRuby master was benchmarked on commit [7adfb14f60](https://github.com/ruby/ruby/commit/7adfb14f60). The branch was rebased on top of the same commit.\r\n\r\nPerformance benchmarks of this branch without VWA turned on are included to make sure this patch does not introduce a performance regression compared to master.\r\n\r\n# Benchmark results\r\n\r\n## Summary\r\n\r\n- On a live, production Shopify service, we see no significant differences in response times. However, VWA has lower memory usage.\r\n- On railsbench, we see a minor performance improvement. However, we also see worse p100 response times. The reason is analyzed in the [railsbench](#railsbench) section below. VWA uses more memory when using glibc, but uses an equal amount of memory for jemalloc.\r\n- On rdoc generation, VWA uses significantly less memory for a small reduction in performance.\r\n- Microbenchmarks show significant performance improvement for strings that are embedded in VWA (e.g. `String#==` is significantly faster).\r\n\r\n## Shopify production\r\n\r\nWe deployed this branch with VWA enabled vs. Ruby master commit 7adfb14f60 on a small portion of live, production traffic for a Shopify web application to test real-world performance. This data was collected for a period of 1 day where they each served approximately 84 million requests. Average, median, p90, p99 response times were within the margin of error of each other (<1% difference). However, VWA consistently had lower memory usage (Resident Set Size) by 0.96x.\r\n\r\n## railsbench\r\n\r\nFor railsbench, we ran the [railsbench benchmark](https://github.com/k0kubun/railsbench/blob/master/bin/bench). For both the performance and memory benchmarks, 25 runs were conducted for each combination (branch + glibc, master + glibc, branch + jemalloc, master + jemalloc).\r\n\r\nIn this benchmark, VWA suffers from poor p100. This is because railsbench is relatively small (only one controller and model), so there are not many pages in each size pools. Incremental marking requires there to be many pooled pages, but because there are not a lot of pooled pages (due to the small heap size), it has to mark a very large number of objects at every step. We do not expect this to be a problem for real apps with a larger number of objects allocated at boot, and this is confirmed by metrics collected in the [Shopify production application](#Shopify-production).\r\n\r\n### glibc\r\n\r\nUsing glibc, VWA is about 1.018x faster than master in railsbench in throughput (RPS).\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master |\r\n+-----------+-----------------+------------------+--------+\r\n| RPS       | 740.92          | 722.97           | 745.31 |\r\n| p50 (ms)  | 1.31            | 1.37             | 1.33   |\r\n| p90 (ms)  | 1.40            | 1.45             | 1.43   |\r\n| p99 (ms)  | 2.36            | 1.80             | 1.78   |\r\n| p100 (ms) | 21.38           | 17.28            | 15.15  |\r\n+-----------+-----------------+------------------+--------+\r\n```\r\n\r\n![](https://i.imgur.com/9yJ3fO5.png)\r\n\r\nAverage max memory usage for VWA: 104.82 MB\r\n\r\nAverage max memory usage for master: 101.17 MB\r\n\r\nVWA uses 1.04x more memory.\r\n\r\n### jemalloc\r\n\r\nUsing glibc, VWA is about 1.06x faster than master in railsbench in RPS.\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master |\r\n+-----------+-----------------+------------------+--------+\r\n| RPS       | 781.21          | 742.12           | 739.04 |\r\n| p50 (ms)  | 1.25            | 1.31             | 1.30   |\r\n| p90 (ms)  | 1.32            | 1.39             | 1.38   |\r\n| p99 (ms)  | 2.15            | 2.53             | 4.41   |\r\n| p100 (ms) | 21.11           | 16.60            | 15.75  |\r\n+-----------+-----------------+------------------+--------+\r\n```\r\n\r\n![](https://i.imgur.com/Nltbqq0.png)\r\n\r\nAverage max memory usage for VWA: 102.68 MB\r\n\r\nAverage max memory usage for master: 103.14 MB\r\n\r\nVWA uses 1.00x less memory.\r\n\r\n## rdoc generation\r\n\r\nIn rdoc generation, we see significant memory usage reduction at the cost of small performance reduction.\r\n\r\n### glibc\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+-------------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master | VWA speedup |\r\n+-----------+-----------------+------------------+--------+-------------+\r\n| Time (s)  | 16.68           | 16.08            | 15.87  | 0.95x       |\r\n+-----------+-----------------+------------------+--------+-------------+\r\n```\r\n\r\n![](https://i.imgur.com/HJCtowS.png)\r\n\r\nAverage max memory usage for VWA: 295.19 MB\r\n\r\nAverage max memory usage for master: 365.06 MB\r\n\r\nVWA uses 0.81x less memory.\r\n\r\n### jemalloc\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+-------------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master | VWA speedup |\r\n+-----------+-----------------+------------------+--------+-------------+\r\n| Time (s)  | 16.34           | 15.64            | 15.51  | 0.95x      |\r\n+-----------+-----------------+------------------+--------+-------------+\r\n```\r\n\r\n![](https://i.imgur.com/lrdUxXw.png)\r\n\r\nAverage max memory usage for VWA: 281.16 MB\r\n\r\nAverage max memory usage for master: 316.49 MB\r\n\r\nVWA uses 0.89x less memory.\r\n\r\n## Liquid benchmarks\r\n\r\nFor the liquid benchmarks, we ran the [liquid benchmark](https://github.com/Shopify/liquid/blob/master/performance/benchmark.rb) averaged over 5 runs each. We see that VWA is faster across the board.\r\n\r\n```\r\n+----------------------+-----------------+------------------+--------+-------------+\r\n|                      | Branch (VWA on) | Branch (VWA off) | Master | VWA speedup |\r\n+----------------------+-----------------+------------------+--------+-------------+\r\n| Parse (i/s)          | 40.40           | 38.44            | 39.47  | 1.02x      |\r\n| Render (i/s)         | 126.47          | 121.97           | 121.20 | 1.04x      |\r\n| Parse & Render (i/s) | 28.81           | 27.52            | 28.02  | 1.03x      |\r\n+----------------------+-----------------+------------------+--------+-------------+\r\n```\r\n\r\n## Microbenchmarks\r\n\r\nThese microbenchmarks are very favourable for VWA since the strings created have a length of 71, so they are embedded in VWA and allocated on the malloc heap for master.\r\n\r\n```\r\n+---------------------+-----------------+------------------+---------+-------------+\r\n|                    | Branch (VWA on) | Branch (VWA off) | Master  | VWA speedup |\r\n+--------------------+-----------------+------------------+---------+-------------+\r\n| String#== (i/s)    | 1.806k          | 1.334k           | 1.337k  | 1.35x       |\r\n| String#times (i/s) | 6.010M          | 5.238M           | 5.247M  | 1.15x       |\r\n| String#[]= (i/s)   | 1.031k          | 863.816          | 897.915 | 1.15x       |\r\n+--------------------+-----------------+------------------+---------+-------------+\r\n```\r\n\r\n{{collapse(Benchmark source code)\r\n\r\n```ruby\r\nrequire \"bundler/inline\"\r\ngemfile do\r\n  source \"https://rubygems.org\"\r\n  gem \"benchmark-ips\"\r\nend\r\n\r\nCOUNT = 10_000\r\n\r\nstrs1 = []\r\nstrs2 = []\r\n\r\nnine = \"9\"\r\n\r\nCOUNT.times do\r\n  strs1 << [*\"A\"..\"Z\", *\"0\"..\"9\"].join(\" \")\r\n  strs2 << [*\"A\"..\"Z\", *\"0\"..\"9\"].join(\" \")\r\nend\r\n\r\nBenchmark.ips do |x|\r\n  x.report(\"String#==\") do |times|\r\n    i = 0\r\n    while i < times\r\n      COUNT.times { |i| strs1[i] == strs2[i] }\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"String#times\") do |times|\r\n    i = 0\r\n    while i < times\r\n      \"a\" * 100\r\n      i += 1\r\n    end\r\n  end\r\n\r\n  x.report(\"String#[]=\") do |times|\r\n    i = 0\r\n    while i < times\r\n      strs1.each { |str| str[-1] = nine }\r\n      i += 1\r\n    end\r\n  end\r\nend\r\n```\r\n}}", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-10-04T18:13:44Z", "updated_on": "2021-10-25T17:26:46Z", "closed_on": "2021-10-25T17:26:46Z", "relations": []}, {"id": 18231, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "`RubyVM.keep_script_lines`", "description": "This ticket proposes the method `RubyVM.keep_script_lines` to manage the flag to keep the source code.\r\n\r\nNow, `SCRIPT_LINES__ = {}` constant is defined, the hash will stores the compiled script with a path name (`{path => src}`). However, `eval` source code doesn't stores in it (maybe because it can be bigger and bigger).\r\n\r\n## Proposal\r\n\r\nThis proposal to add script lines to the ISeq and AST.\r\n\r\n```ruby\r\nRubyVM::keep_script_lines = true\r\n\r\neval(\"def foo = nil\\ndef bar = nil\")\r\npp RubyVM::InstructionSequence.of(method(:foo)).script_lines\r\n#=> [\"def foo = nil\\n\", \"def bar = nil\"]\r\n```\r\n\r\nIn this case, methods `foo` and `bar` are defined by `eval()` and ISeq of `foo` can returns script lines (all script for `eval`).\r\n`ISeq#script_lines` returns compiled script lines.\r\n\r\nWhen `ISeq` is GCed, then the source code will be also free'ed.\r\n\r\n## Discussion\r\n\r\n* This feature will be used by debugger (to show the source code) or REPL support (irb and so on) with `error_highlight`.\r\n* Of course memory usage will be increased.\r\n* We can introduce new status `only_eval` in future which will help REPL systems.\r\n* We can implement `ISeq#source` method like `AST#source` method (similar to `toSource` in JavaScript), but this ticket doesn't contain it.\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/4913\r\n\r\nFor the Ractor support script lines object should be immutable (not implemented yet).\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-30T08:16:12Z", "updated_on": "2021-12-14T16:58:49Z", "closed_on": "2021-12-14T16:58:49Z", "relations": [{"id": 3349, "issue_id": 17930, "issue_to_id": 18231, "relation_type": "relates", "delay": null}, {"id": 3350, "issue_id": 18159, "issue_to_id": 18231, "relation_type": "relates", "delay": null}]}, {"id": 18229, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51917, "name": "maximecb (Maxime Chevalier-Boisvert)"}, "assigned_to": {"id": 10073, "name": "k0kubun (Takashi Kokubun)"}, "subject": "Proposal to merge YJIT", "description": "# Background\r\n\r\nYJIT is a new open source JIT compiler for CRuby.  The project is led by a small team at Shopify in collaboration with developers from GitHub.  The key advantages of this project are that the compiler delivers very fast warm-up and has fine grain control over the entire compiler pipeline.\r\n\r\nThis JIT translates YARV instructions to machine code and employs a technique known as [Lazy Basic Block Versioning (LBBV)](https://drops.dagstuhl.de/opus/volltexte/2015/5219/pdf/9.pdf) in order to specialize code based on types seen at run-time and reduce generated code size without needing to do static type analysis. The YJIT project was [presented at RubyKaigi 2021](https://www.youtube.com/watch?v=PBVLf3yfMs8).\r\n\r\n# Limitations\r\n\r\nYJIT works by translating YARV instructions to x86 machine code.  YJIT doesn\u2019t support all YARV instructions, but is able to gracefully handle unknown instructions by returning control of execution back to the CRuby interpreter.\r\n\r\nToday, YJIT only targets x86-64 architecture.  We may support ARM64 in the future, but due to the nature of the compiler design, we can\u2019t easily support as many platforms as MJIT. Still, we anticipate that x86-64 and ARM64 will cover the needs of the vast majority of users, from PCs to servers to Apple M1s to cell phones and even Raspberry Pis.\r\n\r\n# Advantages\r\n\r\nYJIT has very fast warmup and can produce good real-world benchmark results when compared to other JITs. There are still many options for improving performance further.\r\n\r\n# Integration with MRI\r\n\r\nYJIT can\u2019t work fully as a \u201cplug-in\u201d JIT.  It requires some modifications to CRuby, mostly related to compilation and invalidation.  For example, YJIT needs callbacks so it can be notified when the constant state changes or when BOPs are redefined.  These modifications are quite modest and could be advantageous for MJIT or other JITs in the future.  YJIT\u2019s implementation is contained in the yjit_*.c files with very few modifications to CRuby.\r\n\r\n# Benchmarks\r\n\r\nYJIT optimizes a number of common benchmarks well. Here are some results compared to the CRuby interpreter without MJIT, [current as of Sept 2021](https://speed.yjit.org/benchmarks/bench-2021-09-27-071059):\r\n\r\nactiverecord: 1.37x\r\njekyll: 1.12x\r\nliquid-render: 1.27x\r\nmail gem: 1.09x\r\npsych-load: 1.29x\r\nKokubun's railsbench: 1.16x\r\noptcarrot: 1.68x\r\nChris Seaton's lee benchmark: 1.41x\r\n\r\nSource code for these benchmarks can be found at https://github.com/Shopify/yjit-bench under \"benchmarks\".\r\n\r\n# TODO / Known Bugs\r\n\r\nWe have been running YJIT in production, but it is still experimental.  Some key features are currently missing, the most important being \u201ccode GC\u201d.  Currently, any generated code that is invalidated (or becomes \u201cunusable\u201d) is not collected, nor is the memory allocated for that code reclaimed.  This is rarely a problem in practice because most Ruby programs generate a fixed amount of code, but it is a problem that we want to fix in the short to medium term. This is an area which is currently under development.\r\n\r\n# Stability and Compatibility\r\n\r\nMRI\u2019s full suite of tests including RubySpec tests pass with YJIT enabled.  We\u2019ve tested YJIT against our production application (Shopify\u2019s StoreFront Renderer) and all tests pass there as well.  Finally, GitHub has tested YJIT against their test suite and all tests pass.  We\u2019ve deployed YJIT to production on a subset of servers and seen performance improvements.  See more details here.\r\n\r\n# Merging Proposal\r\n\r\nDespite some of the limitations and TODO\u2019s listed here, we would like to propose merging YJIT so that we can get feedback from the rest of the community as well as add \u201cintegration points\u201d for other JIT implementations.\r\n\r\nWe\u2019ve intentionally made as few changes to MRI as possible to support integrating YJIT.  We\u2019re committed to continue developing YJIT, but intentionally kept the changes to MRI small in order to ease the burden on upstream maintainers.\r\n\r\nYJIT will be disabled by default and require an experimental command-line flag (`--yjit`) to be set.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-27T19:12:32Z", "updated_on": "2021-10-21T04:25:39Z", "closed_on": "2021-10-20T23:21:34Z", "relations": []}, {"id": 18228, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Add a `timeout` option to `IO.copy_stream`", "description": "### Context\r\n\r\nIn many situations dealing with large files, `IO.copy_stream` when usable bring major performance gains (often twice faster at the very least). And more importantly, when the copying is deferred to the kernel, the performance is much more consistent as it is less impacted by the CPU utilization on the machine.\r\n\r\nHowever, it is often unsafe to use because it doesn't have a timeout, so you can only use it if both the source and destination IOs are trusted, otherwise it is trivial for an attacker to DOS the service by reading the response very slowly.\r\n\r\n### Some examples\r\n\r\n- It is [used by `webrick`](https://github.com/ruby/webrick/commit/54be684da9d993ad6c237e2e9853eb98bcbaae6e).\r\n- `Net::HTTP` uses it to send request body if they are IOs, but [it is used with a \"fake IO\" to allow for timeouts](https://github.com/ruby/net-http/pull/27), so `sendfile(2)` &co are never used.\r\n- [A proof of concept of integrating in puma shows a 2x speedup](https://github.com/puma/puma/pull/2703). \r\n- [Various other HTTP client could use it as well](https://github.com/nahi/httpclient/pull/383).\r\n- I used it in private projects to download and upload large archives in and out of Google Cloud Storage with great effects.\r\n\r\n### Possible implementation\r\n\r\nThe main difficulty is that the underlying sycalls don't have a timeout either.\r\n\r\nThe main syscall used in these scenarios is `sendfile(2)`. It doesn't have a timeout parameter, however if called on file descriptors with `O_NONBLOCK` it does return early and allow for a `select/poll` loop. I did a very quick and dirty experiment with this, and it does seem to work.\r\n\r\nThe other two accelerating syscalls are [`copy_file_range(2)`](https://man7.org/linux/man-pages/man2/copy_file_range.2.html) (linux) and [`fcopyfile(2)`](https://developer.apple.com/library/archive/documentation/System/Conceptual/ManPages_iPhoneOS/man3/fcopyfile.3.html) (macOS). Neither have a timeout, and neither manpage document an `EAGAIN / EWOULDBLOCK` error. However these syscalls are limited to real file copies, generally speaking timeouts for real files are less of a critical need, so it would be possible to simply not use these syscalls if a timeout is provided.\r\n\r\n### Interface\r\n\r\n`copy_stream(src, dst, copy_length, src_offset, timeout)`\r\nor `copy_stream(src, dst, copy_length, src_offset, timeout: nil)`\r\n\r\nAs for the return value in case of a timeout, it is important to convey both that a timeout happened, and the number of bytes that were copied, otherwise it makes retries impossible.\r\n\r\n- It could simply returns the number of byte, and let the caller compare it to the expected number of bytes copied, but that wouldn't work in cases where the size of `src` isn't known.\r\n- It could return `-1 - bytes_copied`, not particularly elegant but would work.\r\n- It could return multiple values or some kind of result object when a timeout is provided.\r\n- It could raise an error, with `bytes_copied` as an attribute on the error.\r\n\r\nOr alternatively `copy_stream` would be left without a timeout, and some kind of `copy_stream2` would be introduced so that `copy_stream` return value wouldn't be made inconsistent.\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-27T12:16:09Z", "updated_on": "2021-10-01T05:10:36Z", "closed_on": null, "relations": [{"id": 3114, "issue_id": 17933, "issue_to_id": 18228, "relation_type": "relates", "delay": null}]}, {"id": 18227, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Static class initialization.", "description": "As a follow on from https://bugs.ruby-lang.org/issues/18189 I would like to propose some kind of static class initialization. I'll investigate whether it's possible and create a PR.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-27T03:49:35Z", "updated_on": "2021-09-29T21:21:29Z", "closed_on": null, "relations": []}, {"id": 18194, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "No easy way to format exception messages per thread/fiber scheduler context.", "description": "In the new error highlighting gem, formatting exception messages appears to be per-process which is insufficiently nuanced for existing use cases.\r\n\r\nAs in:\r\n\r\n```ruby\r\nclass TerminalColorFormatter\r\n  def message_for(spot)\r\n    # How do we know the output format here? Maybe it's being written to a log file?\r\n    \"...\"\r\n  end\r\nend\r\n\r\nErrorHighlight.formatter = TerminalColorFormatter.new\r\n```\r\n\r\nBut we won't know until the time we actually write the error message whether terminal codes are suitable or available. Or an error message might be formatted for both the terminal and a log file, which have different formatting requirements. There are many consumers of error messages an some of them produce text, or HTML, or JSON, etc.\r\n\r\nBecause of this design we are effectively forcing everyone to parse the default text output if they want to do any kind of formatting, which will ossify the format and make it impossible in practice for anyone to use anything but the default `ErrorHighlight.format`. For what is otherwise a really fantastic idea, this implementation concerns me greatly.\r\n\r\nI would like us to consider introducing sufficient metadata on the exception object so that complete formatting can be implemented by an output layer (e.g. logger, terminal wrapper, etc). This allows the output layer to intelligently format the output in a suitable way, or capture the metadata to allow for processing elsewhere.\r\n\r\nIn addition, to simplify this general usage, we might like to introduce `Exception#formatted_message`.\r\n\r\nIn order to handle default formatting requirements, we need to provide a hook for formatting uncaught exceptions. This would be excellent for many different use cases (e.g. HoneyBadger type systems), and I suggest we think about the best interface. Probably a thread-local with some default global implementation makes sense... maybe even something similar to `at_exit { ... $! ... }`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-26T20:44:51Z", "updated_on": "2021-09-29T10:10:01Z", "closed_on": null, "relations": [{"id": 3138, "issue_id": 18194, "issue_to_id": 18296, "relation_type": "relates", "delay": null}]}, {"id": 18190, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Split `Random::Formatter` from securerandom", "description": "Now `Random::Formatter` methods are defined in `securerandom.rb`, since it was split from `SecureRandom` module historically.\r\nHowever this module does not need to be `SecureRandom` but just to respond to `bytes` method.\r\nI propose to move `Random::Formatter` module to another file, `random_formatter.rb` or `random/formatter.rb`.\r\nAnd keep only that file in ruby core and remove from securerandom library in future.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-23T08:24:50Z", "updated_on": "2021-12-09T11:27:09Z", "closed_on": "2021-12-09T11:27:09Z", "relations": [{"id": 3188, "issue_id": 18183, "issue_to_id": 18190, "relation_type": "relates", "delay": null}]}, {"id": 18183, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7644, "name": "olleicua (Antha Auciello)"}, "subject": "make SecureRandom.choose public", "description": "This issue https://bugs.ruby-lang.org/issues/10849\r\nadded `SecureRandom.alphanumeric` and also the private method choose.\r\n`choose` was kept private because the method name wasn't the best name to represent the behavior.\r\nI think if it was called `random_string` it would be very clear what it does.\r\nI also think it should be aliased to choose as well to allow backwards compatibility for people bypassing the private method with `send` (e.g. https://www.thetopsites.net/article/58611103.shtml)\r\n\r\nI'm planning to put together a pull request for this. Please let me know if there are any complications I'm not considering.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-21T21:55:50Z", "updated_on": "2022-06-16T07:54:24Z", "closed_on": "2022-06-06T03:28:41Z", "relations": [{"id": 3078, "issue_id": 10849, "issue_to_id": 18183, "relation_type": "relates", "delay": null}, {"id": 3188, "issue_id": 18183, "issue_to_id": 18190, "relation_type": "relates", "delay": null}, {"id": 3340, "issue_id": 18817, "issue_to_id": 18183, "relation_type": "duplicates", "delay": null}]}, {"id": 18181, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 963, "name": "kyanagi (Kouhei Yanagita)"}, "subject": "Introduce Enumerable#min_with_value, max_with_value, and minmax_with_value", "description": "PR is https://github.com/ruby/ruby/pull/4874\r\n\r\nI propose `Enumerable#min_with_value`, `max_with_value` and `minmax_with_value`.\r\nThese methods work like this:\r\n\r\n``` ruby\r\n  %w(abcde fg hijk).min_with_value { |e| e.size } # => ['fg', 2]\r\n  %w(abcde fg hijk).max_with_value { |e| e.size } # => ['abcde', 5]\r\n  %w(abcde fg hijk).minmax_with_value { |e| e.size } # => [['fg', 2], ['abcde', 5]]\r\n```\r\n\r\nCorresponding to `#min(n)`, an integer argument can be passed to `#min_with_value` or `#max_with_value`.\r\n\r\n``` ruby\r\n  %w(abcde fg hijk).min_with_value(2) { |e| e.size } # => [['fg', 2], ['hijk', 4]]\r\n  %w(abcde fg hijk).max_with_value(2) { |e| e.size } # => [['abcde', 5], ['hijk', 4]]\r\n```\r\n\r\n## Motivation\r\n\r\nWhen I use `Enumerable#min_by`, I sometimes want to get not only the minimum element\r\nbut also the value from the given block.\r\n(e.g.: There are many points. Find the nearest point and get distance to it.)\r\n\r\n``` ruby\r\n  elem = enum.min_by { |e| foo(e) }\r\n  value = foo(elem)\r\n```\r\n\r\nThis works, but I'd like to avoid writing foo() twice. (Consider a more complex case.)\r\n\r\nThis can be written without repeated foo() like belows, but it is slightly complicated and needs extra arrays.\r\n\r\n``` ruby\r\n  value, elem = enum.map { |e| [foo(e), e] }.min_by(&:first)\r\n```\r\n\r\nIf the size of enum is enormous, it is hard to use intermediate arrays.\r\n\r\n`Enumerable#min_with_value` solves this problem.\r\n\r\nI think `min_with_value` is the best name I could think of, but any suggestions for better names would be appreciated.\r\n\r\n## Benchmark\r\n\r\nhttps://bugs.ruby-lang.org/issues/18181#note-2\r\n\r\n## Example\r\n\r\nSolving a traveling salesman problem in nearest neighbor algorithm.\r\n\r\n``` ruby\r\nrequire 'set'\r\nPoint = Struct.new(:x, :y)\r\npoints = Set.new([Point.new(1, 1), Point.new(2, 4), Point.new(3, 3), Point.new(2, 2), Point.new(0, 1)])\r\n\r\ntotal = 0\r\ncurrent = points.first\r\npoints.delete(current)\r\npath = [current]\r\n\r\nuntil points.empty?\r\n  current, distance = points.min_with_value do |point|\r\n    Math.hypot(current.x - point.x, current.y - point.y)\r\n  end\r\n  total += distance\r\n  points.delete(current)\r\n  path << current\r\nend\r\n\r\np path\r\np total\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-20T15:25:39Z", "updated_on": "2022-01-25T07:33:37Z", "closed_on": null, "relations": []}, {"id": 18179, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 38759, "name": "ankane (Andrew Kane)"}, "subject": "Add Math methods to Numeric", "description": "Hi, I wanted to get thoughts on adding class methods from `Math` as instance methods on `Numeric`.\r\n\r\n```ruby\r\nx.sqrt # vs Math.sqrt(x)\r\nx.log  # vs Math.log(x)\r\n```\r\n\r\nRust takes this approach and it (subjectively) feels more intuitive/object-oriented. It also seems more consistent with methods like `x.abs`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-20T04:09:13Z", "updated_on": "2022-03-24T14:54:44Z", "closed_on": null, "relations": [{"id": 3211, "issue_id": 18477, "issue_to_id": 18179, "relation_type": "duplicates", "delay": null}]}, {"id": 18176, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Make Coverage suspendable", "description": "I'd like to add `Coverage.suspend`, `Coverage.resume`, and some methods.\r\n\r\n## Synopsis\r\n\r\n```\r\n 1: # target.rb\r\n 2: def foo\r\n 3:   :foo\r\n 4: end\r\n 5:\r\n 6: def bar\r\n 7:   :bar\r\n 8: end\r\n 9:\r\n10: def baz\r\n11:   :baz\r\n12: end\r\n```\r\n\r\n```\r\nrequire \"coverage\"\r\n\r\n# Similar to Coverage.start, but does not start the measurement itself\r\nCoverage.setup(oneshot_lines: true)\r\n\r\nload \"target.rb\"\r\n\r\nfoo              # This call is not counted\r\nCoverage.resume  # Start the measurement\r\nbar              # This call is counted\r\nCoverage.suspend # Stop the measure\r\nbaz              # This call is not counted\r\n\r\n# The result is only for Line 7, the body of method \"bar\"\r\np Coverage.result #=> {\"target.rb\"=>{:oneshot_lines=>[7]}}\r\n```\r\n\r\n## Background\r\n\r\nThe motivation is to divide modules for large web services. For web services with a long history, we tend to lose track of the dependencies between modules. Using this proposal and oneshot coverage, we can gather information about the code used to process a particular endpoint with almost no runtime cost. Gathering the information for some endpoints will give a hint to isolate the modules.\r\n\r\nI've received similar requests in the past to make Coverage restartable but I didn't understand the need for it. (Sorry about that!) I heard directly from those who were actually in trouble in our company, and I finally understand. Also, the introduction of oneshot coverage, which can now be measured at almost no cost, has increased the demand for suspendable coverage.\r\n\r\n## New APIs\r\n\r\n* `Coverage.setup`: Almost the same as `Coverage.start` but does not start the measurement itself.\r\n* `Coverage.resume`: Start/resume the coverage measurement.\r\n* `Coverage.suspend`: Suspend the coverage measurement; it is restartable by using `Coverage.resume`.\r\n* `Coverage.state`: Returns the current state: `:idle`, `:suspended`, and `:running`.\r\n\r\n`Coverage.start(...)` is now the same as `Coverage.start(...); Coverage.resume`.\r\n`Coverage.running?` is the same is `Coverage.state == :running`.\r\n\r\n## Discussion\r\n\r\n* Currently, I think `Coverage.suspend` makes sense only for oneshot coverage, but it supports traditional coverage too, for a unknown use case. However, I may disallow it if we find any problems.\r\n* It is ideal to measure multiple oneshot coverage for each endpoint together, but it was difficult for me to implement it efficiently. My co-workers say that this feature is still valuable even with the limitation.\r\n* Another idea is to use TracePoint. However, I'd like to introduce this feature to the coverage library because (1) the runtime cost of TracePoint seems not to be negligible according to our preliminary experiment, (2) we can use an ecosystem for oneshot coverage (e.g., https://github.com/riseshia/oneshot_coverage), and (3) the changeset for coverage is not so large.\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/4856\r\n\r\nAny comments are welcome.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-17T06:41:10Z", "updated_on": "2021-10-25T11:01:08Z", "closed_on": "2021-10-25T11:01:08Z", "relations": []}, {"id": 18172, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "MatchData#sublen to return the length of a substring", "description": "There are many code taking the length of a substring matched by `Regexp`.\r\nFor instance, in rdoc/markup/attribute_manager.rb:\r\n```ruby\r\n      attr_updated = attrs.set_attrs($`.length + $1.length + $2.length, $3.length, attr)\r\n      if attr_updated\r\n        $1 + NULL * $2.length + $3 + NULL * $2.length + $4\r\n```\r\n\r\nPeople often tends to use such code (although the first addition can be simpler as `$~.begin(3)`), that creates and soon drops substrings, just to take the length.\r\n\r\nTherefore, how about the new method to calculate the length, `MatchData#sublen`?\r\n```ruby\r\n/(\\d+)\\W(\\w+)/ =~ \"1:foo\"\r\n$~.sublen(1)    #=> 1\r\n$~.sublen(2)    #=> 3\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-16T07:34:27Z", "updated_on": "2021-09-17T00:29:43Z", "closed_on": "2021-09-16T12:16:14Z", "relations": []}, {"id": 18168, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 49099, "name": "maximus242 (Philip Solobay)"}, "subject": "Add ActiveSupport deep_transform_values to Ruby", "description": "I think since transform_values is a part of Ruby, it makes sense to support the nested version of transform values", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-15T05:29:44Z", "updated_on": "2021-09-15T05:29:44Z", "closed_on": null, "relations": []}, {"id": 18162, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1855, "name": "tagomoris (Satoshi TAGOMORI)"}, "subject": "Shorthand method Proc#isolate to create isolated proc objects", "description": "Currently, isolated proc objects can be created only via Ractor.make_shareable() method.\r\nBut isolated proc objects are useful for other use-cases too. So I want to propose a new method Proc#isolate to make it isolated.\r\n\r\nFor example, it's useful with async I/O patterns like this:\r\n\r\n```ruby\r\nx = 1\r\ny = 2\r\n\r\nchk1 = ->(async_io){ async_io.write JSON.dump({x:, y:}) }.isolate\r\nasync_make_checkpoint(&chk1)\r\n\r\nx = processing_may_fail(x)\r\ny = processing_may_fail(y)\r\n\r\nchk2 = ->(async_io){ async_io.write JSON.dump({x:, y:}) }.isolate\r\nasync_make_checkpoint(&chk2)\r\n\r\n# ...\r\n```\r\n\r\nIn the use-case above, async_make_checkpoint is to create a checkpoint in an async manner to record the (lexical) \"current\" value of variables. If we can do the thing like above, we'll be able to record how values of x/y are changed (or not changed).\r\nIn my opinion, we'll have many similar use-cases because Ruby 3.x has the fiber scheduler.\r\n\r\nAnd of course, this should be also useful to define shareable methods using Module#define_method.\r\n\r\n```ruby\r\nx = 1\r\ndefine_method(:get_x, &->(){ x }.isolate)\r\n\r\n# is much simpler than below\r\nx = 1\r\ngetter_x = Ractor.make_shareable(->(){ x })\r\ndefine_method(:get_x, &getter_x)\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-13T02:32:40Z", "updated_on": "2021-09-13T02:33:30Z", "closed_on": null, "relations": []}, {"id": 18159, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Integrate functionality of dead_end gem into Ruby", "description": "Missing 'end' errors are difficult to fix. We should integrate the functionality of the dead_end gem (https://github.com/zombocom/dead_end) into Ruby similar to how we integrated did_you_mean. It would greatly help programming Ruby, in particular for beginners.\r\n\r\nSee also Ruby Kaigi Takeout 2021 talk by Richard Schneeman https://rubykaigi.org/2021-takeout/presentations/schneems.html.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-11T03:10:59Z", "updated_on": "2022-06-17T14:06:52Z", "closed_on": null, "relations": [{"id": 3075, "issue_id": 14244, "issue_to_id": 18159, "relation_type": "relates", "delay": null}, {"id": 3350, "issue_id": 18159, "issue_to_id": 18231, "relation_type": "relates", "delay": null}]}, {"id": 18151, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51855, "name": "yann.gouverneur (Yann Gouverneur)"}, "subject": "Incorrect Resolv result when DNS server is unreachable", "description": "The Resolv class has an incorrect behavior when the DNS server can't be reached.\r\n\r\nThe attached script highlight the issue which - depending on your needs in resolving host names - could be really problematic.\r\n\r\nHere's the output of the script:\r\n```\r\n$ ruby test_resolv.rb\r\nResolution of an existing domain name -> OK\r\n[\"142.250.184.68\", \"2a00:1450:4002:806::2004\"]\r\n\r\nResolution of a non existing domain name -> OK\r\n[]\r\n\r\nAttempt of resolving a domain name with an incorrect/unreachable DNS server -> KO\r\n[]\r\n\r\n-> Expecting: ResolvError\r\n```\r\n\r\nObviously the result for both NXDOMAIN and failure to reach the DNS server is identical, hence it make impossible to handle errors programmatically.\r\n\r\nA proper result when the DNS server is not reachable would be to get a ResolvError exception fired.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-06T19:07:21Z", "updated_on": "2021-09-18T00:22:06Z", "closed_on": null, "relations": []}, {"id": 18148, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Marshal.load freeze option", "description": "### Behavior\r\n\r\nIf passed `freeze: true`, all the deserialized objects should be frozen, and if possible, strings should be deduped.\r\n\r\nThis is similar to the `freeze` option recently added to `JSON` (https://github.com/flori/json/pull/447), `Psych` (https://github.com/ruby/psych/pull/414) and `MessagePack` (https://github.com/msgpack/msgpack-ruby/pull/194).\r\n\r\n### Use cases\r\n\r\nThis option is useful in many scenarios:\r\n\r\n  - If the deserialized data is meant to stay on the heap for the lifetime of the program, the string deduplication reduce the memory overhead, and all objects being frozen improve copy on write and ensure that static data isn't accidentally mutated.\r\n  - If the deserialized data is used in a memory cache or similar, deep freezing it protect against mutation and allow to return the value directly without first deep cloning it.\r\n  - While not very performant, it can be used as a `deep_freeze` mechanism with `Marshal.load(Marshal.dump(object), freeze: true)`.\r\n\r\n\r\n\r\n### Snippets\r\n\r\n\r\n```ruby\r\npayload = Marshal.dump({\"foo\" => [\"bar\"]})\r\nobject = Marshal.load(payload, freeze: true)\r\n\r\nobject.frozen?\r\nobject.dig(\"foo\").frozen?\r\nobject.dig(\"foo\", 1).frozen?\r\n\r\n\r\nMarshal.load(payload, ->(obj) { raise \"unexpected\" unless obj.frozen? }, freeze: true)\r\n```\r\n\r\n\r\n```ruby\r\ndef cache_get(key)\r\n  if entry = in_memory_cache.get(key)\r\n    return entry\r\n  end\r\n\r\n  if payload = network_cache.get(key)\r\n    object = Marshal.load(payload, freeze: true)\r\n    in_memory_cache.set(key, object) # if the object tree wasn't frozen, we'd need to deep dup to avoid mutation.\r\n    object\r\n  end\r\nend\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-03T09:14:00Z", "updated_on": "2021-10-05T16:31:43Z", "closed_on": "2021-10-05T16:31:43Z", "relations": []}, {"id": 18146, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9869, "name": "koic (Koichi ITO)"}, "subject": "Add `delete_prefix` and `delete_suffix` to `Pathname`", "description": "`Pathname` has `sub` method, but does not have the methods mentioned in the title.\r\n`Pathname` may be able to provide `delete_prefix` and `delete_suffix` like `String#delete_prefix` and `String#delete_suffix` added in Ruby 2.5\r\n\r\nThis is an idea I got from feedback on RuboCop Performance.\r\nhttps://github.com/rubocop/rubocop-performance/issues/245\r\n\r\nThank you.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-03T04:59:47Z", "updated_on": "2021-09-03T04:59:47Z", "closed_on": null, "relations": []}, {"id": 18145, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 309, "name": "svoop (Sven Schwyn)"}, "subject": "Rescue by nested exception", "description": "The introduction of `Exception#cause` helps a lot when debugging nested errors.\r\n\r\nSame goes for wrapped errors. I'm not really sure whether such wrapped errors are an advisable pattern to begin with, feel free to comment on this, but I've used it in a couple of vendored gems dealing with payment providers.\r\n\r\nHere's some simplified code to illustrate. The `Payment` class deals with all the gory things such as authorization, coercion or API quirks. A simplified version might look like this:\r\n\r\n\r\n```ruby\r\nrequire 'rest_client'\r\n\r\nmodule Provider\r\n  class FindError < StandardError; end\r\n\r\n  class Payment\r\n    attr_reader :id, :amount\r\n\r\n    private_class_method :new\r\n\r\n    def initialize(id, amount)\r\n      @id, @amount = id, amount\r\n    end\r\n\r\n    def self.find(id)\r\n      response = RestClient.get('https://api.provider.com/payments', params: { id: id })\r\n      body = JSON.parse(response.body)\r\n      new(id, body.fetch('amount'))\r\n    rescue\r\n      raise FindError\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nYou can easily `rescue` from anything going wrong when loading a payment:\r\n\r\n```ruby\r\nbegin\r\n  Provider::Payment.find(123)\r\nrescue FindError\r\n  ...\r\nend\r\n```\r\n\r\nHowever, you might want to rescue differently for some specific causes (e.g. not found) but not for others (e.g. timeout):\r\n\r\n```ruby\r\nbegin\r\n  Provider::Payment.find(123)\r\nrescue FindError => error\r\n  if error.cause.instance_of? RestClient::NotFound\r\n    ...\r\n  else\r\n    ...\r\n  end\r\nend\r\n```\r\n\r\nHow about allowing to rescue by nested exception with a syntax like?\r\n\r\n```ruby\r\nbegin\r\n  Provider::Payment.find(123)\r\nrescue FindError & RestClient::NotFound\r\n  ...\r\nrescue FindError\r\n  ...\r\nend\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-02T22:18:11Z", "updated_on": "2021-09-05T08:30:56Z", "closed_on": "2021-09-05T08:30:56Z", "relations": []}, {"id": 18143, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 32, "name": "kou (Kouhei Sutou)"}, "subject": "Add a new method to change GC.stress only in the given block such as GC.with_stress(flag) {...}", "description": "`GC.stress = true` is useful for detecting GC related crashes. We can use it for debugging GC related problems and testing the problem is solved.\r\n\r\nGenerally, we need to enable stress mode before the target code block and disable stress mode after the target code block:\r\n\r\n```ruby\r\nGC.stress = true\r\n# ... something buggy codes ...\r\nGC.stress = false\r\n```\r\n\r\nOr we just enable stress mode before the target code block when the target code block causes a crash:\r\n\r\n```ruby\r\nGC.stress = true\r\n# ... something crash codes ...\r\n```\r\n\r\nIn test code, we must disable stress mode because stress mode slows down test execution:\r\n\r\n```ruby\r\ndef test_gc\r\n  GC.stress = true\r\n  # ... GC related code ...\r\nensure\r\n  GC.stress = false\r\nend\r\n```\r\n\r\nWe have an utility method in CRuby's test utility: `EnvUtil.#under_gc_stress`:\r\n\r\nhttps://github.com/ruby/ruby/blob/ab63f6d8543903f177c46634f38e5428655f003b/tool/lib/envutil.rb#L236-L242\r\n\r\n```ruby\r\n  def under_gc_stress(stress = true)\r\n    stress, GC.stress = GC.stress, stress\r\n    yield\r\n  ensure\r\n    GC.stress = stress\r\n  end\r\n  module_function :under_gc_stress\r\n```\r\n\r\nThis feature is useful not only CRuby's test but also other libraries test and debugging a program that has a GC related problem.\r\n\r\nHow about adding a new singleton method that changes stress mode only in the given block? If we have the method, we don't need to implement a small utility method multiple times for the feature.\r\n\r\nAPI candidates:\r\n\r\n`GC.with_stress(flag) {...}`:\r\n\r\n```ruby\r\nmodule GC\r\n  def self.with_stress(flag)\r\n    flag_old = stress\r\n    self.stress = flag\r\n    yield\r\n  ensure\r\n    self.stress = flag_old\r\n  end\r\nend\r\n```\r\n\r\n`GC.under_stress {...}`:\r\n\r\n```ruby\r\nmodule GC\r\n  def self.under_stress\r\n    flag_old = stress\r\n    self.stress = true\r\n    yield\r\n  ensure\r\n    self.stress = flag_old\r\n  end\r\nend\r\n```\r\n\r\n`GC.stress(flag = true) {...}`:\r\n\r\n```ruby\r\nmodule GC\r\n  def stress flag = true\r\n    if block_given?\r\n      flag_old = Primitive.gc_stress_get\r\n      begin\r\n        GC.stress = flag\r\n      ensure\r\n        GC.stress = flag_old\r\n      end\r\n    else\r\n      Primitive.gc_stress_get\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nNote:\r\n\r\n  * Disadvantage is, `GC.stress` is a getter method and `GC.stress do end` is setter method. It can be confusing.\r\n  * @nobu also pointed out that the block is just ignored on the older Ruby versions.\r\n\r\nSource of implementation and some discussions: https://github.com/ruby/ruby/pull/4793\r\n\r\nBackground:\r\n\r\nI'm maintaining some default gems. They have copy of `EnvUtil` but I don't want to have it for maintainability. If Ruby provides this feature by default, we can use it instead of copying `EnvUtil`. I know that I need to implement/copy the feature in each default gem until Ruby 3.0 reaches EOL. But we don't have the feature now, I need to copy `EnvUtil` forever.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-09-02T02:45:51Z", "updated_on": "2021-09-16T05:02:10Z", "closed_on": "2021-09-16T05:02:10Z", "relations": []}, {"id": 18139, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1855, "name": "tagomoris (Satoshi TAGOMORI)"}, "subject": "Add a method to stop/kill a Ractor from outside", "description": "When a Ractor is doing I/O, it can'tf stop by itself (even when I/O is nonblock, IO.select will block).\r\n\r\n```ruby\r\nr = Ractor.new(listen) { |listen|\r\n  while connection = listen.accept\r\n    # process\r\n  end\r\n}\r\n\r\nSignal.trap(:INT) { r.kill } # I want to do this\r\n# or r.stop, r.interrupt\r\n# or r.raise(MyStopSignalError)\r\n```\r\n\r\nIf a Ractor's input is Ractor.receive only, it can stop itself when it receives a stop signal (via Ractor.receive). But the Ractor is doing I/O, it can't listen Ractor.receive. So there are no any channels to tell it should stop.\r\nUnder the current situation, we can only stop the entire runtime at once without any shutdown processes.\r\n\r\nSo, I want a method to kill or interrupt the Ractor, or to raise an exception in that Ractor from the outside.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-30T02:39:19Z", "updated_on": "2021-12-02T20:59:42Z", "closed_on": "2021-12-02T20:59:42Z", "relations": []}, {"id": 18137, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1855, "name": "tagomoris (Satoshi TAGOMORI)"}, "subject": "A new method to check Proc is isolated or not", "description": "I want to check a Proc is isolated or not, like `Proc#isolated?`.\r\n\r\nProc objects are passed to libraries very often. For example, Rack web application is a callable (`respond_to(:call)`) object, and it may be a Proc.\r\nWhen the library will call that Proc object in a Ractor, the passed Proc should be isolated by `Ractor.make_shareable()`. Otherwise, it causes RuntimeError.\r\n\r\nSo I want to check the Proc object is isolated or not earlier. It should be very helpful for library users because of the early and clear error messages.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-27T10:22:31Z", "updated_on": "2021-10-27T07:30:23Z", "closed_on": null, "relations": []}, {"id": 18136, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "take_while_after", "description": "Sorry, I already tried that once (#16441) but I failed to produce the persuasive example.\r\nSo I am back with a couple of them, much simpler and clear than my initial.\r\n\r\n**The proposal itself:** Have `take_while_after` which behaves like `take_while` but also includes the last element (first where the condition failed). Reason: there are a lot of cases where \"the last good item\" in enumeration is the distinctive one (one where enumeration should stop, but the item is still good.\r\n\r\n**Example 1:** Take pages from paginated API, the last page will have less items than the rest (and that's how we know it is the last):\r\n\r\n```ruby\r\n(0..).lazy\r\n  .map { |offset| get_page(offset, limit) }\r\n  .take_while_after { |response| response.count == limit } # the last will have, say, 10 items, but should still be included!\r\n  .map { process response somehow }\r\n```\r\n\r\n**Example 2:** Same as above, but \"we should continue pagination\" is specified with a separate data key \"can_continue\":\r\n```ruby\r\n(0..).lazy\r\n  .map { |offset| get_page(offset, limit) }\r\n  .take_while_after { |response| response['can_continue'] } # the last will have can_continue=false, but still has data\r\n  .map { process response somehow }\r\n```\r\n\r\n**Exampe 3:** Taking a sentence from a list of tokens like this:\r\n```ruby\r\ntokens = [\r\n  {text: 'Ruby', type: :word},\r\n  {text: 'is', type: :word},\r\n  {text: 'cool', type: :word},\r\n  {text: '.', type: :punctuation, ends_sentence: true},\r\n  {text: 'Rust', type: :word},\r\n  # ...\r\n]\r\n\r\nsentence = tokens.take_while_after { !_1[:ends_sentence] }\r\n```\r\n\r\n(I can get more if it is necessary!)\r\n\r\nNeither of those can be solved by \"Using `take_while` with proper condition.\", as @matz suggested here: https://bugs.ruby-lang.org/issues/16441#note-9\r\n\r\nI typically solve it by `slice_after { condition }.first`, but that's a) uglier and b) greedy when we are working with lazy enumerator (so for API examples, all paginated pages would be fetched at once, and only then processed).\r\n\r\nAnother consideration in #16441 was an unfortunate naming.\r\nI am leaving it to discussion, though I tend to like `#take_upto` from #16446.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-27T09:26:06Z", "updated_on": "2022-01-28T06:23:30Z", "closed_on": null, "relations": []}, {"id": 18135, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51725, "name": "meisel (Michael Eisel)"}, "subject": "Introduce Enumerable#detect_only", "description": "It can be important to get the only element for which a block returns true, and to assert that this is the only element as such. For example, this can be a very helpful sanity check when one is working with data that's outside of their control and is not perfectly understood. They may have a guess as to how to get a specific element matching some criteria, but if they used Enumerable#detect might be hiding the fact that they have written an incorrect block and that there's in fact more than one element that matches it. It could also be a parameter on Typically, I'd do it like this:\r\n\r\n```\r\nmatches = array.select { |elem| some_method(elem) }\r\nraise if matches.size != 0\r\nmatch = matches.first\r\n```\r\nHere, it would be shortened to:\r\n```\r\nmatch = array.detect_only { |elem| some_method(elem) }\r\n```\r\n\r\nIt could also be a parameter on Enumerable#detect instead of a separate method.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-26T19:18:26Z", "updated_on": "2021-09-02T17:44:21Z", "closed_on": null, "relations": [{"id": 3073, "issue_id": 13683, "issue_to_id": 18135, "relation_type": "relates", "delay": null}]}, {"id": 18127, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51834, "name": "rm155 (Rohit Menon)"}, "subject": "Ractor-local version of Singleton", "description": "**Background**\r\nWhen the Singleton module (from the Singleton library) is included in a class, that class will have only one instance. Since the instance can only be in one Ractor at once, Singleton is not Ractor-compatible. For example, the following code would fail upon trying to access Example.instance in the Ractor:\r\n``` ruby\r\nclass Example\r\n  def initialize\r\n    @value = 1\r\n  end\r\nend\r\nExample.include Singleton\r\n\r\nRactor.new do\r\n  Example.instance\r\nend.take\r\n#=> can not access instance variables of classes/modules from non-main Ractors (Ractor::IsolationError)\r\n```\r\n\r\nIn some cases, this may be the desired behavior, as it may be important that the class truly have only one instance. However, in many other cases, it would be more convenient for the class to have one instance per Ractor.\r\n\r\n**Proposal**\r\nThe proposal is to create a RactorLocalSingleton module that can be included instead of Singleton to make the instance Ractor-local.\r\nHere is how RactorLocalSingleton might be used in the situation above:\r\n``` ruby\r\nclass Example\r\n  def initialize\r\n    @value = 1\r\n  end\r\nend\r\nExample.include RactorLocalSingleton\r\n\r\nRactor.new do\r\n  Example.instance\r\nend.take\r\n```\r\n\r\n\r\n\r\n**Discussion**\r\nThe advantage of creating RactorLocalSingleton is that classes could have Singleton-like behavior while being usable in Ractors. Since some libraries, such as Prime, currently rely on the Singleton module, this would enable those libraries to have more flexibility with Ractors.\r\nThe disadvantage of creating this module is that it supports the continued use of the Singleton design pattern, which is sometimes considered harmful. An alternative to RactorLocalSingleton might be to simply use Thread-local variables as Singleton instances. Here is how Thread-local variables might be used in the given situation:\r\n``` ruby\r\nclass Example\r\n  def initialize\r\n    @value = 1\r\n  end\r\nend\r\n\r\nRactor.new do\r\n  Thread.current[:Example] = Example.new\r\n  Thread.current[:Example]\r\nend.take\r\n```\r\n\r\n\r\n**Summary**\r\nClasses that include Singleton are currently incompatible with Ractors. By instead including a new module RactorLocalSingleton, classes can have Singleton-like properties while being used in Ractors. However, this may perpetuate the use of the Singleton design pattern, and using Thread-local variables may be a preferable solution.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-23T21:59:05Z", "updated_on": "2021-11-09T14:45:47Z", "closed_on": null, "relations": []}, {"id": 18124, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 32274, "name": "myxoh (Nicolas Klein)"}, "subject": "Hash shorthands (matching constructors functionality in JS)", "description": "# **Suggestion:**\r\nTo implement one shorthand operators that allows you to construct hash into local variables and construct local variables into a hash.\r\n\r\n# **Context:**\r\nJavascript and other languages have a similar feature. It's helpful, and I don't think there's anything stopping Ruby for supporting it.\r\nhttps://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Destructuring_assignment\r\nRuby also supports destructuring from an array.\r\n\r\n# **Syntax:**\r\n### Constructor:\r\nThe constructor shorthand would allow you to create a hash where the symbol key has the same name as the variable.\r\n\r\nFor example:\r\n\r\n```ruby\r\nlocal_number = 1 \r\nuser = OStruct.new(name: 'john')\r\nhash = %C{ local_var user }\r\n```\r\n\r\nwould be equivalent to:\r\n```ruby\r\nlocal_number = 1 \r\nuser =  OStruct.new(name: 'john')\r\nhash = { local_number: local_number, user: user }\r\n```\r\n\r\nThe new syntax is based on ruby's existing literal constructors syntax.\r\n\r\nEDIT:\r\nEdited to remove a reference to the destructuring, which is already implemented on Ruby 3\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-20T18:04:49Z", "updated_on": "2021-10-15T18:39:46Z", "closed_on": "2021-10-15T18:39:46Z", "relations": [{"id": 3071, "issue_id": 14579, "issue_to_id": 18124, "relation_type": "relates", "delay": null}, {"id": 3072, "issue_id": 17292, "issue_to_id": 18124, "relation_type": "relates", "delay": null}]}, {"id": 18083, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Capture error in ensure block.", "description": "As discussed in https://bugs.ruby-lang.org/issues/15567 there are some tricky edge cases.\r\n\r\nAs a general model, something like the following would be incredibly useful:\r\n\r\n``` ruby\r\nbegin\r\n ...\r\nensure => error\r\n  pp \"error occurred\" if error\r\nend\r\n```\r\n\r\nCurrently you can get similar behaviour like this:\r\n\r\n``` ruby\r\nbegin\r\n  ...\r\nrescue Exception => error\r\n  raise\r\nensure\r\n  pp \"error occurred\" if error\r\nend\r\n```\r\n\r\nThe limitation of this approach is it only works if you don't need any other `rescue` clause. Otherwise, it may not work as expected or require extra care. Also, Rubocop will complain about it.\r\n\r\nUsing `$!` can be buggy if you call some method from `rescue` or `ensure` clause, since it would be set already. It was discussed extensively in https://bugs.ruby-lang.org/issues/15567 if you want more details.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-18T03:03:42Z", "updated_on": "2021-10-21T13:00:40Z", "closed_on": null, "relations": [{"id": 3037, "issue_id": 15567, "issue_to_id": 18083, "relation_type": "relates", "delay": null}]}, {"id": 18070, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35671, "name": "schwad (Nick Schwaderer)"}, "subject": "`attr` should be removed", "description": "I'm digging through some older Ruby versions and discovered that `attr` was deprecated in Ruby 1.9. We still are seeing support for it in Ruby 3.0\r\n\r\nUnless there are internals that require its existence, is it time to remove this deprecated feature? \r\n\r\nIf there's agreement, I'm more than happy to fire up the PR myself. (Also happy to be corrected if there's something I'm missing here :) )\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-08T18:33:16Z", "updated_on": "2021-08-09T17:51:22Z", "closed_on": null, "relations": []}, {"id": 18069, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12651, "name": "ttanimichi (Tsukuru Tanimichi)"}, "subject": "`instance_exec` is just ignored when the block is originally a method", "description": "\r\nI know you can't `instance_exec` a proc which is generated by `Method#to_proc` because it has its original instance's context. But, in such a case, raising `ArgumentError` would be the ideal behavior.\r\n\r\n```ruby\r\nf = -> (x) { a + x }\r\n\r\nclass A\r\n  def a\r\n    1\r\n  end\r\nend\r\n\r\nA.new.instance_exec(1, &f) # => 2\r\n\r\nclass B\r\n  def b(x)\r\n    a + x\r\n  end\r\nend\r\n\r\nproc = B.new.method(:b).to_proc\r\nA.new.instance_exec(1, &proc) # => undefined local variable or method `a' for #<B:0x00007fdaf30480a0> (NameError)\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-08T14:30:31Z", "updated_on": "2021-08-10T05:33:20Z", "closed_on": null, "relations": []}, {"id": 18063, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51781, "name": "eugene.shved (Eugene Shved)"}, "subject": "io_uring implementation", "description": "https://www.youtube.com/watch?v=TYq_ohhYZ9A", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-05T10:02:48Z", "updated_on": "2021-08-05T10:02:48Z", "closed_on": null, "relations": []}, {"id": 18057, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51775, "name": "ggmichaelgo (Michael Go)"}, "subject": "Introduce Array#mean", "description": "Introduce Array#average to calculate the average value of an array.\r\n\r\n```ruby\r\narray = [1, 2, 3]\r\narray.mean # 2\r\n\r\narray = [1.5, 2.2, 3.1]\r\narray.mean(&:round) # 2.3333333333333335\r\n\r\narray = [-3, -2, -1]\r\narray.mean { |e| e.abs } # 2\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-08-02T00:02:51Z", "updated_on": "2021-08-02T14:16:10Z", "closed_on": null, "relations": []}, {"id": 18055, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51771, "name": "shalokshalom (Matthias Schuster)"}, "subject": "Introduce", "description": "Currently, ``autoload`` provides the ability to load libraries on the fly, also called lazy loading, in order to avoid huge startup times.\r\n\r\nThis has some disadvantages, who already lead nearly to its [discontinuation](https://bugs.ruby-lang.org/issues/5653)\r\n\r\nI suggest a proposal, that solves both these issues.\r\n\r\n``introduce``\r\n\r\nI imagine this keyword, respectively method behaves like ```require``` at the top of the file and does act like ```autoload``` within a definition.\r\n\r\nWe can also introduce exceptions for cases like the above linked threads.\r\n\r\nIts also a nice guideline, and easy to remember.\r\n\r\n*Summary*: ``introduce`` can always behave predictable, optimal, and even work fine without the programmer knowing about its implementation. \r\n\r\n\r\nSimilar issues: \r\n - https://bugs.ruby-lang.org/issues/15592", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-30T07:47:12Z", "updated_on": "2021-07-30T09:30:29Z", "closed_on": null, "relations": []}, {"id": 18051, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Move symbols exported under internal", "description": "Some symbols exported in headers under `internal` are declared and used in some extension libraries.\r\nThese seem OK to be moved to public headers.\r\n\r\n* `ruby_scan_digits`\r\n    cgi/escape, date\r\n* `ruby_hexdigits`\r\n    cgi/escape, objspace\r\n* `ruby_digit36_to_number_table`\r\n    cgi/escape\r\n* `rb_int_positive_pow`\r\n    date\r\n* `rb_deprecate_constant`\r\n    etc\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-28T10:39:34Z", "updated_on": "2021-08-24T01:38:19Z", "closed_on": "2021-08-24T01:38:19Z", "relations": []}, {"id": 18047, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51765, "name": "suusan2go (Kenta Suzuki)"}, "subject": "TracePoint: Add event type for constant access", "description": "Hi there\r\nWe've made a PR to add new :constant_access TracePoint event. https://github.com/ruby/ruby/pull/4683\r\nBurke Libbey made some first steps on this idea a few years ago #13133 and we improved his patch based on the comment by ko1.\r\n\r\nAs mentioned in the issue above, this patch allows us to enable boundaries between packages/components. \r\nBurke's [proof-of-concept gem](https://github.com/burke/packages) might help you understand more concrete usage of this patch.\r\n\r\nThe proof-of-concept gem works like the below and this will help us manage large codebases with lots of dependencies.\r\n\r\n```ruby\r\npackage 'product'\r\nclass Book < ApplicationRecord\r\n  belongs_to :user\r\nend\r\n\r\npackage 'user'\r\nclass User < ApplicationRecord\r\n  has_many :books\r\nend\r\n\r\nuser = User.first\r\nuser.books\r\n# => VisibilityError (can't access Book from User)\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-27T01:46:00Z", "updated_on": "2021-12-02T20:35:15Z", "closed_on": "2021-12-02T20:35:15Z", "relations": []}, {"id": 18045, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "assigned_to": {"id": 42491, "name": "peterzhu2118 (Peter Zhu)"}, "subject": "Variable Width Allocation Phase II", "description": "\r\n# GitHub PR: https://github.com/ruby/ruby/pull/4680\r\n\r\n# Feature description\r\n\r\nSince merging the initial implementation in #17570, we've been working on improving the performance of the allocator (which was one of the major drawbacks in the initial implementation). We've chosen to return to using a freelist-based allocator and added support for variable slot size pages in what we call \"size pools\". We're still keeping the `USE_RVARGC` compile-time flag that maintains current behaviour when it is not explicitly enabled.\r\n\r\n## Summary\r\n\r\n- We now use pages with different slot sizes in pools to speed up allocation. Objects will be allocated in the smallest slot size that fits the requested size. This brings us back to the freelist-based allocation algorithm and significantly increases allocation performance.\r\n- The heap growth algorithm has been changed to adapt to the growth pattern of the size pool. Heaps that rapidly allocate and deallocate are considered \"growth heaps\" and are treated differently than heaps that are stable in size.\r\n\r\n## Size pools\r\n\r\nIn this patch, we introduce a new structure into the GC called \"size pools\". Each size pool contains an eden and tomb heap to hold the pages. The size pool determines the slot size of the pages in it. We've chosen powers of 2 multiples of RVALUE size as our slot sizes. In other words, since the RVALUE size is 40 bytes, size pool 0 will have pages with slot size 40B, 80B for size pool 1, 160B for size pool 2, 320B for size pool 3, etc. The reason we chose powers of 2 multiples of RVALUE is that powers of 2 are easy to work with (e.g. we can use bit shifts) and using multiples of RVALUE means that we do not waste space for the single RVALUE (40 byte) allocations. When VWA is not enabled, there is only one size pool.\r\n\r\n## Heap growth algorithm\r\n\r\nThis patch changes heap growth when `USE_RVARGC` is turned on. Heap growth is now calculated after sweeping (rather than after marking). This is because we don't know the characteristics of a size pool after marking (we only know the number of marked slots vs. total number of pages). By keeping track of the number of free slots and swept slots of each size pool during sweeping, we know the exact number of live vs. free slots in each size pool. This allows us to grow the size pool according to its growth characteristics. For example, classes are allocated in the third size pool (160B slot size). For most workloads, classes are allocated at boot and very rarely allocated afterwards. Through the data collected during sweeping, we can determine that this size pool is no longer growing and thus allow it to be very full.\r\n\r\n## Lazy sweeping\r\n\r\nAt every sweeping step, we attempt to sweep a little bit of every size pool. If the size pool we're allocating into didn't yield a page during sweeping and that size pool is not allowed to create new pages, then we must finish sweeping by sweeping all remaining pages in all other size pools. This may cause some lazy sweeping steps to take longer than others, we can see the result of this in the worse p99 response time in railsbench.\r\n\r\n# Benchmark setup\r\n\r\nBenchmarking was done on a bare-metal Ubuntu machine on AWS. All benchmark results are using glibc by default, except when jemalloc is explicitly specified.\r\n\r\n```\r\n$ uname -a\r\nLinux 5.8.0-1038-aws #40~20.04.1-Ubuntu SMP Thu Jun 17 13:25:28 UTC 2021 x86_64 x86_64 x86_64 GNU/Linux\r\n```\r\n\r\nglibc version:\r\n\r\n```\r\n$ ldd --version\r\nldd (Ubuntu GLIBC 2.31-0ubuntu9.2) 2.31\r\nCopyright (C) 2020 Free Software Foundation, Inc.\r\nThis is free software; see the source for copying conditions.  There is NO\r\nwarranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\nWritten by Roland McGrath and Ulrich Drepper.\r\n```\r\n\r\njemalloc version:\r\n\r\n```\r\n$ apt list --installed | grep jemalloc\r\n\r\nWARNING: apt does not have a stable CLI interface. Use with caution in scripts.\r\n\r\nlibjemalloc-dev/focal,now 5.2.1-1ubuntu1 amd64 [installed]\r\nlibjemalloc2/focal,now 5.2.1-1ubuntu1 amd64 [installed,automatic]\r\n```\r\n\r\nTo measure memory usage over time, the [mstat tool](https://github.com/bpowers/mstat) was used.\r\n\r\nMaster was benchmarked on commit 84fea8ee39249ff9e7a03c407e5d16ad93074f3e. The branch was rebased on top of the same commit.\r\n\r\nPerformance benchmarks of this branch without VWA turned on are included to make sure this patch does not introduce a performance regression compared to master.\r\n\r\n# Benchmark results\r\n\r\n## Summary\r\n\r\n- We don't expect to see a significant performance improvement with this patch. In fact, our main goal of this patch is for Variable Width Allocation to have performance and memory usage comparable to master.\r\n- railsbench:\r\n    - VWA uses about 1.02x more memory than master.\r\n    - When using jemalloc, VWA is about 1.027x faster than master.\r\n    - We see no (within margin of error) speedup when using glibc.\r\n    - In both glibc and jemalloc we see worse p99 response times described above in \"Lazy sweeping\" section. However, the p100 response times of VWA is comparable to master.\r\n- rdoc generation:\r\n    - VWA uses 1.13x less memory than master.\r\n- liquid benchmarks:\r\n    - We see no significant performance changes here.\r\n- optcarrot benchmark:\r\n    - We see no significant performance changes here.\r\n\r\n## railsbench\r\n\r\nFor railsbench, we ran the [railsbench benchmark](https://github.com/k0kubun/railsbench/blob/master/bin/bench). For both the performance and memory benchmarks, 50 runs were conducted for each combination (branch + glibc, master + glibc, branch + jemalloc, master + jemalloc).\r\n\r\n### glibc\r\n\r\nFor glibc, the RPS between the three are all within the margin of error. However, the p99 of the branch with VWA is significantly worse than master (3.2ms vs 1.8ms). This is due to the longer lazy sweeping steps discussed above. However, this isn't a problem for p100 response times.\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master |\r\n+-----------+-----------------+------------------+--------+\r\n| RPS       | 731.69          | 724.19           | 727.02 |\r\n| p50 (ms)  | 1.33            | 1.38             | 1.37   |\r\n| p66 (ms)  | 1.37            | 1.41             | 1.40   |\r\n| p75 (ms)  | 1.38            | 1.42             | 1.41   |\r\n| p80 (ms)  | 1.39            | 1.43             | 1.42   |\r\n| p90 (ms)  | 1.41            | 1.45             | 1.45   |\r\n| p95 (ms)  | 1.44            | 1.48             | 1.47   |\r\n| p98 (ms)  | 1.50            | 1.78             | 1.76   |\r\n| p99 (ms)  | 3.23            | 1.84             | 1.83   |\r\n| p100 (ms) | 15.74           | 16.48            | 16.38  |\r\n+-----------+-----------------+------------------+--------+\r\n```\r\n\r\nFor memory usage, we see a slight increase in memory usage when using Variable Width Allocation compared to master.\r\n\r\n![](https://user-images.githubusercontent.com/15860699/125795979-dc006bb5-e129-47f0-8db7-23c203f7baf2.png)\r\n\r\nAverage max memory usage for VWA: 147.08 MB\r\n\r\nAverage max memory usage for master: 143.49 MB\r\n\r\nVWA uses 1.025x more memory.\r\n\r\n### jemalloc\r\n\r\nFor jemalloc, we see that the branch is 1.027x faster than master in RPS (standard deviation is about 3 rps). We once again see the worse p99 response times with VWA enabled.\r\n\r\n```\r\n+-----------+-----------------+------------------+--------+\r\n|           | Branch (VWA on) | Branch (VWA off) | Master |\r\n+-----------+-----------------+------------------+--------+\r\n| RPS       | 756.06          | 741.26           | 736.31 |\r\n| p50 (ms)  | 1.30            | 1.34             | 1.34   |\r\n| p66 (ms)  | 1.32            | 1.36             | 1.37   |\r\n| p75 (ms)  | 1.33            | 1.37             | 1.39   |\r\n| p80 (ms)  | 1.34            | 1.38             | 1.39   |\r\n| p90 (ms)  | 1.36            | 1.40             | 1.41   |\r\n| p95 (ms)  | 1.38            | 1.42             | 1.44   |\r\n| p98 (ms)  | 1.42            | 1.71             | 1.70   |\r\n| p99 (ms)  | 2.74            | 1.78             | 1.78   |\r\n| p100 (ms) | 13.42           | 16.80            | 16.45  |\r\n+-----------+-----------------+------------------+--------+\r\n```\r\n\r\nOnce again, we see a slight increase in memory usage in VWA compared to master.\r\n\r\n![](https://user-images.githubusercontent.com/15860699/125796015-ff2bd763-0646-44df-8b0c-46161bb425c6.png)\r\n\r\nAverage max memory usage for VWA: 145.47 MB\r\n\r\nAverage max memory usage for master: 142.65 MB\r\n\r\nVWA uses 1.020x more memory.\r\n\r\n## rdoc generation\r\n\r\nFor rdoc generation, we ran the following script for the branch and master to collect memory usage.\r\n\r\n```\r\nfor x in $(seq 50)\r\ndo\r\n  sudo rm -rf .ext/rdoc; mstat -o mstat/branch_$x.tsv -freq 59 -- ruby --disable-gems \"./libexec/rdoc\" --root \".\" --encoding=UTF-8 --all --ri --op \".ext/rdoc\" --page-dir \"./doc\" --no-force-update  \".\"\r\ndone\r\n```\r\n\r\nFor rdoc generation, we see a decrease in memory usage when using Variable Width Allocation.\r\n\r\n### glibc\r\n\r\n![](https://user-images.githubusercontent.com/15860699/125796394-b6ae6041-2eb4-4e7d-9e14-e58378d9e218.png)\r\n\r\nAverage max memory usage for VWA: 328.83 MB\r\n\r\nAverage max memory usage for master: 373.17 MB\r\n\r\nVWA uses 1.13x less memory.\r\n\r\n### jemalloc\r\n\r\n![](https://user-images.githubusercontent.com/15860699/125796437-ef9dc34b-ea66-4fa5-a0c2-051f8dc281b3.png)\r\n\r\nAverage max memory usage for VWA: 308.08 MB\r\n\r\nAverage max memory usage for master: 347.07 MB\r\n\r\nVWA uses 1.13x less memory.\r\n\r\n## Liquid benchmarks\r\n\r\nFor the liquid benchmarks, we ran the [liquid benchmark](https://github.com/Shopify/liquid/blob/master/performance/benchmark.rb) averaged over 5 runs each. We don't see any significant performance improvements or regressions here.\r\n\r\n```\r\n+----------------------+-----------------+------------------+--------+\r\n|                      | Branch (VWA on) | Branch (VWA off) | Master |\r\n+----------------------+-----------------+------------------+--------+\r\n| Parse (i/s)          | 39.60           | 39.56            | 39.45  |\r\n| Render (i/s)         | 127.69          | 126.91           | 127.06 |\r\n| Parse & Render (i/s) | 28.42           | 28.40            | 28.30  |\r\n+----------------------+-----------------+------------------+--------+\r\n```\r\n\r\n## optcarrot\r\n\r\nFor optcarrot, we ran the [optcarrot benchmark](https://github.com/mame/optcarrot/blob/master/bin/optcarrot-bench) averaged over 5 runs each. Once again, we don't see any significant performance improvements or regressions here.\r\n\r\n```\r\n+-----+-----------------+------------------+--------+\r\n|     | Branch (VWA on) | Branch (VWA off) | Master |\r\n+-----+-----------------+------------------+--------+\r\n| fps | 44.54           | 45.02            | 44.15  |\r\n+-----+-----------------+------------------+--------+\r\n```\r\n\r\n# Future plans\r\n\r\n- Improve within size pool compaction support. The compaction only currently compacts the first size pool (i.e. size pool with 40B slots).\r\n- Improve ractor support. The ractor cache currently only caches the first size pool (size pool with 40B slots). Any >40B allocations require locking the VM.\r\n- Increase coverage of Variable Width Allocation. Our next candidates are arrays and strings.\r\n- Investigate ways to support resizing of objects within Variable Width Allocation.\r\n    - One idea is to support cross size pool compaction. So when an object requests to be resized it will be moved to the most optimal size pool.\r\n- Use powers of 2 slot sizes in heap pages. We currently use powers of 2 multiples of RVALUE size, but it would be easier and more efficient to use powers of 2 slot sizes (i.e. 32B, 64B, 128B, etc.). However, this would mean that 24B will be wasted for objects that are 40B in size (occupy a single RVALUE) since they will be allocated into 64B slots. We believe that once more objects can take advantage of Variable Width Allocation, we will be able to shrink the size of RVALUE to 32B. As such, we only plan on investigating this once most, if not all, objects can be allocated through Variable Width Allocation.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-26T17:44:24Z", "updated_on": "2021-08-23T13:16:15Z", "closed_on": "2021-08-23T13:16:15Z", "relations": [{"id": 3031, "issue_id": 17816, "issue_to_id": 18045, "relation_type": "relates", "delay": null}]}, {"id": 18042, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51735, "name": "motoroller (Iskandar Gohar)"}, "subject": "YARV code optimization", "description": "Hi! Long period of time I think about programmatically code optimization for YARV. In compiled languages like C/C++ the compiler can do whatever it wants with the code and does for performance optimization. Firstly, ruby developers think about code readability, secondary about performance. Because ruby translates .rb file into bytecode we can do whit this bytecode anything to win in performance and do not lose in the expressiveness of the code. \r\n\r\n But I came to the conclusion that a static bytecode optimizer is not possible, because in translation stage we don't know about which object/class we use. So, did someone think about runtime code analyzing? If we have some type of statistic we can dynamically transform bytecode to optimized version, use optimized version of C functions. Also I thought if we have statistic we can reduce some GC overhead  \r\n\r\n ```ruby \r\n # before  \r\n array.map(&:method1).map(&:method2) \r\n\r\n # if I know for sure that map is not overridden and calls from Enumerable I can rebuild code like this \r\n array.map do \r\n   _1.method1 \r\n   _1.method2 \r\n end \r\n ``` \r\n\r\n In this example 2 `map` calls generate one redundant array which will be destructed by GC, so we can transform it to seconds version. It can be applied not only for `map/select` functions, but many other.  \r\n\r\n What do you think about it? ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-23T16:22:47Z", "updated_on": "2021-07-27T21:11:40Z", "closed_on": "2021-07-27T06:12:04Z", "relations": []}, {"id": 18040, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8741, "name": "bughit (bug hit)"}, "subject": "Why should `foo(1 if true)` be an error?", "description": "There's no ambiguity here that should require another set of parens `foo((1 if true))`", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-19T18:47:40Z", "updated_on": "2021-07-20T13:26:12Z", "closed_on": "2021-07-20T13:26:12Z", "relations": []}, {"id": 18037, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Update Unicode data to Unicode Version 14.0.0", "description": "Unicode Version 14.0.0 is currently in beta. See the announcement at https://home.unicode.org/unicode-14-0-beta-review/ and more details at https://www.unicode.org/versions/beta-14.0.0.html. We should test the new data during the beta period, and later update Ruby after the official release, which is planned for September 14, 2021.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-12T07:44:06Z", "updated_on": "2022-03-16T23:13:07Z", "closed_on": "2022-03-16T23:13:07Z", "relations": [{"id": 3027, "issue_id": 17750, "issue_to_id": 18037, "relation_type": "relates", "delay": null}, {"id": 3275, "issue_id": 18037, "issue_to_id": 18639, "relation_type": "relates", "delay": null}, {"id": 3271, "issue_id": 18636, "issue_to_id": 18037, "relation_type": "blocks", "delay": null}]}, {"id": 18035, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce general model/semantic for immutable by default.", "description": "It would be good to establish some rules around mutability, immutability, frozen, and deep frozen in Ruby.\r\n\r\nI see time and time again, incorrect assumptions about how this works in production code. Constants that aren't really constant, people using `#freeze` incorrectly, etc.\r\n\r\nI don't have any particular preference but:\r\n\r\n- We should establish consistent patterns where possible, e.g.\r\n  - Objects created by `new` are mutable.\r\n  - Objects created by literal are immutable.\r\n\r\nWe have problems with how `freeze` works on composite data types, e.g. `Hash#freeze` does not impact children keys/values, same for Array. Do we need to introduce `freeze(true)` or `#deep_freeze` or some other method?\r\n\r\nBecause of this, frozen does not necessarily correspond to immutable. This is an issue which causes real world problems.\r\n\r\nI also propose to codify this where possible, in terms of \"this class of object is immutable\" should be enforced by the language/runtime, e.g.\r\n\r\n\r\n```ruby\r\nmodule Immutable\r\n  def new(...)\r\n    super.freeze\r\n  end\r\nend\r\n\r\nclass MyImmutableObject\r\n  extend Immutable\r\n\r\n  def initialize(x)\r\n    @x = x\r\n  end\r\n  \r\n  def freeze\r\n    return self if frozen?\r\n    \r\n    @x.freeze\r\n    \r\n    super\r\n  end\r\nend\r\n\r\no = MyImmutableObject.new([1, 2, 3])\r\nputs o.frozen?\r\n```\r\n\r\nFinally, this area has an impact to thread and fiber safe programming, so it is becoming more relevant and I believe that the current approach which is rather adhoc is insufficient.\r\n\r\nI know that it's non-trivial to retrofit existing code, but maybe it can be done via magic comment, etc, which we already did for frozen string literals.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-09T08:10:55Z", "updated_on": "2021-11-09T16:47:21Z", "closed_on": null, "relations": []}, {"id": 18033, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Time.new to parse a string", "description": "Make `Time.new` parse `Time#inspect` and ISO-8601 like strings.\r\n\r\n* `Time.iso8601` and `Time.parse` need an extension library, `date`.\r\n* `Time.iso8601` can't parse `Time#inspect` string.\r\n* `Time.parse` often results in unintentional/surprising results.\r\n* `Time.new` also about 1.9 times faster than `Time.iso8601`.\r\n\r\n    ```\r\n    $ ./ruby -rtime -rbenchmark -e '\r\n    n = 1000\r\n    s = Time.now.iso8601\r\n    Benchmark.bm(12) do |x|\r\n      x.report(\"Time.iso8601\") {n.times{Time.iso8601(s)}}\r\n      x.report(\"Time.parse\") {n.times{Time.parse(s)}}\r\n      x.report(\"Time.new\") {n.times{Time.new(s)}}\r\n    end'\r\n                       user     system      total        real\r\n    Time.iso8601   0.006919   0.000185   0.007104 (  0.007091)\r\n    Time.parse     0.018338   0.000207   0.018545 (  0.018590)\r\n    Time.new       0.003671   0.000069   0.003740 (  0.003741)\r\n    ```\r\n\r\nhttps://github.com/ruby/ruby/pull/4639", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-09T06:13:00Z", "updated_on": "2021-12-07T14:15:10Z", "closed_on": null, "relations": [{"id": 3028, "issue_id": 16005, "issue_to_id": 18033, "relation_type": "relates", "delay": null}, {"id": 3187, "issue_id": 18033, "issue_to_id": 18331, "relation_type": "relates", "delay": null}]}, {"id": 18029, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Update Unicode Emoji version to 13.1", "description": "The current version of Unicode Emoji is 13.1.\r\nThis was announced here:\r\nhttp://blog.unicode.org/2020/09/emoji-131-now-final-to-be-widely.html\r\nFor more details, see also:\r\nhttps://www.unicode.org/emoji/charts-13.1/emoji-released.html\r\nI do not expect any major problems with this, as there are no newly allocated codepoints, only newly recognized combinations of codepoints.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-08T09:11:41Z", "updated_on": "2021-07-27T08:39:58Z", "closed_on": "2021-07-27T08:39:58Z", "relations": [{"id": 3024, "issue_id": 17750, "issue_to_id": 18029, "relation_type": "relates", "delay": null}]}, {"id": 18026, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Add global variables for instruction information", "description": "When I am debugging crashes in Ruby, sometimes it is very convenient to disassemble iseqs in a core file.  For example in Bug #17984, I had a core file from a dead process.  Disassembling the iseqs where the crash occurred helped me to find the cause of the crash.\r\n\r\nHowever, since 72e318f118d5cfde0e66a41acd3a2070fcaf4348, YARV instruction information tables that I need to disassemble the iseqs became static, function local constants.  The problem with function local statics is that the symbol names generated depend on the compiler we use.  For example, [this constant](https://github.com/ruby/ruby/blob/b1b7f997aeb8a09e863f4d6271ab38da179e246d/tool/ruby_vm/views/_insn_name_info.erb#L21-L23), the `x` variable inside the `insn_name` function.  On clang the symbol name is `insn_name.x`:\r\n\r\n```\r\n$ nm ./miniruby | grep insn_name.x\r\n00000001002cc7c0 s _insn_name.x\r\n00000001002ce350 s _insn_name.x\r\n00000001002cf310 s _insn_name.x\r\n```\r\n\r\nBut with gcc the symbol name is `x.SOMENUMBER`:\r\n\r\n```\r\naaron@whiteclaw ~/g/ruby (master)> nm ./miniruby | grep ' x\\.'\r\n00000000003016a0 r x.19369\r\n00000000002f9820 r x.51289\r\n00000000002fa520 r x.51305\r\n00000000002ee4e0 r x.51499\r\n00000000002ef2c0 r x.51515\r\n```\r\n\r\nEven more complicated is that we have other static variables named `x`, so I have to hunt for the right symbol name via trial and error.\r\n\r\nCan we change these symbols to be globals so that debuggers can look for a consistent name?\r\n\r\nThank you!", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-07T02:33:51Z", "updated_on": "2021-10-04T16:43:26Z", "closed_on": "2021-10-04T16:43:26Z", "relations": []}, {"id": 18020, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce `IO::Buffer` for fiber scheduler.", "description": "After continuing to build out the fiber scheduler interface and the specific hooks required for `io_uring`, I found some trouble within the implementation of `IO`.\r\n\r\nI found that in some cases, we need to read into the internal IO buffers directly. I tried creating a \"fake string\" in order to transit back into the Ruby fiber scheduler interface and this did work to a certain extent, but I was told we cannot expose fake string to Ruby scheduler interface.\r\n\r\nSo, after this, and many other frustrations with using `String` as a IO buffer, I decided to implement a low level `IO::Buffer` based on my needs for high performance IO, and as part of the fiber scheduler interface.\r\n\r\nHere is roughly the interface implemented by the scheduler w.r.t. the buffer:\r\n\r\n```ruby\r\nclass Scheduler\r\n  # @parameter buffer [IO::Buffer] Buffer for reading into.\r\n  def io_read(io, buffer, length)\r\n    # implementation provided by `read` system call, IO_URING_READV, etc.\r\n  end\r\n\r\n  # @parameter buffer [IO::Buffer] Buffer for writing from.\r\n  def io_write(io, buffer, length)\r\n    # implementation provided by `write` system call, IO_URING_WRITEV, etc.\r\n  end\r\n\r\n  # Potential new hooks (Socket#recvmsg, sendmsg, etc):\r\n  def io_recvmsg(io, buffer, length)\r\n  end\r\nend\r\n```\r\n\r\nIn reviewing other language designs, I found that this design is very similar to Crystal's IO buffering strategy.\r\n\r\nThe proposed implementation provides enough of an interface to implement both native schedulers as well as pure Ruby schedulers. It also provides some extra functionality for interpreting the data in the buffer. This is mostly for testing and experimentation, although it might make sense to expose this interface for binary protocols like HTTP/2, QUIC, WebSockets, etc.\r\n\r\n## Proposed Solution\r\n\r\nWe introduce new class `IO::Buffer`.\r\n\r\n```ruby\r\nclass IO::Buffer\r\n  # @returns [IO::Buffer] A buffer with the contents of the string data.\r\n  def self.for(string)\r\n  end\r\n\r\n  PAGE_SIZE = # ... operating system page size\r\n\r\n  # @returns [IO::Buffer] A buffer with the contents of the file mapped to memory.\r\n  def self.map(file)\r\n  end\r\n\r\n  # Flags for buffer state.\r\n  EXTERNAL = # The buffer is from external memory.\r\n  INTERNAL = # The buffer is from internal memory (malloc).\r\n  MAPPED = # The buffer is from mapped memory (mmap, VirtualAlloc, etc)\r\n  LOCKED = # The buffer is locked for usage (cannot be resized)\r\n  PRIVATE = # The buffer is mapped as copy-on-write.\r\n  IMMUTABLE = # The buffer cannot be modified.\r\n\r\n  # @returns [IO::Buffer] A buffer with the specified size, allocated according to the given flags.\r\n  def initialize(size, flags)\r\n  end\r\n\r\n  # @returns [Integral] The size of the buffer\r\n  attr :size\r\n\r\n  # @returns [String] A brief summary and hex dump of the buffer.\r\n  def inspect\r\n  end\r\n\r\n  # @returns [String] A brief summary of the buffer.\r\n  def to_s\r\n  end\r\n\r\n  # Flag predicates:\r\n  def external?\r\n  end\r\n\r\n  def internal?\r\n  end\r\n\r\n  def mapped?\r\n  end\r\n\r\n  def locked?\r\n  end\r\n\r\n  def immutable?\r\n  end\r\n\r\n  # Flags for endian/byte order:\r\n  LITTLE_ENDIAN = # ...\r\n  BIG_ENDIAN = # ...\r\n  HOST_ENDIAN = # ...\r\n  NETWORK_ENDIAN= # ...\r\n\r\n  # Lock the buffer (prevent resize, unmap, changes to base and size).\r\n  def lock\r\n    raise \"Already locked!\" if flags & LOCKED\r\n    \r\n    flags |= LOCKED\r\n  end\r\n\r\n  # Unlock the buffer.\r\n  def unlock\r\n    raise \"Not locked!\" unless flags & LOCKED\r\n    \r\n    flags |= ~LOCKED\r\n  end\r\n\r\n  // Manipulation:\r\n  # @returns [IO::Buffer] A slice of the buffer's data. Does not copy.\r\n  def slice(offset, length)\r\n  end\r\n\r\n  # @returns [String] A binary string starting at offset, length bytes.\r\n  def to_str(offset, length)\r\n  end\r\n\r\n  # Copy the specified string into the buffer at the given offset.\r\n  def copy(string, offset)\r\n  end\r\n\r\n  # Compare two buffers.\r\n  def <=>(other)\r\n  end\r\n\r\n  include Comparable\r\n\r\n  # Resize the buffer, preserving the given length (if non-zero).\r\n  def resize(size, preserve = 0)\r\n  end\r\n\r\n  # Clear the buffer to the specified value.\r\n  def clear(value = 0, offset = 0, length = (@size - offset))\r\n  end\r\n\r\n  # Data Types:\r\n  # Lower case: little endian.\r\n  # Upper case: big endian (network endian).\r\n  #\r\n  # :U8        | unsigned 8-bit integer.\r\n  # :S8        | signed 8-bit integer.\r\n  #\r\n  # :u16, :U16 | unsigned 16-bit integer.\r\n  # :s16, :S16 | signed 16-bit integer.\r\n  #\r\n  # :u32, :U32 | unsigned 32-bit integer.\r\n  # :s32, :S32 | signed 32-bit integer.\r\n  #\r\n  # :u64, :U64 | unsigned 64-bit integer.\r\n  # :s64, :S64 | signed 64-bit integer.\r\n  #\r\n  # :f32, :F32 | 32-bit floating point number.\r\n  # :f64, :F64 | 64-bit floating point number.\r\n\r\n  # Get the given data type at the specified offset.\r\n  def get(type, offset)\r\n  end\r\n\r\n  # Set the given value as the specified data type at the specified offset.\r\n  def set(type, offset, value)\r\n  end\r\nend\r\n```\r\n\r\nThe C interface provides a few convenient methods for accessing the underlying data buffer:\r\n\r\n```c\r\nvoid rb_io_buffer_get_mutable(VALUE self, void **base, size_t *size);\r\nvoid rb_io_buffer_get_immutable(VALUE self, const void **base, size_t *size);\r\n```\r\n\r\nIn the fiber scheduler, it is used like this:\r\n\r\n```c\r\nVALUE\r\nrb_fiber_scheduler_io_read_memory(VALUE scheduler, VALUE io, void *base, size_t size, size_t length)\r\n{\r\n    VALUE buffer = rb_io_buffer_new(base, size, RB_IO_BUFFER_LOCKED);\r\n\r\n    VALUE result = rb_fiber_scheduler_io_read(scheduler, io, buffer, length);\r\n\r\n    rb_io_buffer_free(buffer);\r\n\r\n    return result;\r\n}\r\n```\r\n\r\nThis function is invoked from `io.c` at various places to fill the buffer. We specifically the `(base, size)` tuple, along with `length` which is the *minimum* length required and assists with efficient non-blocking implementation.\r\n\r\nThe `uring.c` implementation in the event gem uses this interface like so:\r\n\r\n```c\r\nVALUE Event_Backend_URing_io_read(VALUE self, VALUE fiber, VALUE io, VALUE buffer, VALUE _length) {\r\n\tstruct Event_Backend_URing *data = NULL;\r\n\tTypedData_Get_Struct(self, struct Event_Backend_URing, &Event_Backend_URing_Type, data);\r\n\t\r\n\tint descriptor = RB_NUM2INT(rb_funcall(io, id_fileno, 0));\r\n\t\r\n\tvoid *base;\r\n\tsize_t size;\r\n\trb_io_buffer_get_mutable(buffer, &base, &size);\r\n\t\r\n\tsize_t offset = 0;\r\n\tsize_t length = NUM2SIZET(_length);\r\n\t\r\n\twhile (length > 0) {\r\n\t\tsize_t maximum_size = size - offset;\r\n\t\tint result = io_read(data, fiber, descriptor, (char*)base+offset, maximum_size);\r\n\t\t\r\n\t\tif (result == 0) {\r\n\t\t\tbreak;\r\n\t\t} else if (result > 0) {\r\n\t\t\toffset += result;\r\n\t\t\tif ((size_t)result > length) break;\r\n\t\t\tlength -= result;\r\n\t\t} else if (-result == EAGAIN || -result == EWOULDBLOCK) {\r\n\t\t\tEvent_Backend_URing_io_wait(self, fiber, io, RB_INT2NUM(READABLE));\r\n\t\t} else {\r\n\t\t\trb_syserr_fail(-result, strerror(-result));\r\n\t\t}\r\n\t}\r\n\t\r\n\treturn SIZET2NUM(offset);\r\n}\r\n```\r\n\r\n## Buffer Allocation\r\n\r\nThe Linux kernel provides some advanced mechanisms for registering buffers for asynchronous I/O to reduce per-operation overhead.\r\n\r\n> The io_uring_register() system call registers user buffers or files for use in an io_uring(7) instance referenced by fd. Registering files or user buffers allows the kernel to take long term references to internal data structures or create long term mappings of application memory, greatly reducing per-I/O overhead.\r\n\r\nWith appropriate support, we can use `IORING_OP_PROVIDE_BUFFERS` to efficiently manage buffers in applications which are dealing with lots of sockets. See <https://lore.kernel.org/io-uring/20200228203053.25023-1-axboe@kernel.dk/T/> for more details about how it works. I'm still exploring the performance implications of this, but the proposed implementation provides sufficient meta-data for us to explore this in real world schedulers.\r\n\r\nPR: https://github.com/ruby/ruby/pull/4621", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-07-03T07:24:10Z", "updated_on": "2021-11-10T12:23:59Z", "closed_on": "2021-11-10T06:24:05Z", "relations": []}, {"id": 18015, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Replace copy coroutine with pthread implementation.", "description": "The copy coroutine is unique in that it uses a private stack area. It is also tricky to implement as it uses setjmp/longjmp to update the stack & instruction pointer. Because of this, pointers to stack allocated data are only valid while the fiber is running, and this makes implementation tricky for any code which uses stack allocated structs.\r\n\r\nPreviously we introduced some macros for dealing with this - copy coroutines fall back to malloc/free rather than using stack locals, but the chance if this causing problems is very high. In addition, rb_protect prevents us from switching fibers, which also prevents the fiber scheduler from operating within this context.\r\n\r\nWe propose to remove the copy coroutine implementation and replace it with a pthread-based cooperative scheduled implementation. This implementation uses one native thread per fiber, but only allows one of them to execute at a time using a mutex. This approach should be more consistent with the other native implementations and allow us to simplify a number of implementation details.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-30T04:29:19Z", "updated_on": "2021-07-01T03:41:09Z", "closed_on": "2021-07-01T03:41:09Z", "relations": []}, {"id": 18008, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 13491, "name": "hkdnet (Ko Sato)"}, "subject": "`keyword_init?` method for Struct", "description": "I'd like to know whether my struct was initialized with `keyword_init: true` or not.\r\nThis information is useful when writing a deserializer (attached an example below).\r\n\r\n```ruby\r\nS1 = Struct.new(:a, :b, keyword_init: true)\r\nS2 = Struct.new(:a, :b)\r\n\r\n# Specialized for Struct\r\ndef serialize(d)\r\n  d.to_h.merge(__class_name: d.class.name)\r\nend\r\n\r\ndef deserialize(h)\r\n  klass = Object.const_get(h.delete(:__class_name))\r\n  if keyword_init?(klass)\r\n    # If the class is created with keyword_init: true, the parameter should be passed as keywords\r\n    klass.new(**h)\r\n  else\r\n    # Otherwise, each values are passed in the order of members.\r\n    klass.new(*klass.members.map { |sym| h[sym] })\r\n  end\r\nend\r\n\r\ndef keyword_init?(klass)\r\n  # I don't want to do this...\r\n  # klass.keyword_init? looks cool. \r\n  klass.inspect.end_with?('(keyword_init: true)')\r\nend\r\n\r\ns1 = S1.new(a: 1, b: 2)\r\n\r\np s1\r\np s1_ = deserialize(serialize(s1))\r\np s1 == s1_\r\n\r\ns2 = S2.new(1, 2)\r\n\r\np s2\r\np s2_ = deserialize(serialize(s2))\r\np s2 == s2_\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-27T01:56:23Z", "updated_on": "2021-07-15T09:15:14Z", "closed_on": "2021-07-15T09:15:14Z", "relations": []}, {"id": 18005, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Enable non-blocking `binding.irb`.", "description": "This is a multi-faceted issue.\r\n\r\nFirstly, we need to make some library changes, remove `IO.select`, etc from `reline` and so on.\r\n\r\nThen, we need to make `$stdin` non-blocking (maybe by default - was planned).\r\n\r\nFinally, we need to figure out whether we can relax `rb_protect` to allow fiber transfer.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-23T10:28:05Z", "updated_on": "2021-06-24T19:20:47Z", "closed_on": null, "relations": []}, {"id": 18004, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6603, "name": "shan (Shannon Skipper)"}, "subject": "Add Async to the stdlib", "description": "Adding Async to the stdlib would signal a clear concurrency story for Ruby 3 to compliment Ractor-based parallelism. I don't know how ioquatix feels about adding Async to stdlib, but I wanted to propose it since we keep getting questions about concurrent I/O with Ruby 3 in the community.\r\n\r\nRactors get a fair amount of attention on the #ruby IRC channels and Ruby Discord. When Ractors are discussed, question around concurrent I/O in Ruby 3 often follow. Folk don't seem to be aware of Async, so we often cite the Ruby 3 release notes Async Net::HTTP example shown below.\r\n``` ruby\r\nrequire 'async'\r\nrequire 'net/http'\r\nrequire 'uri'\r\n\r\nAsync do\r\n  [\"ruby\", \"rails\", \"async\"].each do |topic|\r\n    Async do\r\n      Net::HTTP.get(URI \"https://www.google.com/search?q=#{topic}\")\r\n    end\r\n  end\r\nend\r\n```\r\nThe main downside I see for this proposal is the bloat from Async's several gem dependencies. For what it's worth, nio4r has been a staple for a long time and is also the only dependency of Puma.\r\n```\r\nAsync is a composable asynchronous I/O framework for Ruby based on nio4r and timers.\r\n```\r\nAsync is just so useful it would be awesome to add to the stdlib. It fills and important gap for concurrent I/O with Ruby 3 and would be exciting to see included in a future release.\r\n\r\nSee https://github.com/socketry/async#readme", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-22T18:29:26Z", "updated_on": "2021-11-26T06:01:21Z", "closed_on": null, "relations": []}, {"id": 17994, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Clarify `IO.read` behavior and add `File.read` method", "description": "`IO.read` creates a subprocess when a given file name starts with a `|` character.\r\n\r\n```\r\nirb(main):001:0> IO.read(\"| ls /etc/passwd\")\r\n=> \"/etc/passwd\\n\"\r\n```\r\n\r\nTo disable this feature, `File.read` can be used.\r\n\r\n```\r\nirb(main):002:0> File.read(\"| ls /etc/passwd\")\r\n(irb):2:in `read': No such file or directory @ rb_sysopen - | ls /etc/passwd (Errno::ENOENT)\r\n```\r\n\r\nSo, as far as I know, `File.read` is more prefereable to `IO.read` if a user want to just read a file.\r\n\r\nHowever, in terms of the implementation, there is no definition of `File.read`. `File.read` invokes `IO.read` because `IO` is a superclass of `File`, and `IO.read` creates a subprocess only when its receiver is exactly the `IO` class.\r\n\r\nI think there are two problems in the current situation:\r\n\r\n1. The rdoc of `IO.read` does not explain the behavior to disable a subprocess invocation.\r\n2. The rdoc does not have an entry for `File.read`.\r\n\r\nI've created a PR to address the two issues by clarifying `IO.read` behavior and defining `File.read` as an alias to `IO.read`.\r\n\r\nhttps://github.com/ruby/ruby/pull/4579", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-17T03:01:48Z", "updated_on": "2021-07-16T03:04:55Z", "closed_on": null, "relations": []}, {"id": 17992, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51722, "name": "AMomchilov (Alexander Momchilov)"}, "subject": "Upstreaming the htmlentities gem into CGI#.(un)escape_html", "description": "Hi there,\r\n\r\nI was looking to unescape some HTML entities in a String, and I discovered that `CGI#.(un)escape_html` is **really** limited. Many StackOverflow questions share a similar disappointment, and point users to using the [htmlentities gem](https://github.com/threedaymonk/htmlentities):\r\n\r\n1. https://stackoverflow.com/a/383561/3141234\r\n2. https://stackoverflow.com/a/22926384/3141234\r\n\r\nThis solved my problem, but I feel like something this standard/universal should be built-in. To that end, I'm interested in working on merging the htmlentities gem into CGI's repo. Would this be a welcome change?\r\n\r\n* I've e-mailed the author (Paul Battley) privately, and got his blessing to do so.\r\n* It's MIT licensed, so that should be OK.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-15T20:17:23Z", "updated_on": "2021-06-30T14:26:45Z", "closed_on": "2021-06-15T20:50:32Z", "relations": []}, {"id": 17950, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10442, "name": "chucke (Tiago Cardoso)"}, "subject": "Unable to pattern-match against a String key", "description": "I'm unable to parse against an internal hash, when the internal hash contains strings as keys:\r\n\r\n```ruby\r\ncase {status: 200, headers: {\"content-type\" => \"application/json\"}, body: \"bla\"}\r\nin { status: , headers: {\"content-type\" => type}, body: }\r\n# syntax error, unexpected terminator, expecting literal content or tSTRING_DBEG or tSTRING_DVAR or tLABEL_END\r\n# ...tus: , headers: {\"content-type\" => type}, body: }\r\n```\r\n\r\nhowever, this works:\r\n\r\n```ruby\r\nh = {\"content-type\" => \"application/json\"}\r\ncase {status: 200, headers: {\"content-type\" => \"application/json\"}, body: \"bla\"}\r\nin { status: , headers: ^h, body: }\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-12T15:36:53Z", "updated_on": "2021-06-15T11:42:31Z", "closed_on": null, "relations": []}, {"id": 17944, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10968, "name": "pvalena (Pavel Valena)"}, "subject": "Remove Socket.gethostbyaddr and Socket.gethostbyname", "description": "It is marked as unsafe by our static analysis. Can it be removed now?\r\n\r\nIt was deprecated in:\r\n  https://bugs.ruby-lang.org/projects/ruby-master/repository/trunk/revisions/60266\r\n  https://bugs.ruby-lang.org/issues/13097", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-10T08:26:29Z", "updated_on": "2021-06-10T08:26:29Z", "closed_on": null, "relations": []}, {"id": 17942, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 125, "name": "TylerRick (Tyler Rick)"}, "subject": "Add a `initialize(public @a, private @b)` shortcut syntax for defining public/private accessors for instance vars as part of constructor", "description": "This proposal builds on the proposed `initialize(@a, @b)` instance var assignment shortcut syntax described in #15192.\r\n\r\n1. It allows you to add an *optional* `public`/`protected`/`private` modifier before any instance var parameter. Doing so automatically defines *accessor methods* (with the given access modifier; equivalent to `attr_accessor` inside of a  `public`/`protected`/`private` block) for the instance var it precedes.\r\n2. If the visibility modifier is omitted, then it defaults to automatically _no_ getter/setter methods for that instance var (it _only_ does an assignment of that already-private instance var).\r\n\r\n## Parameter properties in TypeScript language\r\n\r\nThis is inspired by TypeScript's `constructor(public a, private b)` syntax, which allows you to write this ([REPL](https://www.typescriptlang.org/play?#code/MYGwhgzhAEBiD29oG8BQ0PWPAdhALgE4Cuw+8hAFAA7EBGIAlsNGAFw7EC2dApoQBpotBs2h0O3PoOGFGANzD5eWST34BKFOkwBfVPqA)):\r\n```js\r\nclass Foo {\r\n    constructor(public a:number, public b:number, private c:number) {\r\n    }\r\n}\r\n```\r\ninstead of this:\r\n```js\r\nclass Foo {\r\n    constructor(a, b, c) {\r\n        this.a = a;\r\n        this.b = b;\r\n        this.c = c;\r\n    }\r\n}\r\n```\r\n\r\n(The `public`/`private` access modifiers actually disappear in the transpiled JavaScript code because it's only the TypeScript compiler that enforces those access modifiers, and it does so at *compile* time rather than at run time.)\r\n\r\nFurther reading:\r\n- https://www.typescriptlang.org/docs/handbook/2/classes.html#parameter-properties\r\n- https://basarat.gitbook.io/typescript/future-javascript/classes#define-using-constructor\r\n- https://kendaleiv.com/typescript-constructor-assignment-public-and-private-keywords/\r\n\r\n\r\n## Differences from TypeScript\r\n\r\nI propose adding a similar feature to Ruby, but with following differences from TypeScript:\r\n\r\n1. Use **`@a`** instead of bare `a`. This makes it *much* clearer that you are assigning directly to instance variables instead of to locals.\r\n    - Rationale: The `@` is actually _part_ of the instance variable name, and is inseparable from it. (This is also consistent with how the `#` is part of the name itself in JavaScript's [(Private instance fields)](https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Classes/Private_class_fields#private_instance_fields).)\r\n    - (`public a` would be a syntax error because there's no such thing as access modifiers for locals. Okay, I guess there's no such thing as access modifiers for instance vars either, which is why...)\r\n\r\n1. Make the syntax for ***assigning*** to instance vars (`@a`) (the proposal in #15192) and defining ***accessor methods*** for those instance vars (`public`/`private`) separate/distinct.\r\n    - In other words, rather than make the `public`/`private` keywords a *required* part of the syntax like it is for TypeScript [parameter properties](https://www.typescriptlang.org/docs/handbook/2/classes.html#parameter-properties), you could omit the modifier and it would still do the instance var _assignment*.\r\n    - The `public`/`private` access modifiers be an additional (*optional*) shortcut when you want to add an ***accessor method*** in *addition* to doing an ***assignment*** .\r\n    - Unlike Java and TypeScript where you _can_ add access modifiers to instance variables, in Ruby, `public`/`private` _can't_ be applied to instance variables (direct access is only possible from within the instance). So if we're going to allow a `public`/`private` modifier here at all, They _must_ refer to methods, specifically accessor methods for those instance variables.\r\n\r\n1. Keep it **private** by default (which of course `@a` by itself implies\u2014it _is_ private unless you add a public accessor).\r\n    - (Rather than make it `public` by default like it is in TypeScript.)\r\n    - Keeping instance variables completely private is probably what people will want most of the time, and we should optimize the ergonomics for the most common case.\r\n    - Private is a safer default, and should be assumed unless you explicitly ask for a public accessor to be added.\r\n    - I bet TypeScript made the `public` the default mostly to be consistent with JavaScript (which TypeScript compiles to): JavaScript (along with other languages like Java) allows direct access (no getter/setter neede) to instance properties/variables from objects outside the instance. JavaScript doesn't even _have_ a way to make instance variables private (but hopefully will soon with this [proposal](https://github.com/tc39/proposal-private-methods) to add `#a` syntax for private properties).\r\n\r\nSo this:\r\n\r\n```ruby\r\nclass Thing\r\n  def initialize(public @a, public @b, @c)\r\n  end\r\nend\r\n```\r\n\r\nwould be equivalent to this:\r\n\r\n```ruby\r\nclass Thing\r\n  attr_accessor :a, :b\r\n\r\n  def initialize(a, b, c)\r\n    @a = a\r\n    @b = b\r\n    @c = c\r\n  end\r\n```\r\n\r\n## How is `initialize(private @a)` different from `initialize(@a)`?\r\n\r\nEven though `@a` by itself is already private...\r\n1. This defines a private accessor for that instance var, which lets you write `self.a =` instead of `@a =` (if you want).\r\n2. Having a concise way to do that is helpful, for example if you want to make it a matter of practice/policy to only set an instance variable by going through its *setter method*. (See [discussion here](https://stackoverflow.com/questions/25571642/ruby-private-and-public-accessors).)\r\n\r\n\r\nWhy not just use `initialize(private @a)` to be consistent with TypeScript spec?\r\n- TypeScript's `public`/`private` is not standard JavaScript. In fact, if the [private methods/fields proposal](https://github.com/tc39/proposal-private-methods) had existed when TypeScript added [parameter properties](https://www.typescriptlang.org/docs/handbook/2/classes.html#parameter-properties), I'd like to think that they might have actually *made use* of the new `#b` syntax and gone with a terser syntax like `constructor(public a, #b)` instead of ``constructor(public a, private b)`.\r\n\r\n\r\n## Upsides of this proposal\r\n\r\n1. Removes even more boilerplate (all those `attr_accessor` lines), much of the time\r\n\r\n## Downsides of this proposal\r\n\r\n1. Only provides a way to define both getter and setter at once. Doesn't provide a way to _just_ define a getter and not a setter, for example.\r\n    - Doesn't seem like a big deal, however. You can just not use this feature and define the getter with `attr_reader :a` instead. Or define private getter/setter with `private @a` and then override with `attr_reader :a` to add a public getter (while keeping the private setter).\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-09T04:55:04Z", "updated_on": "2021-12-13T00:43:18Z", "closed_on": null, "relations": [{"id": 2977, "issue_id": 5825, "issue_to_id": 17942, "relation_type": "relates", "delay": null}]}, {"id": 17938, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 49162, "name": "matheusrich (Matheus Richard)"}, "subject": "Keyword alternative for boolean positional arguments", "description": "Some Ruby methods accept optional boolean arguments. This kind of parameter is known to be confusing since you cannot tell just looking at the method call what the parameter mean. For example:\r\n\r\n```ruby\r\nobject.respond_to?(:symbol, false) # what does `false` mean?\r\nobject.methods(true) # what does `true` mean?\r\n```\r\n\r\nNow compare that to\r\n\r\n```ruby\r\nobject.respond_to?(:symbol, include_all: false)\r\nobject.methods(regular: true)\r\n# or\r\nobject.methods(only_public: true)\r\n# or\r\nobject.methods(include_all: false)\r\n```\r\n\r\nI know Matz doesn't like breaking changes, so maybe we could have both to not break current calls, but allow a nicer syntax in newer Ruby? I don't know the depths of the Ruby C implementation, so here's what I thought in plain Ruby:\r\n\r\n```ruby\r\ndef respond_to?(symbol, include_all_positional=false, include_all: nil)\r\n  include_all ||= include_all_positional\r\n\r\n  # ...\r\nend\r\n```\r\n\r\nI'm willing to tackle this, if approved.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-06-04T19:00:01Z", "updated_on": "2021-07-15T06:46:33Z", "closed_on": null, "relations": []}, {"id": 17930, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Add column information into error backtrace", "description": "Consider the following code and error.\r\n\r\n```\r\ndata[\"data\"].first[\"field\"] #=> undefined method `[]` for nil:NilClass\r\n```\r\n\r\nThere are two possibilities; the variable `data` is nil, or the return value of `first` is nil. Unfortunately, the error message is less informative to say which.\r\n\r\nThis proposal allows to help identifying which method call failed.\r\n\r\n```\r\n$ ruby -r ./sample/no_method_error_ext.rb err1.rb\r\nerr1.rb:2:in `<main>': undefined method `[]' for nil:NilClass (NoMethodError)\r\n\r\ndata[\"data\"].first[\"field\"]\r\n                  ^^^^^^^^^\r\n```\r\n\r\n## Proposal\r\n\r\nI'd like to propose a feature to get column information from each `Thread::BacktraceLocation`. Maybe it is good to provide the following four methods:\r\n\r\n* `Thread::BacktraceLocation#first_lineno`\r\n* `Thread::BacktraceLocation#first_column`\r\n* `Thread::BacktraceLocation#last_lineno`\r\n* `Thread::BacktraceLocation#last_column`\r\n\r\nThese names came from `RubyVM::AbstraceSyntaxTree::Node`'s methods.\r\n\r\n## Implementation\r\n\r\nHere is a proof-of-concept implementation: https://github.com/ruby/ruby/pull/4540\r\n\r\nSee https://github.com/ruby/ruby/pull/4540/commits/6ff516f4985826e9f9c5606638001c3c420f7cad for an example usage.\r\n(Note that, currently, you need to build ruby with `./configure cflags=-DEXPERIMENTAL_ISEQ_NODE_ID` to enable the feature.)\r\n\r\nTo put it simply, this PR provides only a raw API, `Thread::BacktraceLocation#node_id`. To get actual column information, you need to manually identify `RubyVM::AbstractSyntaxTree::Node` that corresponds to `Thread::BacktraceLocation#node_id`.\r\nBut it would be arguable to expose \"node_id\", so I will wrap it as the above four methods if this is accepted.\r\n\r\nCredit: the original implementation was done by @yui-knk.\r\n\r\n## Drawback\r\n\r\nTo use this feature, we need to enable `-DEXPERIMENTAL_ISEQ_NODE_ID` to add \"node_id\" information (a subtree ID of the original abstract syntax tree) into each byte code instruction. If we provide this feature, the option should be enabled by default. However, the option increases memory consumption.\r\n\r\nI performed a simple experiment: I created a scaffold app by `rails new`, and measured the memory usage after `rails s`. The result was 97 MB without `-DEXPERIMENTAL_ISEQ_NODE_ID`, and 100 MB with the option enabled.\r\n\r\nIn my opinion, it is not so large, but requiring more gems will increase the difference. I will appriciate it if anyone could provide the actual memory increase in a more practical Rails app.\r\n\r\nDo you think this feature deserves the memory increase?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-31T09:30:24Z", "updated_on": "2021-07-05T10:02:14Z", "closed_on": "2021-06-29T15:07:30Z", "relations": [{"id": 3349, "issue_id": 17930, "issue_to_id": 18231, "relation_type": "relates", "delay": null}, {"id": 2978, "issue_id": 17930, "issue_to_id": 10982, "relation_type": "duplicates", "delay": null}]}, {"id": 17924, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 16080, "name": "c4am95 (Travis Hunter)"}, "subject": "Range#infinite?", "description": "A boolean method on Range returning true if the range is infinite and false if it is not.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-28T14:46:20Z", "updated_on": "2021-07-08T23:58:20Z", "closed_on": null, "relations": []}], [{"id": 17884, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "locindex for profiling tools", "description": "(MRI internals)\r\n\r\nProfiling tools need to record the code location, mainly a pair of file path and line number (\"file:line\").\r\nTo record this pair in 64bit CPU, 8B (VALUE) + 4B (int) = 12B is needed. In general, the number of pairs (file:line) in a interpreter process does not exceed 32bit boundary (4G pairs). `st_data_t` is 8B (or 4B on 32bit CPU) and we can not store \"file:path\" information as `st_table` key/value.\r\n\r\nAlso getting a line from PC (program counter), is not simple (now we are using succinct bitvector, enough fast and compact data in general, but need some calculations).\r\n\r\nTo solve the size and the time problem, we introduced new concept \"locindex\".\r\n\r\n\"locindex\" is `unsigned int` data structure, maybe 4B in many environments. A \"locindex\" represents a pair of \"iseq\" and \"PC\" (more correctly, \"pc_index\", given by `PC - iseq->body->iseq_encoded`).\r\n\r\nWe can get \"locindexL\" from \"iseqA\" with \"pcB\". \"iseqA\" will not be freed in this process.\r\nFrom \"locindexL\", we can get \"iseqA\" and \"pcB\". We can calculate \"file:line\" information from the iseq/pc pair. \"file:line\" information is needed to see the profiling results, so the performance of getting \"file:line\" from a \"iseq/pc\" pair is not important, in many cases.\r\n\r\n\"locindex\" is calculated by the following pseudo code:\r\n\r\n```ruby\r\n$last_locindex = 1\r\n$global_recorded_ary = []\r\n\r\ndef locindex iseq, pc # pc is pc_index (nth instruction)\r\n  if iseq->locindex_start == 0 # not recorded yet\r\n    iseq->locindex_start = last_locindex\r\n    $last_locindex += iseq->iseq_size\r\n    $global_recorded_ary.push(iseq)\r\n  end\r\n  iseq->locindex_start + pc\r\nend\r\n\r\ndef resolve locindex\r\n  $global_recorded_ary.each{|iseq|\r\n    if locindex is in iseq?\r\n      return [iseq, locindx - iseq->locindex_start]\r\n    end\r\n  }\r\nend\r\n```\r\n\r\n----\r\n\r\n`ObjectSpace.trace_object_allocations` is one of profiling tool and we can use \"locindex\" to make it.\r\nI implemented and measure the performance.\r\n\r\nThe benchmark program:\r\n\r\n```ruby\r\n# This file should be located to the ruby's src directory\r\n\r\nrequire 'objspace/trace'\r\nrequire 'rdoc/rdoc'\r\nrequire 'tmpdir'\r\n\r\nsrcdir = File.expand_path(__dir__)\r\nSTDERR.puts srcdir\r\n\r\nDir.mktmpdir('rdocbench-'){|d|\r\n  dir = File.join(d, 'rdocbench')\r\n  args = %W(--root #{srcdir} --page-dir #{srcdir}/doc --encoding=UTF-8 --no-force-update --all --ri --debug --quiet #{srcdir})\r\n  args << '--op' << dir\r\n\r\n  r = RDoc::RDoc.new\r\n  r.document args\r\n}\r\n```\r\n\r\nResults:\r\n\r\n```\r\n# without 'objspace/trace'\r\nreal    0m19.764s\r\nuser    0m19.200s\r\nsys     0m0.561s\r\n\r\n# with 'objspace/trace'\r\nreal    0m42.638s\r\nuser    0m41.695s\r\nsys     0m0.920s\r\n\r\n# with 'objspace/trace' and locindex\r\nreal    0m36.875s\r\nuser    0m35.956s\r\nsys     0m0.890s\r\n\r\n# with 'objspace/trace' light mode\r\nreal    0m27.743s\r\nuser    0m26.921s\r\nsys     0m0.820s\r\n```\r\n\r\nLight mode is only recording \"locindex\".\r\nI believe that most of case it is enough to see the \"file:line\" pair for performance tuning.\r\n\r\nImplementation: https://github.com/ruby/ruby/pull/4524/\r\n\"light-mode\" seems more practical.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-24T15:41:17Z", "updated_on": "2021-05-24T16:17:35Z", "closed_on": null, "relations": []}, {"id": 17883, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Load bundler/setup earlier to make `bundle exec ruby -r` respect Gemfile", "description": "To reproduce the issue, prepare a Gemfile and run `bundle install --path=vendor/bundle`.\r\n\r\n```\r\n$ cat Gemfile\r\nsource \"https://rubygems.org\"\r\ngem \"activesupport\"\r\n\r\n$ bundle install --path=vendor/bundle\r\n```\r\n\r\n`Kernel#require` respects the Gemfile correctly.\r\n\r\n```\r\n$ bundle exec ruby -e 'require \"active_support\"'\r\n```\r\n\r\nHowever, `bundle exec ruby -ractive_support -e ''` does not.\r\n\r\n```\r\n$ bundle exec ruby -ractive_support -e ''\r\n<internal:/home/mame/work/ruby/local/lib/ruby/3.1.0/rubygems/core_ext/kernel_require.rb>:85:in `require': cannot load such file -- active_support (LoadError)\r\n        from <internal:/home/mame/work/ruby/local/lib/ruby/3.1.0/rubygems/core_ext/kernel_require.rb>:85:in `require'\r\n```\r\n\r\nWe can work around the issue by explicitly passing `-rbundler/setup` before `-ractive_support`, but this is very confusing to me. The same issue was discussed in StackOverflow: https://stackoverflow.com/questions/59623068/correct-way-to-combine-bundle-exec-and-ruby-r\r\n\r\n---\r\n\r\nHere is my analysis. `bundle exec` sets `RUBYOPT=-rbundler/setup` which replaces `Kernel#require` with bundler's own definition. `-e 'require \"active_support\"'` correctly triggers bundler's definition. However, `-ractive_support` is evaluated before `RUBYOPT=-rbundler/setup` is evaluated, so it triggers rubygems' require definition which does not know `vendor/bundle` directory.\r\n\r\nThis is caused by the interpretation order of `RUBYOPT` and command-line arguments.\r\n\r\n```\r\n$ RUBYOPT=-r./a ruby -r./b -e ''\r\n:b\r\n:a\r\n```\r\n\r\nFor compatibility, I don't think that changing the order is a good idea. IMO, it would be good for ruby interpreter to provide Bundler something special, because Bundler is now bundled with Ruby.\r\n\r\nMy naive idea is to make the interpreter load `ENV[\"BUNDLE_BIN_PATH\"] + \"../../lib/bundler/setup\"` before any other `-r` options if `BUNDLE_BIN_PATH` is defined. Or another new dedicated environment variable that `bundle exec` sets may work (for example, `RUBY_BUNDLER_SETUP` or something).\r\n\r\n@deivid @nobu What do you think?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-24T08:35:34Z", "updated_on": "2021-05-25T19:13:27Z", "closed_on": "2021-05-25T16:20:55Z", "relations": []}, {"id": 17881, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "assigned_to": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Add a Module#const_added callback", "description": "### Use case\r\n\r\nAutoloaders like `zeitwerk` need a callback when a new class or module is registered in the constant table.\r\n\r\nCurrently this is implemented with TracePoint's `:class` event. It works, but it is a bit unfortunate to have to use an API intended for debugging to implement production features. It doesn't feel \"conceptually clean\". \r\n\r\nIt also [doesn't play well with MJIT](https://k0kubun.medium.com/ruby-3-jit-can-make-rails-faster-756310f235a), even though it's more of an MJIT limitation.\r\n\r\nAdditionally this usage of TracePoint cause [some incompatibilities with some debuggers like `byebug`](https://github.com/deivid-rodriguez/byebug/issues/564) (even though others don't have this issue). \r\n\r\n### Proposal\r\n\r\nI believe that if Ruby was to call `Module#const_added` when a constant is registered, Zeitwerk could get rid of TracePoint.\r\n\r\nFor now I implemented it as: `const_added(const_name)` for similarity with `method_added`. But maybe it could make sense to have the signature be `const_added(const_name, const_value)`.\r\n\r\nAlso since `method_removed` exists, maybe `const_removed` would need to be added for consistency.\r\n\r\n### Links\r\n\r\nPatch: https://github.com/ruby/ruby/pull/4521\r\nZeitwerk side discussion: https://github.com/fxn/zeitwerk/issues/135\r\n\r\ncc @k0kubun", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-22T11:43:26Z", "updated_on": "2022-01-14T10:30:58Z", "closed_on": "2022-01-14T10:30:58Z", "relations": []}, {"id": 17873, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "subject": "Update of default gems in Ruby 3.1", "description": "I promoted many standard libraries to the default gems. You can see them at https://stdgems.org/#default-gems-ruby-301\r\n\r\nI propose the following libraries to promote the bundled gems from the default gems.\r\n\r\n```\r\nmatrix\r\nprime\r\nnet/ftp\r\nnet/smtp\r\nnet/pop\r\nnet/imap\r\n```\r\n\r\nThey have primary maintainer in the canonical repository in github. So, they can release the new version with their convenience. \r\n\r\n@shugo @marcandre Any thought?\r\n\r\nAnd I also propose to extract the following libraries from the default gems.\r\n\r\n```\r\ntracer\r\ndbm\r\ngdbm\r\n```\r\n\r\nThey are no longer actively maintained and not widely used today.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-20T10:45:25Z", "updated_on": "2022-02-01T14:19:59Z", "closed_on": "2021-12-27T05:42:54Z", "relations": []}, {"id": 17863, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "rewrite lib/debug.rb with latest API", "description": "I rewrite lib/debug.rb (called old debug.rb) with recent TracePoint APIs (called new debug.rb).\r\n\r\nIt has several incompatibility but maybe nobody uses lib/debug.rb so there is no compatible issues. In fact I tried several features of lib/debug.rb and it doesn't work nowaday.\r\n\r\nYou can see the doc on https://github.com/ruby/debug\r\n\r\nCompare with existing other debuggers, it has several advantages:\r\n\r\n* Fast: No performance penalty on non-stepping mode and non-breakpoints.\r\n* Remote debugging: Support remote debugging natively.\r\n  * UNIX domain socket\r\n  * TCP/IP\r\n  * VSCode/DAP integration (TODO)\r\n* Extensible: application can introduce debugging support with several methods\r\n  * By `rdbg` command\r\n  * By loading libraries with `-r` command line option\r\n  * By calling Ruby's method explicitly\r\n* Misc\r\n  * Support threads (almost done) and ractors (TODO).\r\n  * Support suspending and entering to the console debugging with `Ctrl-C` at most of timing.\r\n  * Show parameters on backtrace command.\r\n\r\nAnd do not need to write it on Gemfile because it will be a default gem from Ruby 3.1.\r\n\r\nImportant differences:\r\n\r\n* `require 'debug'` is only a way to enable old debug.rb, but new debug.rb can be enabled with:\r\n  * require\r\n  * `rdbg` command (like bybug)\r\n  * `binding.bp` method like `binding.irb`\r\n* Support remote debugging\r\n* Support several options like non-stop mode and so on\r\n* old debug.rb evaluate unrecognized command as Ruby script, but new debug.rb doesn't allow this spec.\r\n  * `obj.foo` will be evaluated as Ruby script on old debug.rb (and byebug)\r\n  * new debug.rb shows `unknown command` because it is typo safe and extension safe.\r\n  * To see the result, you need to use `p` command like `p obj.foo`.\r\n\r\nNow you can try on 2.6-master with `gem install debug --pre`.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-14T05:42:07Z", "updated_on": "2021-11-24T05:06:20Z", "closed_on": "2021-11-24T05:06:20Z", "relations": []}, {"id": 17859, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7174, "name": "deivid (David Rodr\u00edguez)"}, "subject": "Start IRB when running just `ruby`", "description": "Compare python:\r\n\r\n```\r\n$ python\r\nPython 3.8.3 (default, Jul  8 2020, 16:49:12) \r\n[GCC 7.5.0] on linux\r\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\r\n>>> \r\n```\r\n\r\nTo ruby:\r\n\r\n```\r\n$ ruby\r\n# just hangs\r\n```\r\n\r\nI think firing up a console it's a good default behaviour for beginners.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-12T16:33:10Z", "updated_on": "2021-05-14T07:54:19Z", "closed_on": null, "relations": []}, {"id": 17856, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "ary.member? is slower than ary.include?", "description": "`Array#include?` is defined as a faster version of `Enumerable#include?`, but there is no `Array#member?` defined.\r\n\r\n```\r\n$ time ruby -e 'a = (0..100000).to_a; 1000.times { a.member?(100000) }'\r\n\r\nreal    0m1.722s\r\nuser    0m1.721s\r\nsys     0m0.000s\r\n\r\n$ time ruby -e 'a = (0..100000).to_a; 1000.times { a.include?(100000) }'\r\n\r\nreal    0m0.524s\r\nuser    0m0.523s\r\nsys     0m0.000s\r\n```\r\n\r\nI guess this is not intentional. I'll fix this issue unless there is any objection.\r\n\r\n```diff\r\ndiff --git a/array.c b/array.c\r\nindex 881270b915..92ea9d8059 100644\r\n--- a/array.c\r\n+++ b/array.c\r\n@@ -8402,6 +8402,7 @@ Init_Array(void)\r\n     rb_define_method(rb_cArray, \"clear\", rb_ary_clear, 0);\r\n     rb_define_method(rb_cArray, \"fill\", rb_ary_fill, -1);\r\n     rb_define_method(rb_cArray, \"include?\", rb_ary_includes, 1);\r\n+    rb_define_method(rb_cArray, \"member?\", rb_ary_includes, 1);\r\n     rb_define_method(rb_cArray, \"<=>\", rb_ary_cmp, 1);\r\n\r\n     rb_define_method(rb_cArray, \"slice\", rb_ary_aref, -1);\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-11T10:12:14Z", "updated_on": "2021-05-11T10:12:14Z", "closed_on": null, "relations": []}, {"id": 17853, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51594, "name": "komamitsu (Mitsunori Komatsu)"}, "subject": "Add Thread#thread_id", "description": "# Abstract\r\n\r\nNew method `Thread#thread_id` to get associated native thread id (LWP.) It might return `nil` if OS doesn't support thread id or equivalent.\r\n\r\n# Background\r\n\r\nWhen I tried to investigate which Ruby thread of an application is busy, I did the following steps\r\n- checked the CPU usage of the Ruby application's threads using `ps -eLf` or `top` (with H key) and got which thread is busy\r\n- dumped all the threads of the application using https://github.com/frsyuki/sigdump\r\n- tried to find a busy thread in the thread dump result, but the thread dump doesn't contain thread id...\r\n\r\n`Thread` class itself has no method to get associated thread id. If the class has `#thread_id` or something, I can create a PR on `sigdump` project to add `thread id` in thread dump output to make investigations with thread dump much easier.\r\n\r\n`Thread#name` may seem an alternative to `Thread#thread_id`, but `Thread#name` just returns a value that's set through `Thread#name=` while `Thread#thread_id` returns a thread id that OS or something has assigned.\r\n\r\nIn case of Java, thread dump created by `jcmd ${pid} Thread.print` contains `nid` field which is an associated native thread id\r\n```\r\n\"http-bio-80-exec-77\" daemon prio=6 tid=0x0000000026f29000 nid=0xbd0 runnable [0x0000000020c7f000]\r\n   java.lang.Thread.State: RUNNABLE\r\n    at java.net.SocketInputStream.socketRead0(Native Method)\r\n    at java.net.SocketInputStream.read(Unknown Source)\r\n    at java.net.SocketInputStream.read(Unknown Source)\r\n    at org.apache.coyote.http11.InternalInputBuffer.fill(InternalInputBuffer.java:516)\r\n    at org.apache.coyote.http11.InternalInputBuffer.fill(InternalInputBuffer.java:501)\r\n    at org.apache.coyote.http11.Http11Processor.setRequestLineReadTimeout(Http11Processor.java:167)\r\n    at org.apache.coyote.http11.AbstractHttp11Processor.process(AbstractHttp11Processor.java:946)\r\n    at org.apache.coyote.AbstractProtocol$AbstractConnectionHandler.process(AbstractProtocol.java:607)\r\n    at org.apache.tomcat.util.net.JIoEndpoint$SocketProcessor.run(JIoEndpoint.java:315)\r\n    - locked <0x00000007b16e3e88> (a org.apache.tomcat.util.net.SocketWrapper)\r\n    at java.util.concurrent.ThreadPoolExecutor.runWorker(Unknown Source)\r\n    at java.util.concurrent.ThreadPoolExecutor$Worker.run(Unknown Source)\r\n    at java.lang.Thread.run(Unknown Source)\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-06T08:19:30Z", "updated_on": "2021-06-07T10:09:10Z", "closed_on": "2021-05-26T06:15:03Z", "relations": [{"id": 2935, "issue_id": 11251, "issue_to_id": 17853, "relation_type": "relates", "delay": null}]}, {"id": 17851, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "ruby extension for memoryview", "description": "add an extension to ruby for memoryview - (just like Fiddle::MemoryView but in ruby assuming Fiddle::MemoryView gets slices)\r\nadd a method in Kernel to get initialize a memoryview on an object that is a c memoryview\r\n\r\nlets say we want to partially copy a file - minus the first KB\r\n\r\n``` ruby\r\nf = File.open('test.txt', 'rb') do |f|\r\n  content = f.read\r\n  content_to_write = memoryview(content)[1024..-1]   # here is what I want new -it will use the same memory as content just pointers\r\n  puts \"content length #{content.size} - content_to_write length #{content_to_write.size}\"\r\n  File.open('output.txt','wb') do |f2|\r\n     f2.write(content_to_write)                      # if we have #17832 this will write to file without copying \r\n  end\r\nend\r\n```\r\n\r\nIf we have memoryview extension in ruby we can use less memory because we are no longer copying Strings when doing slices\r\n#17831 \r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-05T13:57:32Z", "updated_on": "2021-05-05T15:15:30Z", "closed_on": null, "relations": [{"id": 2933, "issue_id": 17831, "issue_to_id": 17851, "relation_type": "relates", "delay": null}]}, {"id": 17849, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Fix Timeout.timeout so that it can be used in threaded Web servers", "description": "Making this a separate issue from #17837\r\n\r\nEregon (Benoit Daloze) wrote in https://bugs.ruby-lang.org/issues/17837#note-10 (which is  about timeouts for regular expressions):\r\n\r\n> I think fixing Timeout.timeout might be possible.\r\n> The main/major issue is it can trigger within `ensure`, right? Is there anything else?\r\n> We could automatically mask `Thread#raise` within `ensure` so it only happens after the `ensure` body completes.\r\n> And we could still have a larger \"hard timeout\" if an `ensure` takes way too long (shouldn't happen, but one cannot be sure).\r\n> I recall discussing this with @schneems some time ago on Twitter.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-05T01:41:09Z", "updated_on": "2022-04-10T06:26:54Z", "closed_on": null, "relations": [{"id": 2931, "issue_id": 17837, "issue_to_id": 17849, "relation_type": "relates", "delay": null}, {"id": 2937, "issue_id": 17363, "issue_to_id": 17849, "relation_type": "relates", "delay": null}, {"id": 2941, "issue_id": 13876, "issue_to_id": 17849, "relation_type": "relates", "delay": null}]}, {"id": 17848, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "inline rbs either by rdoc comments or changing syntax", "description": "I like gradual typing - I like the syntax of rbs files but for coding - convenience it would be nice if we had inline syntax for types. \r\nI know that steep allows you to define types inline but because it is valid ruby syntax - the code is not as nice as rbs\r\n\r\ncould we change method arguments syntax to allow rbs type \r\n\r\ndef initialize(from: User | Bot = User.new, string: String = \"I got your message\")  -> void #  I know this has to be fleshed  out to handle all cases (positional , keyword, default but there should be some way we can do it inline)\r\n\r\nEither that or bless (recommend) yard style annotations so it is inline and still has easy syntax\r\n\r\n class Message\r\n    attr_reader id: String\r\n    attr_reader string: String\r\n    attr_reader from: User | Bot                     # `|` means union types: `#from` can be `User` or `Bot`\r\n    attr_reader reply_to: Message?                   # `?` means optional type: `#reply_to` can be `nil`\r\n\r\n    def initialize: (from: User | Bot, string: String) -> void\r\n\r\n    def reply: (from: User | Bot, string: String) -> Message\r\n  end", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-04T16:29:02Z", "updated_on": "2021-12-13T01:39:38Z", "closed_on": "2021-05-05T13:58:32Z", "relations": []}, {"id": 17847, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 89, "name": "gotoken (Kentaro Goto)"}, "assigned_to": {"id": 89, "name": "gotoken (Kentaro Goto)"}, "subject": "`ruby -run -e httpd` displays URL", "description": "The current version of un.rb `httpd` shows port number only:\r\n\r\n```\r\n$ ruby -run -e httpd\r\n[2021-05-03 21:55:09] INFO  WEBrick 1.7.0\r\n[2021-05-03 21:55:09] INFO  ruby 3.1.0 (2021-05-03) [x86_64-linux]\r\n[2021-05-03 21:55:09] INFO  WEBrick::HTTPServer#start: pid=32129 port=8080\r\n```\r\n\r\nTo access this server, we have to type `http://127.0.0.1:8080` in the address bar of browser. \r\n\r\nThis feature request appends URLs as follows:\r\n\r\n```\r\n[2021-05-03 21:55:15] INFO  WEBrick 1.7.0\r\n[2021-05-03 21:55:15] INFO  ruby 3.1.0 (2021-05-03) [x86_64-linux]\r\n[2021-05-03 21:55:15] INFO  WEBrick::HTTPServer#start: pid=32182 port=8080\r\n[2021-05-03 21:55:15] INFO  To access this server, open this file in a browser:\r\n[2021-05-03 21:55:15] INFO      http://127.0.0.1:8080\r\n[2021-05-03 21:55:15] INFO      http://[::1]:8080\r\n```\r\n\r\nThis is often useful. Some terminals also make URLs clickable. \r\n\r\nPull request: https://github.com/ruby/ruby/pull/4415", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-03T12:56:06Z", "updated_on": "2021-08-23T01:59:22Z", "closed_on": "2021-08-23T01:59:22Z", "relations": []}, {"id": 17845, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11129, "name": "MSP-Greg (Greg L)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Windows Ruby - ucrt build?", "description": "Currently, Windows Ruby is normally compiled two ways.\r\n\r\nThe first, mswin, is compiled using Microsoft's current Visual C compiler, and links to the universal runtime (ucrt).\r\n\r\nThe second, mingw, is compiled using MinGW gcc.  This links to msvcrt, an older version of Microsoft's Visual C runtime.\r\n\r\nPreviously, all the MSYS2 MinGW packages linked to msvcrt.  The MSYS2 project is now releasing build tools and packages linking to ucrt.\r\n\r\nMSYS2 has provided ruby packages, and GitHub user @Biswa96 contributed https://github.com/msys2/MINGW-packages/pull/8518, allowing Ruby to compile with ucrt.\r\n\r\nI tried the patch with ruby-loco, and it builds.  There are some test issues, haven't had a chance to look at them yet.\r\n\r\nNormally, using exe/dll/so files together that use different versions of the runtime is not a good idea.  Building extension gems with ucrt may provide gems that can be used with mswin, but can't be compiled due to issues with Visual C (vs gcc).  Also, packages from the vcpkg project may be compatible with Ruby ucrt.\r\n\r\nThe reason for this post is that Windows Ruby built with ucrt is essentially another platform, but the build 'looks like' a mingw build.\r\n\r\nThis is really a third platform choice.  What should it be called? Things like `CONFIG['RUBY_SO_NAME']`, `RUBY_PLATFORM`, etc?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-01T18:38:07Z", "updated_on": "2021-11-25T00:40:30Z", "closed_on": "2021-11-25T00:40:30Z", "relations": []}, {"id": 17844, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 309, "name": "svoop (Sven Schwyn)"}, "subject": "Support list of methods to test with respond_to?", "description": "Not sure whether this is a good idea at all, but I guess it doesn't hurt to put it up for debate.\r\n\r\nThe preferred way to check e.g. whether an argument is acceptable is by use of `respond_to?`:\r\n\r\n\r\n```ruby\r\n# Don't\r\ndef notify(recipient)\r\n  raise ArgumentError unless recipient.instance_of?(User) || recipient.instance_of?(Follower) \r\n  ...\r\nend\r\n\r\n# Do\r\ndef notify(recipient)\r\n  raise ArgumentError unless recipient.respond_to? :email\r\n  ...\r\nend\r\n```\r\n\r\nHowever, sometimes the tested object has to respond to more than one method in order to be acceptable:\r\n\r\n```ruby\r\ndef notify(recipient)\r\n  raise ArgumentError unless recipient.respond_to?(:email) && recipient.respond_to?(:name)\r\n  ...\r\nend\r\n```\r\n\r\nThe refactored version doesn't look much nicer:\r\n\r\n```ruby\r\ndef notify(recipient)\r\n  raise ArgumentError unless %i(email name).reduce(true) do |memo, method| \r\n    memo &&= recipient.respond_to? method \r\n  end\r\n  ...\r\n```\r\n\r\nThe limiting factor here is `respond_to?` which only accepts one method as String or Symbol. How about extending it to accept an Array (of String or Symbol) as well?\r\n\r\n```ruby\r\ndef notify(recipient)\r\n  raise ArgumentError unless recipient.respond_to? %i(email name)\r\n  ...\r\n```\r\n\r\nEven nicer, but more complicated to implement due to the last and optional argument `include_all`:\r\n\r\n```ruby\r\ndef notify(recipient)\r\n  raise ArgumentError unless recipient.respond_to?(:email, :name)\r\n  ...\r\n```\r\n\r\nWhat do you think?\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-05-01T13:01:28Z", "updated_on": "2021-05-06T19:00:00Z", "closed_on": null, "relations": []}, {"id": 17838, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 8, "name": "knu (Akinori MUSHA)"}, "subject": "`Set#intersect?` and enumerables", "description": "`Set#intersect?` currently accepts only a `set` argument.\r\n\r\nIt should accept an enumerable argument:\r\n\r\n```ruby\r\n[1, 2, 3].intersect?(Set[2, 3, 4]) # => true\r\nSet[2, 3, 4].intersection([1, 2, 3]) # => Set[2, 3]\r\nSet[2, 3, 4].intersect?([1, 2, 3]) # => ArgumentError\r\n```\r\n\r\nI expect `set.intersect?(arg)` to be an optimized version of `!set.intersection(arg).empty?`\r\n\r\nShould I prepare a PR?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-28T04:49:30Z", "updated_on": "2021-06-18T22:32:28Z", "closed_on": "2021-06-18T22:32:28Z", "relations": []}, {"id": 17837, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 5660, "name": "sam.saffron (Sam Saffron)"}, "subject": "Add support for Regexp timeouts", "description": "### Background\r\n\r\nReDoS are a very common security issue. At Discourse we have seen a few through the years. https://owasp.org/www-community/attacks/Regular_expression_Denial_of_Service_-_ReDoS\r\n\r\nIn a nutshell there are 100s of ways this can happen in production apps, the key is for an attacker (or possibly innocent person) to supply either a problematic Regexp or a bad string to test it with.\r\n\r\n```\r\n/A(B|C+)+D/ =~ \"A\" + \"C\" * 100 + \"X\"\r\n```\r\n\r\nHaving a problem Regexp somewhere in a large app is a universal constant, it will happen as long as you are using Regexps. \r\n\r\n\r\nCurrently the only feasible way of supplying a consistent safeguard is by using `Thread.raise` and managing all execution. This kind of pattern requires usage of a third party implementation. There are possibly issues with jRuby and Truffle when taking approaches like this.\r\n\r\n### Prior art\r\n\r\n.NET provides a `MatchTimeout` property per: https://docs.microsoft.com/en-us/dotnet/api/system.text.regularexpressions.regex.matchtimeout?view=net-5.0\r\n\r\nJava has nothing built in as far as I can tell: https://stackoverflow.com/questions/910740/cancelling-a-long-running-regex-match\r\n\r\nNode has nothing built in as far as I can tell: https://stackoverflow.com/questions/38859506/cancel-regex-match-if-timeout\r\n\r\n\r\nGolang and Rust uses RE2 which is not vulnerable to DoS by limiting features (available in Ruby RE2 gem)\r\n\r\n```\r\nirb(main):003:0> r = RE2::Regexp.new('A(B|C+)+D')\r\n=> #<RE2::Regexp /A(B|C+)+D/>\r\nirb(main):004:0> r.match(\"A\" + \"C\" * 100 + \"X\")\r\n=> nil\r\n```\r\n\r\n### Proposal\r\n\r\nImplement `Regexp.timeout` which allow us to specify a global timeout for all Regexp operations in Ruby. \r\n\r\nPer Regexp would require massive application changes, almost all web apps would do just fine with a 1 second Regexp timeout.\r\n\r\nIf `timeout` is set to `nil` everything would work as it does today, when set to second a \"monitor\" thread would track running regexps and time them out according to the global value.\r\n\r\n### Alternatives \r\n\r\nI recommend against a \"per Regexp\" API as this decision is at the application level. You want to apply it to all regular expressions in all the gems you are consuming.\r\n\r\nI recommend against a move to RE2 at the moment as way too much would break \r\n\r\n\r\n### See also: \r\n\r\nhttps://people.cs.vt.edu/davisjam/downloads/publications/Davis-Dissertation-2020.pdf\r\nhttps://levelup.gitconnected.com/the-regular-expression-denial-of-service-redos-cheat-sheet-a78d0ed7d865\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-27T23:39:53Z", "updated_on": "2022-03-30T07:51:08Z", "closed_on": "2022-03-30T07:51:08Z", "relations": [{"id": 2931, "issue_id": 17837, "issue_to_id": 17849, "relation_type": "relates", "delay": null}, {"id": 3074, "issue_id": 17837, "issue_to_id": 18144, "relation_type": "relates", "delay": null}]}, {"id": 17834, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "Add a Bytes and BytesArray class that implement memoryview", "description": "\"this is a string\".bytes should == Bytes.new('this is a string')  # an immutable bytes object that implements memory view\r\n\r\n``` ruby\r\nbytestring = Bytes.new('this is a string')\r\n\r\nmv = Fiddle::MemoryView.new(bytestring)\r\nmv[0] # 116\r\n```\r\n\r\n\r\n\r\nsimilary String.new('this is a string').bytes  == ByteArray.new('this is a string')  #  a mutable byte array object that implements memoryview , takes an optional encoding that uses current string encoding\r\n\r\n``` ruby\r\nba = ByteArray.new('this is a string')\r\nmv = Fiddle::MemoryView.new(ba)\r\nmv[0] # 116\r\nmv[0] = 120 # memoryview works on underlying object - changes mv.obj\r\nba.pack('C*').force_encoding('UTF-8') # 'xhis is a string'\r\n\r\n```\r\n\r\nalso it would be good if String#bytes returns the new classes - (return something that implements memoryview) not just plain array\r\nor add a new %b literal that returns an immutable ByteString %b('this is a string')\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-26T23:09:54Z", "updated_on": "2021-05-06T14:22:44Z", "closed_on": null, "relations": []}, {"id": 17833, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "add IO.readinto(b) where b is a bytes like object that is you can get a memoryview from", "description": "``` ruby\r\nf = File.open(FILENAME,'rb')\r\nbytearray = ByteArray.new(File.size(FILENAME)) # ByteArray implements memoryview\r\n\r\nf.readinto(bytearray)\r\n```\r\nFirst, a ByteaArray is created and pre-allocated to the size of the data we're going to read into it. The pre-allocation is important - since readinto directly accesses the internal buffer of bytearray, it won't write more than has been allocated. Next, the file.readinto method is used to read the data directly into the bytearray's internal storage, without going via temporary buffers.\r\n\r\n# Related\r\n#17834 \r\n#17831 \r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-26T22:40:00Z", "updated_on": "2021-06-30T14:36:19Z", "closed_on": null, "relations": []}, {"id": 17832, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "allow IO write to write memoryview object without copying or add IO#write_memoryview", "description": "IO#write() - arguments that are not a string will be converted to string using to_s\r\nwant IO#write to be able to write memoryview objects without conversion to string \r\n\r\n``` ruby\r\nrequire 'fiddle'\r\ninclude Fiddle\r\nptr = Fiddle::Pointer['this is a string']\r\nmv = MemoryView.new ptr\r\nmv.byte_size  #17802 \r\nmv[0]  # 116\r\n'this is a string'.bytes[0] = 116\r\nFile.open('test.txt', 'wb'){ f.write mv}\r\ncontents = File.open('test.txt', 'r'){ |f| f.read}  # contents is  \"#<Fiddle::MemoryView:0x000001a75ae76258>\" not 'this is a string'\r\n\r\nbuffer = ByteBuffer.new('this is a string')\r\nFile.open('test.txt', 'w'){|f| f.write Fiddle::MemoryView.new(buffer)}\r\n```\r\n\r\nallow IO#write to write memoryview objects without converting to string or add a new method on IO to write memoryview objects without converting to string\r\n\r\n# Related\r\n\r\n#17834 \r\n#17833 \r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-26T22:23:32Z", "updated_on": "2021-05-06T21:10:33Z", "closed_on": "2021-05-06T21:10:33Z", "relations": []}, {"id": 17831, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "add slice method to Fiddle::MemoryView", "description": "``` ruby\r\n# Fiddle::MemoryView#slice(start, length)\r\n# Fiddle::MemoryView#slice(range)\r\nmv = Fiddle::MemoryView.new(memory_object)\r\n\r\nwhile mv\r\n  puts mv[0]\r\n  mv = mv.slice(1..-1) # returns a new MemoryView object with the same MemoryView#obj   # that is no copying\r\nend\r\n\r\n```\r\n\r\nrelated to #17832 \r\nrelated to #17851 \r\nrelated to #17833 \r\n\r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-26T22:19:15Z", "updated_on": "2021-05-06T21:11:22Z", "closed_on": "2021-05-06T21:11:22Z", "relations": [{"id": 2933, "issue_id": 17831, "issue_to_id": 17851, "relation_type": "relates", "delay": null}]}, {"id": 17830, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9218, "name": "rafasoares (Rafael Soares)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Add Integer#previous and Integer#prev ", "description": "I think `Integer#pred` is great as the inverse of `#succ`, but it reads a bit weird as the inverse of `#next`, which might be preferable for those going for a more \"reads like English\" approach.\r\n\r\nOn that note, `#previous` reads better, but it's also twice as long as `#pred` (or even `#next`). Which is why I've also added the shorthand `#prev`\r\n\r\nSince Ruby strives for readability, I always thought it was weird that the team omitted this improvement. \r\n\r\nAlso, I thought about writing a gem for this, but:\r\n1. Do we really want to add another gem for such a simple change to every project?\r\n2. Monkey-patching gems feel dirty.\r\n\r\nFinally, I want to mention that I tried looking for previous discussions on this topic, as it seems likely someone would've brought this up at some point, but was unsuccessful. Probably due to the massive amount of baggage in the core issue tracker and mailing lists, I could've missed something among the noise.\r\n\r\nI've created a fork on GitHub (https://github.com/rafasoares/ruby/commit/05119848b1f480db2e809f964528799030cc7ebb) in order to open a PR, but decided to open this ticket as well, after reading the contributing guide more carefully. ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-26T17:27:05Z", "updated_on": "2021-04-27T23:35:32Z", "closed_on": null, "relations": []}, {"id": 17825, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51574, "name": "Aoernis (lucas billaudot)"}, "subject": "Uniformize Float::INFINITY and Date::infinity.new", "description": "With `Float` you can do \r\n``` ruby\r\nFloat::INFINITY # Infinity\r\n```\r\nand with `Date` you can do \r\n``` ruby\r\nDate::Infinity.new # #<Date::Infinity:0x00007f8d46a59ee0 @d=1>\r\n```\r\nbut not \r\n``` ruby\r\nDate::INFINITY # uninitialized constant Date::INFINITY\r\n```\r\n\r\n#### Background\r\n\r\n`Date::Infinity.new` and `Float::INFINITY` have both the same ancestors and have same using purpose\r\nSo it feel odd no be able to call them the same way\r\n\r\n#### Proposal\r\n\r\nJust make `Date::INFINITY` a working thing\r\nAnd maybe mark `Date::Infinity.new` as deprecated \u00af\\_(\u30c4)_/\u00af\r\n\r\nThanks for reading\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-25T11:05:32Z", "updated_on": "2021-05-04T01:43:13Z", "closed_on": null, "relations": []}, {"id": 17816, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 31800, "name": "eightbitraptor (Matthew Valentine-House)"}, "subject": "Move C heap allocations for RVALUE object data into GC heap", "description": "\r\n## Pull Request:\r\n\r\n[Github PR: 4391](https://github.com/ruby/ruby/pull/4391)\r\n\r\n## Introduction\r\n\r\n_**This work supersedes the work in [PR: 4107](https://github.com/ruby/ruby/pull/4107) and [Redmine: 17570](https://bugs.ruby-lang.org/issues/17570). We've reimplemented the feature to make the diff smaller, easier to maintain and less intrusive to existing data structures.**_\r\n\r\nWe're working at Shopify to restructure Ruby memory management in order to allow objects to occupy more than one heap slot. This will allow previously heap allocated data to be stored next to its associated `RVALUE` slot in a contiguous memory region. \r\n\r\nWe believe that this will simplify the internals of the GC by: \r\n\r\n* Removing the distinction between embedded and heap allocated objects as everything will now effectively be embedded across multiple slots.\r\n*   Allowing us to remove the transient heap. The transient heap reduces the number of `malloc` calls for heap allocated objects by deferring them until the object is promoted to an old object. When objects no longer need to call `malloc`, the transient heap can be removed.\r\n\r\nWe believe that there will be performance improvements across most Ruby codebases as a result of these simplifications. Objects will also have improved data locality, resulting in improved hardware cache performance.\r\n\r\n\r\n## Summary of changes\r\n\r\nThis is a rewrite of a feature initially proposed in [PR #4107](https://github.com/ruby/ruby/pull/4107).\r\n\r\n![](https://i.imgur.com/8x22ylD.png)\r\n\r\nThe referenced PR adds the core implementation and API in order to store arbitrary length data inside contiguous free slots on the heap. It also includes a reference implementation for `T_CLASS` objects, that would usually allocate the `rb_classext_t` struct on the system heap. The current API is:\r\n\r\n* `RVARGC_NEWOBJ_OF` - A reimplementation of the `NEWOBJ_OF` macro that takes an additional parameter `payload_length`, the length of the payload data to store in bytes.\r\n* `rb_rvargc_payload_data_ptr` - a `void *` to the start of the region where the extra data can be allocated.\r\n\r\nWe've introduced a new type `T_PAYLOAD` and a `struct RPayload` that contains a single `VALUE flags`. We use the `FL_USER` bits to store the number of payload slots so that we can stride over the payload body in most places where heap walking is required (as these slots can now contain user defined data they will not have accurate `flags` and so most type checks will be incorrect).\r\n\r\nWhen `RVARGC_NEWOBJ_OF` is called with a payload size, we calculate the number of slots required to store the `RVALUE`, an `RPayload` and the payload data itself. We then first search the ractors `newobj_cache` for a region of the required size, remove the slots from the freelist and initialize them.\r\n\r\nThen a pointer to the first allocatable byte in the payload body section can be found using `rb_rvargc_payload_data_ptr`.\r\n\r\nThese changes can be enabled using the compile time flag `USE_RVARGC=1`. \r\n\r\n* **We do not expect anyone to run production Ruby applications with this flag enabled. This is an experimental feature which we will improve incrementally.**\r\n* **Should these experiments prove unsuccessful in the long term, We will completely remove this feature and all related code**\r\n* **This PR has no performance implications when `USE_RVARGC` is disabled. Allocation of `RVALUE`s in a single slot behaves almost identically to before this change (see [Benchmarking data](#Benchmarking).**\r\n\r\n## Features (and challenges)\r\n\r\n* `T_PAYLOAD` is fully integrated with the existing GC. The entire payload region will be treated as one single slot for marking, sweeping and generational purposes. In contrast with our previous attempt this means we no longer need to disable incremental marking, nor do we need to use an extra bitmap attached to a heap_page.\r\n* All slots that are part of a `T_CLASS` and its payload region are pinned, so compaction will not move them. This has impacted the effectiveness of compaction, but unlike our previous PR, doesn't require us to disable compaction completely.\r\n* RSS is significantly larger when `USE_RVARGC` is enabled. This is due to our (currently) naive approach to free region allocation.\r\n\r\n## Next steps\r\n\r\nWith this merged. We have several different directions we intend to investigate\r\n\r\n* Performance benchmarking: Analysing L1, 2 and 3 cache performance to decide where best to introduce RVarGC first, and what (if any) performance gains we'll see by improving data locality. Our current speculative contenders are Arrays, ivars, strings.\r\n* Improvements to the way the Payload data is managed: move the payload length into the RVALUE itself, and inline the payload body, removing the need for the `T_PAYLOAD` object entirely.\r\n* Compaction improvements: Investigating which compaction algorithms perform better with objects of variable size.\r\n* Resize payload regions. Currently we have no support for resizing payload regions. This must be fixed before we can support many of the different Ruby types.\r\n* Free region allocation: Find a way of managing the freelist that performs better with allocations of contiguous regions than the current singly linked freelist appraoch.\r\n\r\nThe end game for this work is to be remove the requirement for an `RVALUE` to be exactly 40 bytes wide. This is obviously a long game, of which this PR takes the first steps.\r\n\r\n\r\n### <a name=\"Benchmarking\">Benchmarking</a>\r\n\r\nWe used [Railsbench](https://github.com/k0kubun/railsbench) to compare the performance of master with our branch, with `USE_RVARGC=0`\r\n```\r\nubuntu@ip-172-31-42-217:~/railsbench$ chruby master\r\nubuntu@ip-172-31-42-217:~/railsbench$ setarch x86_64 -R nice -20 taskset -c 75 ./bin/bench\r\nruby 3.1.0dev (2021-04-19T12:40:29Z master 50f17241a3) [x86_64-linux]\r\n{\"cppflags\"=>\"-DUSE_RVARGC=0\", \"optflags\"=>\"-O3 -fno-fast-math\"}\r\nWarming up...\r\nBenchmark: 10000 requests\r\n\r\nRequest per second: 747.3 [#/s] (mean)\r\n\r\nPercentage of the requests served within a certain time (ms)\r\n  50%    1.32\r\n  66%    1.36\r\n  75%    1.38\r\n  80%    1.39\r\n  90%    1.42\r\n  95%    1.46\r\n  98%    1.53\r\n  99%    1.84\r\n 100%   11.40\r\nubuntu@ip-172-31-42-217:~/railsbench$ setarch x86_64 -R nice -20 taskset -c 75 ./bin/bench\r\nruby 3.1.0dev (2021-04-20T10:02:39Z mvh-rvargc 2045bfb7f7) [x86_64-linux]\r\n{\"cppflags\"=>\"-DUSE_RVARGC=0\", \"optflags\"=>\"-O3 -fno-fast-math\"}\r\nWarming up...\r\nBenchmark: 10000 requests\r\n\r\nRequest per second: 746.3 [#/s] (mean)\r\n\r\nPercentage of the requests served within a certain time (ms)\r\n  50%    1.31\r\n  66%    1.37\r\n  75%    1.39\r\n  80%    1.39\r\n  90%    1.41\r\n  95%    1.44\r\n  98%    1.51\r\n  99%    1.83\r\n 100%    8.97\r\n ```\r\n \r\n And the same comparison using Optcarrot:\r\n \r\n ```\r\n ubuntu@ip-172-31-42-217:~/optcarrot$ chruby master\r\nubuntu@ip-172-31-42-217:~/optcarrot$ ./bin/optcarrot --benchmark examples/Lan_Master.nes\r\nfps: 43.62907118228718\r\nchecksum: 59662\r\nubuntu@ip-172-31-42-217:~/optcarrot$ chruby rvargc\r\nubuntu@ip-172-31-42-217:~/optcarrot$ ./bin/optcarrot --benchmark examples/Lan_Master.nes\r\nfps: 43.90831352849611\r\nchecksum: 59662\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-20T11:49:56Z", "updated_on": "2021-05-07T13:18:00Z", "closed_on": "2021-05-07T13:18:00Z", "relations": [{"id": 3031, "issue_id": 17816, "issue_to_id": 18045, "relation_type": "relates", "delay": null}]}, {"id": 17808, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51554, "name": "Lithium (Brad Krane)"}, "subject": "Feature Request: JS like splat of Object properties as named method parameters", "description": "I'm pretty sure there is no equivalent Ruby for a very convenient JS way to enter named function parameters as below:\r\n\r\n``` javascript\r\nconst test = ({param1,\r\n param2,\r\n param3 = null,\r\n param4 = false,\r\n param5 = null,\r\n }={}) => {\r\n   console.log(`${param1}, ${param2}, ${param3}, ${param4}, ${param5}\\n`)    \r\n }\r\nlet obj = {\r\n param1: 23,\r\n param2: 234,\r\n param3: 235,\r\n param4: 257\r\n};\r\n\r\ntest({...obj});\r\n\r\n```\r\n\r\nwhich is super convenient and as far as I'm aware there is no standard Ruby equivalent. It can be accomplished in Ruby but the call syntax is far less nice. A couple examples below:\r\n\r\n``` ruby\r\n# Implementing such a feature wouldn't be too difficult.\r\n# Ok so here is what you could do it. Patch Kernel with a method splat. (Sorry in advance for formatting)\r\nmodule Kernel\r\n  def splat obj, method:\r\n    new_hash = method.parameters.reduce({}) do |hash, attrr|\r\n      hash[attrr.last] = obj.send(attrr.last)\r\n      hash\r\n    end\r\n  end\r\nend\r\n\r\n# Then you can pass it a list of symbols.\r\n# Then for your method:\r\ndef some_method name:, weight: \r\n    puts \"#{name} weighs #{weight}\"\r\nend\r\n\r\nclass Dog\r\n  attr_reader :name, :weight\r\n  def initialize name:,weight: \r\n    @name = name\r\n    @weight = weight\r\n  end\r\nend\r\n\r\na_dog = Dog.new( name: 'fido', weight: '7kg')\r\nhash_puppy = a_dog.splat(a_dog, method: method(:some_method)  )\r\n\r\nsome_method(**hash_puppy)\r\n```\r\n\r\n\r\nor what I think is a bit better:\r\n\r\n``` ruby\r\n# Same class as above\r\na_dog = Dog.new( name: 'fido', weight: '7kg')\r\n\r\ndef other_splat  obj, method:\r\n  new_hash = method.parameters.reduce({}) do |hash, attrr|\r\n    if obj.class <= Hash\r\n      hash[attrr.last] = obj[attrr.last]      \r\n    else\r\n      hash[attrr.last] = obj.send attrr.last\r\n    end\r\n    hash\r\n  end\r\n  method.call **new_hash\r\nend\r\n\r\nother_splat(a_dog, method: method(:some_method))\r\n\r\n# above line should be like:\r\n# some_method ...a_dog\r\n\r\n```\r\n\r\nSource: https://gist.github.com/bradkrane/e051d205024a5313cb4a5b9eb1eae0e3\r\n\r\nI'm sure I'm missing a possibly more clever way to accomplish this, but I'm pretty sure something like `other_splat(a_dog, method: method(:some_method))` is about as close as it can get, unless I'm missing something? It would be quite nice to have a similar syntax as JS but in Ruby: `some_method ...a_dog`\r\n\r\nThanks for your time and attention!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-16T12:18:59Z", "updated_on": "2021-04-17T23:43:52Z", "closed_on": null, "relations": []}, {"id": 17798, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 14, "name": "znz (Kazuhiro NISHIYAMA)"}, "subject": "exception in finalizer", "description": "https://docs.ruby-lang.org/ja/latest/method/ObjectSpace/m/define_finalizer.html \u306b\r\n\r\n> proc \u306e\u547c\u3073\u51fa\u3057\u3067\u767a\u751f\u3057\u305f\u5927\u57df\u8131\u51fa(exit\u3084\u4f8b\u5916)\u306f\u7121\u8996\u3055\u308c\u307e\u3059\u3002\u3053\u308c\u306f\u3001\u30b9\u30af\u30ea\u30d7\u30c8\u306e\u30e1\u30a4\u30f3\u51e6\u7406\u304c GC \u306e\u767a\u751f\u306b\u3088\u3063\u3066\u975e\u540c\u671f\u306b\u4e2d\u65ad\u3055\u308c\u308b\u306e\u3092\u9632\u3050\u305f\u3081\u3067\u3059\u3002\u4e0d\u5b89\u306a\u3046\u3061\u306f -d \u30aa\u30d7\u30b7\u30e7\u30f3\u3067\u4e8b\u524d\u306b\u4f8b\u5916\u306e\u767a\u751f\u306e\u6709\u7121\u3092\u78ba\u8a8d\u3057\u3066\u304a\u3044\u305f\u65b9\u304c\u826f\u3044\u3067\u3057\u3087\u3046\u3002\r\n\r\n\u3068\u3042\u308a\u307e\u3059\u304c\u3001\u30e1\u30a4\u30f3\u30b9\u30ec\u30c3\u30c9\u4ee5\u5916\u306e\u30b9\u30ec\u30c3\u30c9\u304c\u4f8b\u5916\u3067\u7d42\u4e86\u3057\u305f\u3068\u304d\u306b\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u300cterminated with exception (report_on_exception is true)\u300d\u3068\u51fa\u308b\u3088\u3046\u306b\u3001\u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u306f\u7121\u8996\u305b\u305a\u306b\u30e1\u30c3\u30bb\u30fc\u30b8\u3092\u51fa\u3059\u3088\u3046\u306b\u3057\u3066\u3082\u826f\u3044\u306e\u3067\u306f\u306a\u3044\u3067\u3057\u3087\u3046\u304b?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-13T13:37:13Z", "updated_on": "2021-07-23T03:01:45Z", "closed_on": "2021-07-23T03:01:45Z", "relations": []}, {"id": 17797, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "subject": "MIPS support for addr2line.c", "description": "In MIPS ELF, DWARF sections are of type `MIPS_DWARF`, not `PROGBITS`.\r\n\r\nThe attached patch modifies `addr2line.c` so that it prints file:lineno information correctly for MIPS ELF.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-13T02:59:09Z", "updated_on": "2021-04-13T03:49:04Z", "closed_on": null, "relations": []}, {"id": 17795, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Around `Process.fork` callbacks API", "description": "Replaces: https://bugs.ruby-lang.org/issues/5446\r\n\r\n### Context\r\n\r\nRuby code in production is very often running in a forking setup (puma, unicorn, etc), and it is common some types of libraries to need to know when the Ruby process was forked. For instance:\r\n\r\n  - Most database clients, ORMs or other libraries keeping a connection pool might need to close connections before the fork happens.\r\n  - Libraries relying on some kind of dispatcher thread might need to restart the thread in the forked children, and clear any internal buffer (e.g. statsd clients, newrelic_rpm).\r\n\r\n**This need is only for forking the whole ruby process, extensions doing a `fork(2) + exec(2)` combo etc are not a concern, this aim at only catching `kernel.fork`, `Process.fork` and maybe `Process.daemon`.**.\r\nThe use case is for forks that end up executing Ruby code.\r\n\r\n### Current solutions\r\n\r\nRight now this use case is handled in several ways.\r\n\r\n#### Rely on the integrating code to call a `before_fork` or `after_fork` callback.\r\n\r\nSome libraries simply rely on documentation and require the user to use the hooks provided by their forking server.\r\n\r\nExamples:\r\n\r\n  - Sequel: http://sequel.jeremyevans.net/rdoc/files/doc/fork_safety_rdoc.html\r\n  - Rails's Active Record: https://devcenter.heroku.com/articles/concurrency-and-database-connections#multi-process-servers\r\n  - ScoutAPM (it tries to detect popular forking setup and register itself): https://github.com/scoutapp/scout_apm_ruby/blob/fa83793b9e8d2f9a32c920f59b57d7f198f466b8/lib/scout_apm/environment.rb#L142-L146\r\n  - NewRelic RPM (similarly tries to register to popular forking setups): https://www.rubydoc.info/github/newrelic/rpm/NewRelic%2FAgent:after_fork\r\n\r\n\r\n#### Continuously check `Process.pid`\r\n\r\nSome libraries chose to instead keep the process PID in a variable, and to regularly compare it to `Process.pid` to detect forked children.\r\nUnfortunately `Process.pid` is relatively slow on Linux, and these checks tend to be in tight loops, so it's not uncommon when using these libraries\r\nto spend `1` or `2%` of runtime in `Process.pid`.\r\n\r\nExamples:\r\n\r\n  - Rails's Active Record used to check `Process.pid` https://github.com/Shopify/rails/blob/411ccbdab2608c62aabdb320d52cb02d446bb39c/activerecord/lib/active_record/connection_adapters/abstract/connection_pool.rb#L946, it still does but a bit less: https://github.com/rails/rails/pull/41850\r\n  - the `Typhoeus` HTTP client: https://github.com/typhoeus/typhoeus/blob/a345545e5e4ac0522b883fe0cf19e5e2e807b4b0/lib/typhoeus/pool.rb#L34-L42\r\n  - Redis client: https://github.com/redis/redis-rb/blob/6542934f01b9c390ee450bd372209a04bc3a239b/lib/redis/client.rb#L384\r\n  - Some older versions of NewRelic RPM: https://github.com/opendna/scoreranking-api/blob/8fba96d23b4d3e6b64f625079c184f3a292bbc12/vendor/gems/ruby/1.9.1/gems/newrelic_rpm-3.7.3.204/lib/new_relic/agent/harvester.rb#L39-L41\r\n\r\n#### Continuously check `Thread#alive?`\r\n\r\nSimilar to checking `Process.pid`, but for the background thread use case. `Thread#alive?` is regularly checked, and if the thread is dead, it is assumed that the process was forked.\r\nIt's much less costly than a `Process.pid`, but also a bit less reliable as the thread could have died for other reasons. It also delays re-creating the thread to the next check rather than immediately upon forking.\r\n\r\nExamples:\r\n\r\n  - `statsd-instrument`: https://github.com/Shopify/statsd-instrument/blob/0445cca46e29aa48e9f1efec7c72352aff7ec931/lib/statsd/instrument/batched_udp_sink.rb#L63\r\n\r\n#### Decorate `Kernel.fork` and `Process.fork`\r\n\r\nAnother solution is to prepend a module in `Process` and `Kernel`, to decorate the fork method and implement your own callback. It works well, but is made difficult by `Kernel.fork`.\r\n\r\n\r\nExamples:\r\n\r\n  - Active Support: https://github.com/rails/rails/blob/9aed3dcdfea6b64c18035f8e2622c474ba499846/activesupport/lib/active_support/fork_tracker.rb\r\n  - `dd-trace-rb`: https://github.com/DataDog/dd-trace-rb/blob/793946146b4709289cfd459f3b68e8227a9f5fa7/lib/ddtrace/profiling/ext/forking.rb\r\n  - To some extent, `nakayoshi_fork` decorates the `fork` method: https://github.com/ko1/nakayoshi_fork/blob/19ef5efc51e0ae51d7f5f37a0b785309bf16e97f/lib/nakayoshi_fork.rb\r\n\r\n### Proposals\r\n\r\nI see two possible features to improve this situation:\r\n\r\n####  Fork callbacks\r\n\r\nOne solution would be for Ruby to expose a callback API for these two events, similar to `Kernel.at_exit`.\r\n\r\nMost implementations of this functionnality in other languages ([C's `pthread_atfork`](https://man7.org/linux/man-pages/man3/pthread_atfork.3.html), [Python's `os.register_at_fork`](https://docs.python.org/3/library/os.html#os.register_at_fork)) expose 3 callbacks:\r\n\r\n  - `prepare` or `before` executed in the parent process before the `fork(2)`\r\n  - `parent` or `after_in_parent` executed in the parent process after the `fork(2)`\r\n  - `child` or `after_in_child` executed in the child process after the `fork(2)`\r\n\r\nA direct translation of such API in Ruby could look like `Process.at_fork(prepare: Proc, parent: Proc, child: Proc)` if inspired by `pthread_atfork`.\r\n\r\nOr alternatively each callback could be exposed idependently: `Process.before_fork {}`, `Process.after_fork_parent {}`, `Process.after_fork_child {}`.\r\n\r\nAlso note that similar APIs don't expose any way to unregister callbacks, and expect users to use weak references or to not hold onto objects that should be garbage collected.\r\n\r\nPseudo code:\r\n\r\n```ruby\r\nmodule Process\r\n  @prepare = []\r\n  @parent = []\r\n  @child = []\r\n\r\n  def self.at_fork(prepare: nil, parent: nil, child: nil)\r\n    @prepare.unshift(prepare) if prepare # prepare callbacks are executed in reverse registration order\r\n    @parent << parent if parent\r\n    @child << child if child\r\n  end\r\n\r\n  def self.fork\r\n    @prepare.each(&:call)\r\n    if pid = Primitive.fork\r\n      @parent.each(&:call) # We could consider passing the pid here.\r\n    else\r\n      @child.each(&:call)\r\n    end\r\n  end\r\nend\r\n\r\n```\r\n\r\n#### Make `Kernel.fork` a delegator\r\n\r\nA simpler change would be to just make `Kernel.fork` a delegator to `Process.fork`. This would make it much easier to prepend a module on `Process` for each library to implement its own callback.\r\n\r\nProposed patch: https://github.com/ruby/ruby/pull/4361", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-12T08:09:08Z", "updated_on": "2021-10-25T11:55:11Z", "closed_on": "2021-10-25T11:55:11Z", "relations": [{"id": 2926, "issue_id": 5446, "issue_to_id": 17795, "relation_type": "relates", "delay": null}]}, {"id": 17790, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "Have a way to clear a String without resetting its capacity", "description": "In some tight loop it can be useful to re-use a buffer string. For instance:\r\n\r\n```ruby\r\nbuffer = String.new(encoding: Encoding::BINARY, capacity: 1024)\r\n\r\n10.times do\r\n  build_next_packet(buffer)\r\n  udp_socket.send(buffer)\r\n  buffer.clear\r\nend\r\n```\r\n\r\nCurrently `Array#clear` preserve the Array capacity, but `String#clear` doesn't:\r\n\r\n```ruby\r\n>> puts ObjectSpace.dump(Array.new(20).clear)\r\n{\"address\":\"0x7fd3260a1558\", \"type\":\"ARRAY\", \"class\":\"0x7fd3230972e0\", \"length\":0, \"memsize\":200, \"flags\":{\"wb_protected\":true}}\r\n>> puts ObjectSpace.dump(String.new(encoding: Encoding::BINARY, capacity: 1024).clear)\r\n{\"address\":\"0x7fd322a8a320\", \"type\":\"STRING\", \"class\":\"0x7fd3230b75b8\", \"embedded\":true, \"bytesize\":0, \"value\":\"\", \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n```\r\n\r\nIt would be useful if `String#clear` wouldn't free allocated memory, but if it's a backward compatibility concern to change it, then maybe another method could make sense?\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-09T10:42:37Z", "updated_on": "2021-04-21T23:27:51Z", "closed_on": null, "relations": []}, {"id": 17786, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11075, "name": "jzakiya (Jabari Zakiya)"}, "subject": "Proposal: new  \"ends\" keyword", "description": "I'm submitting this in the same spirit that ''endless methods'' was, to promote and produce more concise and easier to write|read code.\r\n\r\n#### Proposal\r\nThis is a proposal to introduce a new keyword ``ends`` (or ``endall``) as a terminal point to resolve the end of nested ''loops|conditionals''.\r\n\r\n#### Why\r\nIt's a common code occurrence to have multiple levels of loops and/or conditionals, which require separate ``end`` keywords to designate their\r\ntermination points. The ``end`` statements themselves are merely for syntactic purposes.\r\n\r\nIt would be a benefit to programmers, and code readers, to be able to produce|read more concise code, by reducing the ''code noise'' of these\r\nnested multiple ``end`` keywords with a shorter|cleaner syntax.\r\n\r\nThus, I propose creating the keyword ``ends`` as a shorter|cleaner syntax to replace having to write multiple ``end`` keywords.\r\n\r\n#### Example\r\nBelow is an example of real code which performs nested loops. With ''standard'' format it looks like this.\r\n\r\n```ruby\r\ndef render(scene, image, screenWidth, screenHeight)\r\n  screenHeight.times do |y|\r\n    screenWidth.times do |x|\r\n      color = self.traceRay(....)\r\n      r, g, b = Color.toDrawingColor(color)\r\n      image.set(x, y, StumpyCore::RGBA.from_rgb(r, g, b))\r\n    end \r\n  end \r\nend\r\n```\r\n\r\nHowever, from the point of view of the parser, these are all legal|equivalent.\r\n\r\n```ruby\r\ndef render(scene, image, screenWidth, screenHeight)\r\n  screenHeight.times do |y|\r\n    screenWidth.times do |x|\r\n      color = self.traceRay(....)\r\n      r, g, b = Color.toDrawingColor(color)\r\n      image.set(x, y, StumpyCore::RGBA.from_rgb(r, g, b))\r\n    end     end         end     end end end\r\n  end         end       end\r\nend             end     end\r\n```\r\n\r\nThis proposal would allow this type of code to be written as:\r\n\r\n```ruby\r\ndef render(scene, image, screenWidth, screenHeight)\r\n  screenHeight.times do |y|\r\n    screenWidth.times do |x|\r\n      color = self.traceRay(....)\r\n      r, g, b = Color.toDrawingColor(color)\r\n      image.set(x, y, StumpyCore::RGBA.from_rgb(r, g, b))\r\nends\r\n```\r\n\r\n#### Pros\r\n1) code conciseness\r\n2) better readability\r\n3) no whitespace dependencies\r\n4) no conflict with legacy code\r\n5) attractice to people coming from Python|Nim, et al\r\n\r\n#### Cons\r\nNo technical implementation restrictions I can think of.\r\nMaybe alternative name (endall)?\r\n\r\nThanks for consideration.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-08T16:38:10Z", "updated_on": "2021-04-11T01:40:15Z", "closed_on": null, "relations": [{"id": 2922, "issue_id": 17786, "issue_to_id": 5054, "relation_type": "duplicates", "delay": null}, {"id": 2924, "issue_id": 17786, "issue_to_id": 12241, "relation_type": "duplicates", "delay": null}]}, {"id": 17785, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Allow named parameters to be keywords", "description": "We should allow named parameters to be keywords and use add a trailing `_` to the corresponding variable:\r\n\r\n```ruby\r\ndef check(arg, class:)\r\n  arg.is_a?(class_)\r\nend\r\n\r\ncheck(42, class: Integer) # => true\r\n```\r\n\r\nCurrently, if we want such an API we have to use `**rest`:\r\n\r\n```ruby\r\ndef check(arg, **rest)\r\n  class_ = rest.fetch(:class) { raise ArgumentError('missing keyword: :class')}\r\n  if rest.size > 1\r\n    unknown = rest.keys - [:class]\r\n    raise ArgumentError(\"unknown keyword(s): :#{unknown.join(', :')})\r\n  end\r\n\r\n  arg.is_a?(class_)\r\nend\r\n```\r\n\r\nThis is very verbose, much less convenient, much less readable, prevents `steep` from generating the proper signature, etc.\r\n\r\nWe should do the same for pattern match.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-08T15:08:40Z", "updated_on": "2021-12-17T18:10:20Z", "closed_on": null, "relations": [{"id": 2938, "issue_id": 13207, "issue_to_id": 17785, "relation_type": "relates", "delay": null}, {"id": 3192, "issue_id": 17785, "issue_to_id": 18402, "relation_type": "relates", "delay": null}]}, {"id": 17773, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Alias `Numeric#zero?` and `Float#zero?` as `Numeric#empty?` and `Float#empty?`", "description": "When dealing with user input fields as in web applications, there are typical values that we want to consider as the default and/or absence of user input. For string/text inputs, list items, and attributes, we have `String#empty?`, `Array#empty?`, and `Hash#empty?` respectively, which seem to correspond to those cases. As for numerics, there are `Numeric#zero?` and `Float#zero?`.\r\n\r\nHowever, there is no single term that covers all these cases. In a routine to check through the fields whether there is user input, we have to selectively use `empty?` or `zero?` depending on the type of the input field.\r\n\r\nMany programming languages other than Ruby typically consider these values as falsy with respect to logical calculation. Ruby handles only `nil` and `false` as falsy, and that has clear advantages in many aspects, but with the cost of losing a simple way to handle these default values.\r\n\r\nI propose to alias `Numeric#zero?` as `Numeric#empty?` and `Float#zero?` as `Float#empty?` so that we can simply use `empty?`. At first, calling zero as empty might sound strange, but at least for non-negative integers, set theoretic definitions usually define zero as the empty set, so it is not that strange after all.\r\n\r\n\r\nRuby on Rails' `blank?` is conceptually similar to this, but `0.blank?` returns `false`, so it is a different concept.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-02T03:49:45Z", "updated_on": "2021-04-02T15:39:09Z", "closed_on": null, "relations": []}, {"id": 17771, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 286, "name": "headius (Charles Nutter)"}, "subject": "String#start_with? should not construct MatchData or set $~", "description": "I am working on making $~ more thread-safe in JRuby and came across this unexpected behavior:\r\n\r\n```ruby\r\n$ rvm ruby-3.0 do ruby -e '\"foo\".start_with?(/foo/); p $~'\r\n#<MatchData \"foo\">\r\n```\r\n\r\nThe `start_with?` method was added 11 years ago in https://bugs.ruby-lang.org/issues/3388 but I do not think the set of $~ was an intended feature. The `start_with?` method could be much faster and more thread-safe if it did not use the frame-local backref slot and did not allocate a MatchData.\r\n\r\nCompare with `match?` which was added specifically (without MatchData or backref setting) to provide a fast way to check if a Regexp matches.\r\n\r\nI propose that `start_with?` stop constructing MatchData, stop setting backref, and provide only its boolean result in the same way as `match?`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-01T18:08:02Z", "updated_on": "2021-04-02T14:49:32Z", "closed_on": null, "relations": []}, {"id": 17769, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 482, "name": "mrkn (Kenta Murata)"}, "subject": "Proposal: numeric coefficient syntax", "description": "When we write a mathematical equation, we often omit a multiplication operator between a coefficient and a variable like `2x`.\r\nI guess this convention can be useful in computer programming.  Practically, Julia employs this notation:\r\n\r\n```\r\njulia> 2pi\r\n6.283185307179586\r\n\r\njulia> x = 3\r\n3\r\n\r\njulia> 2x\r\n6\r\n\r\njulia> pi\r\n\u03c0 = 3.1415926535897...\r\n\r\njulia> 2pi\r\n6.283185307179586\r\n```\r\n\r\nI wrote a proof-of-concept patch to introduce this notation in Ruby.\r\nWe can write the following with this patch:\r\n\r\n```\r\nirb(main):001:0> x = 3\r\n=> 3\r\nirb(main):002:0> 2x\r\n=> 6\r\nirb(main):003:0> def pi = Math::PI\r\n=> :pi\r\nirb(main):004:0> 2pi\r\n=> 6.283185307179586\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-01T01:23:32Z", "updated_on": "2021-04-05T02:45:35Z", "closed_on": "2021-04-05T02:45:35Z", "relations": []}, {"id": 17768, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Proposal: Downward assignments", "description": "Rightward assignments have been introduced since 3.0.\r\nTo be honest, I'm not a big fan of the syntax because it does not add a new dimension to Ruby.\r\nWhy don't we bring Ruby to the next dimension?\r\n\r\n\r\n## Proposal\r\n\r\nI propose \"downward assignments\".\r\n\r\n```\r\np(2 * 3 * 7)  #=> 42\r\n  ^^^^^var\r\n\r\np var         #=> 6\r\n```\r\n\r\nThis new syntax intercepts the intermediate value of a subexpression.\r\nIn the above example, the subexpression `2 * 3` is captured to `var`.\r\n\r\nYou can capture multiple subexpressions in one line.\r\n\r\n```\r\nputs(\"Hello\" + \"World\")  #=> HelloWorld\r\n     ^^^^^^^x  ^^^^^^^y\r\n\r\np x  #=> \"Hello\"\r\np y  #=> \"World\"\r\n```\r\n\r\nThis proposal solves some long-standing issues in Ruby.\r\n\r\n\r\n## Use case 1\r\n\r\nEveryone has written the following code.\r\n\r\n```\r\nwhile (line = gets) != nil\r\n  p line\r\nend\r\n```\r\n\r\nThis code is not so bad, but there's something that has been on my mind: is it really good to put an assignment into a condition expression?\r\nI'm afraid that it makes the loop condition unclear.\r\n\r\nUnfortunately, it is difficult to keep the condition clear in Ruby.\r\nIf the assignment is removed from the condition, the code becomes even more unclear as follows.\r\n\r\n```\r\nwhile true\r\n  line = gets\r\n  break if line == nil\r\n  p line\r\nend\r\n```\r\n\r\n\r\n\r\nBy using my proposal, you can make the condition crystal-clear.\r\n\r\n```\r\nwhile gets != nil\r\n      ^^^^line\r\n  p line\r\nend\r\n```\r\n\r\n\r\n## Use case 2\r\n\r\nConsider that we want to get from an array the last element that meets a condition.\r\n\r\n```\r\nary = [1, 2, 3, 4, 5]\r\n\r\nary.each {|elem| found = elem if elem.even? }\r\n\r\np found  #=> 4\r\n```\r\n\r\nAs you know, this code does not work.\r\nWe need to add `found = nil` to declare the variable \"found\" in the outer scope.\r\nBut this is unarguably dirty.\r\n\r\nMy proposal allows to make the code very straightforward.\r\n\r\n```\r\nary = [1, 2, 3, 4, 5]\r\n\r\nary.each {|elem| elem if elem.even? }\r\n                 ^^^^found\r\n\r\np found  #=> 4\r\n```\r\n\r\n\r\n## Use case 3\r\n\r\nWhen writing a constructor, we need to write each field name whopping three times.\r\n\r\n```\r\nclass C\r\n  def initialize(foo, bar)\r\n    @foo = foo\r\n    @bar = bar\r\n  end\r\nend\r\n```\r\n\r\nMy proposal mitigates the problem to two times.\r\n\r\n```\r\nclass C\r\n  def initialize(foo,    bar)\r\n                 ^^^@foo ^^^@bar\r\nend\r\n```\r\n\r\n\r\n## Patch\r\n\r\nA proof-of-concept is attached.\r\n\r\n```\r\n$ cat test.rb\r\np(2 * 3 * 7)\r\n  ^^^^^var\r\n\r\np var\r\n\r\n\r\nwhile gets != nil\r\n      ^^^^line\r\n  p line\r\nend\r\n\r\n\r\nary = [1, 2, 3, 4, 5]\r\n\r\nary.each {|elem| elem if elem.even? }\r\n                 ^^^^found\r\n\r\np found  #=> 4\r\n\r\n$ echo -e \"foo\\nbar\" | ./miniruby test.rb\r\n42\r\n6\r\n\"foo\\n\"\r\n\"bar\\n\"\r\n4\r\n```\r\n\r\nNotes:\r\n\r\n* The syntax allows only ASCII characters because [\"East Asian width\"](http://www.unicode.org/reports/tr11/) is a hell.\r\n* My patch does not implement binding a method parameter (Use case 3).\r\n* There are some known bugs. Look for them.\r\n\r\n\r\n## Compatibility\r\n\r\nA line that suddenly starts with `^` is invalid currently.\r\nThis is why I chose \"downward\" since upward assignments are incompatible.\r\n\r\n```\r\n      vvvv line\r\nwhile gets\r\n```\r\n\r\nWhen the previous line continues, `^` is appropriately handled as an XOR binary operator.\r\n\r\n```\r\nx = 1\r\n\r\n# The following is considered as: y = 2^x\r\ny = 2\\\r\n    ^x\r\n\r\np x  #=> 1\r\np y  #=> 3\r\n```\r\n\r\nSo, I think this proposal is 100% compatible.\r\n\r\n\r\n## Discussion\r\n\r\nI'm unsure how should we handle this.\r\n\r\n```\r\np(2 * 3 * 7)\r\n      ^^^^^var\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-04-01T00:10:31Z", "updated_on": "2021-04-02T12:13:37Z", "closed_on": "2021-04-02T12:13:37Z", "relations": []}, {"id": 17763, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9236, "name": "eileencodes (Eileen Uchitelle)"}, "subject": "Implement cache for cvars", "description": "# Introduce inline cache for class variable reads\r\n\r\n@tenderlove and I would like to introduce an inline cache for class variable reads. We've attached a patch that introduces the cache. Class variable reads are popular in Rails applications for example, Active Record's `#logger`.\r\n\r\nGitHub PR: https://github.com/ruby/ruby/pull/4340\r\n\r\n## Cache Design\r\n\r\nThis patch introduces a hash table that's stored on the same class as the class variable value.\r\n\r\nFor example:\r\n\r\n```ruby\r\nclass A\r\n  @@foo = 1\r\nend\r\n\r\nclass B < A\r\n  def self.read_foo\r\n    @@foo\r\n  end\r\nend\r\n```\r\n\r\nThe above code stores the value for `@@foo` on the `A` class and stores an inline cache value on the `A` class as well. The instruction sequences for the `read_foo` method point at the CVAR inline cache entry stored on class `A`.\r\n\r\nThe lifecycle of these caches are similar to instance variable inline caches.\r\n\r\n### Diagram of the cache:\r\n\r\n![cvar cache](https://gist.githubusercontent.com/eileencodes/ddd95be978df27eb76543d352d516449/raw/13e969320159a4e1bff9444694a1ac198e892237/cvar%2520cache@2x%2520(6).png)\r\n\r\n\r\n## Performance Characteristics\r\n\r\nWhen class variables are read, Ruby needs to check each class in the inheritance tree to ensure that the class variable isn't set on any other classes in the tree. If the same cvar is set on a class in the inheritance tree then a \"cvar overtaken\" error will be raised.\r\n\r\nBecause of how cvar reads work, the more classes in the inheritance tree the more expensive a cvar read is. To demonstrate this here is a benchmark that reads a cvar from a class with 1 module, 30 modules, and 100 modules in the inheritance chain. On Ruby master 100 modules is 8.5x slower than including 1 module. With the cache, there is no performance difference between including 1 module and including 100 modules.\r\n\r\nBenchmark script:\r\n\r\n```ruby\r\nrequire \"benchmark/ips\"\r\n\r\nMODULES = [\"B\", \"C\", \"D\", \"E\", \"F\", \"G\", \"H\", \"I\", \"J\", \"K\", \"L\", \"M\", \"N\", \"O\", \"P\", \"Q\", \"R\", \"S\", \"T\", \"U\", \"V\", \"W\", \"X\", \"Y\", \"Z\", \"AA\", \"BB\", \"CC\", \"DD\", \"EE\", \"FF\", \"GG\", \"HH\", \"II\", \"JJ\", \"KK\", \"LL\", \"MM\", \"NN\", \"OO\", \"PP\", \"QQ\", \"RR\", \"SS\", \"TT\", \"UU\", \"VV\", \"WW\", \"XX\", \"YY\", \"ZZ\", \"AAA\", \"BBB\", \"CCC\", \"DDD\", \"EEE\", \"FFF\", \"GGG\", \"HHH\", \"III\", \"JJJ\", \"KKK\", \"LLL\", \"MMM\", \"NNN\", \"OOO\", \"PPP\", \"QQQ\", \"RRR\", \"SSS\", \"TTT\", \"UUU\", \"VVV\", \"WWW\", \"XXX\", \"YYY\", \"ZZZ\", \"AAAA\", \"BBBB\", \"CCCC\", \"DDDD\", \"EEEE\", \"FFFF\", \"GGGG\", \"HHHH\", \"IIII\", \"JJJJ\", \"KKKK\", \"LLLL\", \"MMMM\", \"NNNN\", \"OOOO\", \"PPPP\", \"QQQQ\", \"RRRR\", \"SSSS\", \"TTTT\", \"UUUU\", \"VVVV\", \"WWWW\"]\r\nclass A\r\n  @@foo = 1\r\n\r\n  def self.foo\r\n    @@foo\r\n  end\r\n\r\n  eval <<-EOM\r\n    module #{MODULES.first}\r\n    end\r\n\r\n    include #{MODULES.first}\r\n  EOM\r\nend\r\n\r\nclass Athirty\r\n  @@foo = 1\r\n\r\n  def self.foo\r\n    @@foo\r\n  end\r\n\r\n  MODULES.take(30).each do |module_name|\r\n    eval <<-EOM\r\n      module #{module_name}\r\n      end\r\n\r\n      include #{module_name}\r\n    EOM\r\n  end\r\nend\r\n\r\nclass Ahundred\r\n  @@foo = 1\r\n\r\n  def self.foo\r\n    @@foo\r\n  end\r\n\r\n  MODULES.each do |module_name|\r\n    eval <<-EOM\r\n      module #{module_name}\r\n      end\r\n\r\n      include #{module_name}\r\n    EOM\r\n  end\r\nend\r\n\r\nBenchmark.ips do |x|\r\n  x.report \"1 module\" do\r\n    A.foo\r\n  end\r\n\r\n  x.report \"30 modules\" do\r\n    Athirty.foo\r\n  end\r\n\r\n  x.report \"100 modules\" do\r\n    Ahundred.foo\r\n  end\r\n\r\n  x.compare!\r\nend\r\n```\r\n\r\nRuby 3.0 master:\r\n\r\n```\r\nWarming up --------------------------------------\r\n            1 module     1.231M i/100ms\r\n          30 modules   432.020k i/100ms\r\n         100 modules   145.399k i/100ms\r\nCalculating -------------------------------------\r\n            1 module     12.210M (\u00b1 2.1%) i/s -     61.553M in   5.043400s\r\n          30 modules      4.354M (\u00b1 2.7%) i/s -     22.033M in   5.063839s\r\n         100 modules      1.434M (\u00b1 2.9%) i/s -      7.270M in   5.072531s\r\n\r\nComparison:\r\n            1 module: 12209958.3 i/s\r\n          30 modules:  4354217.8 i/s - 2.80x  (\u00b1 0.00) slower\r\n         100 modules:  1434447.3 i/s - 8.51x  (\u00b1 0.00) slower\r\n```\r\n\r\nRuby 3.0 with cvar cache:\r\n\r\n```\r\nWarming up --------------------------------------\r\n            1 module     1.641M i/100ms\r\n          30 modules     1.655M i/100ms\r\n         100 modules     1.620M i/100ms\r\nCalculating -------------------------------------\r\n            1 module     16.279M (\u00b1 3.8%) i/s -     82.038M in   5.046923s\r\n          30 modules     15.891M (\u00b1 3.9%) i/s -     79.459M in   5.007958s\r\n         100 modules     16.087M (\u00b1 3.6%) i/s -     81.005M in   5.041931s\r\n\r\nComparison:\r\n            1 module: 16279458.0 i/s\r\n         100 modules: 16087484.6 i/s - same-ish: difference falls within error\r\n          30 modules: 15891406.2 i/s - same-ish: difference falls within error\r\n```\r\n\r\n### Rails Application Benchmarks\r\n\r\nWe also benchmarked `ActiveRecord::Base.logger` since `logger` is a cvar and there are 63 modules in the inheritance chain. This is an example of a real-world improvement to Rails applications.\r\n\r\nBenchmark:\r\n\r\n```ruby\r\nrequire \"benchmark/ips\"\r\nrequire_relative \"config/environment\"\r\n\r\nBenchmark.ips do |x|\r\n  x.report \"logger\" do\r\n    ActiveRecord::Base.logger\r\n  end\r\nend\r\n```\r\n\r\nRuby 3.0 master:\r\n\r\n```\r\nWarming up --------------------------------------\r\n              logger   155.251k i/100ms\r\nCalculating -------------------------------------\r\n```\r\n\r\nRuby 3.0 with cvar cache:\r\n\r\n```\r\nWarming up --------------------------------------\r\n              logger     1.546M i/100ms\r\nCalculating -------------------------------------\r\n              logger     14.857M (\u00b1 4.8%) i/s -     74.198M in   5.006202s\r\n```\r\n\r\nWe also measured database queries in Rails and with the cvar cache they are about ~9% faster.\r\n\r\nBenchmark code:\r\n\r\n```ruby\r\nclass BugTest < Minitest::Test                                                                                                                               \r\n  def test_association_stuff                                                                                                                                 \r\n    post = Post.create!                                                                                                                                      \r\n                                                                                                                                                             \r\n    Benchmark.ips do |x|                                                                                                                                     \r\n      x.report \"query\" do                                                                                                                                    \r\n        Post.first                                                                                                                                           \r\n      end                                                                                                                                                    \r\n    end                                                                                                                                                      \r\n  end                                                                                                                                                        \r\nend                                                                                                                                                          \r\n```\r\n\r\nRuby 3.0 master / Rails 6.1:\r\n\r\n```\r\nWarming up --------------------------------------\r\n               query   790.000  i/100ms\r\nCalculating -------------------------------------\r\n               query      7.601k (\u00b1 3.8%) i/s -     38.710k in   5.100534s\r\n```\r\n\r\nRuby 3.0 cvar cache / Rails 6.1:\r\n\r\n```\r\nWarming up --------------------------------------\r\n               query   731.000  i/100ms\r\nCalculating -------------------------------------\r\n               query      7.089k (\u00b1 3.3%) i/s -     35.819k in   5.058215s\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-30T17:57:34Z", "updated_on": "2021-12-24T14:58:29Z", "closed_on": "2021-12-24T14:58:29Z", "relations": []}, {"id": 17762, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "A simple way to trace object allocation", "description": "How about having a short hand to `ObjectSpace.trace_object_allocations_start`, `ObjectSpace.allocation_sourcefile` and `ObjectSpace.allocation_sourceline`?\r\n\r\nThey are a very powerful tool for debugging and code-reading which allows us to identify an allocation site of an object.\r\nThough they are never lightweight, they are the last resort when you try debugging code written by someone else.\r\n\r\nHowever, the names are too long for me to remember and to type. Whenever I want to use them, I have to google, copy and paste the names.\r\n\r\n## Proposal\r\n\r\nTo enable trace allocations:\r\n\r\n```\r\nrequire \"objspace/trace\" #=> objspace/trace is enabled\r\n```\r\n\r\nTo show the allocation site of an object:\r\n\r\n```\r\np obj #=> #<Object:0x...> @ (file.rb):(lineno)\r\n```\r\n\r\n## Example\r\n\r\n```\r\nrequire \"objspace/trace\"\r\nrequire \"active_support/all\"\r\n\r\np ActiveSupport::VERSION::STRING\r\n  #=> \"6.1.3.1\" @ /home/mame/work/ruby/local/lib/ruby/gems/3.1.0/gems/activesupport-6.1.3.1/lib/active_support/gem_version.rb:15\r\n```\r\n\r\n## Discussion\r\n\r\nI've attached a simple patch that is originally authored by @ko1 .\r\n\r\n* Is the message `objspace/trace is enabled` needed or not?\r\n* To stop the trace, you need to use `ObjectSpace.trace_object_allocations_stop`. But, I guess that it is rare that we need to stop it during debugging.\r\n* Is it too radical to redefine `Kernel#p`? I think that it is good enough for many cases. When it matters, the original APIs (`ObjectSpace.trace_object_allocations_start`, ...) can be used.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-30T14:57:23Z", "updated_on": "2021-05-16T23:50:55Z", "closed_on": "2021-05-16T23:50:55Z", "relations": [{"id": 2919, "issue_id": 10932, "issue_to_id": 17762, "relation_type": "relates", "delay": null}]}, {"id": 17760, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 482, "name": "mrkn (Kenta Murata)"}, "subject": "Where we should install a header file when `gem install --user`?", "description": "As `digest` have been made a default gem at Ruby 3.0,  it can be installed by `gem install` command.\r\n\r\nWhen we install `digest`, `digest.h` is installed at the same directory as `ruby.h`.  But when we use `gem install --user` for installing it, where should `digest.h` is installed in?\r\n\r\nNow, the location of `digest.h` is always the same directory as `ruby.h` regardless of whether we use `gem install --user`.  It occurs permission error when non-root user uses `gem install --user` for installing `digest` on the system-ruby.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-30T00:50:44Z", "updated_on": "2021-10-21T09:41:29Z", "closed_on": "2021-03-30T14:20:24Z", "relations": [{"id": 2918, "issue_id": 17760, "issue_to_id": 17761, "relation_type": "relates", "delay": null}]}, {"id": 17758, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4551, "name": "kachick (Kenichi Kamiya)"}, "subject": "Provide Hash#count for performance improvement", "description": "GH-PR: https://github.com/ruby/ruby/pull/4333\r\n\r\nIn my experience, many developers choice `size`, `length` and `count` as a matter of taste.\r\nAnd Ruby already provide `Array#count` for performance improvement reason since https://github.com/ruby/ruby/commit/921fb6ae2593d07d35df0f1f487b9d64a0db9520\r\n\r\nSo how about to provide simple bridge implementation into Hash?\r\n\r\nI have checked the result with `benchmark-driver`, it looks made faster for no arguments pattern, and does not make much slower other arguments pattern.\r\nIt is compared with recently code https://github.com/ruby/ruby/tree/989e22f394c48aae301a0239cad14871dfa96d43.\r\n\r\n```console\r\n$ /Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby -v\r\nruby 3.1.0dev (2021-03-28T14:42:38Z master 989e22f394) [x86_64-darwin20]\r\n\r\n$ ./ruby -v\r\nruby 3.1.0dev (2021-03-28T17:45:56Z hash-count 94b052d7fa) [x86_64-darwin20]\r\n\r\n$ benchmark-driver benchmark/hash_count.yml -e /Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby -e ./ruby\r\n\r\nWarming up --------------------------------------\r\n               count                                                   94.814 i/s -     100.000 times in 1.054702s (10.55ms/i)\r\n      count_with_arg                                                   17.106 i/s -      18.000 times in 1.052250s (58.46ms/i)\r\n    count_with_block                                                   54.992 i/s -      60.000 times in 1.091072s (18.18ms/i)\r\nCalculating -------------------------------------\r\n                     /Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby      ./ruby \r\n               count                                                   92.080     40.571M i/s -     284.000 times in 3.084282s 0.000007s\r\n      count_with_arg                                                   20.483      20.571 i/s -      51.000 times in 2.489822s 2.479206s\r\n    count_with_block                                                   56.792      54.271 i/s -     164.000 times in 2.887742s 3.021896s\r\n\r\nComparison:\r\n                            count\r\n              ./ruby:  40571119.6 i/s \r\n/Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby:        92.1 i/s - 440608.36x  slower\r\n\r\n                   count_with_arg\r\n              ./ruby:        20.6 i/s \r\n/Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby:        20.5 i/s - 1.00x  slower\r\n\r\n                 count_with_block\r\n/Users/kachick/.rubies/ruby-3.1.0dev-989e22f394/bin/ruby:        56.8 i/s \r\n              ./ruby:        54.3 i/s - 1.05x  slower\r\n```\r\n\r\nHow do you think?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-28T18:21:24Z", "updated_on": "2021-03-28T18:39:04Z", "closed_on": null, "relations": []}, {"id": 17753, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Add Module#namespace", "description": "Given code like this:\r\n\r\n```ruby\r\nmodule A\r\n  module B\r\n    class C; end\r\n    class D; end\r\n  end\r\nend\r\n```\r\n\r\nWe can get from `C` to `B` like `C.outer_scope`, or to `A` like\r\n`C.outer_scope.outer_scope`.\r\n\r\nI want to use this in cases where I don't know the outer scope, but I\r\nwant to find constants that are \"siblings\" of a constant.  For example,\r\nI can do `A::B::C.outer_scope.constants` to find the list of \"sibling\"\r\nconstants to `C`.  I want to use this feature when walking objects and\r\nintrospecting.  For example:\r\n\r\n```ruby\r\nObjectSpace.each_object(Class) do |k|\r\n  p siblings: k.outer_scope.constants\r\nend\r\n```\r\n\r\nI've attached a patch that implements this feature, and there is a pull request on GitHub [here](https://github.com/ruby/ruby/pull/4326).", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-26T19:19:42Z", "updated_on": "2021-04-17T08:04:41Z", "closed_on": null, "relations": []}, {"id": 17752, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "assigned_to": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Enable -Wundef for C extensions in repository", "description": "I would like to enable `-Wundef` for C extensions built/bundled with CRuby.\r\n\r\nFrom https://gcc.gnu.org/onlinedocs/gcc/Warning-Options.html\r\n> -Wundef\r\n>    Warn if an undefined identifier is evaluated in an #if directive. Such identifiers are replaced with zero.\r\n\r\nI found this warning to be quite useful, notably when investigating why a given C extension did not include some code I expected, and then building those extensions on TruffleRuby.\r\n\r\nThere are a couple places not respecting this currently but they seem trivial to fix, I can do that.\r\n\r\nFor instance a confusing case is:\r\nhttps://github.com/ruby/ruby/blob/9143d21b1bf2f16b1e847d569a588510726d8860/ext/nkf/nkf-utf8/nkf.h#L19\r\n```\r\n#if DEFAULT_NEWLINE == 0x0D0A\r\n```\r\nwhich without -Wundef would just exclude the code without any warning if DEFAULT_NEWLINE is not defined.\r\n\r\nI'm not sure if we should/can enable it for C extensions in general (installed as gems), as if a C extensions uses -Werror and would have such a warning it would no longer build.\r\n\r\nI can make a PR for this.\r\nI'm not sure where to add -Wundef though, should it be in https://github.com/ruby/ruby/blob/9143d21b1bf2f16b1e847d569a588510726d8860/configure.ac#L620, or maybe in mkmf.rb?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-26T17:04:39Z", "updated_on": "2021-05-05T12:38:10Z", "closed_on": "2021-05-05T12:38:10Z", "relations": [{"id": 2932, "issue_id": 17752, "issue_to_id": 17850, "relation_type": "relates", "delay": null}]}, {"id": 17750, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "assigned_to": {"id": 50, "name": "duerst (Martin D\u00fcrst)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Update Unicode data to Unicode Version 13.0.0", "description": "The newest version of Unicode is Unicode 13.0.0 since about one year (see http://www.unicode.org/versions/Unicode13.0.0/). We should finally update Ruby to use Unicode 13.0.0, and probably also backport the result to Ruby 3.0. This issue serves as the main issue for this update; if necessary, I'll create sub-issues.\r\n\r\nCurrently, I don't expect any major issues (stuff that would require rewriting code) for this upgrade, but I'll check again carefully.\r\n\r\nOne problem I know of is that Unicode changed the structure of their directories somewhat. This may affect the Ruby makefile infrastructure. ", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-26T06:48:38Z", "updated_on": "2021-08-17T08:15:20Z", "closed_on": "2021-08-17T08:15:20Z", "relations": [{"id": 3018, "issue_id": 14802, "issue_to_id": 17750, "relation_type": "relates", "delay": null}, {"id": 3022, "issue_id": 17750, "issue_to_id": 18028, "relation_type": "relates", "delay": null}, {"id": 3023, "issue_id": 17750, "issue_to_id": 18027, "relation_type": "relates", "delay": null}, {"id": 3024, "issue_id": 17750, "issue_to_id": 18029, "relation_type": "relates", "delay": null}, {"id": 3027, "issue_id": 17750, "issue_to_id": 18037, "relation_type": "relates", "delay": null}, {"id": 3267, "issue_id": 15321, "issue_to_id": 17750, "relation_type": "relates", "delay": null}, {"id": 3019, "issue_id": 18022, "issue_to_id": 17750, "relation_type": "blocks", "delay": null}]}, {"id": 17749, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Const source location without name", "description": "Hi,\r\n\r\nI would like to be able to ask a class or module what its source location is without knowing the name.  For example, I want to do this:\r\n\r\n```ruby\r\nmodule A\r\n  class B\r\n  end\r\nend\r\n\r\np A::B.const_source_location\r\n```\r\n\r\nIn other works `A::B.const_source_location` would be equivalent to `A.const_source_location(:B)`.\r\n\r\nThe reason I want to do this is because sometimes it is very difficult to get the name of a constant, and sometimes I don't have access to the constant that \"encloses\" the class or module.\r\n\r\nOne example:\r\n\r\n```ruby\r\nObjectSpace.each_object(Class) do |k|\r\n  p k.const_source_location\r\nend\r\n```\r\n\r\nIn this case I have class objects, but I can't tell what constant `k` was defined *inside* of.  Also I can't trust the \"name\" method on `k` because sometimes it's not the default method (of course I could work around that, but it's not fun).\r\n\r\nI've attached a patch that implements the feature, and there is a PR [here](https://github.com/ruby/ruby/pull/4324)\r\n\r\nSide note: I think I would like \"source_location\" better than `const_source_location`, but I wanted to just file a feature request so we could talk about the feature in general.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-25T23:29:48Z", "updated_on": "2021-04-17T07:38:06Z", "closed_on": null, "relations": [{"id": 2927, "issue_id": 13383, "issue_to_id": 17749, "relation_type": "relates", "delay": null}]}, {"id": 17745, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4551, "name": "kachick (Kenichi Kamiya)"}, "subject": "`IO#close_on_exec=` returns different value when called with `send, __send__, public_send` or not", "description": "```console\r\n$ ruby -v -e 'p(STDIN.close_on_exec = 42)'\r\nruby 3.0.0p0 (2020-12-25 revision 95aff21468) [x86_64-darwin20]\r\n42\r\n```\r\n\r\n```console\r\n$ ruby -v -e 'p(STDIN.__send__ :close_on_exec=, 42)'\r\nruby 3.0.0p0 (2020-12-25 revision 95aff21468) [x86_64-darwin20]\r\nnil\r\n```\r\n\r\nIs this an intentional behavior?\r\n`ruby/spec` has the test case, But I can't think any benefit this different returning value \ud83e\udd14  \r\n\r\nPR: https://github.com/ruby/ruby/pull/4321", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-24T16:22:04Z", "updated_on": "2021-07-20T12:46:58Z", "closed_on": "2021-07-20T12:46:58Z", "relations": []}, {"id": 17744, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Accumulate `Enumerable#tally` results", "description": "A [feature request] at [DevelopersMeeting20200317Japan]:\r\n> * ko1: want to accumulate `Enumerable#tally` results\r\n>\r\n>     ```ruby\r\n>     h = {}\r\n>     [:a,:b,:c].tally(h)\r\n>     [:a,:b,:d].tally(h)\r\n>\r\n>     p h #=> {:a=>2, :b=>2, :c=>1, :d=>1}\r\n>     ```\r\n>\r\n> * matz: looks good. please create a proposal\r\n\r\n[DevelopersMeeting20200317Japan]: https://hackmd.io/nNo0Sb3nRCmQpIwR8XvusA#Other-topics-3\r\n[feature request]: https://github.com/ruby/ruby/pull/4318", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-24T13:10:58Z", "updated_on": "2021-03-26T07:29:43Z", "closed_on": "2021-03-26T07:29:43Z", "relations": []}, {"id": 17743, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 28908, "name": "p8 (Petrik de Heus)"}, "subject": "Show argument types in backtrace", "description": "Given the following Ruby program:\r\n``` ruby\r\ndef say_hi(person)\r\n  puts message(person)\r\nend\r\n\r\ndef message(person)\r\n  \"hi: #{person.name}\"\r\nend\r\n\r\nsay_hi(nil)\r\n```\r\n\r\nIt would be helpful if the backtrace contained the types of the argumets:\r\n```\r\nhi.rb:6:in `message': undefined method `name' for nil:NilClass (NoMethodError)\r\n\tfrom hi.rb:2:in `say_hi' called with NilClass\r\n\tfrom hi.rb:9:in `<main>' called with NilClass\r\n```\r\n\r\nInspired by the following Twitter thread: https://twitter.com/lzsthw/status/1374350046909628423\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-24T09:05:35Z", "updated_on": "2021-03-25T18:39:35Z", "closed_on": null, "relations": []}, {"id": 17741, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51073, "name": "rickmark (Rick Mark)"}, "subject": "Ruby links to `objc` for convenience - this should be moved into a native ext", "description": "As a convenance to extension developers Ruby on macOS always links to libobjc.  This could be better handled with a native ObjC extension so that one could `require 'objc'` to add this to the process.\r\n\r\nThe extension would link to libobjc and provide bindings to `objc_msgSend` and friends.  By not linking to libobjc we can also avoid linking to libc++abi and all that entails.\r\n\r\nThis makes ruby on mac more similar to ruby when compiled on other platforms.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-22T19:56:50Z", "updated_on": "2021-03-23T01:24:24Z", "closed_on": null, "relations": [{"id": 2916, "issue_id": 17730, "issue_to_id": 17741, "relation_type": "relates", "delay": null}]}, {"id": 17730, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 51073, "name": "rickmark (Rick Mark)"}, "subject": "Ruby on macOS transitively links to ~150 dylibs", "description": "By using `-framework Security` and `-framework Foundation` Ruby 3 pulls in about 150 dylibs when compiled for macOS\r\n\r\nBy using CoreCrypto / CoreFoundation I was able to reduce this to ~50.  This greatly reduces Ruby's surface area and dependencies on macOS.  Further CoreFoundation is only used for one call in the entire codebase of `CFStringNormalize(m, kCFStringNormalizationFormC);` - if we can replace this, Ruby could work with only `libSystem` and `libgmp`.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-18T19:16:43Z", "updated_on": "2021-03-22T22:42:10Z", "closed_on": "2021-03-19T07:41:43Z", "relations": [{"id": 2916, "issue_id": 17730, "issue_to_id": 17741, "relation_type": "relates", "delay": null}]}, {"id": 17724, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11242, "name": "jnchito (Junichi Ito)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "Make the pin operator support instance/class/global variables ", "description": "When I use pattern match with instance variables, I get an error message like \"expecting local variable or method\"\r\n\r\n``` ruby\r\n@n = 1\r\ncase 1\r\nin ^@n\r\n  # ...\r\nend\r\n#=> syntax error, unexpected instance variable, expecting local variable or method (SyntaxError)\r\n#   in ^@n\r\n#       ^~\r\n```\r\n\r\nHowever using method is not allowed, either.\r\n\r\n``` ruby\r\ndef n = 1\r\ncase 1\r\nin ^n\r\n  # ...\r\nend\r\n#=> n: no such local variable (SyntaxError)\r\n```\r\n\r\nI think the message \"expecting local variable or method\" is confusing and should be fixed like \"expecting local variable.\"\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-15T01:40:47Z", "updated_on": "2021-07-15T16:56:45Z", "closed_on": "2021-07-15T16:56:45Z", "relations": []}, {"id": 17721, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8741, "name": "bughit (bug hit)"}, "subject": "Proc.new should be able to contruct a lambda", "description": "since procs and lambdas are of the same type, as long as Proc::new exists, it should be able to create either.\r\n\r\n```ruby\r\nclass Proc\r\n  def augment\r\n    self.class.new lambda? do \r\n      call\r\n    end\r\n  end\r\nend\r\n```\r\n    ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-12T18:58:14Z", "updated_on": "2021-12-03T11:52:51Z", "closed_on": "2021-12-02T18:45:02Z", "relations": []}, {"id": 17718, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "a method paramaters object that can be pattern matched against", "description": "```ruby\r\ndef get_perdiem(city: nil, state: nil, zip:nil)\r\n\r\n  case parameters_match  # (return an object of the parameters we can pattern match on)\r\n  in {zip: zip}\r\n     find_perdiem_by_zip(zip)\r\n  in {state: s, city: c}\r\n     find_perdiem_by_state_and_city(s, c)\r\n  in { state: s}\r\n     find_perdiem_by_state(s)\r\n  else\r\n     raise 'need combination of zip, city,state'\r\n  end\r\nend\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-11T21:46:35Z", "updated_on": "2021-03-24T13:29:47Z", "closed_on": null, "relations": []}, {"id": 17685, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "Marshal format for out of band buffer objects", "description": "Allow the use of the marshal protocol to transmit large data (objects) from one process or ractor to another, on same machine or multiple machines without extra memory copies of the data.\r\n\r\nSee Python PEP 574 - https://www.python.org/dev/peps/pep-0574/ Pickle protocol with out of band data.\r\n\r\nWhen marshalling memoryview objects, it would be nice to be able to use zero copy loads of the memoryviews. That way when loading the file we can use that memoryview without copying it also if desired.\r\n\r\nAdd a Marshal::Buffer type in new version of Marshal to represent something that indicates a serializable no-copy buffer view.\r\n\r\nThe marshal_dump must be able to represent references to a Marshal::Buffer to indicate that the loader might get the actual buffer out of band\r\n\r\nThe marshal_load must be able to provide the Marshal::Buffer for deserialization\r\n\r\nMarshal load and dump should work normally if not used out of band.\r\n\r\n```ruby\r\nclass Apache::Arrow\r\n  \r\n  def marshal_dump(*)\r\n     if marshal.version > '0.4'\r\n         Marshal::Buffer.new(self)\r\n     else\r\n        #normal dump\r\n     end\r\n  end\r\nend\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-10T17:43:37Z", "updated_on": "2021-03-24T07:39:50Z", "closed_on": "2021-03-24T07:39:50Z", "relations": []}, {"id": 17684, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "subject": "Remove `--disable-gems` from release version of Ruby", "description": "In my understand, `--disable-gems` is only debugging feature for ruby-core team.\r\n\r\nBut some users enabled its option in test environment for performance or etc. So, `--disable-gems` option is wrong usage for some users.\r\n\r\n* https://github.com/rubygems/bundler/issues/7487#issuecomment-569901549\r\n* https://github.com/rubygems/rubygems/pull/4440#issue-587031184\r\n\r\nWe should remove it from package version of ruby.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-10T12:51:46Z", "updated_on": "2021-03-17T06:39:49Z", "closed_on": "2021-03-17T06:37:08Z", "relations": [{"id": 3185, "issue_id": 17684, "issue_to_id": 18376, "relation_type": "relates", "delay": null}, {"id": 3258, "issue_id": 17684, "issue_to_id": 18568, "relation_type": "relates", "delay": null}]}, {"id": 17682, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11019, "name": "Dan0042 (Daniel DeLorme)"}, "subject": "String#casecmp performance improvement", "description": "I've submitted a PR with up to 27x speedup for `String#casecmp`: https://github.com/ruby/ruby/pull/4133\r\nAccording to [HowToContribute][1] it looks like I was supposed to create a ticket for \"non-tiny\" fixes so I'm now doing this.\r\n\r\nOne point of discussion is that I added a flag for ascii-safe encodings (which is different from ascii-compatible) but I'm not sure hardcoding this list in `enc_register_at` is the correct way to do this. I just didn't see how else. So I'd appreciate some comments/guidance on this. Thank you.\r\n\r\nAlso I didn't find anything in the wiki about naming conventions so I just went by gut feeling. So there may be functions/macros to rename to be more in line with the rest of the codebase.\r\n\r\n\r\n[1]: https://bugs.ruby-lang.org/projects/ruby/wiki/HowToContribute", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-09T15:12:12Z", "updated_on": "2021-03-24T14:29:28Z", "closed_on": null, "relations": []}, {"id": 17674, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12118, "name": "AlexWayfer (Alexander Popov)"}, "subject": "Proposal: `Method#source_location` or `Method#owner` for refined methods", "description": "Inspired by https://bugs.ruby-lang.org/issues/15504#note-17\r\n\r\nI'm working on a gem with Ruby refinements, and some methods are invented in new Ruby versions like 2.5 or 3.0, and I'd like to define in this gem should I refine a method or not.\r\n\r\nSo\u2026 current behavior of `Method#source_location` returns `nil` for core and/or refined methods. I think, refinements should be caught by this method. Also I didn't know about `Method#owner`, but it can be a case for refinements too.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-06T21:24:14Z", "updated_on": "2021-03-15T23:15:34Z", "closed_on": "2021-03-15T23:15:34Z", "relations": []}, {"id": 17670, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance Float#to_i", "description": "\r\nImprove performance `Float#to_i` and `Float#to_int` methods(write in Ruby)\r\n\r\nbenchmark:\r\n```yml\r\nprelude: |\r\n  flo = 4.2\r\nbenchmark:\r\n  to_i: |\r\n    flo.to_i\r\n  to_int: |\r\n    flo.to_int\r\nloop_count: 20000000\r\n\r\n```\r\n\r\nresult:\r\n```bash\r\nsh@DESKTOP-L0NI312:~/rubydev/build$ make benchmark/benchmark.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby\r\ngenerating vm_call_iseq_optimized.inc\r\nvm_call_iseq_optimized.inc unchanged\r\ncompare-ruby: ruby 3.1.0dev (2021-02-28T11:24:42Z master 80e2c45f55) [x86_64-linux]\r\nbuilt-ruby: ruby 3.1.0dev (2021-02-28T11:24:42Z improve_float_to_i 80e2c45f55) [x86_64-linux]\r\n# Iteration per second (i/s)\r\n\r\n|        |compare-ruby|built-ruby|\r\n|:-------|-----------:|---------:|\r\n|to_i    |     69.184M|   78.294M|\r\n|        |           -|     1.13x|\r\n|to_int  |     69.891M|   80.285M|\r\n|        |           -|     1.15x|\r\n```\r\n\r\n`COMPARE_RUBY` is `ruby 3.1.0dev (2021-02-28T11:24:42Z master 80e2c45f55) [x86_64-linux]`. `BENCH_RUBY` is ahead of `ruby 3.1.0dev (2021-02-28T11:24:42Z master 80e2c45f55) [x86_64-linux]`.\r\n\r\npull request: https://github.com/ruby/ruby/pull/4234", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-03-02T13:14:54Z", "updated_on": "2021-12-02T18:31:16Z", "closed_on": "2021-12-02T18:31:16Z", "relations": []}, {"id": 17663, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 12584, "name": "RichOrElse (Ritchie Buitre)"}, "subject": "Enumerator#with, an alternative to Enumerator#with_object", "description": "**Enumerator#with** yields each element along with the arguments\r\n``` ruby\r\nclass Enumerator\r\n  def with(*options)\r\n    return to_enum(:with, *options) unless defined? yield\r\n\r\n    each do |entry|\r\n      yield entry, *options\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nSuppose we have a proc that accepts more than 1 argument.\r\n``` ruby\r\nformat = proc do |value, *option|\r\n  value.to_s(*option)\r\nend\r\n``` \r\nNormally to apply the argument we enclosed it in a block, like so:\r\n``` ruby\r\n(10..15).map { |n| format.(n, 16) } # => [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\r\n```\r\nI found **Enumerator#with_object** method awkward to use.\r\n``` ruby\r\n(10..15).each.with_object(16).map(&format) # => [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\r\n```\r\nTried simplifying this code further, but **Enumerator#with_object** ignores the given block and just returns the argument.\r\n``` ruby\r\n(10..15).map.with_object(16, &format) # => 16\r\n```\r\nCompare to how concise this line using **Enumerator#with** \r\n``` ruby\r\n(10..15).map.with(16, &format)  # => [\"a\", \"b\", \"c\", \"d\", \"e\", \"f\"]\r\n\r\n```\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-27T17:23:33Z", "updated_on": "2021-03-02T17:48:46Z", "closed_on": null, "relations": []}, {"id": 17660, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Expose information about which basic methods have been redefined", "description": "I would like to tell if code is redefining methods that can impact\r\nMRI's optimizations.  This commit exposes which basic methods have been\r\nredefined.  For example:\r\n\r\n```ruby\r\nclass Integer\r\n  def +(x); x ** self; end\r\nend\r\n\r\np RubyVM.redefined_methods # => {Integer=>[:+]}\r\n```\r\n\r\nThis will allow us to prevent basic method redefinitions from happening\r\nby checking for them in CI environments.  For example:\r\n\r\n```ruby\r\nMinitest.after_run {\r\n  fail \"Basic methods have been redefine\" if RubyVM.redefined_methods.any?\r\n}\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-27T00:30:46Z", "updated_on": "2021-03-02T15:31:02Z", "closed_on": null, "relations": []}, {"id": 17651, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10206, "name": "kddeisz (Kevin Newton)"}, "subject": "CSV::Row pattern matching", "description": "", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-23T14:15:46Z", "updated_on": "2021-02-23T21:54:04Z", "closed_on": "2021-02-23T21:54:04Z", "relations": []}, {"id": 17647, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "subject": "Print register `r11` on 32-bit ARM Linux", "description": "In (32-bit) ARM, register `r11` is a general purpose register which is often used as the frame pointer (`fp`), and there seems no reason not to print the value of it. In fact, the value of the (potential) frame pointer is printed for every other architecture; `x29` (or `fp` in Apple) in Aarch64, `EBP` in i386, `RBP` in x86_64, and `s0` in RISC-V.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-20T10:04:32Z", "updated_on": "2021-04-30T11:22:00Z", "closed_on": null, "relations": []}, {"id": 17640, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 15736, "name": "foonlyboy (Eike Dierks)"}, "subject": "allow // for comments", "description": "- ruby uses '#' for comments (from the sh heritage)\r\n- js and css use '//' for comments (from the C++ heritage)\r\n\r\nI'd like to discuss,\r\nto allow '//' in ruby code for comments\r\n\r\nMotivation:\r\n- writing comments is good\r\n- it's cumbersome to adapt the comments to the language currrently active\r\n\r\nImpact:\r\n\r\nPlease check:\r\n- '//' is not a token in ruby?\r\n- there is no way to make a legal expression involving '//'?\r\n- oops ... the empty regexp literal is //\r\n\r\nThis is where the things get complicated\r\nin terms of full backwards compatibility.\r\n\r\nBut I think that can be done.\r\n'//i' is a legal expression,\r\nwhile '// i' never was?\r\n\r\nAnyways, I just want to put this on for a first discussion.\r\n \r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-17T18:07:16Z", "updated_on": "2021-02-19T02:10:51Z", "closed_on": "2021-02-19T02:10:51Z", "relations": []}, {"id": 17638, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "assigned_to": {"id": 5, "name": "naruse (Yui NARUSE)"}, "subject": "Support backtracing with the libbacktrace library", "description": "It seems that Ruby's current `addr2line.c` has trouble with the DWARF 5 debugging format (Bug #17585).\r\n\r\nI propose that there be an option to use the libbacktrace library instead of `addr2line.c`.\r\n\r\nA patch is attached for that. When using libbacktrace, the C level backtrace information looks as follows:\r\n```\r\n-- C level backtrace information -------------------------------------------\r\n0x7f0cc2b3b372 rb_vm_bugreport\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_dump.c:1047\r\n0x7f0cc291e188 rb_bug_for_fatal_signal\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/error.c:801\r\n0x7f0cc2a8a137 sigsegv\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/signal.c:960\r\n0x7f0cc281a9bf ???\r\n\t???:0\r\n0x7f0cc247ddf7 ???\r\n\t???:0\r\n0x7f0cc2a8990d rb_f_kill\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/signal.c:481\r\n0x7f0cc2a2e684 proc_rb_f_kill\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/process.c:8604\r\n0x7f0cc2b0f2a4 ractor_safe_call_cfunc_m1\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:2734\r\n0x7f0cc2b0fecb vm_call_cfunc_with_frame\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:2924\r\n0x7f0cc2b10088 vm_call_cfunc\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:2945\r\n0x7f0cc2b11b3b vm_call_method_each_type\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:3414\r\n0x7f0cc2b11fde vm_call_method\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:3507\r\n0x7f0cc2b121ca vm_call_general\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:3550\r\n0x7f0cc2b144e7 vm_sendish\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm_insnhelper.c:4525\r\n0x7f0cc2b1b196 vm_exec_core\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/insns.def:789\r\n0x7f0cc2b308f5 rb_vm_exec\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm.c:2162\r\n0x7f0cc2b316e8 rb_iseq_eval_main\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/vm.c:2419\r\n0x7f0cc292778d rb_ec_exec_node\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/eval.c:317\r\n0x7f0cc29278d3 ruby_run_node\r\n\t/var/tmp/ruby.build/ruby-devel-x86_64/eval.c:375\r\n0x55ad53234234 main\r\n\t./main.c:47\r\n0x7f0cc2468e59 ???\r\n\t???:0\r\n0x55ad532340f9 ???\r\n\t???:0\r\n0xffffffffffffffff ???\r\n\t???:0\r\n```\r\n\r\nThe source code of libbacktrace is available from: https://github.com/ianlancetaylor/libbacktrace", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-17T13:03:12Z", "updated_on": "2021-03-05T15:40:08Z", "closed_on": null, "relations": []}, {"id": 17633, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 50204, "name": "fidalgo (Paulo Fidalgo)"}, "subject": "Wrong place", "description": "Sorry, I've created the report on the wrong place. Can be deleted/closed.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-16T13:33:14Z", "updated_on": "2021-12-23T23:40:09Z", "closed_on": "2021-02-18T13:44:40Z", "relations": []}, {"id": 17632, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance some Numeric methods", "description": "Improve performance some `Nuemric` methods(write in Ruby)\r\n\r\nbenchmark:\r\n```yml\r\nprelude: |\r\n  int = 42\r\n  flo = 4.2\r\nbenchmark:\r\n  real?: |\r\n    int.real?\r\n  integer?: |\r\n    flo.integer?\r\n  finite?: |\r\n    int.finite?\r\n  infinite?: |\r\n    int.infinite?\r\nloop_count: 20000000\r\n\r\n```\r\n\r\nresult:\r\n```bash\r\nsh@DESKTOP-L0NI312:~/rubydev/build$ make benchmark/numeric_methods.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby\r\ngenerating vm_call_iseq_optimized.inc\r\nvm_call_iseq_optimized.inc unchanged\r\ncompare-ruby: ruby 3.1.0dev (2021-02-15T09:29:35Z master 37b90bcdc1) [x86_64-linux]\r\nbuilt-ruby: ruby 3.1.0dev (2021-02-15T13:18:32Z improve_numeric_me.. 349c5721ad) [x86_64-linux]\r\nlast_commit=Improve Numeric methods\r\n# Iteration per second (i/s)\r\n\r\n|           |compare-ruby|built-ruby|\r\n|:----------|-----------:|---------:|\r\n|real?      |     90.157M|  106.604M|\r\n|           |           -|     1.18x|\r\n|integer?   |     93.559M|  105.397M|\r\n|           |           -|     1.13x|\r\n|finite?    |     90.229M|  104.325M|\r\n|           |           -|     1.16x|\r\n|infinite?  |     89.233M|  113.647M|\r\n|           |           -|     1.27x|\r\n\r\n```\r\n\r\n`COMPARE_RUBY` is `ruby 3.1.0dev (2021-02-15T09:29:35Z master 37b90bcdc1) [x86_64-linux]`. BENCH_RUBY is ahead of `ruby 3.1.0dev (2021-02-15T09:29:35Z master 37b90bcdc1) [x86_64-linux]`.\r\n\r\npull request:\r\nhttps://github.com/ruby/ruby/pull/4190", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-16T11:03:31Z", "updated_on": "2021-02-19T19:12:00Z", "closed_on": "2021-02-19T19:12:00Z", "relations": []}, {"id": 17627, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7486, "name": "keithrbennett (Keith Bennett)"}, "subject": "Suggestion: Implement `freeze_values` instance method on collection-like classes.", "description": "Suggestion: Implement `freeze_values` instance method on collection-like classes.\r\n\r\nBy collection-like classes, I mean classes such as Array, Hash, Set, Struct, OpenStruct, and custom classes containing multiple objects.\r\n\r\nThere has been some discussion of a recursive `deep_freeze` method, and although it could be very useful, there are potential problems regarding unintended consequences, and guarding against these would make the implementation more complex.\r\n\r\nThis complexity could be greatly reduced if we limit the scope of the freeze to only one level, and have the new `freeze_values` method call `freeze`.\r\n\r\nThe implementation would be trivial, I think. For example:\r\n\r\n```\r\nclass Array  # same for Set\r\n  def freeze_values\r\n    each(&:freeze)\r\n  end\r\nend\r\n\r\nclass Hash\r\n  def freeze_values\r\n    values.each(&:freeze)\r\n  end\r\nend\r\n```\r\n\r\nThere would still be a risk that the programmer would call this when some values should not be frozen, but that risk would be smaller and more manageable.\r\n\r\nAlso, there are many cases in which these collections contain simple objects such as strings and numbers. In these cases, recursion would not be necessary or helpful.\r\n\r\nAlthough it could be argued that the implementation is so trivial that it does not need a method implemented, I believe that:\r\n\r\n1) the method would nevertheless simplify the task, encouraging freezing\r\n2) the method name would be a higher level description of the operation, making the code more readable\r\n3) custom classes could implement this contract in their own way, yielding the benefits of polymorphism\r\n\r\nWhat do you think?\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-14T01:20:54Z", "updated_on": "2021-02-16T19:58:23Z", "closed_on": null, "relations": []}, {"id": 17616, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "subject": "Support backtracing on Linux with non-GNU-libc + libunwind", "description": "Currently, `vm_dump.c` assumes that the availability of `backtrace` implies the existence of `execinfo.h`, but it is not the case with non-GNU libc (e.g. musl or Bionic) Linux systems where libunwind is installed.\r\n\r\nA patch is attached to enable backtracing on those systems. With this patch, we modify `configure` so that it (1) always checks if `execinfo.h` exists, and that (2) when it cannot find that file on Linux, then checks if `unw_backtrace` is available.\r\n\r\nIn this patch, we assume (in `vm_dump.c`) that on Linux the availability of `unw_backtrace` implies the existence of `libunwind.h`. If it is not the case, a further modification will be needed.\r\n\r\nIt is preferable if we can choose between `backtrace` in glibc or `unw_backtrace` in libunwind when both are available. With this patch, the former is chosen by default, and the latter is chosen when `ac_cv_header_execinfo_h=no` is passed to `configure`.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-09T13:12:31Z", "updated_on": "2021-02-09T13:12:31Z", "closed_on": null, "relations": []}, {"id": 17615, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "subject": "Dump machine registers on RISC-V Linux", "description": "Dump every integer register that is either callee-saved or used for parameter passing on RISC-V Linux. An example output:\r\n```\r\n-- Machine register context ------------------------------------------------\r\n  sp: 0x0000004001801550  s0: 0x00000040018015b0  s1: 0x0000004000004bb0\r\n  a0: 0x0000000000000000  a1: 0x000000000000000b  a2: 0xffffffffffffffff\r\n  a3: 0x000000000000000b  a4: 0x000000000000000b  a5: 0x0000000000003934\r\n  a6: 0x0000004001ac2ebe  a7: 0x0000000000000081  s2: 0x00000040022a8058\r\n  s3: 0x0000000000000000  s4: 0x0000000000000000  s5: 0x0000000000000000\r\n  s6: 0x0000000000000000  s7: 0x0000000000000000  s8: 0x0000000000000000\r\n  s9: 0x0000000000000000 s10: 0x0000000000000000 s11: 0x0000000000000000\r\n```\r\n\r\nA patch is attached for this purpose. Please consider merging it.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-09T09:33:11Z", "updated_on": "2021-02-09T19:41:25Z", "closed_on": "2021-02-09T19:41:15Z", "relations": []}, {"id": 17614, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance Float#negative? and Float#positive?", "description": "Improve performance `Float#negative?` and `Float#positive?`(write in Ruby)\r\n\r\nbenchmark:\r\n```yml\r\nprelude: |\r\n  flo = 4.2\r\nbenchmark:\r\n  negative?: |\r\n    flo.negative?\r\n  positive?: |\r\n    flo.positive?\r\nloop_count: 20000000\r\n\r\n```\r\n\r\nresult:\r\n```bash\r\nsh@DESKTOP-L0NI312:~/rubydev/build$ make benchmark/benchmark.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby\r\ngenerating vm_call_iseq_optimized.inc\r\nvm_call_iseq_optimized.inc unchanged\r\ncompare-ruby: ruby 3.1.0dev (2021-02-08T12:46:07Z master 4186cd6435) [x86_64-linux]\r\nbuilt-ruby: ruby 3.1.0dev (2021-02-08T13:12:22Z improve_float_method 0dbc6d3f5f) [x86_64-linux]\r\n# Iteration per second (i/s)\r\n\r\n|           |compare-ruby|built-ruby|\r\n|:----------|-----------:|---------:|\r\n|negative?  |     80.954M|   94.642M|\r\n|           |           -|     1.17x|\r\n|positive?  |     79.471M|   95.963M|\r\n|           |           -|     1.21x|\r\n```\r\n\r\n`COMPARE_RUBY` is `ruby 3.1.0dev (2021-02-08T12:46:07Z master 4186cd6435) [x86_64-linux]`. BENCH_RUBY is ahead of `ruby 3.1.0dev (2021-02-08T12:46:07Z master 4186cd6435) [x86_64-linux]`.\r\n\r\npull requests:\r\nhttps://github.com/ruby/ruby/pull/4160\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-09T04:01:39Z", "updated_on": "2021-02-09T04:30:17Z", "closed_on": "2021-02-09T04:30:17Z", "relations": []}, {"id": 17613, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "Eliminate useless catch tables and nops from lambdas", "description": "This patch frees catch tables on iseqs that don't use the catch tables.  It also eliminates `nop` instructions from lambdas that don't need them.\r\n\r\nBefore this patch, lambdas have a \"prelude nop\" that is used for catch table entries:\r\n\r\n```\r\n$ ruby --dump=insn -e '1.times { |x| puts x }'\r\n== disasm: #<ISeq:<main>@-e:1 (1,0)-(1,22)> (catch: FALSE)\r\n== catch table\r\n| catch type: break  st: 0000 ed: 0004 sp: 0000 cont: 0004\r\n| == disasm: #<ISeq:block in <main>@-e:1 (1,8)-(1,22)> (catch: FALSE)\r\n| == catch table\r\n| | catch type: redo   st: 0001 ed: 0006 sp: 0000 cont: 0001\r\n| | catch type: next   st: 0001 ed: 0006 sp: 0000 cont: 0006\r\n| |------------------------------------------------------------------------\r\n| local table (size: 1, argc: 1 [opts: 0, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])\r\n| [ 1] x@0<Arg>\r\n| 0000 nop                                                              (   1)[Bc]\r\n| 0001 putself                                [Li]\r\n| 0002 getlocal_WC_0                          x@0\r\n| 0004 opt_send_without_block                 <calldata!mid:puts, argc:1, FCALL|ARGS_SIMPLE>\r\n| 0006 leave                                  [Br]\r\n|------------------------------------------------------------------------\r\n0000 putobject_INT2FIX_1_                                             (   1)[Li]\r\n0001 send                                   <calldata!mid:times, argc:0>, block in <main>\r\n0004 leave\r\n```\r\n\r\nBut since this particular lambda doesn't use the catch tables, there is no reason to keep the catch table or the `nop` instruction.  This patch eliminates the `nop` instructions as well as the unused catch tables:\r\n\r\n```\r\n> ruby --dump=insn -e '1.times { |x| puts x }'\r\n== disasm: #<ISeq:<main>@-e:1 (1,0)-(1,22)> (catch: FALSE)\r\n0000 putobject_INT2FIX_1_                                             (   1)[Li]\r\n0001 send                                   <calldata!mid:times, argc:0>, block in <main>\r\n0004 leave\r\n\r\n== disasm: #<ISeq:block in <main>@-e:1 (1,8)-(1,22)> (catch: FALSE)\r\nlocal table (size: 1, argc: 1 [opts: 0, rest: -1, post: 0, block: -1, kw: -1@-1, kwrest: -1])\r\n[ 1] x@0<Arg>\r\n0000 putself                                                          (   1)[LiBc]\r\n0001 getlocal_WC_0                          x@0\r\n0003 opt_send_without_block                 <calldata!mid:puts, argc:1, FCALL|ARGS_SIMPLE>\r\n0005 leave\r\n```\r\n\r\nIt's not huge, but this frees about 600kb of catch tables on RailsBench.  Here is a histogram of the catch tables and sizes freed for RailsBench:\r\n\r\n![Freed Catch Tables](https://user-images.githubusercontent.com/3124/107269241-2d723080-69fe-11eb-9bf7-64f102251df7.png)\r\n\r\nThe X axis is the catch table size, so the actually malloc'd size for 2 would be approximately `2 * sizeof(struct iseq_catch_table_entry)`.  So if we have 5 tables of size 2, that would be about `5 * 2 * sizeof(struct iseq_catch_table_entry)`.\r\n\r\nThe size of iseq_catch_table_entry is 32:\r\n\r\n```\r\n(lldb) p sizeof(struct iseq_catch_table_entry)\r\n(unsigned long) $0 = 32\r\n```\r\n\r\nThe total catch tables freed in RailsBench is 18275, so this frees about `18275 * 32` bytes, or about 584kb:\r\n\r\n```\r\n> sum(freed_table_sizes$V1)\r\n[1] 18275\r\n> sum(freed_table_sizes$V1) * 32\r\n[1] 584800\r\n```\r\n\r\nInstruction Sequence size is also reduced due to `nop` elimination, but I didn't measure it.\r\n\r\nFinally, this patch reduces `nop` calls on RailsBench from 6868813 ( 2.1%) to 2467772 ( 0.8%).\r\n\r\n`nop` instructions on the `master` branch (`265c002239`):\r\n\r\n```\r\n[RUBY_INSNS_COUNTER]\tnop                                  6868813 ( 2.1%)\r\n```\r\n\r\n`nop` instructions with this patch applied:\r\n\r\n```\r\n[RUBY_INSNS_COUNTER]\tnop                                  2467772 ( 0.8%)\r\n```\r\n\r\nPull request is [here](https://github.com/ruby/ruby/pull/4125)", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-08T19:37:58Z", "updated_on": "2021-02-16T22:01:10Z", "closed_on": "2021-02-16T22:01:10Z", "relations": [{"id": 3210, "issue_id": 17613, "issue_to_id": 18474, "relation_type": "relates", "delay": null}, {"id": 3212, "issue_id": 17613, "issue_to_id": 18475, "relation_type": "relates", "delay": null}]}, {"id": 17611, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Expose `rb_execarg` interfaces and `rb_grantpt`", "description": "An opaque `struct rb_execarg` has been added 9 years ago, and the latest change on functions deal with it was 3 years ago.\r\nAlso, it has been 3 years since `rb_grantpt` was added.\r\nThese seem stable enough to expose now, but are still internal, and stopping pty from becoming a gem.\r\n\r\nMaybe `rb_grantpt` can be more generic, e.g., calling a function with supspending `waitpid`, though.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-07T01:52:40Z", "updated_on": "2021-02-07T01:52:40Z", "closed_on": null, "relations": []}, {"id": 17610, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "subject": "[PATCH] Reduce RubyVM::InstructionSequence.load_from_binary allocations", "description": "Pull Request: https://github.com/ruby/ruby/pull/4119\r\n\r\n### Context\r\n\r\nWhile profiling our application allocations, I noticed `load_from_binary` would allocate a string for each method:\r\n\r\n```\r\n 305.68 kB    7642  \"initialize\"\r\n              7454  bootsnap-1.5.1/lib/bootsnap/compile_cache/iseq.rb:19\r\n```\r\n\r\nThis lead me to experiment with the following repro script:\r\n```ruby\r\n# frozen_string_literal: true\r\n\r\nrequire 'objspace'\r\nObjectSpace.trace_object_allocations_start\r\npreload = [:some_func, :some_sym, :Foo, :extend, \"Foo\"]\r\n\r\nclass Foo;end\r\nclass Bar;end\r\n\r\nbinary = RubyVM::InstructionSequence.compile(<<~RUBY).to_binary\r\n  class Foo\r\n    def initialize\r\n    end\r\n  end\r\n\r\n  class Bar\r\n    def initialize\r\n    end\r\n  end\r\nRUBY\r\n\r\n4.times { GC.start }\r\nGC.disable\r\ngen = GC.count\r\nRubyVM::InstructionSequence.load_from_binary(binary)\r\nRubyVM::InstructionSequence.load_from_binary(binary)\r\n\r\nputs ObjectSpace.dump_all(output: :string, since: gen).lines.grep(/\"type\":\"STRING\"/)\r\n```\r\n\r\nOn 3.0.0p0 it allocates 12 strings:\r\n```json\r\n{\"address\":\"0x7f90e7027a40\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":11, \"value\":\"<class:Bar>\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027ab8\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":3, \"value\":\"Bar\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027ae0\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":11, \"value\":\"<class:Foo>\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027b08\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":10, \"value\":\"<compiled>\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027b58\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":10, \"value\":\"initialize\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027ba8\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":3, \"value\":\"Foo\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":27, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027cc0\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":11, \"value\":\"<class:Bar>\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027d38\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":3, \"value\":\"Bar\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027d60\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":11, \"value\":\"<class:Foo>\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027d88\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":10, \"value\":\"<compiled>\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027dd8\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":10, \"value\":\"initialize\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n{\"address\":\"0x7f90e7027e28\", \"type\":\"STRING\", \"class\":\"0x7f90e78be870\", \"embedded\":true, \"bytesize\":3, \"value\":\"Foo\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":26, \"method\":\"load_from_binary\", \"generation\":13, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n```\r\n\r\nFor a good part, these allocated strings are immediately passed to `rb_str_intern` to get a symbol, and since constant and method names are very likely to be referenced elsewhere in the application source, most of the time the symbol already exist and could be looked up without first allocating a String.\r\n\r\n### This patch\r\n\r\nBy using `rb_intern3` and `rb_enc_interned_str`, we can lookup existing symbols and fstrings without allocating anything.\r\n\r\nThe same repro script with this patch only allocate a single string:\r\n```json\r\n{\"address\":\"0x7f88ec8dfde8\", \"type\":\"STRING\", \"class\":\"0x7f88ec8be800\", \"frozen\":true, \"embedded\":true, \"fstring\":true, \"bytesize\":10, \"value\":\"<compiled>\", \"encoding\":\"US-ASCII\", \"file\":\"/tmp/load.rb\", \"line\":25, \"method\":\"load_from_binary\", \"generation\":4, \"memsize\":40, \"flags\":{\"wb_protected\":true}}\r\n```\r\n\r\n### Performance\r\n\r\nI added a small micro benchmark which show minor gains:\r\n\r\n```\r\ncompare-ruby: ruby 3.1.0dev (2021-01-21T19:19:44Z master 32b7dcfb56) [x86_64-darwin19]\r\nbuilt-ruby: ruby 3.1.0dev (2021-01-25T09:58:02Z iseq-load-symbol 6b0e2c1580) [x86_64-darwin19]\r\n# Iteration per second (i/s)\r\n\r\n|               |compare-ruby|built-ruby|\r\n|:--------------|-----------:|---------:|\r\n|symbol         |    447.846k|  489.421k|\r\n|               |           -|     1.09x|\r\n|define_method  |    113.035k|  117.016k|\r\n|               |           -|     1.04x|\r\n|all            |     61.421k|   64.382k|\r\n|               |           -|     1.05x|\r\n```\r\n\r\nIn a more real world scenario, this patch reduce `load_from_binary` number of allocations by 65%  ( and number of allocations by `7.7%` during our entire application's boot process) (`~1.7M` allocations avoided):\r\n\r\nBefore:\r\n\r\n```\r\nallocated memory by location\r\n-----------------------------------\r\n 429.56 MB  bootsnap-1.5.1/lib/bootsnap/compile_cache/iseq.rb:19\r\n\r\nallocated objects by location\r\n-----------------------------------\r\n  2748272  bootsnap-1.5.1/lib/bootsnap/compile_cache/iseq.rb:19\r\n```\r\n\r\nAfter:\r\n\r\n```\r\nallocated memory by location\r\n-----------------------------------\r\n 346.06 MB  bootsnap-1.5.1/lib/bootsnap/compile_cache/iseq.rb:19\r\n\r\nallocated objects by location\r\n-----------------------------------\r\n    960451  bootsnap-1.5.1/lib/bootsnap/compile_cache/iseq.rb:19\r\n```\r\n\r\n\r\n\r\nAnd WALL profiling show much less time spent in `load_from_binary`:\r\n\r\n3.0.0-p0:\r\n```\r\n==================================\r\n  Mode: wall(1000)\r\n  Samples: 57745 (13.29% miss rate)\r\n  GC: 16369 (28.35%)\r\n==================================\r\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\r\n      6500  (11.3%)        6497  (11.3%)     RubyVM::InstructionSequence.load_from_binary\r\n``` \r\n\r\n3.0.0-p0 + this patch:\r\n```\r\n==================================\r\n  Mode: wall(1000)\r\n  Samples: 46137 (13.32% miss rate)\r\n  GC: 14094 (30.55%)\r\n==================================\r\n     TOTAL    (pct)     SAMPLES    (pct)     FRAME\r\n      3333   (7.2%)        3331   (7.2%)     RubyVM::InstructionSequence.load_from_binary\r\n```\r\n\r\nI tried measuring the same thing on popular open source applications like Redmine or Discourse, unfortunately I couldn't make them work on Ruby 3.0 yet.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-04T11:33:37Z", "updated_on": "2021-03-15T06:12:30Z", "closed_on": "2021-03-15T06:12:30Z", "relations": []}, {"id": 17608, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Compact and sum in one step", "description": "Many use cases of `Array#sum` are preceded with the `compact` method or are followed by a block to ensure the value is addable.\r\n\r\n```ruby\r\na = [1, nil, 2, 3]\r\n\r\na.sum # !> TypeError\r\n\r\na.compact.sum # => 6\r\n\r\na.sum{_1 || 0} # => 6\r\n```\r\n\r\nI propose there should be a way to do that in one step. I request either of the following:\r\n\r\nA. Change the current behaviour to skip `nil`s.\r\n\r\n```ruby\r\na.sum # => 6\r\n```\r\n\r\nB. `Array#filter_sum` method\r\n\r\n```ruby\r\na.filter_sum # => 6\r\n```\r\n\r\nC. An option for `Array#sum` \r\n\r\n```ruby\r\na.sum(compact: true) # => 6\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-02-04T06:18:38Z", "updated_on": "2021-03-16T10:58:51Z", "closed_on": "2021-02-05T20:03:43Z", "relations": []}, {"id": 17601, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "lib/benchmark: adding `Benchmark::Tms#to_h`", "description": "It seems useful to add `to_h` method to benchmark output.\r\n\r\nI'll take care of that unless there's objection.\r\n\r\nSee https://github.com/ruby/benchmark/pull/4", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-31T17:11:24Z", "updated_on": "2021-02-08T04:06:42Z", "closed_on": "2021-02-08T04:06:42Z", "relations": []}, {"id": 17598, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2, "name": "Anonymous"}, "subject": "\u76f4\u5f8c\u306e\u6539\u884c\u3092\u7121\u8996\u3059\u308b\u547d\u4ee4\uff08......\uff09", "description": "\u6539\u884c\u3092\u7121\u8996\u3059\u308b\u547d\u4ee4\u3001\u4eca `\\(\\n)` \u3068\u306a\u3063\u3066\u3044\u308b\u547d\u4ee4\u306b\u3064\u3044\u3066\u3067\u3059\u3002 `......` \u3092\u63d0\u6848\u3057\u307e\u3059\u3002\r\n\r\n```ruby\r\n(0... ......\r\n5).each ......\r\n.map{_1} ...... # some comments\r\n=> ar\r\n# (0...5).each.map{_1} => ar\r\n```\r\n\r\n(1) \u672c\u5f53\u306f `...` \u304c\u4e00\u756a\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u3057\u304b\u3057 Range \u3067\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u3002\r\n(2) \u4e00\u756a\u826f\u3044\u306e\u304c\u4f7f\u3048\u306a\u3044\u306a\u3089\u9577\u304f\u3057\u3088\u3046\u3002 `......`\r\n(3) \u5b9f\u969b\u306b\u4f7f\u3046\u306e\u306a\u3089 `....` \u304c\u59a5\u5f53\uff1f\r\n(4) `....` \u3068 `......` \u306e\u4e21\u65b9\u4f5c\u3063\u3061\u3083\u3048\u3002\r\n\r\n\u79c1\u306f\u5b9f\u9a13\u7684\u306b (2) \u3092\u5e0c\u671b\u3057\u307e\u3059\u3002", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-30T13:13:56Z", "updated_on": "2021-02-03T01:13:18Z", "closed_on": "2021-02-03T01:13:18Z", "relations": []}, {"id": 17597, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2, "name": "Anonymous"}, "subject": "\u76f4\u5f8c\u306e\u6539\u884c\u3092\u7121\u8996\u3059\u308b\u547d\u4ee4\uff08......\uff09", "description": " \u6539\u884c\u3092\u7121\u8996\u3059\u308b\u547d\u4ee4\u3001\u4eca \\(\\n) \u3068\u306a\u3063\u3066\u3044\u308b\u547d\u4ee4\u306b\u3064\u3044\u3066\u3067\u3059\u3002 ...... \u3092\u63d0\u6848\u3057\u307e\u3059\u3002\r\n \r\n (0... ......\r\n 5).each ......\r\n .map{_1} ...... # some comments\r\n => ar\r\n  # (0...5).each.map{_1} => ar\r\n \r\n \r\n (1) \u672c\u5f53\u306f ... \u304c\u4e00\u756a\u826f\u3044\u3068\u601d\u3044\u307e\u3059\u3002\u3057\u304b\u3057 Range \u3067\u4f7f\u308f\u308c\u3066\u3044\u307e\u3059\u3002\r\n (2) \u4e00\u756a\u826f\u3044\u306e\u304c\u4f7f\u3048\u306a\u3044\u306a\u3089\u9577\u304f\u3057\u3088\u3046\u3002 ......\r\n (3) \u5b9f\u969b\u306b\u4f7f\u3046\u306e\u306a\u3089 .... \u304c\u59a5\u5f53\uff1f\r\n (4) .... \u3068 ...... \u306e\u4e21\u65b9\u4f5c\u3063\u3061\u3083\u3048\u3002\r\n \r\n \u79c1\u306f\u5b9f\u9a13\u7684\u306b (2) \u3092\u5e0c\u671b\u3057\u307e\u3059\u3002", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-30T09:40:58Z", "updated_on": "2021-01-31T08:14:42Z", "closed_on": "2021-01-31T08:14:42Z", "relations": []}, {"id": 17593, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7941, "name": "byroot (Jean Boussier)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "load_iseq_eval should override the ISeq path", "description": "Full context in https://github.com/Shopify/bootsnap/pull/343\r\n\r\nConsider the following script\r\n\r\n```ruby\r\nsystem('mkdir', '-p', '/tmp/build', '/tmp/app')\r\nFile.write('/tmp/app/a.rb', 'p [\"app/a\", __FILE__, __dir__]')\r\nFile.write('/tmp/app/b.rb', 'p [\"app/b\", __FILE__, __dir__]')\r\nFile.write('/tmp/build/a.rb', 'p [\"build/a\", __FILE__, __dir__]; require_relative \"b\"')\r\n\r\n$iseq = RubyVM::InstructionSequence.compile_file('/tmp/build/a.rb')\r\n\r\nclass RubyVM::InstructionSequence\r\n  def self.load_iseq(feature)\r\n    if feature == \"/tmp/app/a.rb\"\r\n      $iseq\r\n    end\r\n  end\r\nend\r\n\r\nrequire '/tmp/app/a.rb'\r\n```\r\n\r\nCurrent behavior:\r\n\r\n```ruby\r\n[\"build/a\", \"/tmp/build/a.rb\", \"/private/tmp/build\"]\r\n/tmp/build/a.rb:1:in `require_relative': cannot load such file -- /private/tmp/build/b (LoadError)\r\n\tfrom /tmp/build/a.rb:1:in `<main>'\r\n\tfrom <internal:/opt/rubies/3.0.0-pshopify2/lib/ruby/3.0.0/rubygems/core_ext/kernel_require.rb>:85:in `require'\r\n\tfrom <internal:/opt/rubies/3.0.0-pshopify2/lib/ruby/3.0.0/rubygems/core_ext/kernel_require.rb>:85:in `require'\r\n\tfrom /tmp/iseq_debug.rb:16:in `<main>'\r\n```\r\n\r\nExpected behavior\r\n\r\n```ruby\r\n[\"build/a\", \"/private/tmp/app/a.rb\", \"/private/tmp/app\"]\r\n[\"app/b\", \"/private/tmp/app/b.rb\", \"/private/tmp/app\"]\r\n```\r\n\r\n### What's going on?\r\n\r\n`RubyVM::InstructionSequence` instances have a `pathobj` property that is recorded when the source is parsed, and when the ISeq is later evaled, the VM use that `path` as if you were loading a `.rb` file located at that path.\r\n\r\nSo if that source use constructs such as `require_relative`, `__FILE__`, `__dir__`, etc, they will all happen relative to where the source was located upon compilation, not relative to the source was upon evaluation.\r\n\r\n### Why is it a problem?\r\n\r\nSome deployment strategies first build the application in one location, and then later move it elsewhere. \r\n\r\nThat's for instance the case on the Heroku platform. e.g. the deploy looks like\r\n\r\n```bash\r\ngit clone <repo> /tmp/build_xxxx\r\ncd /tmp/build_xxxx\r\nrake assets:precompile ...\r\nmv /tmp/build_xxxx /app\r\n```\r\n\r\nBecause of this, all the ISeq cached by bootsnap when the code was in `/tmp/build_xxx` have to be invalidated as soon as the source is moved to `/app`, rendering ISeq caching ineffective, and even detrimental as it causes extra writes to disk without bringing any benefits.\r\n\r\n### Solution\r\n\r\nI believe there are two changes that would be needed.\r\n\r\nFirst I think that `load_iseq_eval` should set the `fname` as the top stack location. Either by copying the ISeq instance and change its `pathobj`, or by having a way to pass an optional path to `vm_set_top_stack` that would take precedence.\r\n\r\nI experimented with [a quick hack that changes the ISeq `pathobj` in place](https://github.com/Shopify/ruby/commit/192f5b477f924243e3f6621383e7a6ad02fbd63d), and it does solve most of the problem.\r\n\r\nHowever even with that quick hack another problem remain, the `__FILE__` still evaluate to the original source location. However `__dir__` works as expected, because it is a method that returns the top_stack location. I think `__FILE__` could be changed to be a method as well.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-29T18:05:42Z", "updated_on": "2021-02-16T08:27:23Z", "closed_on": null, "relations": []}, {"id": 17592, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor should allowing reading shareable class instance variables", "description": "It would be very helpful if Ractor was allowing reading class instance variables from non-main Ractor.\r\n\r\n\r\nCurrently is raises an IsolationError:\r\n\r\n```ruby\r\nmodule Foo\r\n  singleton_class.attr_accessor :config\r\n  Foo.config = {example: 42}.freeze\r\nend\r\n\r\nRactor.new { p Foo.config } # => IsolationError\r\n```\r\n\r\nThis limitation makes it challenging to have an efficient way to store general configs, i.e. global data that mutated a few times when resources get loaded but it immutable afterwards, and needs to be read all the time.\r\n\r\nCurrently the only way to do this is to use a constant and use `remove_const` + `const_set` (which can not be made atomic easily).\r\n\r\nI think that allowing reading only may be the best solution to avoid any race condition, e.g. two different Ractors that call `@counter += 1`.\r\n\r\nThe only 3 scenarios I see here are:\r\n0) declare the constant hack the official way to store config-style data\r\n1) allow reading of instance variables for shareable objects (as long as the data is shareable)\r\n2) allow read-write\r\n\r\nI prefer 1)", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-29T15:29:19Z", "updated_on": "2021-10-22T16:33:51Z", "closed_on": "2021-10-22T16:33:51Z", "relations": [{"id": 3113, "issue_id": 18193, "issue_to_id": 17592, "relation_type": "duplicates", "delay": null}]}, {"id": 17579, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3414, "name": "shevegen (Robert A. Heiler)"}, "subject": "[Proposal] A suggestion for newline-separated shorthand notation, for the creation of Arrays containing strings that may contain ' ' (space) characters", "description": "New year, new proposal! :)\r\n\r\nSummary (TL;DR) of the proposal first: It is here proposed that ruby adds functionality to allow ruby users to create arrays, with (string) members inside that array that may contain ' ' (space) characters.\r\n\r\nThis is akin to, as a shorthand notation, to well known variants like the following one here:\r\n\r\n    %w( foo bar ) # => [\"foo\", \"bar\"]\r\n\r\n(Note that this creates two members in the array, \"foo\" and \"bar\"; my suggestion here is about creating a single String with ' ' one space, e. g. \"foo bar\" in the example above. Note that I do NOT suggest to change the existing %w() syntax; we would need another syntax for this in my opinion, ideally also just one character.)\r\n\r\nSince ruby code is often significantly simpler to understand than a long sentence, let me next show you what I mean with the proposal above.\r\n\r\nConsider the following array:\r\n\r\n    array = [\r\n      'foo bar',\r\n      'bar foo',\r\n      'tom the cat',\r\n      'jerry the mouse'\r\n    ]\r\n\r\nHere we have an array with four members; four string objects, each containing at the least one ' ' (space) character. It may also include strings that do not contain any ' ' though.\r\n\r\nRuby offers several shorthand notations to create arrays.\r\n\r\nA very popular one, and in my (not systematic) opinion probably the most commonly used variant, found in many gems, ruby users use this pattern here commonly:\r\n\r\n    array = %w( one two three )\r\n    # or other \"container\" tokens used, such as:\r\n    array = %w[ one two three ]\r\n    array = %w{ one two three }\r\n\r\nToday I had a use case to create the following array:\r\n\r\n    array = [\r\n      'choice 1',\r\n      'choice 2',\r\n      'choice 3',\r\n      'choice 4',\r\n      'choice 5',\r\n      'choice 6',\r\n      'choice 7',\r\n      'choice 8'\r\n    ]\r\n\r\nThis is ok, syntax-wise; also efficient, so the suggestion here is not that important actually.\r\n\r\nBut!\r\n\r\nI also wondered whether we ruby users COULD actually use a shorter variant for precisely situations like the above. (For anyone wondering why I made such a strange array, I actually wanted to create simple radio-buttons for ruby-gtk, as a \"drop-down\" choice, so I needed a simple array where the user can select one of these different variants, before hitting the \"send\" or \"submit\" button. So the above acted mostly as a place holder for prototyping code. In general I make use of %w() a lot though, so perhaps that is why it felt \"natural\" for me to want to try to look for simpler ways here. %w() is really very efficient IMO.)\r\n\r\nOf course my first \"logical\" attempt would not work:\r\n\r\n    array = %w(\r\n      choice 1\r\n      choice 2\r\n      choice 3\r\n      choice 4\r\n      choice 5\r\n      choice 6\r\n      choice 7\r\n      choice 8\r\n    )\r\n    # => [\"choice\", \"1\", \"choice\", \"2\", \"choice\", \"3\", \"choice\", \"4\", \"choice\", \"5\", \"choice\", \"6\", \"choice\", \"7\", \"choice\", \"8\"]\r\n\r\nThis of course won't work due to the ' ' and %w() splitting on ' '. But the syntax is quite elegant, yes? Short and succinct - it is nice and efficient.\r\n\r\nSo, I was then wondering whether we **could** have a variant that **also** includes the ' ', and splits on newlines rather than ' '.\r\n(For spacing reasons all leading ' ' are also ignored on the newline. This could be argued about either way, but I probably would prefer to be able to retain such a uniform styling in my .rb files, sort of like how %w() can be used. So my whole idea is really mostly aimed at %w(), just with newline splitting rather than ' ' splitting.)\r\n\r\nI wondered whether we could re-use EOF with there here-doc token. Example what I mean here:\r\n\r\n    heredoc = <<-EOF\r\n      choice 1\r\n      choice 2\r\n      choice 3\r\n      choice 4\r\n      choice 5\r\n      choice 6\r\n      choice 7\r\n      choice 8\r\n    EOF\r\n\r\nJust an array, rather than a string. Would be quite efficient. (Evidently heredoc will NOT ignore leading ' ' so it is a bit different anyway.)\r\n\r\nBut then I was thinking ... I am already using newlines there, for readability purposes, see above. So my array will be spread over multiple new lines. So, one new line, one new array element - quite simple! And this is **the** **gist** of my suggestion here really:\r\n\r\n\r\n- A way to create arrays in ruby based on newlines.\r\n\r\n\r\nIf a variant already exists that splits on newlines by default, please disregard this suggestion then. My mind was thinking mostly about shorthand-notation syntax here.\r\n\r\nAs for the syntax for this suggestion ... I am not sure ... this is perhaps the hardest part, because the syntax should be short too, as otherwise the advantage of succinctness would be lessened.\r\n\r\nSo, what do we have available in ruby? Let's look.\r\n\r\nWe have, for array of strings:\r\n\r\n    %w() # I'll ignore the {} and [], so this is just to compile what we have right now.\r\n\r\nArray of Symbols:\r\n\r\n    %i( foo bar ) # see the old SO discussion here, if anyone is curious https://stackoverflow.com/questions/8816877/is-there-a-literal-notation-for-an-array-of-symbols\r\n\r\nFor regular expressions we have:\r\n\r\n    %r()\r\n\r\nFor single-quoted strings and multi-line strings we have:\r\n\r\n    %q()\r\n\r\nDouble-quoted string:\r\n\r\n    %Q()\r\n\r\nShell command:\r\n\r\n    %x() # I don't think I ever used this one actually ... I always use system() or `` and sometimes the popen-family\r\n\r\n    %s() # strange one here ... turns foo into a symbol (:foo). Peculiar ...\r\n\r\nI quickly compared the last one with %i():\r\n\r\n     %s( foo ) # => :\" foo \"\r\n     %i( foo ) # => [:foo]\r\n\r\nI did not know about %s. How odd. :)\r\n\r\nAnyway. My proposal here is about making the \"split\" based on newlines, just as the array example above (e. g. array = [ 'choice 1', etc..) showed.\r\n\r\nI am not entirely sure which shorthand syntax should be used. Ideally we should not use too many shorthand notations in general, because ruby users may have a hard time remembering all of this; I can never remember the old perly $ variables, always have had to look up in a cheat sheet file or had to back when they were more commonly used.\r\n\r\nBut, since these elements in the array are still strings, perhaps they should remain with the %w() syntax family.\r\n\r\nSo, I was thinking, based on that ... something like %wn( ) for a newline?\r\n\r\nLike:\r\n\r\n    array = %wn(\r\n      choice 1\r\n      choice 2\r\n      choice 3\r\n      choice 4\r\n      choice 5\r\n      choice 6\r\n      choice 7\r\n      choice 8\r\n    ) # = ['choice 1','choice 2','choice 3','choice 4','choice 5','choice 6','choice 7','choice 8']\r\n\r\nAlthough, I am not sure ... it would be a simple change perhaps, just append a \"n\" character.\r\n\r\nI much prefer single letters, though. So I am not convinced about %wn. The \"n\" is meant to stand for \"newline\" or \"newlines\".\r\n\r\nPerhaps %n( ) for newline could be used? Or %W( ) could be used? Hmmmmm.\r\n\r\nSyntax choice is sooooo difficult if you want to make a good choice that people could use. Perhaps %W() is not so good\r\nbecause people may make a typo, and confuse it with %w. So %n may be better. Or %wn. (I am trying to \"remain\" in \r\na syntax \"family\", so that it may not be too obscure, although we could use another letter.)\r\n\r\nBut anyway, I believe it may be better to first decide whether this feature is good, useful, or totally pointless. And, based on that, e. g. if it is considered useful (possibly so), to then think more about the syntax choice for it. After all, if the idea is not useful, there is little point in wanting to find a useful syntax for it.\r\n\r\nPlease anyone feel free to comment if you would like to, and give ideas, pros and cons as to whether this may be useful to have or not. I think this can only be potentially useful IF other ruby users may have had a similar use case (because otherwise nobody would use it, so then it would be a mostly \"dead\" feature), but I am actually not even absolutely certain that the proposal is that useful.\r\n\r\nIt is probably quite a niche case idea; but who knows, perhaps at some later time, suggestions and ideas may be picked up again, so I think it would be useful to comment on this suggestion anyway, if only for future references alone. (Or perhaps it was already suggested years ago, I do not know.)\r\n\r\nHopefully I managed to make this suggestion readable; I was writing this in my local editor, as I have a hard time using webforum-based HTML interfaces in general.\r\n\r\nAt any rate, thanks for reading!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-25T11:15:59Z", "updated_on": "2021-01-25T16:33:29Z", "closed_on": null, "relations": []}, {"id": 17576, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 49133, "name": "temabolshakov (Tema Bolshakov)"}, "subject": "Partial Functions (procs, lambdas)", "description": "We already have pattern matching and functions. Let's combine them and introduce a \"partial procs\" as first-class citizens. \r\n\r\nWhat are partial procs? This is a function that works on a subset of arguments. The partial proc's main advantage is that a caller may decide in advance if this proc can accept an argument or not and do something different rather than calling it.\r\n\r\n\r\nThat's how it may look like:\r\n\r\n\r\n```ruby\r\npartial_proc = proc do |arg|\r\nin x if x.odd?\r\n  \"#{x} is odd\"\r\nend\r\n```\r\n\r\nOne can check if a proc is defined on the argument \r\n\r\n```ruby \r\npartial_proc.defined?(42) #=> false\r\npartial_proc.defined?(41) #=> true\r\n```\r\n\r\nYou can call such a partial proc and it raises an error when it's not defined on this argument:\r\n\r\n\r\n```ruby\r\npartial_proc.call(42) #=> raises NoMatchingPatternError (42)\r\npartial_proc.call(41) #=> 41 is odd\r\n```\r\n\r\nAnd finally, we can call or fallback to a default value:\r\n\r\n\r\n```ruby\r\npartial_proc.call_or_else(42) { \"fallback value\" } #=> 'fallback value'\r\npartial_proc.call_or_else(41) { \"fallback value\" } #=> 41 is odd\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-23T11:23:54Z", "updated_on": "2021-01-24T19:58:57Z", "closed_on": null, "relations": []}, {"id": 17570, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 31800, "name": "eightbitraptor (Matthew Valentine-House)"}, "subject": "Move C heap allocations into GC heap for RVALUE object data", "description": "## Feature\r\nMove C heap allocations into GC heap.\r\n\r\n## Pull Request:\r\n[4107](https://github.com/ruby/ruby/pull/4107)\r\n\r\n## Feature description\r\n`RVALUE` is fixed width (40 bytes), some of which is used for accounting information and the remainder being used for storage of the object data (e.g. string contents). If the data required is larger than the available space inside the `RVALUE`, memory is allocated outside of the GC heap using malloc and a pointer to the malloc\u2019d region is stored inside the `RVALUE` instead.\r\n\r\nWe intend to remove this extra memory allocation in favour of storing the extra data in a contiguous region of slots in the heap that are adjacent to the original `RVALUE`.\r\n\r\nThe proposed memory layout changes in this feature branch can be seen in the following diagrams.\r\n\r\nOriginal layout (master branch - with extra data being stored in malloc regions):\r\n\r\n![](https://i.imgur.com/RXNvZkK.png)\r\n\r\nNew layout (feature branch - with extra data being stored adjacent to it's owner in the GC heap):\r\n\r\n![](https://i.imgur.com/oRVgdkU.png)\r\n\r\nOur hypothesis is that this feature will improve performance across Ruby by\r\n \r\n* Improving locality, allowing better cache performance.\r\n* Increased memory efficiency as fragmented data outside of GC can now be controlled and compacted by the GC.\r\n* Reducing pointer indirection - as the extra object data (eg the Class `ivar` table) is in a predictable place, we can find it by using the object address plus some offset rather than hopping over pointers.\r\n* Eventually allowing us to remove the transient heap - The transient heap exists to reduce the number of these \"extra data\" malloc allocations. For new objects, the extra data is stored in a separate, pre-allocated heap, and then transferred to the C heap using `memcpy` once the data owner becomes an old object (survives 3 GC runs). This type of performance optimisation becomes redundant if we can store all object data in the eden heap.\r\n\r\n## Current status\r\n\r\nThis branch is the minimum viable implementation required to test our hypothesis. We introduce an API to allocate regions that are multiple slots wide in the heap and we implement this API for objects of type `T_CLASS` so that the `rb_classext_t` struct is stored in the heap alongside its owning `RVALUE`.\r\n\r\nThere are many things left to implement and some large things to fix. All of which will be addressed in future work, which we're working on at Shopify.\r\n\r\n* We have consciously traded allocation performance for simplicity in this initial approach as read performance is where we think there will be a significant gain.\r\n* GC Compaction is incompatible with this change. The current two finger algorithm is designed to support fixed width memory regions. When an object occupies multiple contiguous slots this algorithm no longer works.\r\n* Incremental marking is disabled when this feature is enabled. This is because we are unable to predict the allocation pattern in each mark step now that allocations can be multiple slots wide.\r\n* We cannot currently resize regions. For example, when mutating strings, we currently `realloc` one region to a new larger region, we will support resizing when all object data is in the eden heap.\r\n* This API is currently only implemented for `T_CLASS` objects, we need to implement it for all other Ruby types to gain the most benefit.\r\n\r\nWe believe this feature is useful enough that we'd like to merge this PR. We would like feedback from the Core team and the community. \r\n\r\nMerging this feature will also allow us to continue working without maintaining a long lived fork of Ruby. \r\n\r\nThere will be no negative effects of merging this PR as all functionality is disabled by default.\r\n\r\n## How to enable this feature\r\n\r\nThis feature must be enabled at compile time with the flag `USE_RVARGC`. E.g.\r\n\r\n```sh\r\ncppflags='-DUSE_RVARGC=1' ./configure\r\nmake clean && make && make install\r\n```\r\n\r\n## Performance\r\n\r\nWe ran the following snippet to generate a heap dump and then used [a separate script to visualise it](https://gist.github.com/peterzhu2118/9e32ee3b67ba85f400d463b7c211c2ae).\r\n```ruby\r\nrequire \"objspace\"\r\n\r\nObjectSpace.dump_all(output: File.open(\"heap.json\", \"w\"), full: true)\r\n```\r\n\r\nIn the following output each 2x2 pixel region represents a single slot in a heap page. Heap pages are organised vertically and from low to high memory address.\r\n\r\n![](https://i.imgur.com/sXYqdJQ.png)\r\n\r\n\r\n* Blue pixels represents `T_CLASS`\r\n* Yellow pixels represents `T_PAYLOAD` slots\r\n* Grey pixels are other live objects\r\n\r\nSo we can see that every `T_CLASS` is now followed by 3 `T_PAYLOAD` objects - this is because `sizeof(rb_classext_t) == 104` and the space available in 3 `T_PAYLOAD` slots is `112` (we require 8 bytes for bookkeeping).\r\n\r\nWe prepared a simple micro-benchmark in order to measure the speed of `ivar` access and method calls, as references to the method table and the ivar table are stored inside `rb_classext_struct`, which is always allocated on the malloc heap.\r\n\r\n```ruby\r\nrequire 'benchmark/ips'\r\n\r\nclass Foobar\r\n  def initialize\r\n    @foo = 3\r\n  end\r\n  \r\n  def foo\r\n    @foo\r\n    self\r\n  end\r\n  \r\n  def bar\r\n    @foo + 1\r\n    self\r\n  end\r\n  \r\n  def baz\r\n    @foo + 2\r\n    self\r\n  end\r\nend\r\n\r\n@f = Foobar.new\r\n\r\nBenchmark.ips do |x|\r\n  x.report(\"method & ivar lookup\") do |times|\r\n    i = 0\r\n    while i < times\r\n      @f.foo.bar.baz\r\n      i += 1\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nWe ran this 5 times on our branch and took the scores, and then again on master (at commit:32b7dcfb56a417c1d1c354102351fc1825d653bf - the base of our feature branch) and took the scores.\r\n\r\nThis graph shows the mean of our results combined with the standard error range for each set of samples.\r\n\r\n![](https://i.imgur.com/84GJ7CS.png)\r\n\r\n```\r\nMicro-benchmark: Million iterations per second, higher is better\r\n\r\nmaster:\r\n    16.372\r\n    16.399\r\n    16.058\r\n    15.98\r\n    16.426\r\n    \r\nfeature:\r\n    16.901\r\n    16.909\r\n    16.695\r\n    16.757\r\n    16.818\r\n```\r\n\r\nThis shows a ~3% improvement in our feature-branch over master on average, with the worst case (upper bound of standard error on master vs lower bound standard error on our feature branch) showing a ~2% improvement.\r\n\r\nWe also ran the optcarrot benchmark on each branch and the results were as follows:\r\n\r\n![](https://i.imgur.com/Q8EQRoE.png)\r\n\r\n```\r\nOptcarrot: Frames per second, higher is better\r\n\r\nmaster:\r\n    43.27430926\r\n    42.65007047\r\n    43.32562887\r\n    42.64047665\r\n    43.40328494\r\n    \r\nfeature:\r\n    41.59069356\r\n    40.51252649\r\n    40.55757381\r\n    41.76160937\r\n    42.95645122\r\n```\r\n\r\nThis shows a that our branch is ~4% slower than master (with the branch upper vs master lower standard error difference being ~2%).\r\n\r\nRaw benchmark numbers and the script used for generating these charts is [in this gist](https://gist.github.com/eightbitraptor/289d2713375034d6d8374d67f6cb7a27).\r\n\r\nDespite the Optcarrot performance drop we feel that these results are promising for the future of this work - taking into consideration our significantly worse allocation performance (improving allocation performance is a high priority part of our roadmap).\r\n\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-22T16:10:50Z", "updated_on": "2021-04-20T13:25:09Z", "closed_on": "2021-04-20T13:25:09Z", "relations": []}, {"id": 17566, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1320, "name": "mperham (Mike Perham)"}, "subject": "Tune thread QoS / efficiency on macOS", "description": "Hi, new Apple M1 processors have \"performance\" and \"efficiency\" cores. Apple provides a QoS API so threads can tune which cores they should execute on. Some threads should be executed as high-priority, some should be treated as low-priority.\r\n\r\nThis page shows the pthread APIs that Apple provides:\r\n\r\nhttps://developer.apple.com/library/archive/documentation/Performance/Conceptual/power_efficiency_guidelines_osx/PrioritizeWorkAtTheTaskLevel.html\r\n\r\n```\r\npthread_set_qos_class_self_np(QOS_CLASS_BACKGROUND, 0)\r\n```\r\n\r\nI noticed Ruby already provides `Thread#priority=` which says `This is just hint for Ruby thread scheduler. It may be ignored on some platform`. Does this API work still or was it only active for Ruby 1.8's green threads? Should this API use the QoS APIs on macOS?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-20T20:25:26Z", "updated_on": "2021-01-29T09:16:39Z", "closed_on": null, "relations": []}, {"id": 17562, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 44830, "name": "ima1zumi (Mari Imaizumi)"}, "subject": "Update -E option in --help", "description": "I would like to propose explaining the arguments of the -E option specifically in --help.\r\n\r\nThe current explanation is a bit difficult for beginners to understand.\r\nI tried to change `Encoding.default_internal`, but I changed `Encoding.default_external` by mistake. That confused me because I didn't know how to use it. Therefore, I have updated the explanation.\r\n\r\n\r\nbefore:\r\n```\r\n  -Eex[:in], --encoding=ex[:in]\r\n                  specify the default external and internal character encodings\r\n```\r\n\r\n\r\nafter:\r\n```\r\n  -Eexternal-encoding[:internal-encoding], --encoding=external-encoding[:internal-encoding]\r\n                  specify the default external and internal character encodings\r\n```\r\n\r\ndiff:\r\n```diff\r\ndiff --git a/ruby.c b/ruby.c\r\nindex 5bac96b5e1..4f8975a399 100644\r\n--- a/ruby.c\r\n+++ b/ruby.c\r\n@@ -281,7 +281,7 @@ usage(const char *name, int help, int highlight, int columns)\r\n        M(\"-Cdirectory\",   \"\",                     \"cd to directory before executing your script\"),\r\n        M(\"-d\",            \", --debug\",            \"set debugging flags (set $DEBUG to true)\"),\r\n        M(\"-e 'command'\",  \"\",                     \"one line of script. Several -e's allowed. Omit [programfile]\"),\r\n-       M(\"-Eex[:in]\",     \", --encoding=ex[:in]\", \"specify the default external and internal character encodings\"),\r\n+       M(\"-Eexternal-encoding[:internal-encoding]\",\", --encoding=external-encoding[:internal-encoding]\",\"specify the default external and internal character encodings\"),\r\n        M(\"-Fpattern\",     \"\",                     \"split() pattern for autosplit (-a)\"),\r\n        M(\"-i[extension]\", \"\",                     \"edit ARGV files in place (make backup if extension supplied)\"),\r\n        M(\"-Idirectory\",   \"\",                     \"specify $LOAD_PATH directory (may be used more than once)\"),\r\n```\r\n\r\nPR: https://github.com/ruby/ruby/pull/4099", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-19T16:42:45Z", "updated_on": "2021-01-19T17:38:11Z", "closed_on": null, "relations": []}, {"id": 17551, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7576, "name": "baweaver (Brandon Weaver)"}, "subject": "Pattern Matching - Default Object#deconstruct and Object#deconstruct_keys", "description": "Pattern Matching is a very powerful feature, but many classes are not able to enjoy its functionality due to the lacking of a default `deconstruct` and `deconstruct_keys` method being present.\r\n\r\nThis feature request is to introduce a series of sane defaults, and what they might look like. What these defaults are or should be is up for debate, but I would like to propose a few ideas to get things started.\r\n\r\n## Reasonable Defaults\r\n\r\n### The Fast Version\r\n\r\nI will elaborate on this in the below content, but the fast version of my proposal is:\r\n\r\n1. `deconstruct_keys` should default to a classes public API\r\n2. `deconstruct` should default to being an alias of `to_a` or other `Array` coercion methods\r\n\r\n### Deconstruct Keys\r\n\r\n`deconstruct_keys` is used for extracting values out of an object in use with a `Hash`-like pattern match. In the case of a literal `Hash` with `Symbol` keys the deconstructed keys are extracted from the `Hash`.\r\n\r\nMy proposal would be to base the default `deconstruct_keys` on the attributes of an object as defined by `attr_*` methods. Consider this `Person` class:\r\n\r\n```ruby\r\nclass Person\r\n  attr_reader :name, :age, :children\r\n  \r\n  def initialize(name:, age:, children: [])\r\n    @name     = name\r\n    @age      = age\r\n    @children = children\r\n  end\r\nend\r\n```\r\n\r\nThe attributes exposed by the proposed default `deconstruct_keys` would be `name`, `age`, and `children`.\r\n\r\nAs `attr_reader` has made these values public they are the interface into the class, meaning this will not break encapsulation of values and relies on the already established API it provides.\r\n\r\nIn current Ruby this behavior can be approximated as seen here in a test gem I call Dio: https://github.com/baweaver/dio#attribute-forwarder\r\n\r\nIt does a comparison of instance variables versus all methods to find public readers:\r\n\r\n```ruby\r\nivars = Set.new base_object\r\n  .instance_variables\r\n  .map { _1.to_s.delete('@').to_sym }\r\n\r\nall_methods = Set.new base_object.methods\r\n\r\nattributes = ivars.intersection(all_methods)\r\n```\r\n\r\nWhich allows me to do this:\r\n\r\n```ruby\r\nPerson.new(\r\n  name: 'Alice',\r\n  age: 40,\r\n  children: [\r\n    Person.new(name: 'Jim', age: 10),\r\n    Person.new(name: 'Jill', age: 10)\r\n  ]\r\n)\r\n\r\ncase Dio.attribute(alice)\r\nin { name: /^A/, age: 30..50 }\r\n  true\r\nelse\r\n  false\r\nend\r\n\r\ncase Dio.attribute(alice)\r\nin { children: [*, { name: /^J/ }, *] }\r\n  true\r\nelse\r\n  false\r\nend\r\n```\r\n\r\nMy list of ideas for this default `deconstruct_keys` method are:\r\n\r\n1. `attr_` based - Any exposed attribute\r\n2. public method based (`public_send`) - All public methods on the class\r\n3. all methods (`send`) - Every potential method\r\n\r\nI believe the first is the most conservative and Ruby-like, as well as the least surprising. A case could be made for the second which allows for more flexibility and remains within the encapsulation of the class. The third is more unrealistic as it exposes everything.\r\n\r\nI would like to discuss between the first two.\r\n\r\n### Deconstruct\r\n\r\n`deconstruct` is used for extracting values out of an object in use with an `Array`-like pattern match. In the case of an `Array` the values are returned directly.\r\n\r\nMy proposal would be to base the default `deconstruct` on the Ruby concept of Duck typing through `to_a` or `Enumerable`:\r\n\r\n```ruby\r\nmodule Enumerable\r\n  alias_method :deconstruct, :to_a\r\nend\r\n```\r\n\r\nConsider this `Node` class:\r\n\r\n```ruby\r\nclass Node\r\n  attr_reader :value, :children\r\n\r\n  def initialize(value, *children)\r\n    @value    = value\r\n    @children = children\r\n  end\r\n\r\n  def to_a() = [@value, @children]\r\n\r\n  def self.[](...) = new(...)\r\nend\r\n```\r\n\r\nIt is `Array`-like in nature, and through `to_a` we could infer `deconstruct` instead of explicitly requiring a method:\r\n\r\n```ruby\r\ntree = Node[1,\r\n  Node[2, Node[3, Node[4]]],\r\n  Node[5],\r\n  Node[6, Node[7], Node[8]]\r\n]\r\n\r\ncase tree\r\nin [1, [*, [5, _], *]]\r\n  true\r\nelse\r\n  false\r\nend\r\n```\r\n\r\nI believe this is a good use of duck typing, and presents a reasonable default. If no `Array` coercion methods are available it would make sense that it cannot be pattern matched against like an Array.\r\n\r\nMy proposal here is to use the established `to_a` or other `Array` coercion methods to imply `deconstruct`\r\n\r\n## Why Defaults?\r\n\r\nMany Ruby gems and code do not implement `deconstruct` or `deconstruct_keys`, meaning pattern matching cannot be used against them easily. This change will allow for pattern matching against Ruby code from any generation, and open up the feature to far more use across code bases.\r\n\r\nI believe this feature would not be substantial work to implement, but will have substantial gains for all Ruby code.\r\n\r\nThank you for your time in reading, and I apologize for another long feature request.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-18T04:25:24Z", "updated_on": "2021-01-19T04:07:38Z", "closed_on": "2021-01-19T04:07:38Z", "relations": []}, {"id": 17550, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48834, "name": "asfarley (Alexander Farley)"}, "subject": "Why no function to get all subdirectories of a directory?", "description": "Googling around, this seems to be a relatively common request. Would you be willing to accept a pull request implementing this  feature? ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-17T20:59:19Z", "updated_on": "2021-01-18T08:57:49Z", "closed_on": null, "relations": []}, {"id": 17548, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7486, "name": "keithrbennett (Keith Bennett)"}, "subject": "Need simple way to include symlink directories in Dir.glob", "description": "I would like to suggest that Ruby provide a simple way to glob that includes the content of symlinked directories.\r\n\r\nI have my Ruby projects in a `~/work` directory that is symlinked to a directory an another partition.\r\n\r\nFor example, `~` is on `/dev/sda1`, whereas `~/work` is a link to a directory on `/dev/sda2`. I need this because I want to operate on the same code bases regardless of which partition I boot from (they are various Linux distros).\r\n\r\nThe array returned by `Dir.glob(Dir.home, '**', '*rb')` does not include any files in ~/work. The size of that array is only 84. In contrast, when I use `find ~ -name \"*rb\" | wc -l` to get the number of files, I get 87,229 files.\r\n\r\nI was hoping that one of the flags that can be passed to `glob` would help, but the only relevant one I found was to *not* follow links, which is the opposite of what I wanted.\r\n\r\nThere are arcane workarounds using fancy glob patterns, but I believe it's important that the language provide a simple way to accomplish this. (For example, the Unix `find` command has an `-L` option for this.) I understand that it may not be possible to retrofit it into the existing functions (`glob` and `[]`), but even providing a different method (e.g. one named `glob_include_links`) would be ok. Or perhaps a `glob2` method could be added that would include simple ways to specify that files in hidden directories should be included, in addition to the option to follow symlinks.\r\n\r\nI admit that I have no idea how much effort this would be to implement, especially regarding Windows compatibility, but this would be nice to have.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-17T00:46:53Z", "updated_on": "2022-03-21T13:35:41Z", "closed_on": null, "relations": []}, {"id": 17546, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48178, "name": "xtkoba (Tee KOBAYASHI)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Native coroutine implementation for riscv64 Linux", "description": "The RISC-V architecture is getting more and more importance in the world. The first affordable RISC-V single board computer debuted last Wednesday.\r\n\r\nA patch is attached which contains a native coroutine implementation for riscv64 Linux, written in analogous to the existing arm64 version (developed from Feature #14739). Please consider merging it.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-15T23:48:37Z", "updated_on": "2021-03-30T06:24:00Z", "closed_on": "2021-03-30T06:24:00Z", "relations": []}, {"id": 17544, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "`Time#strftime` supports RFC 3339 UTC for unknown offset local time", "description": "In RFC 3339, -00:00 is used for the time in UTC is known, but the offset to local time is unknown.\r\nSupport that representation by `-` flag for `z` at `Time#strftime`.\r\n\r\n[patch](https://github.com/ruby/ruby/pull/4075)\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-15T08:54:49Z", "updated_on": "2021-02-16T11:34:43Z", "closed_on": "2021-02-16T11:34:43Z", "relations": []}, {"id": 17528, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10980, "name": "mohamedhafez (Mohamed Hafez)"}, "subject": "Make Addrinfo.getaddrinfo fall back to Timeout.timeout for :resolv_timeout", "description": "Currently, `Addrinfo.getaddrinfo` ignores the `:resolv_timeout` option if we are on a system without `getaddrinfo_a`. It would be great if instead it would fall back to using `Timeout.timeout`.\r\n\r\nThat way, we could get rid of a lot of the usage of `Timeout.timeout` for systems that *do* have `getaddrinfo_a`. For example, for Net::HTTP#connect we could easily then do something like this: https://github.com/ruby/ruby/compare/master...mohamedhafez:patch-3?diff=split.\r\n\r\nThe motivation for this is that the usage of Timeout.timeout is inherently unsafe, and it would be great to stop using it where we can (see https://www.mikeperham.com/2015/05/08/timeout-rubys-most-dangerous-api/ and http://blog.headius.com/2008/02/ruby-threadraise-threadkill-timeoutrb.html)  ", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-11T20:53:33Z", "updated_on": "2021-01-13T20:50:24Z", "closed_on": null, "relations": []}, {"id": 17525, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1913, "name": "Glass_saga (Masaki Matsushita)"}, "assigned_to": {"id": 1913, "name": "Glass_saga (Masaki Matsushita)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Implement Happy Eyeballs Version 2 (RFC8305) in Socket.tcp", "description": "https://github.com/ruby/ruby/pull/4038\r\n\r\nThis change implements Happy Eyeballs Version 2 (RFC8305) in Socket.tcp.\r\nIt enables fallback from IPv6 to IPv4 without a long waiting time.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-10T13:17:37Z", "updated_on": "2022-06-16T01:08:11Z", "closed_on": null, "relations": [{"id": 2866, "issue_id": 15628, "issue_to_id": 17525, "relation_type": "relates", "delay": null}]}, {"id": 17524, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 131, "name": "no6v (Nobuhiro IMAI)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "resolv: add some more characters in IPv6 link local zone id", "description": "According to [RFC6874](https://tools.ietf.org/html/rfc6874#section-2), IPv6 link local zone id is:\r\n\r\n```\r\n   ZoneID = 1*( unreserved / pct-encoded )\r\n```\r\n\r\nwhere `unreserved` in [RFC3986](https://tools.ietf.org/html/rfc3986#section-2.3) is as follow.\r\n\r\n```\r\n   unreserved  = ALPHA / DIGIT / \"-\" / \".\" / \"_\" / \"~\"\r\n```\r\n\r\nActually, `docker` can create such an interface.\r\n\r\n```sh\r\n$ docker network create --ipv6 --subnet fe80::/64 --opt com.docker.network.bridge.name=ruby_3.0.0-1 ruby\r\n$ ruby -rsocket -e 'p Socket.ip_address_list.last'\r\n#<Addrinfo: fe80::1%ruby_3.0.0-1>\r\n```\r\n\r\nThis makes `TestResolvAddr#test_valid_socket_ip_address_list` failure.\r\nSupporting a `pct-encoded` may be overwork, but adding the all of `unreserved` to\r\n\r\n* `Resolv::IPv6::Regex_8HexLinkLocal` and\r\n* `Resolv::IPv6::Regex_CompressedHexLinkLocal`\r\n\r\nsounds reasonable for me. What do you think?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-09T10:36:28Z", "updated_on": "2022-01-05T20:39:25Z", "closed_on": "2022-01-05T20:39:25Z", "relations": []}, {"id": 17520, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 48480, "name": "dorianmariefr (Dorian Mari\u00e9)"}, "subject": "Allow symbols starting with number, e.g. :2_weeks", "description": "\r\nFor instance:\r\n\r\n```\r\np({ 2_weeks: 1 })\r\n```\r\n\r\nresults in:\r\n\r\n```\r\na.rb:1: trailing `_' in number\r\np({ 2_weeks: 1 })\r\na.rb:1: syntax error, unexpected local variable or method, expecting =>\r\np({ 2_weeks: 1 })\r\n```\r\n\r\nand \r\n\r\n```\r\np({ :2_weeks => 1 })\r\n```\r\n\r\nresults in:\r\n\r\n```\r\na.rb:1: trailing `_' in number\r\np({ :2_weeks => 1 })\r\na.rb:1: syntax error, unexpected integer literal, expecting literal content or terminator or tSTRING_DBEG or tSTRING_DVAR\r\n```\r\n\r\nI'm not sure if it's doable as ruby thinks I'm writing a number, just wondering if that could be possible to start a symbol with a number\r\n\r\n(I know `{ \"2_weeks\": 1 }` works, that's what I'm using instead)", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-08T21:59:03Z", "updated_on": "2021-02-09T22:36:00Z", "closed_on": "2021-01-08T22:41:04Z", "relations": []}, {"id": 17500, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "fixed_version": {"id": 37, "name": "3.1"}, "subject": "Move RubyVM::* to ExperimentalFeatures", "description": "`RubyVM` is a trap:\r\n* Users will think from the name it's some official blessed API when it is meant as experimental unstable MRI-specific APIs (the complete opposite).\r\n* CRuby developers seem to see it as an experimental module to put constants and methods which are not stable yet.\r\n* About half the things under RubyVM is MRI-specific and the other half not, which is confusing and problematic for other Ruby implementations.\r\n\r\nI think the best way to solve this is to move everything under RubyVM to `ExperimentalFeatures`, and deprecate `RubyVM`.\r\nThat achieves multiple important things:\r\n* it makes it clear such constants/methods are experimental (documentation is not enough, https://bugs.ruby-lang.org/issues/17490#note-6)\r\n* it makes it possible for other Ruby implementations to implement such API, if it makes sense for compatibility\r\n* it avoids the common pitfall of CRuby developers thinking an API is MRI-specific when in fact it's not, and such an API often end up being used in gems and so other Ruby implementations must implement it for compatibility.\r\n\r\nIn my opinion, keeping the current status quo is irresponsible for compatibility between Rubies.\r\nUsers end up using e.g. RubyVM::AbstractSyntaxTree in gems (often missing the fact it's experimental), which is something other Rubies can technically implement, but currently are prevented to since `RubyVM` is supposed to be MRI-specific. That's just one example, I think more than half of what has been under RubyVM is not MRI-specific.\r\n\r\nSo rather than guessing if some new experimental API is implementation-specific, let's add all new experimental APIs under `ExperimentalFeatures`.\r\nI believe this is better for everyone.\r\n\r\nIt means there is no module for MRI-specific features. That's on purpose, every method in MRI is eventually relied upon by some gem or program, so it should be in `ExperimentalFeatures` if experimental and somewhere as a normal API otherwise.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-01T12:43:10Z", "updated_on": "2021-01-28T20:56:56Z", "closed_on": "2021-01-02T11:12:43Z", "relations": [{"id": 2856, "issue_id": 15743, "issue_to_id": 17500, "relation_type": "relates", "delay": null}, {"id": 2857, "issue_id": 15752, "issue_to_id": 17500, "relation_type": "relates", "delay": null}]}, {"id": 17498, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance some Float methods", "description": "Improve performance some Float methods(write in Ruby)\r\n\r\nbenchmark:\r\n\r\n```yml\r\nprelude: |\r\n  flo = 4.2\r\nbenchmark:\r\n  to_f: |\r\n    flo.to_f\r\n  abs: |\r\n    flo.abs\r\n  magnitude: |\r\n    flo.magnitude\r\n  -@: |\r\n    -flo\r\n  zero?: |\r\n    flo.zero?\r\nloop_count: 20000000\r\n\r\n\r\n```\r\n\r\nresult:\r\n\r\n```bash\r\nsh@DESKTOP-L0NI312:~/rubydev/build$ make benchmark/float_methods.yml -e BENCH_RUBY=../install/bin/ruby -e COMPARE_RUBY=~/.rbenv/shims/ruby\r\n# Iteration per second (i/s)\r\n\r\n|           |compare-ruby|built-ruby|\r\n|:----------|-----------:|---------:|\r\n|to_f       |     60.880M|   81.272M|\r\n|           |           -|     1.33x|\r\n|abs        |     68.162M|   81.264M|\r\n|           |           -|     1.19x|\r\n|magnitude  |     53.441M|   78.829M|\r\n|           |           -|     1.48x|\r\n|-@         |     67.193M|   84.731M|\r\n|           |           -|     1.26x|\r\n|zero?      |     69.894M|   82.032M|\r\n|           |           -|     1.17x|\r\n```\r\n\r\n`COMPARE_RUBY` is `ruby 3.1.0dev (2020-12-31T22:55:59Z master 3d7f71801a) [x86_64-linux]`. `BENCH_RUBY` is ahead of `ruby 3.1.0dev (2020-12-31T22:55:59Z master 3d7f71801a) [x86_64-linux]`.\r\n\r\npull requests:\r\nhttps://github.com/ruby/ruby/pull/4018", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2021-01-01T06:22:11Z", "updated_on": "2021-01-02T02:39:49Z", "closed_on": "2021-01-02T02:39:49Z", "relations": []}, {"id": 17496, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11075, "name": "jzakiya (Jabari Zakiya)"}, "subject": "Add constant Math::TAU", "description": "Excuse me if this has been brought up before.\r\n\r\nThis is a simple proposal to add the math constant ``Math::TAU`` = 2*``Math::PI``.\r\n\r\nSee: https://tauday.com/\r\n\r\n``TAU`` has been included in a growing number of languages (Rust, Python3, Julia, et al), and this would add Ruby to that list, and make it even cooler. :-)", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-31T19:27:40Z", "updated_on": "2021-01-13T05:47:02Z", "closed_on": "2020-12-31T21:13:10Z", "relations": [{"id": 2855, "issue_id": 17496, "issue_to_id": 4897, "relation_type": "duplicates", "delay": null}]}, {"id": 17490, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10073, "name": "k0kubun (Takashi Kokubun)"}, "subject": "Rename RubyVM::MJIT to RubyVM::JIT", "description": "## Background\r\nThese days it's sometimes said that CRuby may add another lightweight JIT. Leaving `RubyVM::MJIT` under such a situation might imply `RubyVM::MJIT` will not impact the future JIT, but I think `MJIT.pause`/`MJIT.resume` should impact all JITs by default if `--jit` is going to enable all the JITs. The current naming will be confusing, and I think these features should named consistently with `--jit`.\r\n\r\nI also think, although this feature is for JIT developers anyway, we should not add many APIs to control JIT (for now I want JIT to be a feature where users don't need to think about tuning it, and having such APIs might end up letting people do that), and this naming change will contribute to discouraging APIs for a particular JIT.\r\n\r\n## Proposal\r\nHave the same constant as `RubyVM::JIT`, deprecate `RubyVM::MJIT` from Ruby 3.1, and remove the old one in Ruby 3.2.\r\n\r\n## Impact\r\nThis impacts only [Feature #14830] `RubyVM::MJIT.pause` / `RubyVM::MJIT.resume`, which is basically for k0kubun's own testing.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-30T05:45:10Z", "updated_on": "2022-01-17T06:32:15Z", "closed_on": "2021-01-14T06:50:23Z", "relations": [{"id": 3216, "issue_id": 17490, "issue_to_id": 18349, "relation_type": "relates", "delay": null}]}, {"id": 17485, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Keyword argument for timezone in Time.new", "description": "Currently, `Time.at` and `Time.now` accept a timezone as a keyword argument, but not `Time.new`.\r\nThis means minor arguments cannot be omitted for `Time.new`.\r\n\r\n```ruby\r\nTime.new(2021, 1, 1, 0, 0, 0, \"+09:00\") #=> ok: 2021-01-01 00:00:00 +0900\r\nTime.new(2021, 1, 1, \"+09:00\")          #=> bad: 2021-01-01 09:00:00 +0900\r\nTime.new(2021, 1, \"+09:00\")             #=> bad: 2021-01-09 00:00:00 +0900\r\nTime.new(2021, \"+09:00\")                #=> ArgumentError (mon out of range)\r\n```\r\n\r\nSuggest that `Time.new` should also accept the `in:` timezone option.\r\n\r\n```ruby\r\nTime.new(2021, 1, 1, in: \"+09:00\") #=> ok: 2021-01-01 00:00:00 +0900\r\nTime.new(2021, in: \"+09:00\")       #=> ok: 2021-01-01 00:00:00 +0900\r\n```\r\n\r\nhttps://github.com/ruby/ruby/pull/4010", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-28T14:04:10Z", "updated_on": "2021-01-13T11:41:51Z", "closed_on": "2021-01-13T11:41:51Z", "relations": [{"id": 2859, "issue_id": 17485, "issue_to_id": 17504, "relation_type": "relates", "delay": null}]}, {"id": 17479, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 47810, "name": "neg_hide (Hidenori Negishi)"}, "subject": "Enable to get \"--backtrace-limit\" value by \"$-B\"", "description": "# Background\r\n\r\nThere is currently no way to get \"--backtrace-limit\" value when outputing backtraces from my script, so I have to ignore this value and output backtraces.\r\n\r\nIn order to be able to output according to \"--backtrace-limit\" value, I need a API to get this value from the Ruby side.\r\n\r\n# Proposal\r\n\r\nI propose a readonly built-in variable \"$-B\" to get \"--backtrace-limit\" value.\r\n\r\n``` ruby\r\n# ruby --backtrace-limit=3 script.rb\r\n\r\nputs $-B # => 3\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-27T10:03:48Z", "updated_on": "2021-02-15T09:29:58Z", "closed_on": "2021-02-15T09:29:58Z", "relations": []}, {"id": 17475, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 309, "name": "svoop (Sven Schwyn)"}, "subject": "Implement arguments forwarding for blocks", "description": "In a gem, I create a bunch of initializer shortcuts as follows:\r\n\r\n    # Shortcut initializers\r\n    CLASSES.each do |element, class_name|\r\n      define_singleton_method(element) do |*args, **kwargs|\r\n        class_name.to_class.new(*args, **kwargs)\r\n      end\r\n    end\r\n\r\nGiven the new, cool arguments forwarding with `...`, it would be a real beauty if the following were possible:\r\n\r\n    # Shortcut initializers\r\n    CLASSES.each do |element, class_name|\r\n      define_singleton_method(element) do |...|\r\n        class_name.to_class.new(...)\r\n      end\r\n    end\r\n\r\n(I'm sorry if this is a duplicate. In some dusty corner of my memory, I believe to have seen a similar issue in the past, but couldn't find it anymore... maybe just dreamt of it. :-)", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T18:57:43Z", "updated_on": "2020-12-30T20:38:01Z", "closed_on": "2020-12-30T20:38:01Z", "relations": []}, {"id": 17474, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11075, "name": "jzakiya (Jabari Zakiya)"}, "subject": "Interpreting constants at compile time", "description": "Ruby has borrowed concepts/idioms from allot of languages.\r\n\r\nI am proposing borrowing a feature from Forth to provide for compile time interpretation of Constants.\r\nThis should make executed code faster|efficient, while maintaining source code brevity|clarity.\r\n\r\nBelow is actual code used in a large rubygem I have.\r\n\r\nTo develop this method, I had to do allot of test runs to determine the range values.\r\nOnce found, these values don't change, but I just kept the computed forms of the values, in case I want to upgrade them.\r\nIn Forth I can interpret those expressions that result in constants, which will be compiled as single values for run time.\r\n\r\nSee wikeipedia article on Forth below starting at **Mixing states of compiling and interpreting**.\r\nhttps://en.wikipedia.org/wiki/Forth_(programming_language)\r\n\r\nForth was designed for, and is still used most frequently, in hardware controllers, and with microprocessors.\r\nIMHO this feature would also make MRuby more code efficient and faster for this domain too, and IOT devices.\r\n\r\nBelow is an example of real code that would benefit from this.\r\nWhile this example would result in numerical constant, string constants could also be interpreted.\r\n\r\n```\r\ndef select_pg(endnum, startnum)\r\n  start_num = end_num \r\n  end_num = endnum;  start_num = startnum\r\n  range = end_num - start_num\r\n  pg = 5\r\n  if start_num <= Integer.sqrt(end_num)  # for one array of primes upto N\r\n    pg =  7 if end_num >  50 * 10**4\r\n    pg = 11 if end_num > 305 * 10**5\r\n  else                                   # for split array cases\r\n    pg =  7 if ((10**6 ... 10**7).include?(range) && start_num < 10**8)       ||\r\n               ((10**7 ... 10**8).include?(range) && start_num < 46 * 10**8)  ||\r\n               ((10**8 ... 10**9).include?(range) && start_num < 16 * 10**10) ||\r\n               (range >= 10**9 && start_num < 26 * 10**12)        \r\n    pg = 11 if ((10**8 ... 10**9).include?(range) && start_num < 55 * 10**7)  ||\r\n               (range >= 10**9 && start_num < 45 * 10**9)\r\n  end\r\n  primes = [2, 3, 5, 7, 11, 13].select { |p| p <= pg }\r\n  {primes, primes.reduce(:*)}            # [excluded primes, modpg] for PG\r\nend\r\n```\r\nAllowing for compile time interpretation, the code could be rewritten as below.\r\n\r\n```\r\ndef select_pg(endnum, startnum)\r\n  start_num = end_num \r\n  end_num = endnum;  start_num = startnum\r\n  range = end_num - start_num\r\n  pg = 5\r\n  if start_num <= Integer.sqrt(end_num)  # for one array of primes upto N\r\n    pg =  7 if end_num >  [50 * 10**4]\r\n    pg = 11 if end_num > [305 * 10**5]\r\n  else                                   # for split array cases\r\n    pg =  7 if (([10**6] ... [10**7]).include?(range) && start_num < [10**8])      ||\r\n               (([10**7] ... [10**8]).include?(range) && start_num < [46 * 10**8]) ||\r\n               (([10**8] ... [10**9]).include?(range) && start_num < [16 * 10**10])|| \r\n               (range >= [10**9] && start_num < [26 * 10**12])        \r\n    pg = 11 if (([10**8] ... [10**9]).include?(range) && start_num < [55 * 10**7]) ||\r\n               (range >= [10**9] && start_num < [45 * 10**9])\r\n  end\r\n  primes = [2, 3, 5, 7, 11, 13].select { |p| p <= pg }\r\n  {primes, primes.reduce(:*)}            # [excluded primes, modpg] for PG\r\nend\r\n\r\n```\r\nThis maintains the original form, so if I need/want to change the range limits again\r\nI can just change the calculation inline, without having to remember where those values came from.\r\n\r\nAs 3.0 has introduced many new features and idioms, this could be introduced with no breaking change too.\r\nOld code would work as before, while new code could take advantage of this feature.\r\n\r\nThanks is advance of giving this proposal serious consideration.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T16:36:51Z", "updated_on": "2021-01-07T16:40:47Z", "closed_on": "2020-12-27T16:08:25Z", "relations": [{"id": 2860, "issue_id": 8804, "issue_to_id": 17474, "relation_type": "relates", "delay": null}]}, {"id": 17473, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Make Pathname to embedded class of Ruby", "description": "pathname is one of most useful utility class of Ruby. I'm happy to use Pathname without require it.\r\n\r\nAny thought?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T12:00:42Z", "updated_on": "2022-01-07T09:25:45Z", "closed_on": null, "relations": []}, {"id": 17472, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 5, "name": "naruse (Yui NARUSE)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "HashWithIndifferentAccess like Hash extension", "description": "Rails has [ActiveSupport::HashWithIndifferentAccess](https://api.rubyonrails.org/classes/ActiveSupport/HashWithIndifferentAccess.html), which is widely used in Rails to handle Request, Session, ActionView's form construction, ActiveRecord's DB communication, and so on. It receives String or Symbol and normalize them to fetch the value. But it is implemented with Ruby. If we provide C implementation of that, Rails will gain the performance improvement.\r\n\r\nsummary of previous discussion: https://github.com/rails/rails/pull/40182#issuecomment-687607812", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T11:04:18Z", "updated_on": "2022-06-16T01:08:11Z", "closed_on": null, "relations": []}], [{"id": 17471, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 32311, "name": "ozu (Fabio Pesari)"}, "subject": "send_if method for improved conditional chaining", "description": "# Background\r\n\r\nMethod chaining is very important to many Ruby users, since everything in Ruby is an object.\r\n\r\nIt also allows easier functional programming, because it implements a pipeline where each step can happen without mutation.\r\n\r\nConditional chaining allows an even more declarative style of programming. Right now, it is possible to conditionally chain methods to a degree but in some cases it is a bit verbose.\r\n\r\n# Proposal\r\n\r\nI propose that a `send_if` method is added, which works roughly like this:\r\n\r\n``` ruby\r\n# Internal condition\r\nputs 'If you give me a number larger than 5, I will double it. I will subtract 1 in any case.'\r\nnumber = gets.chomp.to_i\r\n# An implementation without send_if\r\nputs (number > 5 ? number.send(:*, 2) : number).send(:-, 1)\r\n# Implementation with send_if [1]\r\nputs number.send_if(:*, 2) {|obj| obj > 5}.send(:-, 1)\r\n\r\n# External condition\r\nputs 'Do you want a loud Merry Christmas? (y or I take it as a no)'\r\nanswer = gets.chomp\r\n# An implementation without send_if\r\nputs %w(Merry Christmas).send(:map, &->(e) {answer == 'y' ? e.upcase : e}).join(' ')\r\n# Implementation with send_if [2]\r\nputs %w(Merry Christmas).send_if(:map, proc: :upcase ) { answer == 'y' }.join(' ')\r\n```\r\n# Implementation\r\n\r\nHere is a Ruby implementation (obviously, everything is released under the same license terms as Ruby itself):\r\n\r\n```ruby\r\nclass Object\r\n  def send_if(method, *args, proc: nil)\r\n     yield(self) ? self.send(method, *args, &proc) : self\r\n  end\r\nend\r\n```\r\n\r\nThis implementation works as intended with both examples I posted above.\r\n\r\n\r\n# Evaluation\r\n\r\nI don't believe `send_if` brings significant performance penalties, compared to the alternatives.\r\n\r\nI am not 100% satisfied with my implementation in terms of usability, for two reasons:\r\n1. I did not find any stdlib methods which are consistent with the function signature I've specified. More specifically, I don't like the named `proc:` parameter I used, but I couldn't think of a better alternative. Please, tasukete!\r\n2. Ruby does not support multiple blocks, which would be required for my ideal implementation (short of [3], see later):\r\n\r\n```ruby\r\nputs %w(Merry Christmas).send_if(:map, &:upcase) { answer == 'y' }.join(' ')\r\n```\r\n\r\n# Discussion\r\n\r\nI know for sure there are more skilled Rubyists than myself here who can come up with nicer alternatives to my `send_if` examples, but I think `send_if` would be nice to have because:\r\n* The `*_if` family of methods is a staple of the stdlib (e.g. `receive_if`, `delete_if`, `keep_if`, etc.)\r\n* In some cases, it decreases the amount of code needed\r\n\r\nI know my examples could be written without ever using `send` but `send` makes it possible to use any Ruby method (rather than write specific methods like `map_if`, etc.).\r\n\r\nIn the future, some syntactic sugar could be built so that method chaining is even more fluid, without any need for `send`. An example using an `.?{}` operator I just made up:\r\n\r\n```ruby\r\n# Syntax-level conditional chaining [3]\r\nputs %w(Merry Christmas).?{answer == 'y'}map(&:upcase).join(' ')\r\n```\r\n\r\nOf course, `{answer == 'y'}` would be a block and this would be equivalent to my example above [2], but without any need for a `send` method (since this operator would apply to all methods).\r\n\r\nIf someone is interested, I can make a separate proposal for this operator, but perhaps it's asking too much :)\r\n\r\nI'd be happy to discover more elegant solutions and critiques!\r\n\r\nMerry Christmas to everybody and thanks for reading!", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T10:37:01Z", "updated_on": "2020-12-29T15:23:14Z", "closed_on": null, "relations": []}, {"id": 17470, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce non-blocking `Timeout.timeout`", "description": "In this bug report, user complained that `Timeout.timeout` does not work correctly with scheduler: https://github.com/socketry/async-io/issues/43\r\n\r\nWe should introduce non-blocking timeout.\r\n\r\nI propose the following:\r\n\r\n```\r\nrb_fiber_scheduler_with_timeout(VALUE scheduler, VALUE timeout, VALUE block)\r\n```\r\n\r\nWe can directly modify `Timeout.timeout` to invoke this hook.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-26T07:42:23Z", "updated_on": "2021-03-30T05:38:30Z", "closed_on": "2021-03-30T05:38:30Z", "relations": [{"id": 2854, "issue_id": 17363, "issue_to_id": 17470, "relation_type": "relates", "delay": null}]}, {"id": 17468, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 5, "name": "naruse (Yui NARUSE)"}, "fixed_version": {"id": 70, "name": "3.2"}, "subject": "Deprecate RUBY_DEVEL", "description": "Some configuration of Ruby use RUBY_DEVEL, which depends PATCH_LEVEL.\r\nBut depending PATCH_LEVEL causes issues which will become revealed on the final release.\r\nThough we release some previews and RCs, they don't contributes the quality around RUBY_DEVEL.\r\n\r\nTherefore to ensure CI tests the quality of the final release, we need to deprecate RUBY_DEVEL.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-25T09:32:50Z", "updated_on": "2022-06-16T01:08:11Z", "closed_on": null, "relations": []}, {"id": 17433, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Expose atomic operation macros with RUBY prefix", "description": "Because of Ractor, now we need synchronization more widely in extension libraries.\r\nAtomic operations are lighter than mutex, and enough in many cases.\r\nhttps://github.com/ruby/ruby/pull/3983", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-23T16:47:38Z", "updated_on": "2020-12-24T02:52:35Z", "closed_on": "2020-12-24T02:52:35Z", "relations": []}, {"id": 17432, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Check deprecated methods at compilation time", "description": "Currently `rb_warn_deprecated_to_remove` shows the deprecation warning with the version to remove.  Often we can miss it however, especially as now deprecation warnings are suppressed by default.  It's better to notice automatically, probably at build-time.\r\n\r\nhttps://github.com/ruby/ruby/pull/3972 is not perfect, but it can detect the miss at least a few jobs in the CIs.\r\n\r\nAlso, this changes the message not to print the future version, as [@shyouhei said](https://github.com/ruby/ruby/pull/3424/commits/2f730d89ada6f73b5e2bf06acc19452b7e900607).\r\n> Proper annotation of when to remove a feature helps us a lot (\"don't delete it now\" sign), but can rarely be useful to end users.  Let's just use the info internally.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-23T16:42:26Z", "updated_on": "2021-06-30T01:47:54Z", "closed_on": "2021-06-30T01:47:54Z", "relations": []}, {"id": 17418, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Add `Ractor.main?` and `Ractor.main`", "description": "Since main Ractor is special, it seems useful to have an easy way to check if the current ractor is the main ractor.\r\n\r\n```ruby\r\nRactor.main? # => true\r\nRactor.new { Ractor.main? }.take # => false\r\n```\r\n\r\nAs far as I know, a gem could be loaded from a non-main Ractor so there is no reliable way for a gem to know the main Ractor (except than trying to do something that is not allowed)\r\n\r\nWe might as well add `Ractor.main` to return the main Ractor (probably less useful though).", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-21T16:25:20Z", "updated_on": "2020-12-21T20:57:13Z", "closed_on": "2020-12-21T20:54:44Z", "relations": []}, {"id": 17416, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance Kernel#itself", "description": "Improve performance `Kernel#itself` with Ruby code.\r\n\r\nlike this.\r\n\r\n```ruby\r\nmodule Kernel\r\n  #\r\n  #  call-seq:\r\n  #     obj.itself    -> obj\r\n  #\r\n  #  Returns the receiver.\r\n  #\r\n  #     string = \"my string\"\r\n  #     string.itself.object_id == string.object_id   #=> true\r\n  #\r\n  #\r\n  def itself\r\n    return self\r\n  end\r\nend\r\n```\r\n\r\nbenchmark:\r\n\r\n```yaml\r\nprelude: |\r\n  obj = Object.new\r\n  ary = Array.new\r\n  str = String.new\r\n  int = 42\r\n  flt = 4.2\r\nbenchmark:\r\n  object: |\r\n    obj.itself\r\n  array: |\r\n    ary.itself\r\n  string: |\r\n    str.itself\r\n  integer: |\r\n    int.itself\r\n  float: |\r\n    flt.itself\r\nloop_count: 20000000\r\n\r\n```\r\n\r\nbenchmark result:\r\n```bash\r\nsh@MyComputer:~/rubydev/build$ make benchmark/benchmark.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby\r\n# Iteration per second (i/s)\r\n\r\n|         |compare-ruby|built-ruby|\r\n|:--------|-----------:|---------:|\r\n|object   |     58.924M|   70.285M|\r\n|         |           -|     1.19x|\r\n|array    |     56.428M|   65.275M|\r\n|         |           -|     1.16x|\r\n|string   |     50.311M|   63.087M|\r\n|         |           -|     1.25x|\r\n|integer  |     54.838M|   62.510M|\r\n|         |           -|     1.14x|\r\n|float    |     56.372M|   65.399M|\r\n|         |           -|     1.16x|\r\n```\r\n\r\nCOMPARE_RUBY is `ruby 3.0.0dev (2020-12-21T09:17:45Z master d84dd66da0) [x86_64-linux]`. BENCH_RUBY is ahead of `ruby 3.0.0dev (2020-12-21T09:17:45Z master d84dd66da0) [x86_64-linux]`.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-21T13:14:04Z", "updated_on": "2020-12-21T13:14:04Z", "closed_on": null, "relations": []}, {"id": 17414, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor should allow access to shareable attributes for Modules/Classes", "description": "Current situation is *very* limiting.\r\n\r\nUse-case: global config.\r\n\r\nExample: [yaml has a global config](https://github.com/ruby/psych/blob/master/lib/psych.rb#L637-L640) and it's not clear to me how to make that Ractor-aware (nicely).\r\n\r\nIt is possible to have the same effect but in ugly ways:\r\n\r\n```ruby\r\n# Using instance variables of Module not allowed:\r\n\r\nmodule Config\r\n  class << self\r\n    attr_accessor :conf\r\n  end\r\n  self.conf = 42\r\nend\r\n\r\nRactor.new { Config.conf = 66 }.take # => can not access instance variables from non-main Ractors\r\nRactor.new { puts Config.conf }.take # => can not access instance variables from non-main Ractors\r\n\r\n# Same functionality using constants allowed:\r\nmodule Config\r\n  class << self\r\n    def conf\r\n      CONF\r\n    end\r\n\r\n    def conf=(new_conf)\r\n      remove_const(:CONF)\r\n      const_set(:CONF, new_conf)\r\n    end\r\n  end\r\n  CONF = 42\r\nend\r\n\r\nRactor.new { Config.conf = 66 }.take # => ok\r\nRactor.new { puts Config.conf }.take # => 66\r\n\r\n# Same functionality using methods allowed:\r\nmodule Config\r\n  class << self\r\n    def conf\r\n      42\r\n    end\r\n\r\n    def conf=(new_conf)\r\n      singleton_class.undef_method(:conf)\r\n      define_singleton_method(:conf, &Ractor.make_shareable(Proc.new { new_conf }))\r\n    end\r\n  end\r\nend\r\n\r\nRactor.new { Config.conf = 66 }.take # => ok\r\nRactor.new { puts Config.conf }.take # => 66\r\n```\r\n\r\nThe priority would be to allow reading these instance variables if they are shareable. Ideally writing would also be allowed, but limiting that to main ractor is less probablematic than with reading.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-21T01:55:02Z", "updated_on": "2020-12-21T15:56:39Z", "closed_on": null, "relations": []}, {"id": 17411, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "Allow expressions in pattern matching", "description": "Code:\r\n\r\n```ruby\r\nversion = {name: '2.6', released_at: Time.new(2018, 12, 25)}\r\nversion in {released_at: Time.new(2010)..Time.new(2020)}\r\n#                            ^ syntax error, unexpected '.', expecting '}'\r\n\r\n# This works:\r\nrange = Time.new(2010)..Time.new(2020)\r\nversion in {released_at: ^range}\r\n#=> true\r\n```\r\n(Fails with all versions of the pattern matching, `in`, `=>` and `case ... in`, and on Ruby 2.7 too.)\r\n\r\nAm I missing something about the syntax?..", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-19T18:16:33Z", "updated_on": "2021-03-21T06:14:59Z", "closed_on": "2021-03-21T06:14:59Z", "relations": []}, {"id": 17407, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "Fiber.current and require 'fiber'", "description": "Maybe it is not the right time to ask, but why one need to do `require 'fiber'` before using `Fiber.current`?\r\n\r\nFor what I can see, \r\n* it is this way since [their introduction](https://docs.ruby-lang.org/en/2.0.0/Fiber.html#method-c-current), \r\n* the actual code is defined in the core [cont.c](https://github.com/ruby/ruby/blob/master/cont.c#L2480)\r\n* the `ext/fiber.c` [does very little](https://github.com/ruby/ruby/blob/master/ext/fiber/fiber.c)\r\n\r\nI was just bitten by it again preparing the changelog (stuck with `NoMethodError` and for a few minutes thought the build is broken), is there a reason to have it this way?..\r\nJust clarifying for docs sake, at least.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-18T23:08:43Z", "updated_on": "2021-01-13T15:18:49Z", "closed_on": "2021-01-13T15:18:49Z", "relations": []}, {"id": 17406, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "Add `NoMatchingPatternError#depth`", "description": "Could we have `NoMatchingPatternError#depth`, returning the number of `case...in...end` an exception has traversed?\r\n\r\n```ruby\r\ndef show_depth\r\n  yield\r\nrescue NoMatchingPatternError => e\r\n  puts \"Depth: #{e.depth}\"\r\n  raise\r\nend\r\n\r\nshow_depth do\r\n  case [1,2,3]\r\n  in [x, y, z] then\r\n    show_depth do\r\n      x => [a, b] # => raises NoMatchingPatternError\r\n    end\r\n  end\r\nend\r\n\r\n# Prints \"Depth: 0\" then \"Depth: 1\"\r\n```\r\n\r\nThis could help bring pattern match closer to a language construct people can play with.\r\n\r\nExample usecase: implement `Ractor#receive_if` as in https://bugs.ruby-lang.org/issues/17378#note-6", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-18T21:45:35Z", "updated_on": "2020-12-19T15:18:12Z", "closed_on": null, "relations": []}, {"id": 17404, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor `move:` API to allow shareability check", "description": "I'd like to `ractor.send(message)` and express that `message` should be shareable. Currently I'm given two choices: `move: true` and `move: false` / nothing, neither of which have an effect if my `message` is shareable, and neither of which will tell me in case there's a bug in my program and `message` is not shareable.\r\n\r\nCould we consider a slightly different API (for 3.0 or 3.1)?\r\n\r\n```ruby\r\nractor.send(message, pass: :copy) # => like current `move: false`\r\nractor.send(message, pass: :move) # => like current `move: true`\r\nractor.send(message, pass: :share) # => raise in case message is not shareable\r\nractor.send(message) # => same as `pass: :copy`\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-17T18:29:50Z", "updated_on": "2020-12-18T21:17:26Z", "closed_on": null, "relations": []}, {"id": 17403, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Remove Fixnum and Bignum", "description": "They are warned as deprecated since 2.4.\r\nAs deprecated warnings are not shown by default since 2.7.2, I think we should clean up longstanding warnings.\r\n\r\nhttps://github.com/ruby/ruby/pull/3927", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-17T13:24:15Z", "updated_on": "2022-03-10T20:38:35Z", "closed_on": "2022-03-10T20:38:35Z", "relations": []}, {"id": 17401, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "The class `Ractor::MovedObject` should not be frozen", "description": "If `Ractor::MovedObject` can be not frozen that would be more helpful than currently. For example, to implement a helpful `inspect` in pure Ruby 3.0 like in #17393\r\n\r\nIt is currently possible to go around the fact that it is frozen with refinements:\r\n```ruby\r\nusing Module.new {\r\n  refine Ractor::MovedObject do\r\n    def inspect\r\n      \"I was moved! Don't use me!\"\r\n    end\r\n  end\r\n}\r\no = Object.new\r\nRactor.new{ receive }.send(o, move:true)\r\nputs o.inspect # => \"I was moved! Don't use me!\"\r\n```\r\n\r\nAnother (ugly) way to bypass the fact that it is frozen without refinements is to modify its ancestor:\r\n\r\n```ruby\r\nmodule Ext\r\n  def inspect\r\n    return super unless Ractor::MovedObject === self\r\n\r\n    \"I was moved! Don't use me!\"\r\n  end\r\nend\r\n\r\nBasicObject.prepend Ext\r\n\r\no = Object.new\r\nRactor.new{ receive }.send(o, move:true)\r\np o # => \"I was moved! Don't use me!\"\r\n```\r\n\r\nMy point remain that this \"security\" can be bypassed unless it is stricly necessary it, it would be nice to unfreeze the class. It could be documented that this is experimental / not recommended to modify the class in production, for example.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-17T00:59:09Z", "updated_on": "2020-12-18T20:59:14Z", "closed_on": "2020-12-18T20:59:14Z", "relations": []}, {"id": 17398, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "SyntaxError in endless method", "description": "This works:\r\n```ruby\r\ndef foo() = puts(\"bar\")\r\n```\r\n\r\nThis does not:\r\n```ruby\r\ndef foo() = puts \"bar\"\r\n#                ^ syntax error, unexpected string literal, expecting `do' or '{' or '('\r\n```\r\n\r\nIs this intentional or accidental? Not sure how it is reasoned.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-16T19:52:17Z", "updated_on": "2021-05-12T15:17:49Z", "closed_on": "2021-05-12T15:17:49Z", "relations": []}, {"id": 17397, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "`shareable_constant_value: literal` should check at runtime, not at parse time", "description": "I think `shareable_constant_value: literal` is too strict because it has too crude checks at parse time.\r\n\r\nI wish the following code would parse and run:\r\n\r\n```ruby\r\n# shareable_constant_value: literal\r\n\r\nclass Foo < RuntimeError\r\nend\r\n\r\n# Similar code, but does not parse:\r\nBar = Class.new(RuntimeError) # => unshareable expression\r\n\r\nBaz = Ractor.make_shareable(anything_here) # => unshareable expression\r\n\r\nQux = Set[1, 2, 3].freeze # => unshareable expression\r\n```\r\n\r\nCould we instead raise some sort of RuntimeError when an assignment is made that is not shareable?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-16T18:25:35Z", "updated_on": "2020-12-23T04:51:22Z", "closed_on": "2020-12-23T04:51:22Z", "relations": [{"id": 2813, "issue_id": 17273, "issue_to_id": 17397, "relation_type": "relates", "delay": null}]}, {"id": 17393, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "`Ractor::Moved#inspect`", "description": "It could be helpful to define `Ractor::Moved#inspect` and output the source location of when the data was moved. If preferred, it could raise an error with this information:\r\n\r\n```\r\nx = []\r\nRactor.new{ receive }.send(x, move: true)\r\np x # => \"Data was moved in `example.rb:4`\"\r\n# or\r\np x # => \"Data was moved in `example.rb:4`\" (Ractor::MovedError)\r\n```\r\n\r\nAlso @zverok and myself were wondering if there was a technical reason to freeze `Ractor::Moved`? If not, is it only to \"force\" people to use refinements (which are allowed on frozen classes)? It's already known that it is in general a bad idea to modify builtin classes, so it's not clear to me that freezing that class is best.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-14T20:48:49Z", "updated_on": "2020-12-21T17:47:28Z", "closed_on": null, "relations": []}, {"id": 17392, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 37693, "name": "jackmaple (maple jack)"}, "subject": "Is there any plan to unify the namespace after ruby3", "description": "\r\nHello.Currently, methods and variables in ruby are separated (lisp-2 semantics), but few people define variables and methods as the same name, right?\r\nAlthough some people may do this, should we unify the namespace for the better development of ruby in the future? Does this improve the performance of the language and avoid name confusion.\r\nexample:\r\n``` ruby\r\ndef foo\r\n    puts \"ruby method\"\r\nend\r\n\r\nfoo = 3\r\n\r\nputs foo # show 3\r\nfoo() # call method\r\n```\r\nIt doesn't feel very good.But can we add an option switch to ensure compatibility?\r\n``` ruby\r\nuse ruby3\r\ndef foo\r\n    puts \"ruby method\"\r\nend\r\nfoo = 3\r\nputs foo # show 3\r\nfoo() # error\r\n```\r\nIf we implement a unified namespace, can we call lambda, proc, block and so on without using call, so that the call forms of methods are unified.\r\n``` ruby\r\nuse ruby3\r\ndef foo x\r\n    return x + 1\r\nend\r\nf = -> x {x + 1}\r\nfoo 2 # result = 3\r\nf 2 # result = 3\r\n```\r\nIn this way, we can make the language more friendly and design more unified.And now there is a scope problem: when defining a method within a method, it should not be visible to the public.\r\n``` ruby\r\ndef test\r\n   def test2\r\n       puts \"test2\"\r\n   end\r\n   puts \"test\"\r\nend\r\n\r\ntest # show \"test\"\r\ntest2 # show \"test2\" but this method should not be called\r\n```\r\nAlthough syntax supports defining methods within methods, they should not be visible to the public, so this is also a problem.\r\nWhat do you think of this problem? Thank you.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-14T20:30:15Z", "updated_on": "2020-12-15T01:17:55Z", "closed_on": "2020-12-15T01:17:55Z", "relations": []}, {"id": 17391, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11242, "name": "jnchito (Junichi Ito)"}, "subject": "How about removing File.exists?", "description": "`File.exists?` has been deprecated since Ruby 2.1.0. I think the release of Ruby 3.0.0 might be a good time to remove it.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-13T20:09:24Z", "updated_on": "2022-01-11T02:25:03Z", "closed_on": "2022-01-11T02:25:03Z", "relations": []}, {"id": 17384, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 47401, "name": "tjdgnsqn133 (Kim Seonghoon)"}, "subject": "shorthand of Hash#merge", "description": "Hi, all.\r\nWhen I used Hash#merge, I thought it is uncomfortable.\r\n\r\n``` ruby\r\na = {k: 1}\r\nb = {j: 2}\r\nc = a.merge(b)\r\n```\r\n\r\nIf hash provides + like array, so useful.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-10T04:49:49Z", "updated_on": "2020-12-10T06:14:17Z", "closed_on": "2020-12-10T05:07:01Z", "relations": [{"id": 2804, "issue_id": 17384, "issue_to_id": 6225, "relation_type": "duplicates", "delay": null}]}, {"id": 17380, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Useful `include/prepend` in `refine`", "description": "Currently, `prepend/include` within a `refine` block leads to a method not being to see itself, or others defined in the same module:\r\n\r\n```ruby\r\nmodule Code\r\n  def recurse(value = nil)\r\n    return value if value\r\n\r\n    recurse(42) # => NoMethodError!!!\r\n  end\r\nend\r\n\r\nmodule Extension\r\n  refine Object do\r\n    include Code\r\n  end\r\nend\r\n\r\nusing Extension\r\n:x.recurse(:y) # => :y (ok)\r\n:x.recurse     # => NoMethodError, was hoping for 42\r\n```\r\n\r\nI find this unintuitive and not useful.\r\n\r\nThe conclusion of the current situation from @shugo and others is [\"I don't recommend module inclusion to define refined methods\"](https://bugs.ruby-lang.org/issues/17374#note-9)\r\n\r\nCould we change this situation so it can be recommended to use it?\r\n\r\nWhat I believe would be more useful and is what I expected was that `include/prepend` within a `Module` would bring in the current methods in the Module, with the current refinements activated.\r\n\r\nOne use-case in particular is to publish libraries where one can give the option to the user to either:\r\n- call `using GreatExtension` in each and every file that need it\r\n- or `MyClass.prepend GreatExtension` once.\r\n\r\nWhile [Jeremy Evans found a way to do it](https://bugs.ruby-lang.org/issues/17374#note-8), it remains challenging and unnatural.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-09T04:31:11Z", "updated_on": "2021-10-27T22:50:15Z", "closed_on": "2021-10-27T22:50:15Z", "relations": [{"id": 2803, "issue_id": 17374, "issue_to_id": 17380, "relation_type": "relates", "delay": null}]}, {"id": 17378, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor#receive with filtering like other actor langauge", "description": "With discussion with @marcandre, we found good extension for `Ractor.receive` with block.\r\n\r\n```ruby\r\nRactor.receive do |msg|\r\n  if msg is match to condition?\r\n    true\r\n  else\r\n    false\r\n  end\r\nend\r\n```\r\n\r\nThis block iterates incoming queue's values and the value is passed in `msg`.\r\nIf the passed value is matched you want to process, the block should return true and the value will be removed from the queue.\r\nOtherwise (returning falsy value), the value remains in the queue, and other `Ractor.receive` accesses it again.\r\nIf there is not more values in queue, the interpreter sleeps until new values are received.\r\n\r\n```ruby\r\nr = Ractor.new do |;r|\r\n  loop do\r\n    r, msg = Ractor.receive\r\n    r << msg\r\n    r << 1\r\n    r << 2\r\n    r << 3\r\n  end\r\nend\r\n\r\nr.send([Ractor.current, :ping])\r\n\r\n# incoming queue: [:ping, 1, 2, 3] (3 is at the last)\r\n\r\nRactor.receive #=> :ping # without a block\r\n\r\n# incoming queue: [1, 2, 3]\r\n\r\np Ractor.receive{|msg| msg == 2}\r\n#=> 2 \r\n\r\n# incoming queue: [1, 3]\r\nbegin\r\n  # exception in the block doesn't touch the queue\r\n  p Ractor.receive{|msg| raise \"err\"}\r\nrescue => e\r\n  p e.message #=> \"err\"\r\nend\r\n\r\n# incoming queue: [1, 3]\r\np Ractor.receive #=> 1\r\n\r\n# incoming queue: [3]\r\np Ractor.receive #=> 3\r\n```\r\n\r\nWith multiple server, we can make it:\r\n\r\n```ruby\r\nmorning_server = Ractor.new do\r\n  loop do\r\n    task = Proc.new{|obj| \"Good morning #{obj}\"}\r\n    r, req = Ractor.receive\r\n    res = task.(req)\r\n    r.send([Ractor.current, res])\r\n  end\r\nend\r\n\r\nevening_server = Ractor.new do\r\n  loop do\r\n    task = Proc.new{|obj| \"Good evening #{obj}\"}\r\n    r, req = Ractor.receive\r\n    res = task.(req)\r\n    r.send([Ractor.current, res])\r\n  end\r\nend\r\n\r\nmorning_server << [Ractor.current, 'ko1']\r\nmorning_server << [Ractor.current, 'ko2']\r\nmorning_server << [Ractor.current, 'ko3']\r\n\r\nevening_server << [Ractor.current, 'ko1']\r\nevening_server << [Ractor.current, 'ko2']\r\nevening_server << [Ractor.current, 'ko3']\r\n\r\ndef receive r\r\n  Ractor.receive{|(from, msg)|\r\n    r == from\r\n  }[1]\r\nend\r\n\r\np receive(morning_server) #=> \"Good morning ko1\"\r\np receive(evening_server) #=> \"Good evening ko1\"\r\np receive(morning_server) #=> \"Good morning ko2\"\r\np receive(evening_server) #=> \"Good evening ko2\"\r\np receive(morning_server) #=> \"Good morning ko3\"\r\np receive(evening_server) #=> \"Good evening ko3\"\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-08T15:27:33Z", "updated_on": "2020-12-20T16:25:39Z", "closed_on": "2020-12-16T10:13:11Z", "relations": [{"id": 2799, "issue_id": 17365, "issue_to_id": 17378, "relation_type": "relates", "delay": null}]}, {"id": 17375, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 33540, "name": "nevans (Nicholas Evans)"}, "subject": "Add scheduler callbacks for transferring fibers", "description": "When working on #17325 (`Fiber#cancel`) and #17331 (`Fiber#raise` on transferring fibers), two very reasonable questions keep coming up:\r\n* \"how and when should control pass back to the current fiber?\" and\r\n* \"is it expected that terminating fibers will return to the root fiber chain?\"\r\n\r\nRather than deal with that complexity, I've passed the buck: that's out of scope for those tickets. The end user should just call their scheduler library and let it coordinate, right?\r\n\r\nBut with a couple of optional hooks on the scheduler, I think we can answer both of those questions.  I'm not sure that these are the ideal API, but what do you think about *something* similar to the following?\r\n\r\n### \"how and when should control pass back to the current fiber?\"\r\n\r\n```ruby\r\n# Called before transferring into another fiber.\r\n# @param target [Fiber] the fiber that will be transferred into\r\n# @param reason [:transfer, :raise, :cancel] How the transfer was initiated \r\n# @param args the arguments sent to transfer, raise, or cancel.\r\n#\r\n# @raise [FiberTransferInterrupted] to prevent the transfer without raising an\r\n#     exception in the calling fiber.\r\n# @raise [Exception] prevents the transfer and raises in the calling fiber\r\n#\r\n# This can be used to ensure the current fiber is appropriately scheduled for\r\n# return, and it can also prevent the transfer or schedule the transfer to\r\n# happen asynchronously.\r\n#\r\n# In addition to raising exceptions, any call to a fiber switching method (e.g.\r\n# resume, yield, or transfer) will prevent the transfer. When a transfer is\r\n# prevented, any associated cancellation or exception will not happen.\r\n#\r\n# This will only be called for transfers, not for resume, yield, or termination.\r\ndef transferring(target, reason, *args)\r\n  # one possible implementation:\r\n  return if Fiber.current == @scheduler # always allow transfer from scheduler\r\n  if target == @scheduler\r\n    # guard transfer to the scheduler\r\n    raise FiberError, \"invalid transfer to scheduler\" if invalid?(reason, *args)\r\n  else\r\n    # schedule all transfers instead of running immediately\r\n    @next_tick << [target, reason, *args]\r\n    @next_tick << [Fiber.current, :transfer] unless blocking?\r\n    @scheduler.transfer\r\n  end\r\nend\r\n```\r\n\r\nThis would be useful for more than just `Fiber#raise` and `Fiber#cancel`. It could allows any non-scheduler code to safely call `Fiber#transfer` (or to indirectly transfer via `#raise` or `#cancel`) without confusing or breaking the scheduler. Or the scheduler could **disallow** any transfers but its own. Or it could intercept certain internal framework exceptions. It allows the scheduler some control over transfer and over raise/cancel with transferring fibers.\r\n\r\n### \"exceptions raised from terminating transferred fibers will return to the root fiber chain\"\r\n\r\n```ruby\r\n# Select the return fiber for a transferring fiber when it terminates.\r\n# @param terminating [Fiber] The terminating fiber\r\n# @param retval [Object] return value of the terminating fiber\r\n# @param error [Exception, nil] raised by terminating fiber\r\n# @return [Fiber, nil] fiber to transfer into. `nil` uses default behavior\r\n#\r\n# If the selected return fiber can't be transferred to (because it is yielding\r\n# or resuming or dead), FiberError will be raised on root fiber chain.\r\n#\r\n# This will be run in the terminating fiber after its block has completed.\r\n# If this raises an exception, that will be raised on the root fiber chain.\r\n#\r\ndef select_return_fiber(terminating, retval, error)\r\n  supervisor = @supervised[terminating]\r\n  if supervisor&.alive?\r\n    supervisor\r\n  elsif @scheduled.include?(terminating)\r\n    @scheduler\r\n  elsif !error\r\n    raise FiberError, \"unsupervised transfer fiber terminated\"\r\n  end\r\nend\r\n```\r\n\r\nIn addition to answering the question raised by #17325 and #17331, I think this also simplifies some other useful patterns, e.g. supervisors.\r\n\r\nIt would also let me easily fix one of the things that ruby 3.0 breaks in my current code: I liked to \"init\" my transfer fibers by first resuming into them from their supervisor and then immediately transferring back out. That sets the return_fiber for when it terminates. A workaround is to use an ensured `supervisor.transfer` on the last line of the fiber and then abandon the almost dead fiber. But that might lead to a bug later if some other code held onto a reference to that fiber, saw it was still alive, and transferred into it (unlikely, but plausible). And it's still brittle: if any errant code calls `Fiber.yield`, the return_fiber will be lost and can never be recovered. Letting the scheduler manage this would provide the lost ruby 2 functionality and more.\r\n\r\nWhat do you think?", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-07T23:31:22Z", "updated_on": "2020-12-07T23:31:22Z", "closed_on": null, "relations": []}, {"id": 17371, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "fixed_version": {"id": 5, "name": "3.0"}, "subject": "Reintroduce `expr in pat`", "description": "How about reintroducing `expr in pat`, as akr-san proposed in DevelopersMeeting20201026Japan.\r\n\r\nThe difference between `expr => pat` and new `expr in pat` is the return value of the expression.\r\n\r\n```\r\n# expr => pat\r\n0 => a #=> void (succeeded)\r\n0 => 1 #=> NoMatchingPatternError (failed)\r\n\r\n# expr in pat\r\n0 in a #=> true (succeeded)\r\n0 in 1 #=> false (failed)\r\n```\r\n\r\nMotivation and use cases are described at [Feature #15865]. \r\n\r\nI pointed out that there is a concern that in this specification a user might overlook the pattern did not match, and changed the return value at [Feature #16355]. \r\nHowever, now we already have new \"rightward assignment style\" pattern matching syntax, so we can say that this problem is solved.\r\n\r\nIf `expr in pat` is accepted, I also propose that the return value of `expr => pat` on a successful match be the left-hand side value.\r\nBecause, in this case, it becomes more clear that the use of `expr => pat` is assignment.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-06T14:54:34Z", "updated_on": "2020-12-13T02:52:21Z", "closed_on": "2020-12-13T02:52:21Z", "relations": [{"id": 2794, "issue_id": 15865, "issue_to_id": 17371, "relation_type": "relates", "delay": null}, {"id": 2795, "issue_id": 16355, "issue_to_id": 17371, "relation_type": "relates", "delay": null}]}, {"id": 17370, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce non-blocking `Addrinfo.getaddrinfo` and related methods.", "description": "We would like to introduce a new scheduler hook for non-blocking `getaddrinfo`.\r\n\r\n```\r\nclass Scheduler\r\n  def address_resolve(...)\r\n    [array of addrinfo objects]\r\n  end\r\n```\r\n\r\nhttps://github.com/bruno-/ruby/pull/1\r\n\r\nThis is a work in progress.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-05T12:18:27Z", "updated_on": "2022-05-28T02:47:51Z", "closed_on": "2022-05-28T02:47:51Z", "relations": []}, {"id": 17369, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "assigned_to": {"id": 3344, "name": "ioquatix (Samuel Williams)"}, "subject": "Introduce non-blocking `Process.wait`, `Kernel.system` and related methods.", "description": "https://github.com/ruby/ruby/pull/3853\r\n\r\nThis PR introduces optional hooks to the scheduler interface for handling `Process.wait`, `Kernel.system` and other related methods (`waitpid`, `wait2`, etc).\r\n\r\nIt funnels all methods through a new interface `Process::Status.wait` which is almost identical to `Process.wait` except for several key differences:\r\n\r\n- The return value is a single instance of `Process::Status`.\r\n- It does not set thread local `$?`.\r\n\r\nThis is necessary for keeping the scheduler interface simple (and side effects are generally bad anyway).", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-05T12:10:34Z", "updated_on": "2021-10-21T07:50:20Z", "closed_on": "2021-10-21T07:50:20Z", "relations": []}, {"id": 17365, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "Can not respond (well) to a Ractor ", "description": "Summary: currently there is no good way to return a response to a Ractor message.\r\n\r\nSorry, this is long.\r\nPoints 1 to 3 look at possible current solutions and why they aren't great.\r\nPoint 4 discusses how Elixir/Erlang's builtin filtering allows responses.\r\nLast point proposes one of the many APIs that would allow responses.\r\n\r\nDetails:\r\n\r\nIf I want to program a \"server\" using Ractor, there has to be some way to receive the data from it.\r\nTo simplify, say I want a global `Config` that can be used to set/retrieve some global config parameters.\r\nTo set a parameter, I can use `server.send [:set, :key, 'value']`.\r\nBut what about retrieving? There is no good way to achieve that with the current API.\r\n\r\n1) \"pull\" API\r\n\r\nIt is not safe, as two clients could send a `:set` before the server answers, and the clients could resolve their `server.take` in the reverse order.\r\n\r\nAnother issue is that `Ractor.yield` is blocking, so the unexpected death of the client could mean the server hangs, and subsequent requests/responses are desynchronized and thus wrong.\r\n\r\nMy impression is that the \"pull\" API is best only used for monitoring of Ractors, rescuing exceptions, etc., or otherwise reserved for Ractors that are not shared, is this correct?\r\n\r\n2) \"push\" API\r\n\r\nIt seems much more appropriate to design a server such that one sends the client ractor with the push API. E.g. the client calls `server.send [:retrieve, :key, Ractor.current]`; the server can use the last element `cient_ractor` to respond with `client_ractor.send 'value'` that is non-blocking.\r\n\r\nThe client can then call `Ractor.receive`, immediately or later, to get the answer.\r\n\r\nThis is perfect, *except* that the client can not use `Ractor.receive` for any other purpose. It can not act itself a server, or if it calls multiple servers then it must do so synchroneously. Otherwise it might `receive` a request for something other than the response it was waiting for.\r\n\r\n3) create Ractor + \"push\" + \"pull\"\r\n\r\nThe only way I can think of currently is to create a temporary private Ractor (both to be able to use the \"pull\" and the \"push\" API):\r\n\r\n\r\n```ruby\r\n# on the client:\r\nresponse = Ractor.new(server, *etc) { |server, *etc|\r\n  server.send [:retrieve, :key, Ractor.current].freeze\r\n  Ractor.yield(Ractor.receive, move: true)\r\n}.take\r\n\r\n# on the server\r\ncase Ractor.receive\r\nin [:retrieve, key, client_ractor]\r\n  client_ractor.send('response')\r\n# ...\r\nend\r\n```\r\n\r\nI fear this would be quite inefficient (one Ractor per request, extra `move` of data) and seems very verbose.\r\n\r\n4) Filtered `receive`\r\n\r\nIf I look at Elixir/Erlang, this is not an issue because the equivalent of `Ractor.receive` has builtin pattern matching.\r\n\r\nThe key is that unmatched messages are [queued for later retrieval](https://www.erlang-solutions.com/blog/receiving-messages-in-elixir-or-a-few-things-you-need-to-know-in-order-to-avoid-performance-issues.html#receiving-messages-with-%E2%80%9Ca-priority%E2%80%9D). This way there can be different `Ractor.receive` used in different ways in the same Ractor and they will not interact (assuming they use different patterns).\r\n\r\nFor a general server (\"gen_server\"), a unique tag is created for each request, that is [sent with the request and with the response](https://stackoverflow.com/questions/56741322/gen-serverreply-2-format-of-message-sent-to-client)\r\n\r\nThe same pattern is possible to implement with Ruby but this can only work if as long as all the `Ractor.receive` use this implementation in a given Ractor, it has to be thread-safe, etc.\r\n\r\nIssue is that it may not be possible to have the same protocol and access to the same `receive` method, in particular if some of the functionality is provided in a gem.\r\n\r\n5) In conclusion...\r\n\r\nThe API of `Ractor` is currently lacking a good way to handle responses.\r\n\r\nIt needs to allow filtering/subdivision of the inbox in some way.\r\n\r\nOne API could be to add a `tag: nil` parameter to `Ractor#send` and `Ractor.receive` that would use that value to match.\r\n\r\nA server could decide to use the default `nil` tag for it's main API, and ask its clients to specify a tag for a response:\r\n\r\n```ruby\r\nmy_tag = :some_return_tag\r\nserver.send(:retrieve, :key, Ractor.current, my_tag)\r\nRactor.receive tag: my_tag\r\n\r\n# on the server\r\ncase Ractor.receive\r\nin [:retrieve, key, client_ractor, client_tag]\r\n  client_ractor.send('response', tag: client_tag)\r\n# ...\r\nend\r\n```\r\n\r\nTags would have to be Ractor-shareable objects and they could be compared by identity.\r\n\r\nNote that messages sent with a non-nil tag (e.g. `send 'value' tag: 42`) would not be matched by `Ractor.receive`.\r\nMaybe we should allow for a special `tag: :*` to match any tag?\r\n\r\n\r\nThere are other solutions possible; a request ID could be returned by `Ractor#send`, or there could be an API to create object for returns (like a \"Self-addressed stamped envelope\"), etc.\r\n\r\nThe basic filtering API I'm proposing has the advantage of being reasonable easy to implement efficiently and still allowing other patterns (for example handling messages by priority, assuming there can be a 0 timeout, see #17363), but I'll be happy as long as we can offer efficient and reliable builtin ways to respond to Ractor messages.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-04T05:05:31Z", "updated_on": "2020-12-18T20:25:23Z", "closed_on": "2020-12-18T20:25:23Z", "relations": [{"id": 2799, "issue_id": 17365, "issue_to_id": 17378, "relation_type": "relates", "delay": null}]}, {"id": 17363, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Timeouts", "description": "Builtin methods like `Queue.pop` and `Ractor.receive` have no timeout parameter.\r\n\r\nWe should either:\r\n- provide such a parameter\r\n- and/or provide a `Timeout::wake` that raises an timeout error only if the block is currently sleeping.\r\n\r\nDetails:\r\n\r\n```ruby\r\nq = Queue.new\r\n# ...\r\nelem = Timeout::timeout(42) { q.pop } # => It is possible that an element is retreived from the queue but never stored in `elem`\r\n\r\nelem = Timeout::wake(42) { q.pop } # => Guaranteed that either element is retrieved from the queue or an exception is raised, never both\r\nTimeout::wake(42) { loop {} } # => infinite loop\r\n# and/or\r\nelem = q.pop(timeout: 42)\r\n```\r\n\r\nCurrently, the only reliable way to have a Queue that accepts a timeout is to re-implement it from scratch. This post describe how involved that can be: https://spin.atomicobject.com/2017/06/28/queue-pop-with-timeout-fixed/", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-03T14:58:16Z", "updated_on": "2022-05-14T09:06:39Z", "closed_on": null, "relations": [{"id": 2854, "issue_id": 17363, "issue_to_id": 17470, "relation_type": "relates", "delay": null}, {"id": 2937, "issue_id": 17363, "issue_to_id": 17849, "relation_type": "relates", "delay": null}, {"id": 3329, "issue_id": 17363, "issue_to_id": 18774, "relation_type": "relates", "delay": null}]}, {"id": 17361, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 14, "name": "znz (Kazuhiro NISHIYAMA)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "lambda(&block) does not warn with lazy proc allocation", "description": "In NEWS,\r\n\r\n```\r\n        * Kernel#lambda now warns if called without a literal block.\r\n          [[Feature #15973]]\r\n```\r\n\r\nBut the following code from https://docs.ruby-lang.org/ja/latest/method/Kernel/m/lambda.html (<https://github.com/rurema/doctree/blob/495868c466c97c9bcca28d64d6ce0d68350de3e2/refm/api/src/_builtin/functions#L2436-L2441>) does not warn.\r\n\r\n```ruby\r\ndef foo &block\r\n  lambda(&block)\r\nend\r\n\r\nit = foo{p 12}\r\nit.call #=> 12\r\n```\r\n\r\nOnce block assign to a local variable, it warns.\r\n\r\n```ruby\r\ndef foo &block\r\n  b = block\r\n  lambda(&b)\r\nend\r\n\r\nit = foo{p 12}\r\nit.call #=> 12\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-03T02:45:23Z", "updated_on": "2020-12-11T02:58:00Z", "closed_on": "2020-12-11T02:58:00Z", "relations": [{"id": 2792, "issue_id": 15973, "issue_to_id": 17361, "relation_type": "relates", "delay": null}]}, {"id": 17357, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "`Queue#pop` should have a block form for closed queues", "description": "It is currently difficult to reliably distinguish a `nil` value in a queue from the `nil` that is returned when a Queue is closed:\r\n\r\n```ruby\r\nn = 100_000\r\nresult = []\r\nt2 = Thread.new { n.times { Thread.pass }} # to make things less predictable\r\nn.times.count do\r\n  q = Queue.new\r\n  t = Thread.new { q.pop; result << q.closed? }\r\n  q << nil\r\n  q.close\r\n  t.join\r\nend\r\nputs result.count(true) # => some number usually > 9990 and < 10000\r\n````\r\n\r\nTo be completely sure, one needs a Mutex or wrap/unwrap `nil` values.\r\n\r\n`Queue#pop` should offer a surefire way to handle closed queues. I propose that an optional block be called in this case:\r\n\r\n```ruby\r\nq = Queue.new.close\r\nq.pop # => nil\r\nq.pop { :closed }  # => :closed\r\n````\r\n\r\nProposed PR: https://github.com/ruby/ruby/pull/3830", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-12-01T01:42:16Z", "updated_on": "2021-01-12T07:32:17Z", "closed_on": null, "relations": [{"id": 2805, "issue_id": 10600, "issue_to_id": 17357, "relation_type": "relates", "delay": null}]}, {"id": 17356, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 46785, "name": "AndreaRibuoli (Andrea Ribuoli)"}, "subject": "Alignment of memory allocated through Fiddle struct's malloc", "description": "I am testing a low-level patch for **Ruby 3** that inside *gc.c* replaces:\r\n\r\n  `TRY_WITH_GC(size, mem = malloc(size));`\r\n\r\nwith:\r\n\r\n  `TRY_WITH_GC(size, mem = aligned_alloc(16,size));`\r\n\r\nThis should allow me to control that Fiddle returns pointers quad-words aligned.\r\n\r\nIs it possible to introduce a configure parameter to control this kind of setting?\r\n\r\nRefer to [issue opened on Fiddle](https://github.com/ruby/fiddle/issues/53).\r\n\r\nKind regards,\r\n\r\n   Andrea Ribuoli", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-30T08:25:26Z", "updated_on": "2020-12-02T11:06:09Z", "closed_on": null, "relations": []}, {"id": 17355, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8259, "name": "decuplet (Nikita Shilnikov)"}, "assigned_to": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "subject": "Using same set of names in or-patterns (pattern matching with Foo(x) | Bar(x))", "description": "Given pattern matching is officially supported in Ruby 3, I have an idea about making it more flexible.\r\n\r\nCurrently, this piece of code produces a syntax error\r\n```ruby\r\ncase [1, 2]\r\nin [1, a] | [a, 3] => a then a\r\nend # duplicated variable name\r\n```\r\nDuplications don't seem to be a problem here, semantically-wise. We just need to check if all patterns have the same set of names. It's supported in OCaml (also here's an RFC in Rust https://github.com/rust-lang/rust/issues/54883) so I think it can work in Ruby too.\r\n\r\nI've been using pattern matching in Ruby since day 1 and it worked great so far. Since I use OCaml daily too I miss this feature every once in a while :) \r\nA more practical example: imagine you have code like this\r\n\r\n```ruby\r\ndef user_email(user)\r\n  case user\r\n  in User(email:) then email\r\n  in Admin(email:) then email\r\n  in Moderator(email:) then email\r\n  end\r\nend\r\n```\r\n\r\nClearly, it could be simplified if or-patterns were supported:\r\n\r\n```ruby\r\ndef user_email(user)\r\n  case user\r\n  in User(email:) | Admin(email:) | Moderator(email:) then email\r\n  end\r\nend\r\n```\r\n\r\nI'd like to know @ktsj's thoughts on this.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-29T19:41:28Z", "updated_on": "2021-09-13T09:11:45Z", "closed_on": null, "relations": []}, {"id": 17353, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 45793, "name": "fulcanelly (Maks Kompanienko)"}, "subject": "Functional chaining operator", "description": "Since ruby already moving in that direction(functional), I would like to propose add to it OCaml-like chaining/pipe operator into ruby.\r\nWhich would allow such syntax\r\n\r\n``` ruby\r\ndef handle(requests) = requests\r\n  |> Array.filter { not _1.from.user.banned? }\r\n  |> Array.map { _1 |> main_router.emit }\r\n  |> Array.each &awaiter\r\n\r\n```\r\nWhat exactly happens here ?\r\n\r\nLet's look at a bit easier example:\r\n\r\n``` ruby\r\ngets.to_i\r\n|> make_stuff\r\n|> format \"the number is %d\"\r\n|> puts\r\n\r\n```\r\nWhich is expands exactly to the code below\r\n\r\n```ruby\r\nputs(format(\"the number is %d\", make_stuff(gets.to_i)))\r\n```\r\n\r\nSo what this operator does is nothing but just tricky form of AST building \r\n\r\nAdvantages:\r\n * Increase readability\r\n * It's more duck type-ish\r\n \r\nLimitations:\r\n  * cant be overloaded \r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-29T14:06:24Z", "updated_on": "2020-11-30T03:29:31Z", "closed_on": null, "relations": [{"id": 2790, "issue_id": 15799, "issue_to_id": 17353, "relation_type": "relates", "delay": null}, {"id": 2791, "issue_id": 16794, "issue_to_id": 17353, "relation_type": "relates", "delay": null}]}, {"id": 17351, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Deprecate Random::DEFAULT", "description": "From https://bugs.ruby-lang.org/issues/17322#note-11\r\n\r\nI think we should deprecate the `Random::DEFAULT` constant, it doesn't make sense anymore and it's longer than using Random class methods (Random.rand) or Kernel instance methods (#rand).\r\nAlso, people might expect it to be global.\r\n\r\nIf users want a Random instance they should just use `Random.new`, not assume there is a global instance in Random::DEFAULT, which is actually rather misleading now (Random::DEFAULT is no longer an instance of Random).\r\n\r\nAlso note that JRuby & TruffleRuby use a per-thread instance for Kernel#rand, etc, to avoid contention (otherwise it becomes a huge source of contention when threads run in parallel).\r\nWhich means on those implementations using Random::DEFAULT was inefficient (extra synchronization).\r\n\r\nSo for all these reasons I think it's time to deprecate `Random::DEFAULT` and then later remove it (in 3.1?).\r\n\r\nI don't think there is any use case for `Random::DEFAULT`, but happy to hear if there is and there is no trivial replacement.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-27T11:16:44Z", "updated_on": "2021-10-27T11:02:24Z", "closed_on": "2020-12-14T19:31:11Z", "relations": [{"id": 2788, "issue_id": 17322, "issue_to_id": 17351, "relation_type": "relates", "delay": null}]}, {"id": 17347, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 46708, "name": "asilano (Chris Howlett)"}, "subject": "Enumerator::Chain of Enumerator::Lazy should be lazy", "description": "ruby 2.6.6p146 (2020-03-31 revision 67876) [x86_64-linux]\r\n\r\nConsider the following script:\r\n``` ruby\r\na = [1,2,3].lazy\r\np a\r\nb = [4,5,6].lazy\r\np b\r\nc = a + b\r\np c\r\n```\r\n\r\nThis gives the output:\r\n```\r\n#<Enumerator::Lazy: [1, 2, 3]>\r\n#<Enumerator::Lazy: [4, 5, 6]>\r\n#<Enumerator::Chain: [#<Enumerator::Lazy: [1, 2, 3]>, #<Enumerator::Lazy: [4, 5, 6]>]>\r\n```\r\n\r\nNote that `c` is just `Enumerator::Chain`; but all its component enumerators are lazy, so it would be nice if `c` were lazy.\r\n\r\nThat is, I'd like the output to be:\r\n```\r\n#<Enumerator::Lazy: [1, 2, 3]>\r\n#<Enumerator::Lazy: [4, 5, 6]>\r\n#<Enumerator::Lazy: #<Enumerator::Chain: [#<Enumerator::Lazy: [1, 2, 3]>, #<Enumerator::Lazy: [4, 5, 6]>]>>\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-26T16:12:49Z", "updated_on": "2021-03-06T21:59:00Z", "closed_on": "2021-03-06T21:59:00Z", "relations": [{"id": 2787, "issue_id": 17347, "issue_to_id": 17216, "relation_type": "duplicates", "delay": null}]}, {"id": 17342, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8409, "name": "MaxLap (Maxime Lapointe)"}, "subject": "Hash#fetch_set", "description": "I would like to propose adding the `fetch_set` method to `Hash`. It behaves just like `fetch`, but when using the default value (2nd argument or the block), it also sets the value in the Hash for the given key.\r\n\r\nWe often use the pattern `cache[key] ||= calculation`. This pattern however has a problem when the calculation could return false or nil, as in those case, the calculation is repeated each time.\r\n\r\nI believe the best practice in that case is:\r\n\r\n```ruby\r\ncache.fetch(key) { cache[key] = calculation }\r\n```\r\n\r\nWith my suggestion, it would be:\r\n\r\n```ruby\r\ncache.fetch_set(key) { calculation }\r\n```\r\n\r\nIn these examples, each part is very short, so the `fetch` case is still clean. But as each part gets longer, the need to repeat cache[key] becomes more friction.\r\n\r\nHere is a more realistic example:\r\n\r\n```ruby\r\n# Also using the key argument to the block to avoid repeating the\r\n# long symbol, adding some indirection\r\nRequestStore.store.fetch(:monitor_value_is_delayed?) do |key|\r\n  RequestStore.store[key] = !MonitorValue.where('date >= ?', Time.now - 5.minutes).exists?\r\nend\r\n\r\nRequestStore.store.fetch_set(:monitor_value_is_delayed?) do\r\n  !MonitorValue.where('date >= ?', Time.now - 5.minutes).exists?\r\nend\r\n```\r\n\r\nThere is a precedent for such a method: Python has it, but with a quite confusing name: `setdefault(key, default_value)`. This does not set a default for the whole dictionary as the name would make you think, it really just does what is proposed here. https://docs.python.org/3/library/stdtypes.html#dict.setdefault", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-25T20:36:08Z", "updated_on": "2020-12-17T05:28:19Z", "closed_on": "2020-12-10T07:32:10Z", "relations": []}, {"id": 17339, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 46508, "name": "chumaltd (Takahiro Chuma)"}, "assigned_to": {"id": 482, "name": "mrkn (Kenta Murata)"}, "subject": "Semantic grouping with BigDecimal#to_s", "description": "# Abstract\r\nThousands, millions, ... should be expressible with `BigDecimal#to_s`.\r\n\r\n# Background\r\n`BigDecimal('1234567').to_s('3F')` returns \"123 456 7.0\".\r\n\r\n# Proposal\r\n  - Have an option with which `BigDecimal('1234567').to_s('3F')` returns \"_1 234 567_.0\".\r\n  - With decimal, `BigDecimal('1234567.8901234').to_s('3F')` should return \"1 234 567.890 123 4\".\r\n  - Default behavior should be the above in long term.\r\n  - And/Or, it would be nice to have a pretty method name. I think #to_s('3F') has universal use cases like money calculation.\r\n\r\n# Discussion\r\n  - International System of Units aka SI defines 3-digit-grouping on long numeric sequence.\r\n    https://www1.bipm.org/jsp/en/ViewCGPMResolution.jsp?CGPM=22&RES=10\r\n  - Original discussion in 1948 shows some example of 3-digit-grouping.\r\n    https://www1.bipm.org/utils/common/pdf/CGPM/CGPM9.pdf#page=117\r\n\r\n# Summary\r\n  We want to have a natural format.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-21T07:05:31Z", "updated_on": "2021-12-20T12:39:17Z", "closed_on": null, "relations": [{"id": 3194, "issue_id": 17339, "issue_to_id": 18410, "relation_type": "relates", "delay": null}]}, {"id": 17336, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 10073, "name": "k0kubun (Takashi Kokubun)"}, "subject": "using refined: do ... end", "description": "## Problem\r\nWhen we need a monkey patch which is used only in a single file, we'd like to define a refinement and use it in the same place. The problem is that it needs deep indentation and `Module.new { ... }` which feels redundant.\r\n\r\n```rb\r\nclass Foo\r\n  using Module.new {\r\n    refine Array do\r\n      def flat_map!(&block)\r\n        replace(flat_map(&block))\r\n      end\r\n    end\r\n  }\r\n  \r\n  # ...\r\nend\r\n```\r\n\r\n@tagomoris proposed an idea to reduce indentation and remove `Module.new { ... }`. This looks pretty convenient, but I want to write `do ... end`, which would make it a block of `using` here, because we almost always use `... end` for defining methods or modules.\r\n\r\n```rb\r\nmodule Kernel\r\n  def refined(mod, &block)\r\n    Module.new do\r\n      refine(mod, &block)\r\n    end\r\n  end\r\nend\r\n\r\nclass Foo\r\n  using refined(Array) {\r\n    def flat_map!(&block)\r\n      replace(flat_map(&block))\r\n    end\r\n  }\r\n\r\n  # ...\r\nend\r\n```\r\n\r\n## Proposal\r\nHow about supporting this? Because `using` currently doesn't take a block, it doesn't conflict with the existing syntax.\r\n\r\n```rb\r\nclass Foo\r\n  using refined: Array do\r\n    def flat_map!(&block)\r\n      replace(flat_map(&block))\r\n    end\r\n  end\r\n\r\n  # ...\r\nend\r\n```\r\n\r\nThis syntax is based on ideas of @tagomoris and @znz .", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-20T07:18:51Z", "updated_on": "2020-11-21T14:41:25Z", "closed_on": "2020-11-20T17:00:13Z", "relations": [{"id": 2783, "issue_id": 17336, "issue_to_id": 16241, "relation_type": "duplicates", "delay": null}]}, {"id": 17333, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 23655, "name": "okuramasafumi (Masafumi OKURA)"}, "subject": "Enumerable#many?", "description": "`Enumerable#many?` method is implemented in ActiveSupport.\r\nhttps://api.rubyonrails.org/classes/Enumerable.html#method-i-many-3F\r\nHowever, it's slightly different from Ruby's core methods such as `one?` or `all?`, where they take pattern argument.\r\nI believe these methods should behave the same so that it's easier to guess and learn.\r\n\r\nWe already have `none?`, `one?`, `any?` and `all?`, which translate into `== 0`, `== 1`, `> 0` and `== self.size`.\r\n`many?` method translates into `> 1`, which is reasonable to exist.\r\nCurrently we need to write something this:\r\n\r\n```ruby\r\n[1, 2, 3].count(&:odd?) > 1\r\n```\r\n\r\nWith `many?`, we can make it simpler:\r\n\r\n```ruby\r\n[1, 2, 3].many?(&:odd?)\r\n```\r\n\r\nPull Request on GitHub is available at https://github.com/ruby/ruby/pull/3785", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-18T12:58:53Z", "updated_on": "2020-12-11T03:38:22Z", "closed_on": null, "relations": []}, {"id": 17330, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "Object#non", "description": "(As always \"with core\" method proposals, I don't expect quick success, but hope for a fruitful discussion)\r\n\r\n### Reasons:\r\n\r\nRuby always tried to be very chainability-friendly. Recently, with introduction of `.then` and `=>`, even more so. But one pattern that frequently emerges and doesn't have good idiomatic expression: calculate something, and if it is not a \"good\" value, return `nil` (or provide default value with `||`). There are currently two partial solutions:\r\n\r\n1. `nonzero?` in Ruby core (frequently mocked for \"inadequate\" behavior, as it is looking like predicate method, but instead of `true`/`false` returns an original value or `nil`)\r\n2. ActiveSupport `Object#presence`, which also returns an original value or `nil` if it is not \"present\" (e.g. `nil` or `empty?` in AS-speak)\r\n\r\nBoth of them prove themselves quite useful in some domains, but they are targeting only those particular domains, look unlike each other, and can be confusing.\r\n\r\n### Proposal:\r\n\r\nMethod `Object#non` (or `Kernel#non`), which receives a block, calls it with receiver and returns `nil` (if block matched) or receiver otherwise.\r\n\r\n##### Prototype implementation:\r\n\r\n```ruby\r\nclass Object\r\n  def non\r\n    self unless yield(self)\r\n  end\r\nend\r\n```\r\n\r\n##### Usage examples:\r\n\r\n1. With number:\r\n\r\n    ```ruby\r\n    limit = calculate.some.limit\r\n    limit.zero? ? DEFAULT_LIMIT : limit\r\n    # or, with nonzero?\r\n    calculate.some.limit.nonzero? || DEFAULT_LIMIT\r\n    # with non:\r\n    calculate.some.limit.non(&:zero?) || DEFAULT_LIMIT\r\n    # ^ Note here, how, unlike `nonzero?`, we see predicate-y ?, but it is INSIDE the `non()` and less confusing\r\n    ```\r\n\r\n2. With string:\r\n\r\n    ```ruby\r\n    name = params[:name] if params[:name] && !params[:name].empty?\r\n    # or, with ActiveSupport:\r\n    name = params[:name].presence\r\n    # with non:\r\n    name = params[:name]&.non(&:empty?)\r\n    ```\r\n\r\n3. More complicated example\r\n\r\n    ```ruby\r\n    action = payload.dig('action', 'type')\r\n    return if PROHIBITED_ACTIONS.include?(action)\r\n    send(\"do_#{action}\")\r\n    # with non & then:\r\n    payload.dig('action', 'type')\r\n      .non { |action| PROHIBITED_ACTIONS.include?(action) }\r\n      &.then { |action| send(\"do_#{action}\") }\r\n    ```\r\n\r\n### Possible extensions of the idea\r\n\r\nIt is quite tempting to define the symmetric method named -- as we already have `Object#then` -- `Object#when`:\r\n```ruby\r\nsome.long.calculation.when { |val| val < 10 } # returns nil if value >= 10\r\n# or even... with support for ===\r\nsome.long.calculation.when(..10)&.then { continue to do something }\r\n```\r\n...but I am afraid I've overstayed my welcome :)\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-17T12:49:02Z", "updated_on": "2021-01-25T15:54:53Z", "closed_on": null, "relations": [{"id": 2778, "issue_id": 12075, "issue_to_id": 17330, "relation_type": "relates", "delay": null}]}, {"id": 17328, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 46282, "name": "sdwolfz (Codru\u021b Gu\u0219oi)"}, "subject": "Extend `un.rb` to be usable by everyone", "description": "I've opened the PR here: https://github.com/ruby/ruby/pull/3771, although if you need me to submit a patch just let me know.\r\nBasically I want to be able to use `ruby -run` for more than just running a http server, and thought it could require a local `run.rb` file with code that end users provide.\r\n\r\nNot sure if this was proposed before but let me know what you think.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-16T14:37:17Z", "updated_on": "2020-11-17T00:08:27Z", "closed_on": "2020-11-17T00:08:27Z", "relations": []}, {"id": 17327, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8671, "name": "chrisseaton (Chris Seaton)"}, "assigned_to": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "The Queue constructor should take an initial set of items", "description": "I often create a `Queue` and then process it with a set of concurrent workers in threads. I end up writing:\r\n\r\n```ruby\r\nq = Queue.new\r\nworklist.each do |work|\r\n  q.push work\r\nend\r\n```\r\n\r\nI'd rather be able to write\r\n\r\n```ruby\r\nq = Queue.new(*worklist)\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-15T22:06:45Z", "updated_on": "2021-02-12T04:36:08Z", "closed_on": "2021-02-12T04:36:08Z", "relations": []}, {"id": 17326, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 46252, "name": "jez (Jake Zimmerman)"}, "subject": "Add Kernel#must! to the standard library", "description": "# Abstract\r\n\r\nWe should add a method `Kernel#must!` (name TBD) which raises if `self` is `nil` and returns `self` otherwise.\r\n\r\n\r\n# Background\r\n\r\nRuby 3 introduces type annotations for the standard library.\r\nType checkers consume these annotations, and report errors for type mismatches.\r\nOne of the most common and most valuable type errors is whether `nil` is allowed as an argument or return value.\r\nSorbet's type system tracks this, and RBS files have syntax for annotating whether `nil` is allowed or not.\r\n\r\nSince Sorbet checks proper usage of `nil`, it requires code that looks like this:\r\n\r\n```ruby\r\nif thing.nil?\r\n  raise \"The thing was nil\"\r\nend\r\n\r\nthing.do_something\r\n```\r\n\r\nThis is good because it forces the programmer to acknowledge that the thing might be `nil`, and declare\r\nthat they'd rather raise an exception in that case than handle the `nil` (of course, there are many other\r\ntimes where `nil` is both possible and valid, which is why Sorbet forces at least considering in all cases).\r\n\r\nIt is annoying and repetitive to have to write these `if .nil?` checks everywhere to ignore the type error,\r\nso Sorbet provides it as a library function, called `T.must`:\r\n\r\n```ruby\r\nT.must(thing).do_something\r\n```\r\n\r\nSorbet knows that the call to `T.must` raises if `thing` is `nil`.\r\nTo make this very concrete, here's a Sorbet playground where you can see this in action:\r\n\r\n[\u2192 View on sorbet.run](https://sorbet.run/#%23%20typed%3A%20true%0Aextend%20T%3A%3ASig%0A%0Aclass%20Thing%0A%20%20def%20do_something%3B%20end%0Aend%0A%0Asig%20%7Bparams(thing%3A%20T.nilable(Thing)).void%7D%0Adef%20example1(thing)%0A%20%20%23%20error%2C%20might%20be%20nil%3A%0A%20%20thing.do_something%0Aend%0A%0Asig%20%7Bparams(thing%3A%20T.nilable(Thing)).void%7D%0Adef%20example2(thing)%0A%20%20if%20thing.nil%3F%0A%20%20%20%20raise%20%22The%20thing%20was%20nil%22%0A%20%20end%0A%0A%20%20%23%20no%20error%2C%20because%20it's%20after%20the%20%60if%20.nil%3F%60%20check%3A%0A%20%20thing.do_something%0Aend%0A%0Asig%20%7Bparams(thing%3A%20T.nilable(Thing)).void%7D%0Adef%20example3(thing)%0A%20%20%23%20no%20error%2C%20because%20it's%20after%20the%20%60if%20.nil%3F%60%20check%3A%0A%20%20T.must(thing).do_something%0Aend)\r\n\r\nYou can read more about `T.must` in the [Sorbet documentation](https://sorbet.org/docs/type-assertions#tmust).\r\n\r\n\r\n# Problem\r\n\r\nWhile `T.must` works, it is not ideal for a couple reasons:\r\n\r\n1.  It leads to a weird outward spiral of flow control, which disrupts method chains:\r\n\r\n    ```ruby\r\n    # \u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\r\n    # \u2502      \u250c\u2500\u2500\u2500\u2500\u2510     \u2502\r\n    # \u25bc      \u25bc    \u2502     \u2502\r\n    T.must(T.must(task).mailing_params).fetch('template_context')\r\n    # \u2502      \u2502          \u25b2               \u25b2\r\n    # \u2502      \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518               \u2502\r\n    # \u2514\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2518\r\n    ```\r\n\r\n    compare that control flow with this:\r\n\r\n    ```ruby\r\n    # \u250c\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2510\u250c\u2500\u2500\u2500\u2500\u2510\r\n    # \u2502    \u25bc\u2502    \u25bc\u2502             \u25bc\u2502    \u25bc\r\n      task.must!.mailing_params.must!.fetch('template_context')\r\n    ```\r\n\r\n2.  It is not a method, so you can't `map` it over a list using `Symbol#to_proc`. Instead, you have to expand the block:\r\n\r\n    ```ruby\r\n    array_of_integers = array_of_nilable_integers.map {|x| T.must(x) }\r\n    ```\r\n\r\n    Compare that with this:\r\n\r\n    ```ruby\r\n    array_of_integers = array_of_nilable_integers.map(&:must!)\r\n    ```\r\n\r\n3.  It is in a Sorbet-specific gem. We do not intend for Sorbet to be the only type checker.\r\n    It would be nice to have such a method in the Ruby standard library so that it can be shared by all type checkers.\r\n\r\n4.  This method can make Ruby codebases that **don't** use type checkers more robust!\r\n    `Kernel#must!` could be an easy way to assert invariants early.\r\n    Failing early makes it more likely that a test will fail, rather than getting `TypeError`'s and `NoMethodError`'s in production.\r\n    This makes all Ruby code better, not just the Ruby code using types.\r\n\r\n\r\n# Proposal\r\n\r\nWe should extend the Ruby standard library with something like this::\r\n\r\n```ruby\r\nmodule Kernel\r\n  def must!; self; end\r\nend\r\n\r\nclass NilClass\r\n  def must!\r\n    raise TypeError.new(\"nil.must!\")\r\n  end\r\nend\r\n```\r\n\r\nThese methods would get type annotations that look like this:\r\n(using Sorbet's RBI syntax, because I don't know RBS well yet)\r\n\r\n```ruby\r\nmodule Kernel\r\n  sig {returns(T.self_type)}\r\n  def must!; end\r\nend\r\n\r\nclass NilClass\r\n  sig {returns(T.noreturn)}\r\n  def must!; end\r\nend\r\n```\r\n\r\nWhat these annotations say:\r\n\r\n- In `Kernel#must!`, the return value is `T.self_type`, or \"whatever the type of the receiver was.\"\r\n  That means that `0.must!` will have type `Integer`, `\"\".must!` will have type `String`, etc.\r\n\r\n- In `NilClass#must!`, there is an override of `Kernel#must!` with return type `T.noreturn`.\r\n  This is a fancy type that says \"this code either infinitely loops or raises an exception.\"\r\n  This is the name for Sorbet's [bottom type](https://en.wikipedia.org/wiki/Bottom_type), if you\r\n  are familiar with that terminology.\r\n\r\nHere is a Sorbet example where you can see how these annotations behave:\r\n\r\n[\u2192 View on sorbet.run](https://sorbet.run/#%23%20typed%3A%20true%0A%0Amodule%20Kernel%0A%20%20T%3A%3ASig%3A%3AWithoutRuntime.sig%20%7Breturns(T.self_type)%7D%0A%20%20def%20must!%3B%20self%3B%20end%0Aend%0A%0Aclass%20NilClass%0A%20%20T%3A%3ASig%3A%3AWithoutRuntime.sig%20%7Breturns(T.noreturn)%7D%0A%20%20def%20must!%0A%20%20%20%20raise%20TypeError.new(%22nil.must!%22)%0A%20%20end%0Aend%0A%0Axs%20%3D%20T%3A%3AArray%5BInteger%5D.new(%5B0%5D)%0AT.reveal_type(xs.first)%20%20%20%20%20%20%20%23%20T.nilable(Integer)%0AT.reveal_type(xs.first.must!)%20%23%20Integer%0A%0Ays%20%3D%20T%3A%3AArray%5BT.nilable(Integer)%5D.new(%5B0%2C%20nil%2C%201%2C%20nil%2C%202%5D)%0AT.reveal_type(ys)%20%20%20%20%20%20%20%20%20%20%20%20%20%20%23%20T%3A%3AArray%5BT.nilable(Integer)%5D%0AT.reveal_type(ys.map(%26%3Amust!))%20%23%20T%3A%3AArray%5BInteger%5D)\r\n\r\n# Alternatives considered\r\n\r\nThere was some discussion of this feature at the Feb 2020 Ruby Types discussion:\r\n\r\nSummarizing:\r\n\r\n- Sorbet team frequently recommends people to use `xs.fetch(0)` instead of `T.must(xs[0])`\r\n  on `Array`'s and `Hash`'s because it chains and reads better.\r\n  `.fetch` not available on other classes.\r\n\r\n- It's intentional that `T.must` requires as many characters as it does.\r\n  Making it slightly annoying to type encourages developers to refactor their code so that `nil` never occurs.\r\n\r\n- There was a proposal to introduce new syntax like `thing.!!`. This is currently a syntax error.\r\n\r\n  **Rebuttal**: There is burden to introducing new syntax. Tools like Rubocop, Sorbet, and syntax highlighting\r\n  plugins have to be updated. Also: it is hard to search for on Google (as a new Ruby developer). Also: it\r\n  is very short\u2014having something slightly shorter makes people think about whether they want to type it out\r\n  instead of changing the code so that `nil` can't occur.\r\n\r\nAnother alternative would be to dismiss this as \"not useful / common enough\". I don't think that's true.\r\nHere are some statistics from Stripe's Ruby monolith (~10 million lines of code):\r\n\r\n| methood | percentage of files mentioning method | number of occurrences of method |\r\n| --- | --- | --- |\r\n| `.nil?` | 16.69% | 31340 |\r\n| `T.must` | 23.89% | 74742 |\r\n\r\nFrom this, we see that\r\n\r\n- `T.must` is in 1.43x more files than `.nil?`\r\n- `T.must` occurs 2.38x more often than `.nil?`\r\n\r\n\r\n# Naming\r\n\r\nI prefer `must!` because it is what the method in Sorbet is already called.\r\n\r\nI am open to naming suggestions. Please provide reasoning.\r\n\r\n\r\n# Discussion\r\n\r\nIn the above example, I used `T.must` twice. An alternative way to have written that would have been using save navigation:\r\n\r\n```ruby\r\nT.must(task&.mailing_params).fetch('template_context')\r\n```\r\n\r\nThis works as well. The proposed `.must!` method works just as well when chaining methods with safe navigation:\r\n\r\n```ruby\r\ntask&.mailing_params.must!.fetch('template_context')\r\n```\r\n\r\nHowever, there is still merit in using `T.must` (or `.must!`) twice\u2014it calls out that the programmer\r\nintended neither location to be `nil`. In fact, if this method had been chained across multiple lines,\r\nthe backtrace would include line numbers saying specifically **which** `.must!` failed:\r\n\r\n\r\n```ruby\r\ntask.must!\r\n  .mailing_params.must!\r\n  .fetch('template_context')\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-14T23:15:30Z", "updated_on": "2022-06-22T16:10:27Z", "closed_on": null, "relations": []}, {"id": 17325, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 33540, "name": "nevans (Nicholas Evans)"}, "subject": "Adds Fiber#cancel, which forces a Fiber to break/return", "description": "\r\nCalling `Fiber#cancel` will force a fiber to return, skipping rescue and catch blocks but running all ensure blocks. It behaves as if a `break` or `return` were used to jump from the last suspension point to the top frame of the fiber. Control will be transferred to the canceled fiber so it can run its ensure blocks.\r\n\r\n## Propagation from resuming to resumed fibers\r\n\r\nAny non-root living fiber can be canceled and cancellation will propagate to child (resumed) fibers. In this way, a suspended task can be canceled even if it is e.g. resuming into an enumerator, and the enumerator will be canceled as well. Transfer of control should match #17221's *(much improved)* transfer/resume semantics. After the cancellation propagates all the way to the bottom of the fiber resume stack, the last fiber in the chain will then be resumed. Resuming fibers will not run until they are yielded back into.\r\n\r\n## Suspension of canceled fibers\r\n\r\nCanceled fibers can still transfer control with `resume`, `yield`, and `transfer`, which may be necessary in order to release resources from `ensure` blocks. For simplicity, subsequent cancels will behave similarly to calling `break` or `return` inside an `ensure` block, and the last cancellation reason will overwrite earlier reasons.\r\n\r\n## Alternatives\r\n\r\n`Fiber#raise` could be used, but:\r\n* Can only raise on resumable fibers.\r\n* Cannot propagate cancellation down to resumed fibers.\r\n* Exceptions are bigger and slower than `break`.\r\n* `#raise` can't (and shouldn't) be sent to resuming fibers. (It can't propagate.)\r\n* Exceptions can be caught. This might be desirable, but that should be at the discretion of the calling fiber.\r\n\r\nCatch/Throw could be used (with an anonymous `Object.new`), but:\r\n* We would need to add `Fiber#throw` (or wrap/intercept `Fiber.yield`).\r\n* A hypothetical `Fiber#throw` should probably have similar semantics to `#resume` and thus only be allowed on resumable fibers.\r\n  * In that case, it wouldn't propagate down to resumed fibers.\r\n* `catch` adds an extra stack frame.\r\n\r\nWe could use go-style \"Context\" objects that contain a \"done?\" queue/future.\r\n* These would need to be explicitly passed around.\r\n* Although their usage could be enforced via linters like rubocop, I think that placing it off to the side will give developers the impression that it is optional Some sort of cancel propagation mechanism is not optional for structured concurrency.\r\n* It should built into any task-scheduler library, which would allow application code to use it explicitly.\r\n* But this suffers the same problem as current Fiber wrappers: it works fine if your code uses the wrapper, but code that uses fibers without the wrapper can be incompatible and introduce bugs (e.g. fibers that are released without running their `ensure` blocks).\r\n* This make sense for a language like go which doesn't have exceptions but does have a convention of returning an \"error\" value. It feels out of place in ruby, IMO. Letting the fiber-task-scheduler mitigates that... for code that uses the fiber-task-scheduler.\r\n\r\nWe could add a keyword option to `Fiber#raise` that gives it similar propagation semantics to this.\r\n* IMO, the simplicity of `Fiber#raise` simply being a specialized version of `Fiber#resume` is worth preserving.\r\n* The propagation changes alone are enough of a semantic difference to warrant a new method.\r\n\r\nWe could implement `Fiber#cancel` by using `fiber.raise(FiberCancellationError)` on the bottom fiber and catching that exception during termination of the canceled fiber.\r\n* This would have the \"benefit\" that the exception could be rescued.\r\n* I might be wrong, but I think that doing this would mostly duplicate my PR, but with some added complexity around exception construction and catching.\r\n* It might be a good keyword option? e.g. `Fiber#cancel(with_exception: [true,#exception,#to_str])`\r\n\r\nJust let the task-fiber-scheduler library handle this.\r\n* That's what I'm already doing now. It's mostly fine. It works in my code.\r\n* Putting it into ruby core should lead to a small performance boost on very commonly repeated code.\r\n  * There's probably a better way to store the `cancel_reason` that doesn't require the overhead of adding another `VALUE` to `rb_fiber_struct`. Maybe it can be placed directly into `errinfo`?\r\n* Although the common cases can be handled via a trampoline fiber or #17221, there can still be situations where your application's fiber-scheduler library might not know about fibers created by other libraries. This adds interoperability to a common scenario.\r\n* Coroutine cancellation is IMO a core feature. It's important to have something like this for all applications and libraries to use as a baseline for interoperability.\r\n\r\nImplementation:  https://github.com/ruby/ruby/pull/3766", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-14T22:43:31Z", "updated_on": "2020-11-19T00:34:28Z", "closed_on": null, "relations": [{"id": 2784, "issue_id": 17325, "issue_to_id": 17331, "relation_type": "relates", "delay": null}]}, {"id": 17323, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor::LVar to provide ractor-local storage", "description": "Ruby supports thread and fiber local storage:\r\n\r\n* `Thread#[sym]` provides *Fiber* local storage\r\n* `Thread#thread_variable_get(sym)`\r\n\r\nThese APIs can access other threads/fibers like that:\r\n\r\n```ruby\r\nth = Thread.new{\r\n  Thread.current.thread_variable_set(:a, 10)\r\n}\r\nth.join\r\n# access from main thread to child thread\r\np th.thread_variable_get(:a)\r\n```\r\n\r\nTo make Ractor local storage, this kind of feature should not be allowed to protect isolation.\r\n\r\nThis ticket propose alternative API `Ractor::LVar` that allows to provide Ractor local variable.\r\n\r\n```ruby\r\nLV1 = Ractor::LVar.new\r\n\r\np LV1.value #=> nil # default value\r\nLV1.value = 'hello' # can set unshareable objects because LVar is ractor local.\r\n\r\nRactor.new do\r\n  LV1.value = 'world' # set Ractor local variable\r\nend.take\r\n\r\np LV1.value #=> 'hello'\r\n\r\n\r\n# Lvar.new can accept default_proc which should be isolated Proc.\r\n\r\nLV2 = Ractor::LVar.new{ \"x\" * 4 }\r\np LV2.value #=> \"xxxx\"\r\nLV2.value = 'yyy'\r\n\r\nRactor.new do\r\n  p LV2.value #=> 'xxx'\r\nend\r\n\r\np LV2.value #=> 'yyy'\r\n```\r\n\r\nThis API doesn't support accessing from other ractors.\r\n\r\n`Ractor::LVar` is from `Ractor::TVar`, but I have no strong opinion about it.\r\nFor example, `Ractor::LocalVariable` is longer and clearer.\r\n\r\nImplementation: https://github.com/ruby/ruby/pull/3762\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-12T16:55:20Z", "updated_on": "2021-01-07T13:11:10Z", "closed_on": "2020-12-21T20:58:39Z", "relations": []}, {"id": 17322, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Deprecate `Random::DEFAULT` and introduce `Random.default()` method to provide Ractor-supported default random generator", "description": "`Random::DEFAULT` a default random generator used by `rand`, `srand`, `Array#shuffle` without a given random generator, and so on.\r\n\r\nRandom generators are not thread-safe, so they are not ractor safe, and they are not shareable.\r\nSo a program refer to `Random::DEFAULT` on non-main ractor, it causes an error.\r\n\r\nTo provide per-ractor default random generator, this ticket propose the `Random.default()` method which returns per-ractor random generator.\r\n`Random::DEFAULT` is a result of `Random.default()` on main-ractor and it should be deprecated, or at least it should not be used on multi-ractor supporting apps and libraries.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-12T01:48:26Z", "updated_on": "2020-11-27T08:03:52Z", "closed_on": "2020-11-27T08:03:52Z", "relations": [{"id": 2788, "issue_id": 17322, "issue_to_id": 17351, "relation_type": "relates", "delay": null}]}, {"id": 17316, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "On memoization", "description": "I have seen so many attempts to memoize a value in the form:\r\n\r\n```ruby\r\n@foo ||= some_heavy_calculation(...)\r\n```\r\n\r\nimproperly, i.e., even when the value can potentially be falsy. This practice is wide spread, and since in most cases memoization is about efficiency and it would not be critical if it does not work correctly, people do not seem to care so much about correcting the wrong usage.\r\n\r\nIn such case, the correct form would be:\r\n\r\n```ruby\r\nunless instance_variable_defined?(:@foo)\r\n  @foo = some_heavy_calculation(...)\r\nend\r\n```\r\n\r\nbut this looks too long, and perhaps that is keeping people away from using it.\r\n\r\nWhat about allowing `Kernel#instance_variable_set` to take a block instead of the second argument, in which case the assignment should be done only when the instance variable is not defined?\r\n\r\n```ruby\r\ninstance_variable_set(:@foo){some_heavy_calculation(...)}\r\n```\r\n\r\nOr, if that does not look right or seems to depart from the original usage of `instance_variable_set`, then what about having a new method?\r\n\r\n```ruby\r\nmemoize(:foo){some_heavy_calculation(...)}\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-11T10:22:03Z", "updated_on": "2022-05-13T11:32:06Z", "closed_on": null, "relations": []}, {"id": 17315, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 124, "name": "dsisnero (Dominic Sisneros)"}, "subject": "Hash #transform", "description": "Add new methods to `transform` or `transform!` both the keys and the values of a hash.\r\n#7793 \r\n\r\n```ruby\r\nh = {'name' => 'dominic ', 'email' => 'dominic.mail.com '}\r\nh.transform!{|k,v| [k.to_sym, v.strip]}\r\nh # => {name: 'dominic', email: 'dominic.mail.com'}\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-10T19:41:59Z", "updated_on": "2020-11-13T20:38:06Z", "closed_on": "2020-11-10T20:53:21Z", "relations": []}, {"id": 17314, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 69, "name": "radarek (Rados\u0142aw Bu\u0142at)"}, "subject": "Provide a way to declare visibility of attributes defined by attr* methods in a single expression", "description": "**Description**\r\n\r\nMany of us (me included) declare class attributes, even if they are private, on the top of class definition. When reading source code it's convinient to see what kind of attributes class has.\r\n\r\nTo declare private attributes we can:\r\n* declare them with one of `attr*` methods and later change visiblity calling `private`\r\n* call `private` without argument, then declare attributes and finally call (in most cases) `public` to keep defining public methods\r\n* declare attribute on top of the class but make them private in private section later in a file\r\n\r\n``` ruby\r\nclsss Foo\r\n  attr_accessor :foo\r\n  private :foo, :foo= # we have to remember about :foo= too\r\n\r\n  private\r\n\r\n  attr_accessor :bar\r\n\r\n  public\r\n\r\n  # rest of the code\r\nend\r\n```\r\n\r\nTo simplify it and create other possibilites I propose to:\r\n* change `attr*` methods so as they return array of defined methods names\r\n* allow `public/protected/private` methods to receive array of methods names (single argument)\r\n\r\nWith requested feature we could write code like this:\r\n\r\n``` ruby\r\nclass Foo\r\n  private attr_accessor :foo, :bar\r\nend\r\n```\r\n\r\nAdditionaly you could use `attr*` with your own methods. Something like this:\r\n\r\n``` ruby\r\nclass Module\r\n  def traceable(names)\r\n    # ...\r\n    names\r\n  end\r\nend\r\n\r\nclass Foo\r\n  traceable attr_accessor :foo\r\n  # it can be mixed with public/protected/private too\r\n  protected traceable attr_accessor :bar\r\nend\r\n```\r\n\r\n**Backward compatibility**\r\n\r\n* `attr*` methods currently return `nil` so there should be no problem with changing them\r\n* `public/protected/private` methods receive multiple positional arguments and convert all non symbol/string objects to strings. I can imagine only one case where compatibility would be broken:\r\n\r\n``` ruby\r\nclass Foo\r\n  def foo; end\r\n  def bar; end\r\n\r\n  arr = [:foo]\r\n  def arr.to_str\r\n    'bar'\r\n  end\r\n\r\n  private arr\r\nend\r\n\r\np [Foo.public_instance_methods(false), Foo.private_instance_methods(false)]\r\n```\r\n\r\nCurrently `[[:foo], [:bar]]` would be displayed, `[[:bar], [:foo]]` after requested feature is implemented.\r\n\r\n**Implementation**\r\n\r\nYou can view my implementation in this (draft) PR: https://github.com/ruby/ruby/pull/3757\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-10T18:22:36Z", "updated_on": "2020-12-23T15:47:20Z", "closed_on": "2020-12-18T04:04:12Z", "relations": [{"id": 2923, "issue_id": 6470, "issue_to_id": 17314, "relation_type": "relates", "delay": null}]}, {"id": 17312, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 710, "name": "zverok (Victor Shepelev)"}, "subject": "New methods in Enumerable and Enumerator::Lazy: flatten, product, compact", "description": "(The offspring of #16987, which was too vague/philosophical)\r\n\r\nI propose to add to `Enumerable` and `Enumerator::Lazy` the following methods:\r\n* `compact`\r\n* `product`\r\n* `flatten`\r\n\r\nAll of them can be performed with a one-way enumerator. All of them make sense for situations other than \"just an array\". All of them can be used for processing large sequences, and therefore meaningful to add to `Lazy`.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-09T13:27:12Z", "updated_on": "2021-01-02T08:28:05Z", "closed_on": "2021-01-02T08:28:05Z", "relations": [{"id": 2781, "issue_id": 16987, "issue_to_id": 17312, "relation_type": "relates", "delay": null}]}, {"id": 17311, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 35524, "name": "S_H_ (Shun Hiraoka)"}, "subject": "Improve performance Array#deconstruct & Array#to_ary", "description": "Improve performance `Array#deconstruct` & `Array#to_ary` with Ruby code.\r\n\r\nlike this.\r\n\r\n```ruby\r\nclass Array\r\n  def deconstruct\r\n    return self\r\n  end\r\n\r\n  def to_ary\r\n    return self\r\n  end\r\nend\r\n```\r\n\r\nbenchmark:\r\n\r\n```yml\r\nprelude: |\r\n  sary = Array.new(10)\r\n  mary = Array.new(1000)\r\n  lary = Array.new(30_000_000)\r\nbenchmark:\r\n  - sary.deconstruct\r\n  - mary.deconstruct\r\n  - lary.deconstruct\r\n  - sary.to_ary\r\n  - mary.to_ary\r\n  - lary.to_ary\r\nloop_count: 20000000\r\n\r\n\r\n```\r\n\r\nbenchmark result:\r\n\r\n```bash\r\nsh@MyComputer:~/rubydev/build$ make benchmark/benchmark.yml -e COMPARE_RUBY=~/.rbenv/shims/ruby -e BENCH_RUBY=../install/bin/ruby\r\n# Iteration per second (i/s)\r\n\r\n|                  |compare-ruby|built-ruby|\r\n|:-----------------|-----------:|---------:|\r\n|sary.deconstruct  |     72.866M|   74.310M|\r\n|                  |           -|     1.02x|\r\n|mary.deconstruct  |     73.665M|   80.049M|\r\n|                  |           -|     1.09x|\r\n|lary.deconstruct  |     74.924M|   86.865M|\r\n|                  |           -|     1.16x|\r\n|sary.to_ary       |     70.203M|   81.387M|\r\n|                  |           -|     1.16x|\r\n|mary.to_ary       |     72.142M|   78.847M|\r\n|                  |           -|     1.09x|\r\n|lary.to_ary       |     70.473M|   86.382M|\r\n|                  |           -|     1.23x|\r\n```\r\n\r\nCOMPARE_RUBY is `ruby 3.0.0dev (2020-11-07T13:12:22Z master 5823f6c25b) [x86_64-linux]`. BENCH_RUBY is ahead of `ruby 3.0.0dev (2020-11-07T13:12:22Z master 5823f6c25b) [x86_64-linux]`.\r\n\r\nAlso expect to improve the performance of pattern matching using arrays.\r\n\r\nPR:\r\nhttps://github.com/ruby/ruby/pull/3744", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-08T07:08:55Z", "updated_on": "2020-11-08T07:12:55Z", "closed_on": null, "relations": []}, {"id": 17307, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "A way to mark C extensions as thread-safe, Ractor-safe, or unsafe", "description": "I would like to design a way to mark C extensions as thread-safe, Ractor-safe, or unsafe (= needs process-global lock).\r\nBy default, if not marked, C extensions would be treated as unsafe for compatibility.\r\n\r\nSpecifically, TruffleRuby supports C extensions, but for scalability it is important to run at least some of them in parallel (e.g., HTTP parsing in Puma).\r\nThis was notably mentioned in my [RubyKaigi talk](https://speakerdeck.com/eregon/running-rack-and-rails-faster-with-truffleruby?slide=17).\r\nTruffleRuby defaults to acquire a global lock when executing C extension code for maximum compatibility (Ruby code OTOH can always run in parallel).\r\nThere is a command-line option for that lock and it can be disabled, but then it is disabled for all C extensions.\r\nThe important property for TruffleRuby is that the C extension does not need a global lock, i.e., that it synchronizes any mutable state in C that could be accessed by multiple threads, such as global C variables.\r\nI believe many C extensions are already thread-safe, or can easily become thread-safe, because they do not rely on global state and do not share the RData objects between threads.\r\n\r\nRactor also needs a way to mark C extensions, to know if it's OK to use the C extension in multiple Ractors in parallel, and that the C extension will not leak non-shareable objects from one Ractor to another, which would lead to bugs & segfaults.\r\nOtherwise, C extensions could only be used on the main/initial Ractor (or need to acquire a process-global lock whenever executing C extension code and ensure no non-shareable objects leak between Ractors), which would be a very big limitation (almost every non-trivial application depends on a C extension transitively).\r\n\r\nIn both cases, global state in the C extension needs synchronization.\r\nIn the thread-safe case, mutable state in C that could be accessed by multiple Ruby threads needs to be synchronized too (there might be no such state, e.g., if C extension objects are created per Thread).\r\nIn the Ractor case, the C extension must never pass an object from a Ractor to another, unless it is a shareable object.\r\n\r\nWhat do you think would be a good way to \"mark\" C extensions?\r\nMaybe defining a symbol in the C extension, similar to the `Init_foo` we have, like say `foo_is_thread_safe`/`foo_is_ractor_safe`?\r\nA symbol including the C extension name seems best, to avoid any possible confusion when looking it up.\r\n\r\nMaybe there are other ways to mark C extensions than defining symbols, that could still be read by the Ruby implementation reliably?\r\n\r\nI used the term `C extensions` but of course it would apply to native extensions too (including C++/Rust/...).\r\n\r\ncc @ko1", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-05T11:10:52Z", "updated_on": "2020-12-19T11:19:53Z", "closed_on": "2020-12-01T06:44:39Z", "relations": []}, {"id": 17303, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "fixed_version": {"id": 5, "name": "3.0"}, "subject": "Remove webrick from stdlib", "description": "I propose to move webrick to bundled gems or remove it from stdlib of ruby.\r\n\r\nWe have several vulnerability issues in webrick gem.\r\n\r\nhttps://www.ruby-lang.org/en/news/2020/09/29/http-request-smuggling-cve-2020-25613/\r\n\r\nThe ruby core team don't have enough time to handle them. We should remove webrick from default gems at least.\r\n\r\nPatch for this feature: https://github.com/ruby/ruby/pull/3729", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-11-02T11:13:08Z", "updated_on": "2020-12-10T12:45:52Z", "closed_on": "2020-12-10T12:45:52Z", "relations": [{"id": 2850, "issue_id": 15657, "issue_to_id": 17303, "relation_type": "relates", "delay": null}]}, {"id": 17298, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor's basket communication APIs", "description": "This ticket proposes `send_basket`/`receive_basket`, `yield_basket`/`take_basket` APIs to make effective and flexible bridge ractors.\r\n\r\n## Background\r\n\r\nWhen we want to send an object as a message, we usually need to copy it. Copying is achieved according to marshal protocol, and the receiver loads it immediately.\r\n\r\nIf we want to make a bridge ractor that receives a message and sends it to another ractor, immediate loading is not effective.\r\n\r\n```ruby\r\nbridge = Ractor.new do\r\n  Ractor.yield Ractor.receive\r\nend\r\n\r\nconsumer = Ractor.new bridge do |from|\r\n  obj = from.take\r\n  do_task(obj)\r\nend\r\n\r\nmsg = [1, 2, 3]\r\nbridge.send msg\r\n```\r\n\r\nIn this case, the array (`[1, 2, 3]`) is\r\n\r\n* (1) dumped at the first `bridge.send msg`\r\n* (2) loaded at `Ractor.receive`\r\n* (3) dumped again at `Ractor.yield`\r\n* (4) loaded at `from.take`\r\n\r\nEssentially, we only need one dump/load pair, but now it needs two pairs.\r\n\r\nMixing \"moving\" status is more complex. Now there is no way to pass the \"moving\" status to bridge ractors, so we cannot make a moving bridge.\r\n\r\n## Proposal\r\n\r\nTo make more effective and flexible bridge ractors, we propose new basket APIs\r\n\r\n* `Ractor.receive_basket`\r\n* `Ractor#send_basket`\r\n* `Ractor#take_basket`\r\n* `Ractor.yield_basket`\r\n\r\nThey receive a message, retains the dumped state, and sends it without dumping again. We can rewrite the above example with these APIs.\r\n\r\n```ruby\r\nbridge = Ractor.new do\r\n  Ractor.yield_basket Ractor.receive_basket\r\nend\r\n\r\nconsumer = Ractor.new bridge do |from|\r\n  obj = from.take\r\n  do_task(obj)\r\nend\r\n\r\nmsg = [1, 2, 3]\r\nbridge.send msg\r\n```\r\n\r\nIn this case,\r\n\r\n* (1) dumped at the first `bridge.send msg`\r\n* (2) loaded at `from.take`\r\n\r\nwe only need one dump/load pair.\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/3725\r\n\r\n## Evaluation\r\n\r\nThe following program makes four types of bridges and passes an array as a message through them.\r\n\r\n```ruby\r\nUSE_BASKET = false\r\n\r\nreceive2yield = Ractor.new do\r\n  loop do\r\n    if USE_BASKET\r\n      Ractor.yield_basket Ractor.receive_basket\r\n    else\r\n      Ractor.yield Ractor.receive\r\n    end\r\n  end\r\nend\r\n\r\nreceive2send = Ractor.new receive2yield do |r|\r\n  loop do\r\n    if USE_BASKET\r\n      r.send_basket Ractor.receive_basket\r\n    else\r\n      r.send Ractor.receive\r\n    end\r\n  end\r\nend\r\n\r\ntake2yield = Ractor.new receive2yield do |from|\r\n  loop do\r\n    if USE_BASKET\r\n      Ractor.yield_basket from.take_basket\r\n    else\r\n      Ractor.yield from.take\r\n    end\r\n  end\r\nend\r\n\r\ntake2send = Ractor.new take2yield, Ractor.current do |from, to|\r\n  loop do\r\n    if USE_BASKET\r\n      to.send_basket from.take_basket\r\n    else\r\n      to.send from.take\r\n    end\r\n  end\r\nend\r\n\r\nAN = 1_000\r\nLN = 10_000\r\n\r\nary = Array.new(AN) # 1000\r\nLN.times{\r\n  receive2send << ary\r\n  Ractor.receive\r\n}\r\n\r\n# This program passes the message as:\r\n#   main ->\r\n#   receive2send ->\r\n#   receive2yield ->\r\n#   take2yield ->\r\n#   take2send ->\r\n#   main\r\n```\r\n\r\nThe result is:\r\n\r\n```\r\nw/ basket API   0m2.056s\r\nw/o basket API  0m5.974s\r\n```\r\n\r\non my machine (=~ x3 faster).\r\n\r\n(BTW, if we have a TVar, we can change the value `USE_BASKET` dynamically)\r\n\r\n## Discussion\r\n\r\n### Naming\r\n\r\nOf course, naming is an issue. Now, I named it \"_basket\" because the source code uses this terminology. There are other candidates:\r\n\r\n* container metaphor\r\n  * package\r\n  * parcel\r\n  * box\r\n  * envelope\r\n  * packet (maybe bad idea because of confusion of networking)\r\n  * bundle (maybe bad idea because of confusion of bin/bundle)\r\n* \"don't touch the content\" metaphor\r\n  * raw\r\n  * sealed\r\n  * unopened\r\n\r\nI like \"basket\" because I like picnic.\r\n\r\n### Feature\r\n\r\nNow, basket is represented by \"Ractor::Basket\" and there are no methods. We can add the following feature:\r\n\r\n* `Ractor::Basket#sender` returns the sending ractor.\r\n* `Ractor::Basket#sender = a_ractor` changes the sending ractor.\r\n* `Ractor::Basket#value` returns the content.\r\n\r\nThere was another proposal `Ractor.recvfrom`, but we only need these APIs.\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-30T18:30:17Z", "updated_on": "2020-11-13T16:16:55Z", "closed_on": null, "relations": []}, {"id": 17297, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Feature:  Introduce Pathname.mktmpdir", "description": "\r\nWhen I want to create a tmpdir I often want to manipulate it as a pathname. By introducing Pathname.mktmpdir I can get this behavior. \r\n\r\nCurrently I must:\r\n\r\n```ruby\r\nDir.mktmpdir do |dir|\r\n  dir = Pathname(dir)\r\n  # ... code\r\nend\r\n```\r\n\r\nI would like to be able to instead:\r\n\r\n```ruby\r\nPathname.mktmpdir do |dir|\r\n  # ... code\r\nend\r\n```\r\n\r\nDiff:\r\n\r\n```\r\n$ git diff master\r\ndiff --git a/ext/pathname/lib/pathname.rb b/ext/pathname/lib/pathname.rb\r\nindex e6fb90277d..ec32e7d611 100644\r\n--- a/ext/pathname/lib/pathname.rb\r\n+++ b/ext/pathname/lib/pathname.rb\r\n@@ -597,3 +597,20 @@ def rmtree\r\n   end\r\n end\r\n\r\n+class Pathname    # * tmpdir *\r\n+  # Creates a tmp directory and wraps the returned path in a Pathname object.\r\n+  #\r\n+  # See Dir.mktmpdir\r\n+  def self.mktmpdir\r\n+    require 'tmpdir' unless defined?(Dir.mktmpdir)\r\n+    if block_given?\r\n+      Dir.mktmpdir do |dir|\r\n+        dir = self.new(dir)\r\n+        yield dir\r\n+      end\r\n+    else\r\n+      self.new(Dir.mktmpdir)\r\n+    end\r\n+  end\r\n+end\r\n+\r\ndiff --git a/test/pathname/test_pathname.rb b/test/pathname/test_pathname.rb\r\nindex 43cef4849f..8edcccf666 100644\r\n--- a/test/pathname/test_pathname.rb\r\n+++ b/test/pathname/test_pathname.rb\r\n@@ -1272,6 +1272,14 @@ def test_s_glob_3args\r\n     }\r\n   end\r\n\r\n+  def test_mktmpdir\r\n+    Pathname.mktmpdir do |dir|\r\n+      assert_equal Pathname(dir), dir\r\n+      assert dir.directory?\r\n+      assert dir.exist?\r\n+    end\r\n+  end\r\n+\r\n   def test_s_getwd\r\n     wd = Pathname.getwd\r\n     assert_kind_of(Pathname, wd)\r\n```\r\n\r\nGithub link: https://github.com/ruby/ruby/pull/3709", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-30T15:09:41Z", "updated_on": "2021-08-30T06:51:44Z", "closed_on": null, "relations": []}, {"id": 17296, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Feature: Pathname#chmod use FileUtils.chmod instead of File", "description": "\r\n\r\nThe `FileUtils.chmod` provides the same numerical interface as `File.chmod` and it also includes a \"symbolic mode\" interface. With this patch you'll be able to run this code:\r\n\r\n```ruby\r\nPathname.new(\"bin/compile\").chmod(\"+x\")\r\n```\r\n\r\nI believe that this is backwards compatible with the existing  implementation and all changes are an extension. The only difference between File.chmod and FileUtils.chmod I could find is they have different return values and the previous implementation of `Pathname#chmod` returned the result of the `File.chmod` call. From the docs `File.chmod` returns the number of files modified, since we're only ever able to pass in a maximum of one file through this interface, the return value will always be a `1` or an exception if the file does not exist.\r\n\r\nI checked and the exceptions when the file does not exist match:\r\n\r\n```\r\nirb(main):004:0> File.chmod(0444, \"doesnotexist.txt\")\r\nTraceback (most recent call last):\r\n        6: from /Users/rschneeman/.rubies/ruby-2.7.2/bin/irb:23:in `<main>'\r\n        5: from /Users/rschneeman/.rubies/ruby-2.7.2/bin/irb:23:in `load'\r\n        4: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/gems/2.7.0/gems/irb-1.2.6/exe/irb:11:in `<top (required)>'\r\n        3: from (irb):3\r\n        2: from (irb):4:in `rescue in irb_binding'\r\n        1: from (irb):4:in `chmod'\r\nErrno::ENOENT (No such file or directory @ apply2files - doesnotexist.txt)\r\nirb(main):005:0> FileUtils.chmod(0444, \"doesnotexist.txt\")\r\nTraceback (most recent call last):\r\n       10: from /Users/rschneeman/.rubies/ruby-2.7.2/bin/irb:23:in `<main>'\r\n        9: from /Users/rschneeman/.rubies/ruby-2.7.2/bin/irb:23:in `load'\r\n        8: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/gems/2.7.0/gems/irb-1.2.6/exe/irb:11:in `<top (required)>'\r\n        7: from (irb):4\r\n        6: from (irb):5:in `rescue in irb_binding'\r\n        5: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/2.7.0/fileutils.rb:1016:in `chmod'\r\n        4: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/2.7.0/fileutils.rb:1016:in `each'\r\n        3: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/2.7.0/fileutils.rb:1017:in `block in chmod'\r\n        2: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/2.7.0/fileutils.rb:1346:in `chmod'\r\n        1: from /Users/rschneeman/.rubies/ruby-2.7.2/lib/ruby/2.7.0/fileutils.rb:1346:in `chmod'\r\nErrno::ENOENT (No such file or directory @ apply2files - doesnotexist.txt)\r\n```\r\n\r\nIf you're open to changing the interface of the return value my preference would be to return `self` from this method so that it can be chained. Otherwise this current patch is a smaller change.\r\n\r\n\r\nDiff:\r\n\r\n```\r\n$ git diff master\r\ndiff --git a/ext/pathname/lib/pathname.rb b/ext/pathname/lib/pathname.rb\r\nindex e6fb90277d..cb6e32d9ac 100644\r\n--- a/ext/pathname/lib/pathname.rb\r\n+++ b/ext/pathname/lib/pathname.rb\r\n@@ -585,6 +585,15 @@ def mkpath\r\n     nil\r\n   end\r\n\r\n+  # Changes file permissions.\r\n+  #\r\n+  # See FileUtils.chmod\r\n+  def chmod(mode)\r\n+    require 'fileutils'\r\n+    FileUtils.chmod(mode, self)\r\n+    return 1\r\n+  end\r\n+\r\n   # Recursively deletes a directory, including all directories beneath it.\r\n   #\r\n   # See FileUtils.rm_r\r\ndiff --git a/ext/pathname/pathname.c b/ext/pathname/pathname.c\r\nindex f71cec1b25..6778d4f102 100644\r\n--- a/ext/pathname/pathname.c\r\n+++ b/ext/pathname/pathname.c\r\n@@ -12,7 +12,6 @@ static ID id_binwrite;\r\n static ID id_birthtime;\r\n static ID id_blockdev_p;\r\n static ID id_chardev_p;\r\n-static ID id_chmod;\r\n static ID id_chown;\r\n static ID id_ctime;\r\n static ID id_directory_p;\r\n@@ -552,20 +551,6 @@ path_mtime(VALUE self)\r\n     return rb_funcall(rb_cFile, id_mtime, 1, get_strpath(self));\r\n }\r\n\r\n-/*\r\n- * call-seq:\r\n- *   pathname.chmod(mode_int)  -> integer\r\n- *\r\n- * Changes file permissions.\r\n- *\r\n- * See File.chmod.\r\n- */\r\n-static VALUE\r\n-path_chmod(VALUE self, VALUE mode)\r\n-{\r\n-    return rb_funcall(rb_cFile, id_chmod, 2, mode, get_strpath(self));\r\n-}\r\n-\r\n /*\r\n  * call-seq:\r\n  *   pathname.lchmod(mode_int) -> integer\r\n@@ -1448,7 +1433,6 @@ path_f_pathname(VALUE self, VALUE str)\r\n  * - #birthtime\r\n  * - #ctime\r\n  * - #mtime\r\n- * - #chmod(mode)\r\n  * - #lchmod(mode)\r\n  * - #chown(owner, group)\r\n  * - #lchown(owner, group)\r\n@@ -1495,6 +1479,7 @@ path_f_pathname(VALUE self, VALUE str)\r\n  * === Utilities\r\n  *\r\n  * These methods are a mixture of Find, FileUtils, and others:\r\n+ * - #chmod(mode)\r\n  * - #find(&block)\r\n  * - #mkpath\r\n  * - #rmtree\r\n@@ -1542,7 +1527,6 @@ Init_pathname(void)\r\n     rb_define_method(rb_cPathname, \"birthtime\", path_birthtime, 0);\r\n     rb_define_method(rb_cPathname, \"ctime\", path_ctime, 0);\r\n     rb_define_method(rb_cPathname, \"mtime\", path_mtime, 0);\r\n-    rb_define_method(rb_cPathname, \"chmod\", path_chmod, 1);\r\n     rb_define_method(rb_cPathname, \"lchmod\", path_lchmod, 1);\r\n     rb_define_method(rb_cPathname, \"chown\", path_chown, 2);\r\n     rb_define_method(rb_cPathname, \"lchown\", path_lchown, 2);\r\n@@ -1618,7 +1602,6 @@ InitVM_pathname(void)\r\n     id_birthtime = rb_intern(\"birthtime\");\r\n     id_blockdev_p = rb_intern(\"blockdev?\");\r\n     id_chardev_p = rb_intern(\"chardev?\");\r\n-    id_chmod = rb_intern(\"chmod\");\r\n     id_chown = rb_intern(\"chown\");\r\n     id_ctime = rb_intern(\"ctime\");\r\n     id_directory_p = rb_intern(\"directory?\");\r\ndiff --git a/test/pathname/test_pathname.rb b/test/pathname/test_pathname.rb\r\nindex 43cef4849f..5673691231 100644\r\n--- a/test/pathname/test_pathname.rb\r\n+++ b/test/pathname/test_pathname.rb\r\n@@ -823,6 +823,11 @@ def test_chmod\r\n       path.chmod(0444)\r\n       assert_equal(0444, path.stat.mode & 0777)\r\n       path.chmod(old)\r\n+\r\n+      skip \"Windows has different symbolic mode\" if /mswin|mingw/ =~ RUBY_PLATFORM\r\n+      path.chmod(\"u=wrx,g=rx,o=x\")\r\n+      assert_equal(0751, path.stat.mode & 0777)\r\n+      path.chmod(old)\r\n     }\r\n   end\r\n```\r\n\r\nGithub link: https://github.com/ruby/ruby/pull/3708", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-30T15:08:09Z", "updated_on": "2021-08-30T06:51:51Z", "closed_on": null, "relations": []}, {"id": 17295, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Feature: Create a directory and file with Pathname#touch", "description": "\r\n\r\nRight now if a developer wants to create a file and is not sure if the path exists yet or not they must:\r\n\r\n```ruby\r\nPathname.new(\"/a/b/c/d.txt\").tap {|p| p.dirname.mkpath; FileUtils.touch(p)}\r\n```\r\n\r\nAfter this patch a developer can instead call:\r\n\r\n```ruby\r\nPathname.new(\"/a/b/c/d.txt\").touch\r\n```\r\n\r\nAn alternative name for this behavior could be `mkfile` but I think it is confusing to have a `mkfile` and a `mkpath` where one creates a directory and one creates a file.\r\n\r\nDiff:\r\n\r\n```\r\n$ git diff master\r\ndiff --git a/ext/pathname/lib/pathname.rb b/ext/pathname/lib/pathname.rb\r\nindex e6fb90277d..2ed02a6633 100644\r\n--- a/ext/pathname/lib/pathname.rb\r\n+++ b/ext/pathname/lib/pathname.rb\r\n@@ -585,6 +585,27 @@ def mkpath\r\n     nil\r\n   end\r\n\r\n+  # Creates a file and the full path to the file including any intermediate directories that don't yet\r\n+  # exist.\r\n+  #\r\n+  # Example:\r\n+  #\r\n+  #   Dir.exist?(\"/a/b/c\") # => false\r\n+  #\r\n+  #   p = Pathname.new(\"/a/b/c/d.txt\")\r\n+  #   p.file? => false\r\n+  #   p.touch\r\n+  #   p.file? => true\r\n+  #\r\n+  #   Dir.exist?(\"/a/b/c\") # => true\r\n+  def touch\r\n+    require 'fileutils'\r\n+    dirname.mkpath\r\n+\r\n+    FileUtils.touch(self)\r\n+    self\r\n+  end\r\n+\r\n   # Recursively deletes a directory, including all directories beneath it.\r\n   #\r\n   # See FileUtils.rm_r\r\ndiff --git a/test/pathname/test_pathname.rb b/test/pathname/test_pathname.rb\r\nindex 43cef4849f..3c518cc3da 100644\r\n--- a/test/pathname/test_pathname.rb\r\n+++ b/test/pathname/test_pathname.rb\r\n@@ -1394,6 +1394,14 @@ def test_mkpath\r\n     }\r\n   end\r\n\r\n+  def test_touch\r\n+    with_tmpchdir('rubytest-pathname') {|dir|\r\n+      Pathname(\"a/b/c/d.txt\").touch\r\n+      assert_file.directory?(\"a/b/c\")\r\n+      assert_file.file?(\"a/b/c/d.txt\")\r\n+    }\r\n+  end\r\n+\r\n   def test_rmtree\r\n     with_tmpchdir('rubytest-pathname') {|dir|\r\n       Pathname(\"a/b/c/d\").mkpath\r\n```\r\n\r\n\r\nGithub link: https://github.com/ruby/ruby/pull/3706\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-30T15:06:39Z", "updated_on": "2021-09-28T01:20:09Z", "closed_on": null, "relations": []}, {"id": 17294, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "Feature: Allow method chaining with Pathname#mkpath Pathname#rmtree", "description": "\r\nCurrently in my code when I want to create a pathname object and create a path at the same time I must use tap\r\n\r\n```\r\npath = Pathname.new(\"/tmp/new\").tap(&:mkpath)\r\n```\r\n\r\nI think it would be cleaner to be able to chain on the results of these methods instead:\r\n\r\n```\r\npath = Pathname.new(\"/tmp/new\").mkpath\r\n```\r\n\r\nThis is a change in return value but after research on github I do not believe many (if any) are relying on the current behavior to return nil https://github.com/search?l=&p=1&q=.mkpath+language%3ARuby&ref=advsearch&type=Code.\r\n\r\nHere is my diff: \r\n\r\n```\r\n$ git diff master schneems/return-self-pathname\r\ndiff --git a/ext/pathname/lib/pathname.rb b/ext/pathname/lib/pathname.rb\r\nindex e6fb90277d..f1eb1e00ae 100644\r\n--- a/ext/pathname/lib/pathname.rb\r\n+++ b/ext/pathname/lib/pathname.rb\r\n@@ -582,7 +582,7 @@ class Pathname    # * FileUtils *\r\n   def mkpath\r\n     require 'fileutils'\r\n     FileUtils.mkpath(@path)\r\n-    nil\r\n+    self\r\n   end\r\n\r\n   # Recursively deletes a directory, including all directories beneath it.\r\n@@ -593,7 +593,7 @@ def rmtree\r\n     # File::Path provides \"mkpath\" and \"rmtree\".\r\n     require 'fileutils'\r\n     FileUtils.rm_r(@path)\r\n-    nil\r\n+    self\r\n   end\r\n end\r\n\r\ndiff --git a/test/pathname/test_pathname.rb b/test/pathname/test_pathname.rb\r\nindex 43cef4849f..149fe15c3a 100644\r\n--- a/test/pathname/test_pathname.rb\r\n+++ b/test/pathname/test_pathname.rb\r\n@@ -1389,7 +1389,8 @@ def test_find\r\n\r\n   def test_mkpath\r\n     with_tmpchdir('rubytest-pathname') {|dir|\r\n-      Pathname(\"a/b/c/d\").mkpath\r\n+      path = Pathname(\"a/b/c/d\")\r\n+      assert_equal(path, path.mkpath)\r\n       assert_file.directory?(\"a/b/c/d\")\r\n     }\r\n   end\r\n@@ -1398,7 +1399,8 @@ def test_rmtree\r\n     with_tmpchdir('rubytest-pathname') {|dir|\r\n       Pathname(\"a/b/c/d\").mkpath\r\n       assert_file.exist?(\"a/b/c/d\")\r\n-      Pathname(\"a\").rmtree\r\n+      path = Pathname(\"a\")\r\n+      assert_equal(path, path.rmtree)\r\n       assert_file.not_exist?(\"a\")\r\n     }\r\n   end\r\n```\r\n\r\nGithub PR: https://github.com/ruby/ruby/pull/3705. If accepted I will make a pr to update the tests here as well https://github.com/ruby/rbs/blob/b0dee64fdd00cc41c0729fa2c239fc2dcb9c3b18/test/stdlib/Pathname_test.rb#L456-L463.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-30T15:04:06Z", "updated_on": "2021-08-30T06:52:13Z", "closed_on": null, "relations": []}, {"id": 17292, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 7576, "name": "baweaver (Brandon Weaver)"}, "subject": "Hash Shorthand / Punning", "description": "### Set Literal vs Javascript Object Punning\r\n\r\nThere was a proposal for a Set literal here: https://bugs.ruby-lang.org/issues/16989\r\n\r\n```ruby\r\nset = { 1, 2, 3 }\r\n```\r\n\r\n...but it was brought up that this is similar to the Javascript Object punning, or Object shorthand syntax:\r\n\r\n```js\r\nconst a = 1, b = 2, c = 3;\r\n\r\nconst punnedObject = { a, b, c }\r\n// => { a: 1, b: 2, c: 3 }\r\n```\r\n\r\n**Proposition**: I believe we should use brackets (`{}`) for a shorthand Hash syntax similar to Javascript.\r\n\r\n### Hash Punning\r\n\r\nMy first proposal in this feature request is Hash punning, or Hash shorthand:\r\n\r\n```ruby\r\na = 1\r\nb = 2\r\nc = 3\r\n\r\n{ a:, b:, c: }\r\n# => { a: 1, b: 2, c: 3 }\r\n```\r\n\r\nThis syntax avoids the ambiguous syntax of empty block (`{}`) versus empty set (`{}`), and with the presence of Symbols it introduces a distinct syntax that would be easier to parse against.\r\n\r\nOne potential issue would be mixed syntax:\r\n\r\n```ruby\r\n{ a:, b: 2 }\r\n# => { a: 1, b: 2 }\r\n```\r\n\r\n### Method Punning\r\n\r\nThis syntax can also be used for keyword argument and method call punning:\r\n\r\n```ruby\r\ndef method_name(a:, b:, c:)\r\n  a + b + c\r\nend\r\n\r\na = 1\r\nb = 2\r\nc = 3\r\n\r\nmethod_name(a:, b:, c:)\r\n# => 6\r\n```\r\n\r\nI believe this existing syntax for required keywords gives credence to the idea of introducing punning to Ruby, as it's very similar to existing syntax, and therefor feels \"Ruby-like\".\r\n\r\n### Pattern Matching\r\n\r\nThis syntax is also already present and used in pattern matching, making it already part of the language:\r\n\r\n```ruby\r\ncase { x: 1, y: 2 }\r\nin { x:, y: }\r\n  { x:, y: y + 1} # new\r\nelse\r\n  # ...\r\nend\r\n```\r\n\r\nI believe this further justifies the case for punning syntax.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-29T05:07:18Z", "updated_on": "2021-09-11T09:59:53Z", "closed_on": "2021-09-11T09:59:53Z", "relations": [{"id": 3072, "issue_id": 17292, "issue_to_id": 18124, "relation_type": "relates", "delay": null}, {"id": 2775, "issue_id": 17292, "issue_to_id": 14579, "relation_type": "duplicates", "delay": null}]}, {"id": 17291, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 2, "name": "Assigned", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 482, "name": "mrkn (Kenta Murata)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Optimize __send__ call", "description": "I made a patch to optimize a `__send__` call. This optimization replaces a `__send__` method call with a call of the method whose name is the first argument of `__send__` method. The patch is available in [this pull-request](https://github.com/ruby/ruby/pull/3720).\r\n\r\nBy this change, the redefined `__send__` method is no longer called when it is called by a symbol method name. I guess it is no problem because the following warning message is displayed for a long time.\r\n\r\n    $ ruby -e 'def __send__; end'\r\n    -e:1: warning: redefining `__send__' may cause serious problems\r\n\r\nThis proposal introduces two new instructions: `sendsym` and `opt_sendsym_without_block`.  These instructions handle the cases that the first argument of `__send__` method is not a symbol literal.  I think I can combine these two instructions into one if prefered.\r\n\r\nThis proposal includes the change proposed in #17288.  I'll mark it as a duplicate of this proposal.\r\n\r\nI don't handle `send` method in this proposal. The reason is that we need to examine the redefinition of `send` method in the instruction execution time. I want to discuss only `__send__` method in this ticket.\r\n\r\nThe benchmark result is below:\r\n\r\n```\r\n# Iteration per second (i/s)\r\n\r\n|                 |compare-ruby|built-ruby|\r\n|:----------------|-----------:|---------:|\r\n|vm_send_sym      |     18.001M|  112.208M|\r\n|                 |           -|     6.23x|\r\n|vm_send_var      |     17.779M|   30.922M|\r\n|                 |           -|     1.74x|\r\n|vm_send_var_alt  |      3.817M|    6.817M|\r\n|                 |           -|     1.79x|\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-29T03:05:45Z", "updated_on": "2021-01-12T05:47:36Z", "closed_on": null, "relations": [{"id": 2774, "issue_id": 17288, "issue_to_id": 17291, "relation_type": "duplicates", "delay": null}]}, {"id": 17290, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Syntax sugar for boolean keyword argument", "description": "We frequently use keyword arguments just to pass `true` value out of the truthy/falsy options given. And in many such cases, the falsy option is set as the default, and only the truthy value is ever passed explicitly. I propose to have a syntax sugar to omit the value of a keyword argument. When omitted, it should be interpreted with value `true`.\r\n\r\n```ruby\r\ngets(chomp:)\r\nCSV.parse(\" foo var \", strip:)\r\n```\r\n\r\nshould be equivalent to\r\n\r\n```ruby\r\ngets(chomp: true)\r\nCSV.parse(\" foo var \", strip: true)\r\n```\r\n\r\nAdditionally, we may also extend this to pragmas.\r\n\r\n```ruby\r\n# frozen_string_literal:\r\n```\r\n\r\nto be equivalent to:\r\n\r\n```ruby\r\n# frozen_string_literal: true\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-29T02:54:40Z", "updated_on": "2020-10-29T04:51:36Z", "closed_on": null, "relations": []}, {"id": 17288, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 482, "name": "mrkn (Kenta Murata)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Optimize __send__ call with a literal method name", "description": "I made a patch to optimize a `__send__` call with a literal method name.  This optimization replaces a `__send__` method call with a `send` instruction.  The patch is available in [this pull-request](https://github.com/ruby/ruby/pull/3707).\r\n\r\nBy this change, the redefined `__send__` method is no longer called when it is called by a literal method name.  I guess it is no problem because the following warning message is displayed for a long time.\r\n\r\n    $ ruby -e 'def __send__; end'\r\n    -e:1: warning: redefining `__send__' may cause serious problems\r\n\r\nThis change makes the optimized case x5~x6 faster.  The benchmark result is below:\r\n\r\n```\r\n$ make benchmark COMPARE_RUBY=\"../../ruby/build-o3/ruby\" ITEM=vm_send.yml\r\n(snip)\r\n# Iteration per second (i/s)\r\n\r\n|             |compare-ruby|built-ruby|\r\n|:------------|-----------:|---------:|\r\n|vm_send      |     18.536M|  113.778M|\r\n|             |           -|     6.14x|\r\n|vm_send_var  |     18.085M|   16.595M|\r\n|             |       1.09x|         -|\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-27T08:32:40Z", "updated_on": "2020-10-30T00:17:47Z", "closed_on": null, "relations": [{"id": 2774, "issue_id": 17288, "issue_to_id": 17291, "relation_type": "duplicates", "delay": null}]}, {"id": 17287, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6346, "name": "schneems (Richard Schneeman)"}, "assigned_to": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "subject": " Faster Pathname FileUtils methods", "description": "I have a patch that I would like to merge into Pathname for increased performance. I understand that akr maintains pathname and may not be on GitHub. Here is a link to my patch:\r\n\r\nhttps://github.com/ruby/ruby/pull/3693\r\n\r\nHere is the diff:\r\n\r\n```\r\n$ git diff master\r\ndiff --git a/ext/pathname/lib/pathname.rb b/ext/pathname/lib/pathname.rb\r\nindex e6fb90277d..c3af24837f 100644\r\n--- a/ext/pathname/lib/pathname.rb\r\n+++ b/ext/pathname/lib/pathname.rb\r\n@@ -575,12 +575,13 @@ def find(ignore_error: true) # :yield: pathname\r\n\r\n\r\n class Pathname    # * FileUtils *\r\n+  autoload(:FileUtils, 'fileutils')\r\n+\r\n   # Creates a full path, including any intermediate directories that don't yet\r\n   # exist.\r\n   #\r\n   # See FileUtils.mkpath and FileUtils.mkdir_p\r\n   def mkpath\r\n-    require 'fileutils'\r\n     FileUtils.mkpath(@path)\r\n     nil\r\n   end\r\n@@ -591,7 +592,6 @@ def mkpath\r\n   def rmtree\r\n     # The name \"rmtree\" is borrowed from File::Path of Perl.\r\n     # File::Path provides \"mkpath\" and \"rmtree\".\r\n-    require 'fileutils'\r\n     FileUtils.rm_r(@path)\r\n     nil\r\n   end\r\n```\r\n\r\n## Description\r\n\r\nCurrently when calling any of the \"FileUtils\" methods on pathname `require` is called every time even though that library might already be loaded. This is slow.\r\n\r\nWe can speed it up by either checking first if the constant is already defined, or by using autoload.\r\n\r\nUsing defined speeds up the action by about 300x and using autoload is about twice as fast as that (600x faster than current require method).\r\n\r\nI'm proposing we use autoload:\r\n\r\n```ruby\r\nrequire 'benchmark/ips'\r\n\r\nBenchmark.ips do |x|\r\n  autoload(:FileUtils, \"fileutils\")\r\n  x.report(\"require\") { require 'fileutils' }\r\n  x.report(\"defined\") { require 'fileutils' unless defined?(FileUtils) }\r\n  x.report(\"autoload\") { FileUtils }\r\n\r\n  x.compare!\r\nend\r\n\r\n# Warming up --------------------------------------\r\n#              require     3.624k i/100ms\r\n#              defined     1.465M i/100ms\r\n#             autoload     2.320M i/100ms\r\n# Calculating -------------------------------------\r\n#              require     36.282k (\u00b1 2.4%) i/s -    184.824k in   5.097153s\r\n#              defined     14.539M (\u00b1 2.0%) i/s -     73.260M in   5.041161s\r\n#             autoload     23.100M (\u00b1 1.9%) i/s -    115.993M in   5.023271s\r\n\r\n# Comparison:\r\n#             autoload: 23099779.2 i/s\r\n#              defined: 14538544.9 i/s - 1.59x  (\u00b1 0.00) slower\r\n#              require:    36282.3 i/s - 636.67x  (\u00b1 0.00) slower\r\n```\r\n\r\nBecause this autoload is scoped to Pathname it will not change the behavior of existing programs that are not expecting FileUtils to be loaded yet:\r\n\r\n```\r\nruby -rpathname -e \"class Pathname; autoload(:FileUtils, 'fileutils'); end; puts FileUtils.exist?('foo')\"\r\nTraceback (most recent call last):\r\n-e:1:in `<main>': uninitialized constant FileUtils (NameError)\r\n```\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-26T18:33:36Z", "updated_on": "2021-08-30T06:53:31Z", "closed_on": "2021-08-30T06:53:31Z", "relations": []}, {"id": 17286, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "`Ractor.new` should accept `move: true`", "description": "Another surprise when writing my backport is that `Ractor.new` does not accept `move:` keyword argument.\r\n\r\n```ruby\r\nRactor.new(val, move: true) { |data| ... }\r\n# equivalent to\r\nRactor.new { data = Ractor.receive; ... }.tap { |r| r.send(val, move: true) }\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-26T05:10:00Z", "updated_on": "2020-11-08T03:01:00Z", "closed_on": null, "relations": []}, {"id": 17285, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "Less strict `Ractor.select`", "description": "Summary: could we have a way for `Ractor.select` to skip ractors with closed queues and raise only if no ractor with an open queue remains?\r\n\r\nDetail:\r\n\r\nI [backported `Ractor` for earlier Ruby versions](https://github.com/marcandre/backports/pull/153), as I'd like to use it in some gems that would work great in 3.0 and work ok in older Rubies without rewriting. That was a lot of fun :-)\r\n\r\nOne surprise for me was that `Ractor.select` enforces that no given ractor is terminated(*).\r\n\r\nThis means that one must remove terminated ractors from a pool of ractors before calling `select` again:\r\n\r\n```ruby\r\npool = 20.times.map { Ractor.new{ do_processing } }\r\n\r\n20.times do\r\n  ractor, result = Ractor.select(*pool)\r\n  handle(result)\r\n  pool.delete(ractor) # necessary!\r\nend\r\n```\r\n\r\n0) This can be tedious, but I know I'm very lazy\r\n\r\n1) It is not convenient to share a pool between different ractors. Try writing code that starts 5 ractors that would consume the results from `pool` above.\r\n\r\n2) It might require special synchronization if the ractors may yield a variable number of values:\r\n\r\n```ruby\r\ndef do_processing\r\n  rand(10).times do {\r\n    Ractor.yield :a_result\r\n  }\r\n  :finish\r\nend\r\n\r\npool = 20.times.map { Ractor.new{ do_processing } }\r\n\r\nuntil pool.empty? do\r\n  ractor, result = Ractor.select(*pool)\r\n  if result == :finish\r\n    pool.delete(ractor)\r\n  else\r\n    do_something_with(result)\r\n  end\r\nend\r\n```\r\n\r\nI would like to propose that it would be allowed (by default or at least via keyword parameter) to call `select` on terminated ractors, as long as there is at least one remaining open one.\r\n\r\nThis would make it very to resolve 1 and 2 above. Here's an example combine them both together:\r\n\r\n```ruby\r\ndef do_processing\r\n  rand(10).times do {\r\n    Ractor.yield :a_result\r\n  }\r\n  Ractor.current.close # avoid yielding a value at the end\r\nend\r\n\r\npool = 20.times.map { Ractor.new{ do_processing } }.freeze\r\n\r\n5.times do # divide processing into 5 ractors\r\n  Ractor.new(pool) do |pool|\r\n    loop do\r\n      _ractor, result = Ractor.select(*pool) # with my proposed lax select\r\n      do_something_with(result)\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nThe `loop` above terminates when `Ractor.select` raises an error once the whole `pool` is terminated.\r\n\r\nI'm new to actors but my intuition currently is that I will never want to take care of a pool of Ractors myself and would always prefer if `Ractor.select` did it for me. Are there use-cases where `Ractor.select` raising an error if it encounters a closed queue is helpful?\r\n\r\nNotes: \r\n- (*) `Ractor.select` doesn't really enforce ractors to be opened of course, it will work if the ractors are consumed in the right order, like in this example by chance:\r\n\r\n```ruby\r\n10.times.map do\r\n  r = 2.times.map { Ractor.new{ sleep(0.05); :ok } }\r\n  Ractor.select(*r) # Get first available result\r\n  # Don't remove the ractor from `r`\r\n  Ractor.select(*r).last rescue :error  # Get second result\r\nend\r\n # => [:ok, :error, :error, :error, :error, :error, :error, :ok, :ok, :ok]\r\n```\r\n\r\n- I think `Ractor.select(*pool, yield_value: 42)` would raise only if the current outgoing queue is closed, even if the whole pool was terminated \r\n- Similarly `Ractor.select(*pool, Ractor.current)` would raise only if the current incomming queue is also closed. \r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-26T02:49:44Z", "updated_on": "2020-10-26T03:15:47Z", "closed_on": null, "relations": []}, {"id": 17284, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Shareable Proc", "description": "For some reasons, we need to provide a way to make sharable Proc between ractors.\r\n\r\n* (1) A block for the `Ractor.new`.\r\n* (2) Send a proc between ractors.\r\n* (3) A block for global callback methods: `define_method` ([Bug #17159]), `TracePoint`, ...\r\n\r\nFor (1), we use `Proc#isolate` (`isolate` is temporary name here) which prohibit to access outer variables.\r\n\r\n```ruby\r\na = 1\r\nProc.new{\r\n  p a \r\n}.isolate # => can not isolate a Proc because it accesses outer variables (a).\r\n          # error on `isolate` method call\r\n```\r\n\r\nThere are no states to share, so it is okay.\r\n\r\nFor (2), `Proc#isolate` is one option because we can send parameters with an argument `call`.\r\nBut it should be a bit long.\r\n\r\n```ruby\r\ni, j, k = nil\r\n\r\npr = Proc.new do |i, j, k|\r\n  p i, j, k\r\nend.isolate\r\n\r\nr = Ractor.new do |task, param|\r\n  task.call(*param)\r\nend\r\n\r\nr.send([pr, [i, j, k]])\r\n\r\n```\r\n\r\nFor (3), maybe we need to make more flexible Proc which can *read* outer block parameter on that snapshot (discussed in #17159).\r\n\r\nNow, I named it with `freeze`, because it seems frozen Proc.\r\n\r\n```ruby\r\na = 1\r\n\r\n# try to read, and returns old value (snapshot at `freeze`)\r\npr = Proc.new{\r\n  p a #=> 1\r\n}\r\npr = pr.freeze\r\npr.call\r\n\r\na = 2\r\n\r\npr.call #=> 1\r\n\r\n\r\n# try to write, and it is not allowed\r\npr2 = Proc.new{\r\n  a = 1\r\n}\r\npr2 = pr.freeze\r\n#=> can not freeze a Proc because it accesses outer variables (a). (ArgumentError)\r\n```\r\n\r\nTo share the \"frozen\" Proc between ractors, outer values should be (deep) frozen. It means readable values (in above case, `a`) should be shareable.\r\nNow we named it `Proc#shareable!`\r\n\r\n```ruby\r\na = [1, [2, 3]]\r\npr = Proc.new{\r\n  p a.frozen? #=> true\r\n}.shareable!\r\n\r\na[0] = 0 #=> frozen error\r\n```\r\n\r\nThis ticket has three different variant of mutability and shareability for Proc.\r\n\r\n|               | outer lvar    | shareable  | freeze/making shareable other objects\r\n|---------------|---------------|------------|------------------------------------------\r\n|a. isolate     | N/A           | Yes        | No\r\n|b. freeze      | allow to read | No         | No\r\n|c. shareable!  | allow to read | Yes        | Yes\r\n\r\nI want to introduce functionality of `shareable!`, but not sure the Ruby-level API.\r\n\r\nI think (b) `freeze` for this semantics is good name because it only allows to read-only local variables.\r\nHowever, it is not enough to make a sharable Proc because read objects from the Proc should be also sharable.\r\n\r\nMaking `freeze` with (c) `shareable!` functionality is one idea, but I think `freeze` should not deep-freezing because it is very surprising that read objects become the sharable (== frozen) for usual Ruby users.\r\nMaybe `Ractor.make_sharable(pr)` makes `pr` sharable is no surprise because it is good declaration the `pr` should be shareable, even if the read objects from `pr` become shareable (== frozen).\r\n\r\nRemoving (a) `isolate` and using (c) `shareable!` at `Ractor.new(&b)` is one idea, but I think it is surprising that they can access outer local variables, but the they can not access newly assigned variables as usual blocks.\r\n\r\n```\r\na = 1\r\nRactor.new do\r\n  p a # only 1\r\nend\r\n\r\na = 2\r\n```\r\n\r\n(a) `isolate` does not have such issue because all outer lvars accesses are not allowed == easy to understand, easy to debug.\r\n\r\nIn practice, accessing outer variables with multi-ractor program is very useful because we need to declare same local variables if we want to access them from different ractors.\r\n\r\nThe following example is from [Feature #17261]:\r\n\r\n```ruby\r\ntv1 = Thread::TVar.new(0)\r\ntv2 = Thread::TVar.new(0)\r\n\r\nr1 = Ractor.new tv1, tv2 do |tv1, tv2|    # <-- here\r\n  loop do\r\n    Thread.atomically do\r\n      v1, v2 = tv1.value, tv2.value\r\n      raise if v1 != v2\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nWith (c) `shareable!` semantics, it is easier to write:\r\n\r\n```ruby\r\ntv1 = Thread::TVar.new(0)\r\ntv2 = Thread::TVar.new(0)\r\n\r\nr1 = Ractor.new do\r\n  loop do\r\n    Thread.atomically do\r\n      v1, v2 = tv1.value, tv2.value\r\n      raise if v1 != v2\r\n    end\r\n  end\r\nend\r\n```\r\n\r\nAbove example is also enable to make more simple:\r\n\r\n```ruby\r\ni, j, k = nil\r\n\r\npr = Proc.new do\r\n  p i, j, k\r\nend\r\n\r\nr = Ractor.new do |task|\r\n  task.call\r\nend\r\n\r\nr.send(pr)\r\n\r\n```\r\n\r\nHowever, using this semantics (`shareable!`) can freeze extra-variables in accidents:\r\n\r\n\r\n```ruby\r\na = [1, 2, 3]\r\n\r\nRactor.new do\r\n  do_something if a.length > 0\r\nend\r\n\r\na << 4 # raises FrozenError\r\n```\r\n\r\nIt is clear that there is a syntax or method to apply `shareable!` functionality.\r\n\r\n```ruby\r\na = [1, 2, 3]\r\nRactor.new &(Ractor.make_shareable(Proc.new{ a.length ... })\r\n```\r\n\r\nIt can be used with `define_method` which can invoke from ractors:\r\n\r\n```ruby\r\ndefine_method(name, Ractor.make_shareable(Proc.new{ ... }))`\r\n```\r\n\r\nBut it is too long.\r\n\r\nThere are implementations for (a), (b) and (c), but the API is not fixed, so there is no PR now.\r\n\r\nI'm thinking to introduce (c)'s feature in `Ractor.make_sharaeble(pr)`.\r\nTo use with `define_method`, maybe it should be more friendly. Ideally, new syntax is great.\r\n\r\nThere is no conclusion, and your comments are welcome.\r\n\r\nThanks,\r\nKoichi\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-25T17:04:36Z", "updated_on": "2020-10-29T19:49:59Z", "closed_on": "2020-10-29T18:12:35Z", "relations": []}, {"id": 17282, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 8, "name": "Third Party's Issue", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 8088, "name": "olivierlacan (Olivier Lacan)"}, "subject": "Deprecate Digest::SHA1", "description": "In light of the widespread deprecation of SHA1 due to collision risk it poses, should Ruby still expose it without a warning within Digest::SHA1? \r\n\r\n[FIPS PUB 180-1](https://csrc.nist.gov/publications/detail/fips/180/1/archive/1995-04-17) which is referenced by the [Digest::SHA1 documentation](https://docs.ruby-lang.org/en/master/Digest/SHA1.html) was withdraw on August 01, 2002, superseded by [FIPS 180-2](https://csrc.nist.gov/publications/detail/fips/180/2/archive/2002-08-01) (which introduced SHA-256, SHA-384, and SHA-512), and later withdrawn and superseded multiple times until [FIPS 180-4](https://csrc.nist.gov/publications/detail/fips/180/4/final) which recommends SHA3. \r\n\r\nSHA3 isn't currently supported by the Digest class although there exists Ruby gem implementations: \r\n- https://github.com/johanns/sha3\r\n- https://github.com/phusion/digest-sha3-ruby\r\n\r\nReferences: \r\n- https://mailarchive.ietf.org/arch/msg/openpgp/Rp-inhYKT8A9H5E34iLTrc9I0gc/\r\n- https://csrc.nist.gov/news/2017/research-results-on-sha-1-collisions\r\n- https://csrc.nist.gov/publications/detail/sp/800-131a/rev-1/archive/2015-11-06\r\n- https://csrc.nist.gov/publications/detail/sp/800-131a/rev-2/final\r\n\r\nQuoting from NIST's piece on research regarding SHA1 collisions: \r\n> NIST deprecated the use of SHA-1 in 2011  and disallowed its use for digital signatures at the end of 2013, based on both the Wang, et. al, attack and the potential for brute-force attack.  To ensure that practitioners have secure and efficient hash algorithms to provide long-term security, NIST organized an international competition to select a new hash algorithm standard, SHA-3, which is specified in FIPS 202.\r\n\r\nMy recommendation would be to print a deprecation warning when Digest::SHA1 is used to alert Ruby users that they should perhaps upgrade to a safer standard. SHA3 should perhaps be supported by Digest as well.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-24T05:06:28Z", "updated_on": "2020-10-26T01:12:32Z", "closed_on": "2020-10-26T01:12:32Z", "relations": []}, {"id": 17281, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 4, "name": "nobu (Nobuyoshi Nakada)"}, "subject": "Remove support for mathn", "description": "As [mathn is deprecated], canonicalization for it also should be removed, I think.\r\nhttps://github.com/ruby/ruby/pull/3691\r\n\r\n[mathn is deprecated]: https://github.com/ruby/mathn#deprecation", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-23T05:40:18Z", "updated_on": "2020-11-10T02:18:40Z", "closed_on": "2020-11-10T02:18:40Z", "relations": [{"id": 2773, "issue_id": 13334, "issue_to_id": 17281, "relation_type": "relates", "delay": null}]}, {"id": 17279, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 482, "name": "mrkn (Kenta Murata)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Allow a negative step in Range#step with a block", "description": "`Range#step` prohibits a negative step when a block is given.\r\n\r\n```\r\n>> (6..3).step(-1) {|i| p i }\r\nTraceback (most recent call last):\r\n        5: from /home/mrkn/.rbenv/versions/2.7/bin/irb:23:in `<main>'\r\n        4: from /home/mrkn/.rbenv/versions/2.7/bin/irb:23:in `load'\r\n        3: from /home/mrkn/.rbenv/versions/2.7.1/lib/ruby/gems/2.7.0/gems/irb-1.2.4/exe/irb:11:in `<top (required)>'\r\n        2: from (irb):1\r\n        1: from (irb):1:in `step'\r\nArgumentError (step can't be negative)\r\n```\r\n\r\nBut `Range#step` allows a negative step when it is called without a block.  In this case, `Range#step` creates an ArithmeticSequence, and `ArithmeticSequence#each` can iterate with a negative step.\r\n\r\n```\r\n>> (6..3).step(-1).each {|i| p i }\r\n6\r\n5\r\n4\r\n3\r\n=> ((6..3).step(-1))\r\n```\r\n\r\nI think the prohibition of a negative step in `Range#step` has already been meaningless, so it may be better to permit it for consistency.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-22T02:23:48Z", "updated_on": "2020-10-22T02:23:48Z", "closed_on": null, "relations": []}, {"id": 17278, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11019, "name": "Dan0042 (Daniel DeLorme)"}, "subject": "On-demand sharing of constants for Ractor", "description": "### Description \r\n\r\nThis proposal aims to reduce (but not eliminate) the need for freezing/sharing boilerplate code needed by ractors.\r\n\r\n```ruby\r\nA = [1, [2, [3, 4]]]\r\nH = {a: \"a\"}\r\nRactor.new do\r\n  p A  #A is not actually modified anywhere, so ok\r\nend.take\r\nH[:b] = \"b\"  #H was never touched by ractor, so ok\r\n```\r\n\r\n## Background\r\n\r\nRactors require objects to be preemptively deep-frozen in order to be shared between ractors. This has an especially visible and restrictive effect on globals and constants. I tried thinking of a different way, and maybe I found one. So please allow me to humbly present this possibility.\r\n\r\n## Proposal\r\n\r\nA constant would be by default in a \"auto-shareable\" state (A) which can change atomically to either\r\n(B) \"non-shareable\" if it is modified by the main ractor\r\n(C) \"shareable\" (and frozen) if it is accessed by a non-main ractor\r\n\r\nIn detail:\r\n1. When an object is assigned to a constant, it is ~~added to a list of ractor-reachable objects~~\r\n2. ~~When the first ractor is created, the objects in that list are~~ recursively marked with FL_AUTOSHARE\r\n   * ~~after this point, constant assignments result directly in FL_AUTOSHARE~~\r\n3. In the main ractor, a call to `rb_check_frozen` (meaning the object is being modified) will\r\n   1. if FL_AUTOSHARE is set (state A) **and ractors have been created**\r\n      * [with ractor lock]\r\n         * unless object is shareable\r\n             * unset FL_AUTOSHARE (state B)\r\n   2. raise error if frozen\r\n      * ideally with different message if object has FL_SHAREABLE\r\n4. When a non-main ractor accesses a non-shareable constant\r\n   1. if object referenced by constant has FL_AUTOSHARE set (state A)\r\n      * [with ractor lock]\r\n         * if all objects recursively are still marked with FL_AUTOSHARE\r\n             * make_shareable (state C)\r\n         * else\r\n             * unset top objects's FL_AUTOSHARE (state B)\r\n   2. raise error if not shareable \r\n\r\n## Result\r\n\r\nSo in the case that these 2 things happen in parallel:\r\n1) main ractor modifies content of constant X\r\n2) non-main ractor accesses constant X\r\n\r\nThere are 2 possible outcomes:\r\na) main ractor error \"can't modify frozen/shared object\"\r\nb) non-main ractor error \"can not access non-shareable objects in constant X\"\r\n\r\n## Benefits\r\n\r\nIn the normal case where non-frozen constants are left untouched after being assigned, this allows to skip a lot of `.freeze` or `Ractor.make_shareable` or `# shareable_constant_value: true` boilerplate.\r\n\r\nWhen you get the error \"can not access non-sharable objects in constant X by non-main Ractor\", first you have to make that constant X shareable. Then this can trigger a secondary error that X is frozen, that you also have to debug. This way cuts the debugging in half by skipping directly to the FrozenError.\r\n\r\n## Downsides\r\n\r\nWhen you get the error \"can not access non-sharable objects in constant X by non-main Ractor\" you may want to solve the issue by e.g. copying the constant X rather than freezing it. This way makes it slightly harder  to find where X is being accessed in the non-main ractor.\r\n\r\nIn the case of conflict, whether the error occurs in the main ractor or the non-main ractor can be non-deterministic.\r\n\r\n## Applicability\r\n\r\nThis probably applies as well to global variables, class variables, and class instance variables.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-21T19:39:19Z", "updated_on": "2021-02-01T16:24:14Z", "closed_on": "2020-10-26T09:04:13Z", "relations": [{"id": 2812, "issue_id": 17273, "issue_to_id": 17278, "relation_type": "relates", "delay": null}]}, {"id": 17277, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 13458, "name": "greggzst (Grzegorz Jakubiak)"}, "assigned_to": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "Make Enumerator#with_index yield row and col indices for Matrix", "description": "Given a matrix:\r\n\r\n```ruby\r\nmatrix = Matrix[[0,2,3,4], [6,7,8,9], [1,4,5,8]]\r\n```\r\n\r\nYou could get the row and col indices of a matrix using `Matrix#each_with_index`:\r\n\r\n```ruby\r\nmatrix\r\n.each_with_index { |e, row, col| p [row, col] }\r\n[0, 0]\r\n[0, 1]\r\n[0, 2]\r\n[0, 3]\r\n[1, 0]\r\n[1, 1]\r\n[1, 2]\r\n[1, 3]\r\n[2, 0]\r\n[2, 1]\r\n[2, 2]\r\n[2, 3] \r\n```\r\n\r\nYou can chain it with other enumerators and access indices within them:\r\n\r\n```ruby\r\nmatrix\r\n.each_with_index\r\n.filter_map { |e, row, col| [row, col] if e % 4 == 0}\r\n# => [[0, 0], [0, 3], [1, 2], [2, 1], [2, 3]]\r\n```\r\n\r\nMeanwhile, `with_index` after `Matrix#each` returns flattened indices, not row or column indices, which does not look right:\r\n\r\n```ruby\r\nmatrix\r\n.each.with_index { |e, index| p index }\r\n0\r\n1\r\n2\r\n3\r\n4\r\n5\r\n6\r\n7\r\n8\r\n9\r\n10\r\n11\r\n```\r\n\r\nI feel we should override `with_index` for `Matrix` so it returns row and column indices.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-21T10:07:09Z", "updated_on": "2020-12-16T15:47:23Z", "closed_on": "2020-12-16T15:47:23Z", "relations": []}, {"id": 17276, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 131, "name": "no6v (Nobuhiro IMAI)"}, "subject": "Ripper stops tokenizing after keyword as a method parameter", "description": "Although these are obviously syntax errors at this time, the following\r\ncodes cannot be tokenized correctly by `Ripper.tokenize`.\r\n\r\n```\r\n$ cat src.rb\r\ndef req(true) end\r\ndef opt(true=0) end\r\ndef rest(*true) end\r\ndef keyrest(**true) end\r\ndef block(&true) end\r\n->true{}\r\n->true=0{}\r\n->*true{}\r\n->**true{}\r\n->&true{}\r\n$ ruby -rripper -vlne 'p Ripper.tokenize($_)' src.rb\r\nruby 3.0.0dev (2020-10-21T00:24:47Z master da25affdac) [x86_64-linux]\r\n[\"def\", \" \", \"req\", \"(\", \"true\", \")\"]\r\n[\"def\", \" \", \"opt\", \"(\", \"true\", \"=\", \"0\", \")\"]\r\n[\"def\", \" \", \"rest\", \"(\", \"*\", \"true\", \")\"]\r\n[\"def\", \" \", \"keyrest\", \"(\", \"**\", \"true\", \")\"]\r\n[\"def\", \" \", \"block\", \"(\", \"&\", \"true\", \")\"]\r\n[\"->\", \"true\", \"{\"]\r\n[\"->\", \"true\", \"=\", \"0\", \"{\"]\r\n[\"->\", \"*\", \"true\", \"{\"]\r\n[\"->\", \"**\", \"true\", \"{\"]\r\n[\"->\", \"&\", \"true\", \"{\"]\r\n```\r\n\r\n`end` and `}` are not shown in result.\r\n\r\nThis seems to prevent `irb` from determining the continuity of the input.\r\nSee: https://github.com/ruby/irb/issues/38\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-21T10:00:28Z", "updated_on": "2020-11-19T14:33:36Z", "closed_on": "2020-11-18T05:16:11Z", "relations": []}, {"id": 17274, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Ractor.make_shareable(obj)", "description": "This ticket describes the semantics of \"shareable\" and proposes a new method `Ractor.make_shareable(obj)`.\r\nWith this method, `obj` becomes a shareable object by freezing it and reachable objects if it is necessary and it is possible.\r\n\r\n## Background\r\n\r\n\"Shareable object\" is new term used by Ractors.\r\n\r\n* (1) We can send a reference to send a shareable object instead of doing deep copy.\r\n* (2) We can access to a constant which contains a shareable object from non-main ractors.\r\n\r\n(1) is (mainly) performance and (2) is programmability (how to rewrite the libraries and so on). See [Feature #1727] for the examples of (2).\r\n\r\nThe definition of shareable object is thread-safe, ractor-safe object, they are safe to access from multiple ractors simultaneously.\r\n\r\nThe following conditions are definition of \"shareable object\" (`obj` is shareable object if ...).\r\n\r\n* SPECIAL_CONST objects are shareable (also be frozen).\r\n* if `RBASIC(obj)->flags | FL_SHAREABLE` is true, it is shareable.\r\n* T_OBJECT: if all instance variables only refer to shareable objects (def1) and itself is frozen (def2)\r\n* T_ARRAY: (def1) + (def2) + if all elements are shareable objects\r\n* T_HASH: (def1) + (def2) + if all keys and values are sharable objects and default_proc/value (IFNONE, in C-level) is a sharable object\r\n* T_STRUCT: (def1) + (def2) + if all members are shareable objects\r\n* T_RATIONAL: (def1) + (def2) + if num/den are shareaable\r\n* T_COMPLEXL: (def1) + (def2) + if imag/real are shareable \r\n* T_STRING, T_FILE, T_MATCH, T_REGEXP: (def1) + (def2)\r\n\r\n`T_DATA` (user customizable data structure) is difficult problem because if it is frozen, it can modify a state (== we can use (def2)), for example current Queue implementation ignores frozen flag. So we define the semantics like:\r\n\r\n* `T_DATA`: (def1) + if `RTYPEDDATA_P(obj)` is true and `rb_data_type_t::flags | RUBY_TYPED_FROZEN_SHAREABLE`, we rely on (def2). Otherwize, this T_DATA object can not become a shareable object. Also we need to check reachable objects are shareable.\r\n\r\n`Ractor.shareable?(obj)` checks this definitions.\r\n\r\nNote that you can add `FL_SHAREABLE` flag to any objects, so if you know there is no mutation or enough protected, you can set the flag and it will be a shareable object. For example, [Feature #17261] use this flag and `TVar`s are shareable objects.\r\n\r\n## Proposal\r\n\r\nAs you can see, most of objects are shareable if they are frozen and they are only refers shareable/frozen objects.\r\n`Ractor.make_shareable(obj)` tries to freeze objects recursively if it is non-shareable objects.\r\n\r\n```ruby\r\n# puseudo-code\r\n\r\ndef Ractor.make_shareable(obj)\r\n  return obj if Ractor.shareable(obj)\r\n\r\n  obj.freeze\r\n\r\n  if obj.is T_DATA and (obj.type.flags | RUBY_TYPED_FROZEN_SHAREABLE) == 0\r\n    raise \"can not make shareable object for ...\"\r\n  end\r\n\r\n  obj.reachable_objects{|o|\r\n    Ractor.make_shareable(o)\r\n  }\r\n\r\n  # only refer to the shareable objects, so it can be a shareable.\r\n  obj.set! FL_SHAREBLE\r\nend\r\n```\r\n\r\nIf it raises an error in the middle of the process, half-baked state are remained.\r\n\r\n```\r\nbegin\r\n  Ractor.make_shareable [ a1 = [1, 2],\r\n                          Thread.new{},\r\n                          a2 = [3, 4]]\r\nrescue Ractor::Error\r\nend\r\n\r\np Ractor.shareable?(a1) #=> true\r\np Ractor.shareable?(a2) #=> false\r\n```\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/3678\r\nand it was already merged to propose https://bugs.ruby-lang.org/issues/17273\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-21T06:47:55Z", "updated_on": "2020-12-19T22:12:49Z", "closed_on": "2020-12-19T22:12:49Z", "relations": [{"id": 2768, "issue_id": 17145, "issue_to_id": 17274, "relation_type": "relates", "delay": null}, {"id": 2771, "issue_id": 17273, "issue_to_id": 17274, "relation_type": "relates", "delay": null}]}, {"id": 17273, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "shareable_constant_value pragma", "description": "This proposal is to introduce `# shareable_constant_value: true` pragma to make constant values shareable objects.\r\nWith this pragma, you don't need to add `freeze` to access from non-main ractors.\r\n\r\n```ruby\r\n# shareable_constant_value: true\r\n\r\nA = [1, [2, [3, 4]]]\r\nH = {a: \"a\"}\r\n\r\nRactor.new do\r\n  p A\r\n  p H\r\nend.take\r\n```\r\n\r\n## Background\r\n\r\nNow, we can not access constants which contains a unshareable object from the non-main Ractor.\r\n\r\n```ruby\r\nA = [1, [2, [3, 4]]]\r\nH = {a: \"a\"}\r\n\r\nRactor.new do\r\n  p A #=> can not access non-sharable objects in constant Object::A by non-main Ractor. (NameError)\r\n  p H\r\nend.take\r\n```\r\n\r\nIf we know we don't modify `A` and `H` is frozen object, we can freeze them, and other ractors can access them.\r\n\r\n\r\n```ruby\r\nA = [1, [2, [3, 4].freeze].freeze].freeze\r\nH = {a: \"a\".freeze}.freeze\r\n\r\nRactor.new do\r\n  p A #=> [1, [2, [3, 4]]]\r\n  p H #=> {:a=>\"a\"}\r\nend.take\r\n```\r\n\r\nAdding nesting data structure, we need many `.freeze` method.\r\nRecently, I added `Ractor.make_shareable(obj)` makes `obj` shareable with freezing objects deeply (see [Feature #17274]).\r\nWe only need to introduce this method for each constant.\r\n\r\n```ruby\r\nA = Ractor.make_shareable( [1, [2, [3, 4]]] )\r\nH = Ractor.make_shareable( {a: \"a\"} )\r\n\r\nRactor.new do\r\n  p A #=> [1, [2, [3, 4]]]\r\n  p H #=> {:a=>\"a\"}\r\nend.take\r\n```\r\n\r\nHowever, if we have 100 constants, it is troublesome.\r\n\r\n## Proposal\r\n\r\nWith `# shareable_constant_value: true`, you can specify all constants are shareable.\r\n\r\n```ruby\r\n# shareable_constant_value: true\r\n\r\nA = [1, [2, [3, 4]]]\r\n# compiled with: A = Ractor.make_shareable( [1, [2, [3, 4]]] )\r\nH = {a: \"a\"}\r\n# compiled with: H = Ractor.make_shareable( {a: \"a\"} )\r\n\r\nRactor.new do\r\n  p A\r\n  p H\r\nend.take\r\n```\r\n\r\n(Strictly speaking, don't call `Ractor.make_shareable`, but apply same effect. This means rewriting `Ractor.make_shareable` doesn't affect this behavior)\r\n\r\nYou can specify `# shareable_constant_value: false` in the middle of the place.\r\n\r\n```ruby\r\n# shareable_constant_value: true\r\n\r\nS1 = 'str' #\r\np S1.frozen? #=> true\r\n\r\n# shareable_constant_value: false\r\n\r\nS2 = 'str' #\r\np S2.frozen? #=> false\r\n```\r\n\r\nThe effect of this pragma is closed to the scope.\r\n\r\n```ruby\r\nclass C\r\n  # shareable_constant_value: true\r\n  A = 'str'\r\n  p A.frozen? #=> true\r\n\r\n  1.times do\r\n    # shareable_constant_value: false\r\n    B = 'str'\r\n    p B.frozen? #=> false\r\n  end\r\nend\r\n\r\nX = 'str'\r\np X.frozen? #=> false\r\n```\r\n\r\n`Ractor.make_shareable(obj)` doesn't affect anything to shareable objects.\r\n\r\n\r\n```ruby\r\n# shareable_constant_value: true\r\nclass C; end\r\n\r\nD = C\r\np D.frozen? #=> false\r\n```\r\n\r\nSome objects can not become shareable objects, so it raises an exception:\r\n\r\n```ruby\r\n# shareable_constant_value: true\r\n\r\nT = Thread.new{}\r\n#=> `make_shareable': can not make shareable object for #<Thread:0x000055952e40ffb0 /home/ko1/ruby/src/trunk/test.rb:3 run> (Ractor::Error)\r\n```\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/3681/files", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-21T05:56:19Z", "updated_on": "2020-12-16T18:36:36Z", "closed_on": "2020-12-16T18:36:36Z", "relations": [{"id": 2771, "issue_id": 17273, "issue_to_id": 17274, "relation_type": "relates", "delay": null}, {"id": 2772, "issue_id": 17145, "issue_to_id": 17273, "relation_type": "relates", "delay": null}, {"id": 2812, "issue_id": 17273, "issue_to_id": 17278, "relation_type": "relates", "delay": null}, {"id": 2813, "issue_id": 17273, "issue_to_id": 17397, "relation_type": "relates", "delay": null}]}, {"id": 17270, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "ObjectSpace.each_object should be restricted on multi-Ractors", "description": "Unshareable objects should not be touched from multiple ractors\r\nso ObjectSpace.each_object should be restricted. On multi-ractor\r\nmode, ObjectSpace.each_object only iterates shareable objects\r\neven if running on the main ractor.\r\n\r\nhttps://github.com/ruby/ruby/pull/3672\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-20T02:28:05Z", "updated_on": "2020-10-26T16:36:49Z", "closed_on": "2020-10-20T06:39:54Z", "relations": []}, {"id": 17269, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Frozen Process::Status", "description": "It seems immutable information.\r\nhttps://github.com/ruby/ruby/pull/3671\r\n\r\nSomeone can define singleton methods on that, so it is no strong feature request.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-20T02:07:39Z", "updated_on": "2020-10-29T16:05:02Z", "closed_on": "2020-10-29T16:05:02Z", "relations": []}, {"id": 17267, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "assigned_to": {"id": 572, "name": "hsbt (Hiroshi SHIBATA)"}, "subject": "Remove Win32API at Ruby 3.0", "description": "https://github.com/ruby/ruby/blob/master/ext/win32/lib/Win32API.rb#L5 says \"Win32API is deprecated after Ruby 1.9.1; use fiddle directly instead\".\r\n\r\nWe have enough time to deprecate for this module.\r\n\r\nCan we remove it from our repo?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-19T23:58:55Z", "updated_on": "2020-11-11T19:27:50Z", "closed_on": "2020-11-11T00:28:21Z", "relations": []}, {"id": 17266, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 18, "name": "mame (Yusuke Endoh)"}, "assigned_to": {"id": 18, "name": "mame (Yusuke Endoh)"}, "subject": "Bundle TypeProf", "description": "I'm working on bundling [TypeProf](https://github.com/ruby/typeprof), a type analyzer for non-annotated Ruby code, with Ruby 3.0.  The following PR bundles TypeProf as a bundled gem.\r\n\r\nhttps://github.com/ruby/ruby/pull/3668\r\n\r\nMatz was very positive to bundle it with Ruby 3.0, but just for case, I'd like to get approval from matz in a public ticket. I hope we can bundle it in 3.0 preview 2.\r\n\r\nFor TypeProf, please see my talk at RubyKaigi Takeout 2020:\r\n\r\n* https://rubykaigi.org/2020-takeout/presentations/mametter.html\r\n* https://www.youtube.com/watch?v=6KcFdQWp8W0", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-19T14:55:29Z", "updated_on": "2020-10-28T12:19:43Z", "closed_on": "2020-10-27T11:25:54Z", "relations": []}, {"id": 17265, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Add `Bool` module", "description": "1-line Summary: `rbs` would benefit from the existence of common ancestor `Bool` for `TrueClass` and `FalseClass`.\r\n\r\nDetail:\r\nMatz: I am aware you rejected a similar request, but could we revisit this in light of RBS?\r\n\r\nOne use case was for an easy way to check for `true` or `false` values, instead of simply for truthiness (e.g. for data transfer, strict argument checking, testing, etc.)\r\n\r\nI believe there's a new use case: `RBS`\r\n\r\nIn `RBS`, the most used types like `String` and `Integer` have types for \"string-like\" and \"integer-like\" objects: `string` and `integer` (all lowercase).\r\n\r\nFor example the signature for `Integer#>>` is:\r\n\r\n```\r\ndef >>: (int) -> Integer\r\n```\r\n\r\nIt accepts an `Integer` *or an object responding to `to_int`* (summarized by `int`) and returns an `Integer` (and never another class of object responding to `to_int` or not).\r\n\r\nThere is a similar idea with boolean values, where a method may accept any object and will use it's truthiness, while returning `true | false`. For example one of the interface for `Enumerable#all?` should look like:\r\n\r\n```\r\ndef all?: () { (Elem) -> bool } -> true | false\r\n```\r\n\r\nThe user supplied block can return any value, and its truthiness (anything else than `nil` or `false`) will be used to determine the result of `all?`. That result will be `true | false`, and no other value.\r\n\r\nIf RBS is to be popular, there will be *many* signatures for such predicates (in builtin Ruby, stdlib, any gems, applications, etc.). I feel the best option would be `Bool`, if this would be reflected in Ruby itself.\r\n\r\nProposal: a new global module called `Bool`, without any method of constant, included in `TrueClass` and `FalseClass`.\r\n\r\nFollowing reasons for rejection were given at the time:\r\n\r\n> many gems and libraries had already introduced Boolean class. I don't want to break them.\r\n\r\nI looked and found the [`bool` gem](https://rubygems.org/gems/bool) that defines a `Bool` module. My proposal is compatible. In any case, this gem looks abandoned, the author Aslak Helles\u00f8y doesn't have the code on github, the gem has had 7000 downloads in the past 6 years and [has no public reverse dependency](https://rubygems.org/gems/bool/reverse_dependencies). It also fails to install on my machine.\r\n\r\nI am not aware of incompatibilities.\r\n\r\n>  `true` and `false` are the only representative of true-false values. In Ruby. `nil` and `false` are falsy values, and everything else is a true value. There's no meaning for having a superclass of `TrueClass` and `FalseClass` as `Boolean`.\r\n\r\nThe proposal is exactly to be able to easily write about this duality of `Bool` as having only `true` and `false` as members, and every Ruby object as being implicitly convertible as being truthy or falsy (`bool` in RBS).\r\n\r\nDiscussion in RBS:\r\n* https://github.com/ruby/rbs/issues/133\r\n\r\nPrevious feature requests for `Boolean`:\r\n* https://bugs.ruby-lang.org/issues/14224\r\n* https://bugs.ruby-lang.org/issues/12515\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-19T00:11:59Z", "updated_on": "2020-10-26T09:44:08Z", "closed_on": "2020-10-26T07:55:15Z", "relations": []}, {"id": 17261, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "subject": "Software transactional memory (STM) for Threads and Ractors", "description": "## Abstract\r\n\r\nI propose Software transactional memory (STM) for threads and ractors.\r\n\r\nImplementation is here: https://github.com/ruby/ruby/pull/3652\r\n\r\nThe interface is similar to concurrent-ruby, but not the same.\r\nhttp://ruby-concurrency.github.io/concurrent-ruby/1.1.4/Concurrent/TVar.html\r\n\r\n## Basic concept\r\n\r\nhttps://en.wikipedia.org/wiki/Software_transactional_memory\r\nTransaction is popular idea on data base systems to keep state consistency.\r\n\r\nSTM is similar idea to implement optimistic synchronization strategy.\r\n\r\nThere are several advantages compare with traditional synchronization techniques like Mutex and so on:\r\n\r\n* Performance: in some cases, it is faster because of optimistic nature.\r\n* Composability: multiple locks can introduce dead-lock. STM allows nested transaction. In other words, (some kind of) STM can guarantee the progressiveness.\r\n\r\nThe disadvantages is, it can lead slow down on high-contention cases.\r\n\r\n## API\r\n\r\n* `Thread::atomically do expr end`: make a new transaction and run `expr` in it. `expr` can be retried if the conflict is detected.\r\n* `Thread::TVar.new(default_value)`\r\n* `Thread::TVar#value`: get current value of TVar\r\n* `Thread::TVar#value = val`: set TVar value `val`.\r\n* `Thread::TVar#increment(n=1)`: Just same as `Thread.atomically{ tv.value += 1 }`.\r\n\r\nNote that `expr` for `Thread.atomically` can retries and all `TVar#value=` (set TVar values) are reverted before retries. Another operations such as other memory modification, IO operations includes network operations etc are not reverted.\r\n\r\nThe very difference between `Concurrent::TVar` is:\r\n\r\n* TVar only refer to shareable objects to support Ractor.\r\n* `TVar#value=` should be used with `atomically`. We can define as `Thread.atomically{ tv.value = val }`, but it can lead misusing without `atomically`.\r\n* `TVar#increment` is special case to allow setting without `atomically` to support typical single counter cases.\r\n\r\n## Implementation\r\n\r\nhttps://github.com/ruby/ruby/pull/3652\r\n\r\nThe implementation is almost same as TL2, lock-based STM with global version clock with pthread/win32 threads.\r\nWe can use atomic operations but not supported yet (but only a few performance benefit on my measuremnets).\r\n\r\n## Example\r\n\r\n```ruby\r\nN = 1_000_000\r\n\r\ntv1 = Thread::TVar.new(0)\r\ntv2 = Thread::TVar.new(0)\r\n\r\nr1 = Ractor.new tv1, tv2 do |tv1, tv2|\r\n  loop do\r\n    Thread.atomically do\r\n      v1, v2 = tv1.value, tv2.value\r\n      raise if v1 != v2\r\n    end\r\n  end\r\nend\r\n\r\nrs = 3.times.map do\r\n  Ractor.new tv1, tv2 do |tv1, tv2|\r\n    N.times do\r\n      Thread.atomically do\r\n        tv1.value += 1\r\n        tv2.value += 1\r\n      end\r\n    end\r\n  end\r\nend\r\n\r\nrs.each{|r| r.take}\r\np [tv1.value, tv2.value] #=> [3000000, 3000000]\r\n```\r\n\r\nIn this case, \r\n\r\n* all `atomically` blocks keep consistency that `tv1.value == tv2.value`.\r\n* the results `[3000000, 3000000]` shows consistency on `+=1`.\r\n\r\nHere is famous bank-account example:\r\n\r\n\r\n```ruby\r\nclass Account\r\n  COUNT = Thread::TVar.new 0\r\n\r\n  def initialize deposit = 0\r\n    @i = COUNT.increment\r\n    @balance = Thread::TVar.new(deposit)\r\n  end\r\n\r\n  def transfer_from acc, n\r\n    Thread::atomically do\r\n      acc.withdraw n\r\n      self.deposit n\r\n    end\r\n  end\r\n\r\n  def transfer_to acc, n\r\n    Thread::atomically do\r\n      self.withdraw n\r\n      acc.deposit n\r\n    end\r\n  end\r\n\r\n  def withdraw n\r\n    @balance.value -= n\r\n  end\r\n\r\n  def deposit n\r\n    @balance.value += n\r\n  end\r\n\r\n  def balance\r\n    @balance.value\r\n  end\r\nend\r\n\r\nAN =  1_0000\r\nN = 10_000_000\r\nRN = 10\r\niter = 0\r\naccs = AN.times.map{Account.new.freeze}.freeze\r\n\r\nrequire 'benchmark'\r\n\r\n# :forward\r\n#   two ractors operate N times: a[i].transfer(a[i+1])\r\n#     R1: a1->a2, a2->a3, ...\r\n#     R2: a1->a2, a2->a3, ...\r\n\r\n# :reverse\r\n#   two ractors operate N times: a[i].transfer(a[i+1]),\r\n#   but the oroder of accounts are reversed.\r\n#     R1: a1->a2, a2->a3, ...\r\n#     R2: a1->aN-1, a2->aN-2, ...\r\n\r\n# :shuffle\r\n#   RN ractors operate N times: a[rand].transfer(a[rand])\r\n#   It simulates normal bank-operation\r\n\r\nmode = :shuffle\r\n\r\nloop do\r\n  iter += 1\r\n\r\n  btime = Time.now\r\n\r\n  case mode\r\n  when :forward\r\n    rs = []\r\n\r\n    rs << Ractor.new(accs) do |accs|\r\n      N.times{|i|\r\n        a1, a2 = accs[i%accs.size], accs[(i+1)%accs.size]\r\n        a1.transfer_to(a2, 1)\r\n      }\r\n    end\r\n\r\n    rs << Ractor.new(accs) do |accs|\r\n      N.times{|i|\r\n        a1, a2 = accs[i%accs.size], accs[(i+1)%accs.size]\r\n        a1.transfer_from(a2, 1)\r\n      }\r\n    end\r\n\r\n    rs.each{|r| r.take}\r\n\r\n  when :reverse\r\n    rs = []\r\n\r\n    rs << Ractor.new(accs) do |accs|\r\n      N.times{|i|\r\n        a1, a2 = accs[i%accs.size], accs[(i+1)%accs.size]\r\n        a1.transfer_to(a2, 1)\r\n      }\r\n    end\r\n\r\n    rs << Ractor.new(accs.reverse.freeze) do |accs|\r\n      N.times{|i|\r\n        a1, a2 = accs[i%accs.size], accs[(i+1)%accs.size]\r\n        a1.transfer_from(a2, 1)\r\n      }\r\n    end\r\n\r\n    rs.each{|r| r.take}\r\n\r\n  when :shuffle\r\n    RN.times.map{\r\n      Ractor.new(accs) do |accs|\r\n        rnd = Random.new\r\n        N.times{\r\n          a1 = accs.sample random: rnd\r\n          a2 = accs.sample random: rnd\r\n          redo if a1 == a2\r\n          a1.transfer_to(a2, rnd.rand(1000))\r\n        }\r\n      end\r\n    }.each{|r| r.take}\r\n\r\n  else\r\n    raise\r\n  end\r\n\r\n  sum = accs.inject(0){|r, acc| acc.balance + r}\r\n  if sum != 0\r\n    pp accs\r\n    raise \"iter #{iter} sum:#{sum}\"\r\n  end\r\n\r\n  etime = Time.now\r\n  p time: etime - btime\r\n\r\n  # break\r\nend\r\n\r\n```\r\n\r\nThis program create AN bank accounts and repeat N transafer operations.\r\nYou can observe that huge AN reduces conflicts and the execution time is low. Small AN reduces conflicts -> many retries and the execution time is high.\r\n\r\n```\r\n     AN    Execution time (s)  Retry counts\r\n    100                6.914        958,969\r\n  1_000                3.107        186,267\r\n 10_000                2.549         26,183\r\n100_000                2.627          2,458\r\n```\r\n\r\nNow x10 retries doesn't affect execution time x10, this is because the current Ractor implementation (acquiring a global lock to raise an exception, and it reduces the retry counts). If we improve the Ractor's implementation, the result would be more worse.\r\n\r\n\r\n## Consideration\r\n\r\n### `Thread.atomically` in ractors\r\n\r\nAt first, I implemented this feature with `Ractor::atomically` and `Ractor::TVar`.\r\nHowever, this STM feature will help the thread programming.\r\nThis is why I moved from `Ractor::atomically` to `Thread::atomically`.\r\n\r\nIntroduce `Concurrent` namespace what concurrent-ruby are using. However, there are small differences so that I'm not sure is is feasible.\r\n\r\nAnother idea is to support alias: `Thread.atomically` and `Ractor.atomically`.\r\n\r\n### `Thread::TVar` can refer only shareable objects\r\n\r\nThreads can access all objects so we don't need to restrict by such rule.\r\nHowever, to support ractors, this restriction is needed.\r\n\r\nOne idea is separate `Thread::TVar` and `Ractor::TVar`, but it can introduce confusion.\r\nOnly with shareable objects, thread programs become more thread-safe, so I think it is good choice to have current restriction.\r\n\r\n### Bug detection\r\n\r\nSimilar to locking, we can forget to use a `atomically` like that:\r\n\r\n```ruby\r\nclass C\r\n  def initialize\r\n    @tv1 = Thread::TVar.new(0)\r\n    @tv2 = Thread::TVar.new(0)\r\n  end\r\n  def tv1() = @tv1.value\r\n  def tv2() = @tv2.value\r\n  def tv1 = (v)\r\n    Thread.atomically{ @tv1.value = v }\r\n  end\r\n  def tv2 = (v)\r\n    Thread.atomically{ @tv2.value = v }\r\n  end\r\nend\r\n\r\nobj = C.new\r\nobj.tv1 += 1\r\nobj.tv2 += 2\r\n```\r\n\r\nIt works but it can introduce inconsistency if tv1 and tv2 are tightly coupled with because tv1 and tv2 are not accessed in the same transaction.\r\nIf tv1 and tv2 need to be modified consistently, we need to write like the following:\r\n\r\n```ruby\r\nThread.atomically do\r\n  obj.tv1 += 1\r\n  obj.tv2 += 1\r\nend\r\n```\r\n\r\nand `tv1/tv2/tv1=/tv2=` methods should not be defined.\r\n\r\nI mean we can write bad programs easily.\r\n\r\nIt is same situation with traditional locking (we need to use `Mutex` appropriately). The duty to use it correctly is for programmer.\r\n\r\nThere are some advantages compared with traditional locking:\r\n\r\n* We can concentrate on TVars. On traditional thread programming we need to check all memory state.\r\n* We can introduce logging mechanism and we can find wrong usage (for example: tv1 and tv2 are set within independent transactions). I think we can make some checker based on the log. On traditional thread programming, there are several similar works, but it is difficult to check it because the target of state is most of memory operations.\r\n\r\n## Related works\r\n\r\n* There are many STM implementation techniques. https://www.morganclaypool.com/doi/abs/10.2200/S00070ED1V01Y200611CAC002\r\n* Concurrent Haskell and Clojure are famous to support STM in language (I think).\r\n  * The model of STM is similar to Clojure.\r\n    * Clojure allows to access TVar (`ref` in Clojure) value without `atomically` (`dosync` in Clojure).\r\n    * Clojure doesn't allow to set TVar value without `atomically`.\r\n  * The API is similar to Concurrent Haskell (`TVar` and `atomically`.\r\n* Concurrent-ruby has `Concurrent::TVar`.\r\n  * But it allows to have an unshareable object.\r\n  * But is allows to set the value with `atomically`.\r\n\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-12T08:24:16Z", "updated_on": "2020-10-30T00:17:39Z", "closed_on": "2020-10-29T16:03:29Z", "relations": []}, {"id": 17260, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 3007, "name": "ktsj (Kazuki Tsujimoto)"}, "fixed_version": {"id": 5, "name": "3.0"}, "subject": "Promote pattern matching to official feature", "description": "I propose to promote pattern matching to official feature.\r\n\r\nThe current specification is basically fine, but I'd like to reconsider single line pattern matching (`expr in pat`) and suggest removing it once in 3.0.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-11T12:03:15Z", "updated_on": "2020-10-26T09:00:47Z", "closed_on": "2020-10-26T09:00:47Z", "relations": [{"id": 2810, "issue_id": 14912, "issue_to_id": 17260, "relation_type": "relates", "delay": null}]}, {"id": 17259, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "fixed_version": {"id": 5, "name": "3.0"}, "subject": "Kernel#warn should ignore <internal: entries", "description": "`Kernel#warn` currently does not skip `<internal:` entries from core library methods defined in Ruby.\r\nThis can cause rather unhelpful locations to be used for warnings.\r\n\r\nFor instance:\r\n```\r\n$ ruby -v --disable=gems -e 'def deprecated; warn \"use X instead\", uplevel: 1; end; tap(&:deprecated)'\r\nruby 3.0.0preview1 (2020-09-25 master 0096d2b895) [x86_64-linux]\r\n<internal:kernel>:90: warning: use X instead\r\n# expected: \"-e:1: warning: use X instead\"\r\n```\r\n\r\nNote that RubyGems overrides Kernel#warn since https://github.com/rubygems/rubygems/pull/2442 and https://github.com/rubygems/rubygems/blob/c1bafab1d84e0aad06e377e9db4b74cccab4b43a/lib/rubygems/core_ext/kernel_warn.rb#L42,\r\nso `--disable-gems` is needed to observe this behavior.\r\nI think it is very suboptimal that RubyGems needs to monkey-patch Kernel#warn to remove RubyGems' `require` from `Kernel#warn` location.\r\nThat is both fragile (as we've seen from various incompatible behavior and bugs in that monkey-patch) and inefficient (walking the stack multiple times).\r\n\r\nSo I would suggest to actually skip all backtraces entries starting with `<internal:` for `Kernel#warn(message, uplevel:)`.\r\nBTW this is already what [TruffleRuby does](https://github.com/oracle/truffleruby/blob/c3bcccfd8db7d460e23f0371e7ceaf5fdb71275c/src/main/ruby/truffleruby/core/kernel.rb#L656).\r\n\r\nAs a bonus, by filtering out `<internal:`, RubyGems could define its `require` in an `eval(code, nil, '<internal:rubygems-require>', line)` and it would automatically be skipped, without needing to monkey-patch Kernel#warn at all!", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-10T13:29:11Z", "updated_on": "2020-11-20T18:27:55Z", "closed_on": "2020-10-26T07:47:51Z", "relations": []}, {"id": 17258, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 45106, "name": "jemmai (Jemma Issroff)"}, "subject": "Oneshot Branch Coverage", "description": "# Description\r\n\r\nI'd like to propose adding a new option to `Coverage.start`: oneshot branch coverage. It will be analogous to the existing \"oneshot lines coverage\". Oneshot branch coverage will record the first execution of each branch.\r\n\r\n# Background\r\n\r\nTwo years ago, oneshot lines coverage was [added to the Coverage module](https://github.com/ruby/ruby/commit/47ea999b4689fc591478a05da1670d2008a4a705). It records the first execution of every line, and returns the line numbers of newly executed lines.\r\n\r\nAs the [original feature request](https://bugs.ruby-lang.org/issues/15022) described, this reduced overhead to calculations for line coverage. It solved two primary use cases, more easily enabling both coverage measurement in production and coverage measurement in CPU-intensive programs.\r\n\r\nLine coverage alone does not actually indicate full coverage of all branch options. See [this blog post](https://jemma.dev/blog/ruby-code-coverage) for more description about why not. It would therefore make sense that for the same reasons as oneshot line coverage was implemented, we should implement oneshot branch coverage to tell the full story of coverage in a way that enables coverage measurement in production and CPU-intensive programs.\r\n \r\n# Proposal\r\n\r\n## Coverage.start(oneshot_branches: true)\r\nWe add the ability to pass `oneshot_branches: true` to `Coverage.start` to return a Hash that would indicate if branches had been executed or not. It would use the same `[BRANCH_TYPE, UNIQUE_ID, START_LINE_NUMBER, START_COLUMN_NUMBER, END_LINE_NUMBER, END_COLUMN_NUMBER]` format to uniquely identify branches as the `branches: true` keyword argument already returns.\r\n\r\nHere is an example:\r\n\r\ntest.rb\r\n\r\n```\r\nrequire \"coverage\"\r\nCoverage.start(oneshot_branches: true)\r\nload \"target.rb\"\r\nputs Coverage.result\r\n```\r\n\r\ntarget.rb\r\n\r\n```\r\n2.times do\r\n  if 1 == 0\r\n    puts :match\r\n  else\r\n    puts :not_match\r\n  end\r\nend\r\n```\r\n\r\nRunning `test.rb` would output the following:\r\n\r\n```\r\n$ ruby test.rb\r\nnot_match\r\nnot_match\r\n{\r\n  \"target.rb\"=>{\r\n    :oneshot_branches=>{\r\n      [:if, 0, 2, 2, 6, 5]=>{\r\n        [:then, 1, 3, 4, 3, 15]=>0,\r\n        [:else, 2, 5, 4, 5, 19]=>1\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\n\r\n\r\n# Discussion\r\n\r\nIf we've deemed oneshot line coverage necessary, and we know that line coverage does not accurately demonstrate full coverage, it only makes sense to also implement oneshot branch coverage.\r\n\r\nReiterating the points made in the [feature request for oneshot line coverage](https://bugs.ruby-lang.org/issues/15022), there are two main drivers for oneshot branch coverage:\r\n\r\n### Branch coverage measurement in production\r\n\r\nOneshot branch coverage will allow us to print one shot branch coverage to logs and indicate where there is dead code for branch conditions in which one (or more) conditions never actually occur.\r\n\r\n### Branch coverage in CPU-intensive programs\r\n\r\nThere is an overhead to running coverage measurements on test suites. It is encouraged to run branch coverage as well as line coverage, for the reasons indicated above. Oneshot branch coverage will allow us to run branch coverage easily in CPU-intensive programs.\r\n\r\n# Summary\r\n\r\nAnalogous to `oneshot_lines`, exposing a `oneshot_branches` option for `Coverage.start` will allow for a fuller picture of coverage in a less CPU-intensive way.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-09T20:26:23Z", "updated_on": "2020-10-09T20:26:23Z", "closed_on": null, "relations": []}, {"id": 17256, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 17, "name": "ko1 (Koichi Sasada)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Freeze all Regexp objects", "description": "To be shared between ractors, Regexp objects should be frozen.\r\n\r\nNow, Matz has proposed to make all Regexp objects frozen.\r\n\r\nTen months ago, there was a note https://bugs.ruby-lang.org/issues/16377#note-7 :\r\n\r\n> For the record: Regexp.new should continue to return unfrozen Regexp instance.\r\n\r\nSo I'm not sure whether it is a good way or not.\r\n\r\nCould you give me your comment on it?\r\n\r\nIf no comments are given, I'll try to freeze them before Ruby 3.0 preview 2.\r\n\r\nBTW, I believe `/#{expr}/o` should be frozen because this expression only returns one Regexp object.\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-09T07:42:33Z", "updated_on": "2020-10-29T16:05:33Z", "closed_on": "2020-10-29T16:05:33Z", "relations": []}, {"id": 17219, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 6766, "name": "lzap (Lukas Zapletal)"}, "subject": "Make URI#hostname 86-89% and hostname= 55-154% faster", "description": "Hello,\r\n\r\nURI#hostname extends URI#host with IPv6 support. In URI, IPv6 address must have square brackets (e.g. `http://[2001:db8::1]`), URI#hostname strips these characters out while URI#hostname= adds them if missing. There are three regular expressions to perform these tasks which can dramatically slow down performance. I am attaching a two-line patch and here is a benchmark: https://gist.github.com/lzap/24cbecb47daf29111350e41a24250922\r\n\r\nResults are in the gist. A patch and a PR incoming.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-07T08:35:07Z", "updated_on": "2021-03-04T23:49:41Z", "closed_on": "2021-03-04T23:49:41Z", "relations": []}, {"id": 17210, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "assigned_to": {"id": 8, "name": "knu (Akinori MUSHA)"}, "subject": "More readable and useful `Set#inspect`", "description": "I would like to change `Set#inspect`/`to_s`:\r\n\r\n```ruby\r\n# before\r\nputs Set[1,2,3] # => \"#<Set: {1, 2, 3}>\"\r\n\r\n# after\r\nputs Set[1,2,3] # => \"Set[1, 2, 3]\"\r\n```\r\n\r\nThis output is shorter, readable, and has the property that it corresponds to Ruby code", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-02T04:33:18Z", "updated_on": "2021-05-19T22:12:31Z", "closed_on": null, "relations": []}, {"id": 17208, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 9869, "name": "koic (Koichi ITO)"}, "subject": "Add `Set#compact` and `Set#compact!` methods", "description": "This is a proposal to add `compact` and `compact!` methods already owned by `Array` and `Hash` to `Set`.\r\n\r\n- `Array#compact` and `Array#compact!` has been around for a long time.\r\n- `Hash#compact` has `Hash#compact!` been added since Ruby 2.4 ... https://bugs.ruby-lang.org/issues/11818\r\n- There is `Set` in collection libraries other than `Array` and `Hash`. But `Set` doesn't have `compact` and `compact!` methods.\r\n\r\nIt behaves the same as `compact` and `compact!` methods of `Array` and `Hash` as follows.\r\n\r\n`Set#compact!`:\r\n\r\n```ruby\r\n# Removes all nil elements from self. Returns self if any elements removed, otherwise nil.\r\nset = Set[1, 'c', nil]            #=> #<Set: {1, \"c\", nil}>\r\nset.compact!                      #=> #<Set: {1, \"c\"}>\r\nset                               #=> #<Set: {1, \"c\"}>\r\n\r\nset = Set[1, 'c']                 #=> #<Set: {1, \"c\"}>\r\nset.compact!                      #=> nil\r\nset                               #=> #<Set: {1, \"c\"}>\r\n```\r\n\r\n`Set#compact`:\r\n\r\n```ruby\r\n# Returns a new Set containing all non-nil elements from self.\r\nset = Set[1, 'c', nil]            #=> #<Set: {1, \"c\", nil}>\r\nset.compact                       #=> #<Set: {1, \"c\"}>\r\nset                               #=> #<Set: {1, \"c\", nil}>\r\n\r\nset = Set[1, 'c']                 #=> #<Set: {1, \"c\"}>\r\nset.compact                       #=> #<Set: {1, \"c\"}>\r\nset                               #=> #<Set: {1, \"c\"}>\r\n```\r\n\r\nPull Request ... https://github.com/ruby/ruby/pull/3617", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-10-01T19:32:01Z", "updated_on": "2020-11-05T10:44:22Z", "closed_on": null, "relations": []}, {"id": 17206, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 43351, "name": "fatkodima (Dima Fatko)"}, "subject": "Introduce new Regexp option to avoid global MatchData allocations", "description": "Originates from https://bugs.ruby-lang.org/issues/17030\r\n\r\nWhen this option is specified, ruby will not create global `MatchData` objects, when not explicitly needed by the method.\r\n\r\nIf the new option is named `f`, we can write as `/o/f`, and `grep(/o/f)` is faster than `grep(/o/)`.\r\n\r\nThis speeds up not only `grep`, but also `all?`, `any?`, `case` and so on.\r\n\r\nMany people have written code like this:\r\n```ruby\r\nIO.foreach(\"foo.txt\") do |line|\r\n  case line\r\n  when /^#/\r\n    # do nothing \r\n  when /^(\\d+)/\r\n    # using $1\r\n  when /xxx/\r\n    # using $&\r\n  when /yyy/\r\n    # not using $&\r\n  else\r\n    # ...\r\n  end\r\nend\r\n```\r\n\r\nThis is slow, because of the above mentioned problem.\r\nReplacing `/^#/` with `/^#/f`, and `/yyy/` with `/yyy/f` will make it faster.\r\n\r\nSome benchmarks - https://bugs.ruby-lang.org/issues/17030#note-9 which show `2.5x` to `5x` speedup.\r\n\r\nPR: https://github.com/ruby/ruby/pull/3455", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-30T15:42:27Z", "updated_on": "2020-10-28T22:43:08Z", "closed_on": null, "relations": []}, {"id": 17195, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 772, "name": "Eregon (Benoit Daloze)"}, "subject": "Freeze Enumerator::ArithmeticSequence objects", "description": "Now, all Ranges are frozen (#15504).\r\n\r\nEnumerator::ArithmeticSequence is very similar to Range, just with an extra `step`.\r\nThey're essentially already immutable, except that one could use set instance variables, but it seems of little use.\r\n\r\nSo, should we make Enumerator::ArithmeticSequence frozen too?", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-26T13:20:38Z", "updated_on": "2020-10-09T18:15:36Z", "closed_on": "2020-10-09T18:15:36Z", "relations": [{"id": 2733, "issue_id": 15504, "issue_to_id": 17195, "relation_type": "relates", "delay": null}]}, {"id": 17187, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1913, "name": "Glass_saga (Masaki Matsushita)"}, "assigned_to": {"id": 1913, "name": "Glass_saga (Masaki Matsushita)"}, "subject": "Add connect_timeout to TCPSocket", "description": "Add connect_timeout to TCPSocket.new in the same way as Socket.tcp.\r\n\r\n```ruby\r\nTCPSocket.new(\"192.0.2.1\", 1234, connect_timeout: 1) #=> raise Errno::ETIMEDOUT\r\n```", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-25T11:17:09Z", "updated_on": "2020-12-29T06:56:52Z", "closed_on": "2020-12-10T11:55:01Z", "relations": [{"id": 2731, "issue_id": 16381, "issue_to_id": 17187, "relation_type": "relates", "delay": null}, {"id": 2732, "issue_id": 17134, "issue_to_id": 17187, "relation_type": "relates", "delay": null}]}, {"id": 17184, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 11109, "name": "sheerun (Adam Stankiewicz)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "No stdlib function to perform simple string replacement", "description": "I have following simple `build.rb`:\r\n\r\n```rb\r\ntemplate = File.read('template.vim')\r\nscript = File.read('script.vim')\r\nFile.write('app.vim', template.gsub(\"SCRIPT\", script))\r\n```\r\n\r\nAnd then following `template.vim`:\r\n\r\n```vim\r\n\" some header\r\nSCRIPT\r\n```\r\n\r\nPlus following `script.vim`:\r\n\r\n\r\n```vim\r\nif g:something =~ \"\\s\\+\"\r\n  echo 'g:something is empty'\r\nendif\r\n```\r\n\r\nI'd expect that the script above produces `app.vim` with following contents:\r\n\r\n```vim\r\n\" some header\r\nif g:something =~ \"\\s\\+\"\r\n  echo 'g:something is empty'\r\nendif\r\n```\r\n\r\nUnfortunately it produces following:\r\n\r\n```vim\r\n\" some header\r\nif g:something =~ \"\\s\"\r\n  echo 'g:something is empty'\r\nendif\r\n```\r\n\r\nIt's probably because gsub interprets `\\+` in script as back-reference.\r\n\r\nI tried to find replacement function in ruby that just replaces one string with something else, without interpreting replacement in any way, but surprisingly I haven't found any.. Am I mistaken?\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-24T11:37:04Z", "updated_on": "2021-02-23T21:27:52Z", "closed_on": null, "relations": []}, {"id": 17177, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Include the current file name and the line number in the output of `p`", "description": "In many debugging situations, we want to inspect some objects in more than one source location throughout the code. To be identified where it is called from, it is very common that the method `p` is used together with a `puts` method that outputs some marker that distinguishes the location:\r\n\r\n```ruby\r\n... # some buggy area or conditional branch\r\nputs \"== A ==\"\r\np foo\r\n... # another buggy area or conditional branch\r\nputs \"== B ==\"\r\np foo\r\n... # another buggy area or conditional branch\r\nputs \"bar is:\"\r\np bar\r\n...\r\n```\r\n\r\n\r\nBut this is cumbersome.\r\n\r\nAlso, after debugging, when we want to remove the `p` calls from the code, it is sometimes not so trivial to identify where those method calls are written.\r\n\r\nI propose that the method `p` should display not only the objects passed as arguments, but also its source location. Supposing we have a file `bar.rb` like this,\r\n\r\n```rb\r\nfoo = \"a\"\r\np foo\r\n```\r\n\r\nrunning `ruby bar.rb` should perhaps have an output like this:\r\n\r\n```\r\nAt bar.rb:2\r\n\"a\"\r\n```\r\n\r\nThen, in a debugging situation like the above, we would only need to write:\r\n\r\n\r\n```ruby\r\n... # some buggy area or conditional branch\r\np foo\r\n... # another buggy area or conditional branch\r\np foo\r\n... # another buggy area or conditional branch\r\np bar\r\n...\r\n```\r\n", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-18T12:17:57Z", "updated_on": "2020-09-30T10:19:49Z", "closed_on": "2020-09-18T14:24:47Z", "relations": []}, {"id": 17176, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 73, "name": "tenderlovemaking (Aaron Patterson)"}, "subject": "GC.auto_compact / GC.auto_compact=(flag)", "description": "Hi,\r\n\r\nI'd like to make compaction automatic eventually.  As a first step, I would like to introduce two functions:\r\n\r\n* GC.enable_autocompact\r\n* GC.disable_autocompact\r\n\r\nOne function enables auto compaction, the other one disables it.  Automatic compaction is *disabled* by default.  When it is enabled it will happen only on every major GC.\r\n\r\nI've made a pull request here: https://github.com/ruby/ruby/pull/3547\r\n\r\nThis patch makes _object movement_ happen at the same time as page sweep.  When one page finishes sweeping, that page is filled.\r\n\r\n## Sweep + Move Phase\r\n\r\nDuring sweep, we keep a pointer to the current sweeping page.  This pointer is kept in [`heap->sweeping_page`](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4817).  At the beginning of sweep, this is the *first* element of the heap's linked list.\r\n\r\nAt the same time, the compaction process points at the *last* page in the heap, and that is stored in `heap->compact_cursor` [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L5023).\r\n\r\nIncremental sweeping sweeps one page at a time in the [`gc_page_sweep` function](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4624).  At the end of that function, we call [`gc_fill_swept_page`](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4738-L4742).  `gc_fill_swept_page` fills the page that was just swept and moves the movement cursor towards the sweeping cursor.\r\n\r\nWhen the sweeping cursor and the movement cursor meet, sweeping is paused, and references are updated.  This can happen in 2 ways, the sweeping cursor \"runs in to the moving cursor\" which is [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4634-L4644).  Or the moving cursor runs in to the sweep cursor which happens [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4425-L4430).\r\n\r\nEither way, the sweep step is paused and references are updated.\r\n\r\n## Reference Updating\r\n\r\nReference updating hasn't changed, but since reference updating happens before the GC finishes a cycle, it must take in to account garbage objects [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L8971-L8977).\r\n\r\n## Read Barrier\r\n\r\nDuring the sweep phase, some objects may touch other objects.  For example, `T_CLASS` [must remove itself from a parent class](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L2769-L2770).\r\n\r\n```ruby\r\nclass A; end\r\nclass B < A; end\r\n\r\nconst_set(:B, nil)\r\n```\r\n\r\nWhen `B` is freed, it must remove itself from `A`'s subclasses.  But what if `A` moved?  To fix this, I've introduced a read barrier.  The read barrier protects `heap_page_body` using `mprotect`.  If something tries to read from the page, an exception will occur and we can move all objects back to the page (invalidate the movement).\r\n\r\nThe lock function is [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4321-L4335).\r\nThe unlock function is [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4337-L4351).\r\n\r\nIt uses `sigaction` to catch the exception [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4514-L4530).\r\n\r\n## Cross Platform\r\n\r\n`mprotect` and `sigaction` are not cross platform, they doesn't work on Windows. On Windows the read barrier uses exception handlers that are built in to Windows.  I implemented them [here](https://github.com/ruby/ruby/blob/8a4d8fa0ea463d44486bf2447ea9830593768fd7/gc.c#L4471-L4503).\r\n\r\nThe read barrier seems to work on all platforms we're testing.\r\n\r\n## Statistics\r\n\r\n`GC.stat(:compact_count)` contains the number of times compaction has happened, so we can write things like this:\r\n\r\n```ruby\r\nGC.enable_autocompact\r\n\r\ncc = GC.stat(:compact_count)\r\nlist = []\r\nloop do\r\n  500.times { list << Object.new }\r\n  break if cc < GC.stat(:compact_count)\r\nend\r\n\r\np GC.stat(:compact_count)\r\n```\r\n\r\nWe can check when the read barrier is triggered with `GC.stat(:read_barrier_faults)`\r\n\r\nI've also added `GC.latest_compact_info` so you can see what types of objects moved and how many.  For example:\r\n\r\n```\r\n[aaron@tc-lan-adapter ~/g/ruby (autocompact)]$ cat test.rb\r\nlist = []\r\n500.times {\r\n  list << Object.new\r\n  Object.new\r\n  Object.new\r\n}\r\n\r\nGC.enable_autocompact\r\ncount = GC.stat :compact_count\r\nloop do\r\n  list << Object.new\r\n  break if GC.stat(:compact_count) > count\r\nend\r\n\r\np GC.latest_compact_info\r\n[aaron@tc-lan-adapter ~/g/ruby (autocompact)]$ make runruby\r\n./miniruby -I./lib -I. -I.ext/common  ./tool/runruby.rb --extout=.ext  -- --disable-gems ./test.rb\r\n{:considered=>{:T_OBJECT=>408}, :moved=>{:T_OBJECT=>408}}\r\n[aaron@tc-lan-adapter ~/g/ruby (autocompact)]$\r\n```\r\n\r\n## Recap\r\n\r\nNew methods:\r\n\r\n* GC.enable_autocompact\r\n* GC.disable_autocompact\r\n* GC.last_compact_info\r\n\r\nNew statistics in `GC.stat`:\r\n\r\n* GC.stat(:read_barrier_faults)\r\n\r\nDiff is here: https://github.com/ruby/ruby/pull/3547", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-16T18:39:14Z", "updated_on": "2020-11-02T22:43:29Z", "closed_on": "2020-11-02T22:43:29Z", "relations": []}, {"id": 17173, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 14, "name": "znz (Kazuhiro NISHIYAMA)"}, "assigned_to": {"id": 271, "name": "akr (Akira Tanaka)"}, "subject": "open-uri \u3067 ciphers \u3092\u8a2d\u5b9a\u3057\u305f\u3044", "description": "Debian GNU/Linux 10 (buster) \u306e OpenSSL 1.1.1d \u306e\u74b0\u5883\u3060\u3068 https://www.famitsu.com \u3067 `dh key too small` \u306b\u306a\u3063\u3066\u3064\u306a\u304c\u3089\u306a\u3044\u306e\u3067\u3059\u304c\u3001 `ciphers` \u306b `DEFAULT:!DH` \u3092\u8a2d\u5b9a\u3059\u308b\u3068\u3064\u306a\u304c\u308b\u306e\u3067\u3001 `open-uri` \u7d4c\u7531\u3067\u3082 `ciphers` \u3092\u8a2d\u5b9a\u3057\u305f\u3044\u3067\u3059\u3002\r\n\r\ncurl \u3067\u306e\u78ba\u8a8d:\r\n\r\n```\r\n% curl --head https://www.famitsu.com/\r\ncurl: (35) error:141A318A:SSL routines:tls_process_ske_dhe:dh key too small\r\nzsh: exit 35    curl --head https://www.famitsu.com/\r\n% curl --ciphers 'DEFAULT:!DH' --head https://www.famitsu.com/\r\nHTTP/1.1 200 OK\r\nServer: nginx/1.12.2\r\nDate: Wed, 16 Sep 2020 04:48:25 GMT\r\nContent-Type: text/html\r\nConnection: keep-alive\r\nVary: Accept-Encoding\r\nAccept-Ranges: bytes\r\nVary: Accept-Encoding\r\nStrict-Transport-Security: max-age=60\r\n```\r\n\r\nruby \u3067\u306e\u78ba\u8a8d:\r\n\r\n```\r\n% ruby -r open-uri -e 'open(\"https://www.famitsu.com/\")'\r\nTraceback (most recent call last):\r\n        13: from -e:1:in `<main>'\r\n        12: from /usr/lib/ruby/2.5.0/open-uri.rb:35:in `open'\r\n        11: from /usr/lib/ruby/2.5.0/open-uri.rb:735:in `open'\r\n        10: from /usr/lib/ruby/2.5.0/open-uri.rb:165:in `open_uri'\r\n         9: from /usr/lib/ruby/2.5.0/open-uri.rb:224:in `open_loop'\r\n         8: from /usr/lib/ruby/2.5.0/open-uri.rb:224:in `catch'\r\n         7: from /usr/lib/ruby/2.5.0/open-uri.rb:226:in `block in open_loop'\r\n         6: from /usr/lib/ruby/2.5.0/open-uri.rb:755:in `buffer_open'\r\n         5: from /usr/lib/ruby/2.5.0/open-uri.rb:337:in `open_http'\r\n         4: from /usr/lib/ruby/2.5.0/net/http.rb:909:in `start'\r\n         3: from /usr/lib/ruby/2.5.0/net/http.rb:920:in `do_start'\r\n         2: from /usr/lib/ruby/2.5.0/net/http.rb:985:in `connect'\r\n         1: from /usr/lib/ruby/2.5.0/net/protocol.rb:44:in `ssl_socket_connect'\r\n/usr/lib/ruby/2.5.0/net/protocol.rb:44:in `connect_nonblock': SSL_connect returned=1 errno=0 state=error: dh key too small (OpenSSL::SSL::SSLError)\r\nzsh: exit 1     ruby -r open-uri -e 'open(\"https://www.famitsu.com/\")'\r\n% ruby -r net/http -e 'http=Net::HTTP.new(\"www.famitsu.com\", 443); http.use_ssl=true; http.ciphers=\"DEFAULT:!DH\"; p http.get(\"/\")'\r\n#<Net::HTTPOK 200 OK readbody=true>\r\n```\r\n\r\nhttps://www.ssllabs.com/ssltest/analyze.html?d=www.famitsu.com \u306b\u3088\u308b\u3068 Cipher Suites \u306f\r\n\r\n```\r\n# TLS 1.2 (suites in server-preferred order)\r\nTLS_DHE_RSA_WITH_AES_256_GCM_SHA384 (0x9f)   DH 1024 bits   FS   WEAK\t256\r\nTLS_DHE_RSA_WITH_AES_128_GCM_SHA256 (0x9e)   DH 1024 bits   FS   WEAK\t128\r\nTLS_DHE_RSA_WITH_AES_256_CBC_SHA256 (0x6b)   DH 1024 bits   FS   WEAK\t256\r\nTLS_DHE_RSA_WITH_AES_128_CBC_SHA256 (0x67)   DH 1024 bits   FS   WEAK\t128\r\nTLS_RSA_WITH_AES_256_GCM_SHA384 (0x9d)   WEAK\t256\r\nTLS_RSA_WITH_AES_128_GCM_SHA256 (0x9c)   WEAK\t128\r\nTLS_RSA_WITH_AES_256_CBC_SHA256 (0x3d)   WEAK\t256\r\nTLS_RSA_WITH_AES_128_CBC_SHA256 (0x3c)   WEAK\t128\r\nTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)   ECDH secp384r1 (eq. 7680 bits RSA)   FS\t256\r\nTLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)   ECDH secp384r1 (eq. 7680 bits RSA)   FS\t128\r\nTLS_ECDHE_RSA_WITH_AES_256_CBC_SHA384 (0xc028)   ECDH secp384r1 (eq. 7680 bits RSA)   FS   WEAK\t256\r\nTLS_ECDHE_RSA_WITH_AES_128_CBC_SHA256 (0xc027)   ECDH secp384r1 (eq. 7680 bits RSA)   FS   WEAK\t128\r\n```\r\n\r\n\u3068\u306a\u3063\u3066\u3044\u3066\u3001 Handshake Simulation \u3067\u306f\r\n\r\n```\r\nChrome 80 / Win 10  R\tRSA 2048 (SHA256)  \tTLS 1.2\tTLS_RSA_WITH_AES_256_GCM_SHA384  No FS\r\nFirefox 73 / Win 10  R\tRSA 2048 (SHA256)  \tTLS 1.2\tTLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384   ECDH secp256r1  FS\r\nOpenSSL 1.1.1c  R\tRSA 2048 (SHA256)  \tTLS 1.2\tTLS_DHE_RSA_WITH_AES_256_GCM_SHA384   DH 1024  FS\r\n```\r\n\r\n\u306e\u3088\u3046\u306b\u306a\u3063\u3066\u3044\u3066\u3001 `TLS_DHE_RSA_WITH_AES_256_GCM_SHA384` \u304c\u9078\u3070\u308c\u3066 DH 1024 bit \u3092\u62d2\u5426\u3059\u308b\u30af\u30e9\u30a4\u30a2\u30f3\u30c8\u304b\u3089\u306f\u7e4b\u3089\u306a\u3044\u8a2d\u5b9a\u306b\u306a\u3063\u3066\u3044\u308b\u30b5\u30fc\u30d0\u30fc\u304c\u3042\u308b\u3088\u3046\u3067\u3059\u3002(`dh key too small` \u3067 web \u691c\u7d22\u3059\u308b\u3068\u540c\u69d8\u306e\u8a2d\u5b9a\u306e\u30b5\u30fc\u30d0\u30fc\u306f\u4ed6\u306b\u3082\u3042\u308b\u3088\u3046\u3067\u3059\u3002)", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-16T04:55:19Z", "updated_on": "2020-09-25T09:17:47Z", "closed_on": null, "relations": []}, {"id": 17171, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 6, "name": "Rejected", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 182, "name": "marcandre (Marc-Andre Lafortune)"}, "subject": "Why is the visibility of constants not affected by `private`?", "description": "```ruby\r\nclass Foo\r\n  def call_me\r\n    # ...\r\n  end\r\n\r\n  private\r\n \r\n  SOME_DATA = %i[...].freeze  # is public, why not private?\r\n\r\n  def calc_stuff  # is private, ok.\r\n    # ...\r\n  end\r\nend\r\n```\r\n\r\nIt's probably a naive question, but why shouldn't `SOME_DATA`'s visibility be private?\r\n\r\nWhen writing gems, more often than not the constants that I write are not meant for public consumption. I find it redundant (and tiresome) to explicitly write `private_constant :SOME_DATA`.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-15T20:34:44Z", "updated_on": "2020-10-26T07:52:20Z", "closed_on": "2020-10-26T07:52:20Z", "relations": [{"id": 2727, "issue_id": 16752, "issue_to_id": 17171, "relation_type": "relates", "delay": null}]}, {"id": 17170, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 7, "name": "Feedback", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 15736, "name": "foonlyboy (Eike Dierks)"}, "subject": "Numeric.zero, Numeric.one", "description": "Hi at the ruby team,\r\n\r\nI'd like to suggest to enhance `Numeric` to provide two new class methods, which shall be: `zero` and `one`.\r\n\r\n- `Integer.zero` shall be equal to `Integer(0)`\r\n- `Float.zero` shall be equal to `Float(0)`\r\n- `BigDecimal.zero` shall be equal to `BigDecimal(0)`\r\n- `Complex.zero` shall be equal to `Complex(0)`\r\n\r\nLikewise for `one`, you get the idea.\r\n\r\n`Numeric` already provides `#zero?`, so `Numeric.zero.zero?` shall always be `true`.\r\n\r\nI expect this to make code more explicit. And it would save a pair of braces.\r\n(Don't laugh--This really got me here.)\r\n\r\n---\r\n\r\nMaybe you already considered that for 3.0, which would be a late addition.\r\n\r\nRuby shines in teaching mathematics. You know, we have zero and one there.\r\n\r\nI use ruby in the financial realm. For me, it's important to write `BigDecimal.zero`.\r\n\r\n---\r\n\r\nI expect that the new API should not break existing code. We could try it with Rails first. Let's ask them.\r\n\r\nIt would be nice to have that in [Rails] 3.\r\n\r\n~eike\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-15T19:07:11Z", "updated_on": "2020-09-16T01:36:51Z", "closed_on": "2020-09-16T00:11:06Z", "relations": []}, {"id": 17168, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 5, "name": "Closed", "is_closed": true}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 370, "name": "soutaro (Soutaro Matsumoto)"}, "assigned_to": {"id": 13, "name": "matz (Yukihiro Matsumoto)"}, "subject": "Bundle RBS", "description": "@hsbt and I have been working to make RBS one of the bundled gems.\r\nWe are finalizing the patch and hope we can finish it tonight.\r\n\r\nhttps://github.com/ruby/ruby/pull/3496\r\n\r\nI'd like to ask Matz to approve bundling it in Ruby 3.0 (hopefully before preview 1).\r\n\r\n----\r\n\r\nRBS is a Ruby gem to support static analyzers in Ruby 3. It consists of the standard library type signatures (.RBS files) and Ruby code to parse and process .RBS files. The repository for RBS is https://github.com/ruby/rbs.", "start_date": null, "due_date": null, "done_ratio": 100, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-15T09:11:09Z", "updated_on": "2020-10-29T05:22:38Z", "closed_on": "2020-10-29T05:22:38Z", "relations": []}, {"id": 17166, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 1372, "name": "hadmut (Hadmut Danisch)"}, "subject": "net/http not supporting unix domain sockets", "description": "Hi,\r\n\r\nmeanwhile it's common and state of the art to offer rest apis not just over tcp/ip, but over unix domain sockets as well for machine-internal use and advanced security. \r\n\r\n\r\nUnfortunately net/http does not support unix domain sockets. Although there is a workaround with the gem net_http_unix  /  NetX::HTTPUnix, this is rather useless, since most programs, libs, gems (e.g. rest-client) are based on net/http. \r\n\r\n\r\nHowever, there's some security consideration. When evaluating e.g. HTML and accessing URLs, it could be harmful or leak information, if an URL point to some unix domain path could reveal information or allow to trigger something, e.g. tell through error messages whether a file exists or let someone unintentionally install a packet through ubuntu's snap mechanism (which is controlled through a unix domain socket with rest api). \r\n\r\nIt should, however, be possible to use unix domain sockets (without workaround, third party gem or low level code). \r\n\r\nregards\r\n", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-12T14:51:16Z", "updated_on": "2020-09-12T14:51:38Z", "closed_on": null, "relations": []}, {"id": 17165, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Add `filter` and `flatten` keywords to `Enumerable#map`", "description": "I had a use case to do `map` on an enumerable, with 1-level flattening, while skipping `nil` values.\r\n\r\nThere are convenient `Enumerable#flat_map` and `Enumerable#filter_map` methods, but the problem is that they cannot be used at the same time. I had to chose to do either of the following:\r\n\r\n```ruby\r\narray\r\n.filter_map do |foo|\r\n  bar = baz(foo)\r\n  next unless bar\r\n  bar.map{...}\r\nend\r\n.flatten(1)\r\n```\r\n\r\n```ruby\r\narray\r\n.flat_map do |foo|\r\n  bar = baz(foo)\r\n  next unless bar\r\n  bar.map{...}\r\nend\r\n.compact\r\n```\r\n\r\n```ruby\r\narray\r\n.flat_map do |foo|\r\n  bar = baz(foo)\r\n  next [] unless bar\r\n  bar.map{...}\r\nend\r\n```\r\n\r\nThe last one of the above may not look so bad, but it requires an extra consideration, and is a bit hacky. When you are in a hurry, it just might not come to your mind.\r\n\r\nThis led me to realize that `flat_map` and `filter_map` should not be independent operations, but are rather some different modes of the operation `map`. There is no reason for the modes to be mutually exclusive of one another, and a use case that I mentioned above may arise.\r\n\r\nI propose to add `filter` and `flatten` as optional keyword arguments to `Enumerable#map`.\r\n\r\n\r\n```ruby\r\narray\r\n.map(filter: true, flatten: 1) do |foo|\r\n  bar = baz(foo)\r\n  next unless bar\r\n  bar.map{...}\r\nend\r\n```\r\n\r\nIn fact, even when the two parameters are not used together, I believe it would be easier to the brain and I would feel much more comfortable to pass `filter: true` or `flatten: 1` to `map` when necessary rather than having to deicide whether to use `map` or `flat_map` or use `map` or `filter_map`.\r\n\r\nFurthermore, this would make it possible to do flattening of an arbitrary depth (as specified by the parameter) during map.", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-12T14:46:54Z", "updated_on": "2020-09-13T09:41:57Z", "closed_on": null, "relations": []}, {"id": 17163, "project": {"id": 1, "name": "Ruby master"}, "tracker": {"id": 2, "name": "Feature"}, "status": {"id": 1, "name": "Open", "is_closed": false}, "priority": {"id": 4, "name": "Normal"}, "author": {"id": 2963, "name": "sawa (Tsuyoshi Sawada)"}, "subject": "Rename `begin`", "description": "`Range#begin` is a getter method; it returns a value, and does not have a side effect, or does any calculation. Nevertheless, \"begin\" is a verb, so there is a mismatch. I would rather expect a noun.\r\n\r\nIt has a counterpart `Range#end`, and \"end\" is a noun as well as a verb, so that is not strange.\r\n\r\nI propose to alias `Range#begin` to a noun or a nominal. \"beginning\" will work, but it may be too long, so what about \"start\", which works as a noun (as well as a verb)?\r\n\r\n```ruby\r\nRange#start\r\n```", "start_date": null, "due_date": null, "done_ratio": 0, "is_private": false, "estimated_hours": null, "total_estimated_hours": null, "created_on": "2020-09-09T03:04:22Z", "updated_on": "2020-09-09T03:04:22Z", "closed_on": null, "relations": []}]]}